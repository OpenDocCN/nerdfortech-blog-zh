<html>
<head>
<title>Brain Tumor MRI segmentation using Deep Learning.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的脑肿瘤磁共振图像分割。</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/brain-tumor-mri-segmentation-using-deep-leaning-322adebd1aa7?source=collection_archive---------1-----------------------#2021-09-14">https://medium.com/nerd-for-tech/brain-tumor-mri-segmentation-using-deep-leaning-322adebd1aa7?source=collection_archive---------1-----------------------#2021-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/343a545b254657dba42b9b386d655547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wsyMyOlXgu0ZHQPV"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@umanoide?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乌曼诺德</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="2119" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="67e9" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">生物医学成像，如X射线、CT扫描、MRI，有助于医生评估患者的当前状况。肿瘤是异常细胞的团块或生长。大脑中的早期肿瘤检测将拯救许多生命。由于肿瘤的形状和大小各不相同，很难确定确切的位置。在MRI中检测和定位肿瘤需要相当长的时间。</p><p id="c422" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这一过程的自动化将提高系统的效率，并节省医务人员的时间，以便为更多的患者提供服务。它消除了发展中国家由于缺乏训练有素的医务人员而更常见的人为错误。</p><h1 id="a51b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">关于数据集:</h1><p id="50f6" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">数据集来源<a class="ae iu" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。</p><p id="5e5b" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">数据集由110名患者MRI(磁共振成像)和手动FLAIR(液体衰减反转恢复)异常分割屏蔽组成，从癌症成像档案馆(TCIA)获得。</p><p id="c115" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">data.csv文件包含患者数据和肿瘤基因组簇。核磁共振扫描在110个文件夹里，这些文件夹都是以病例编号命名的。每个文件夹包含以下命名约定的MR图像:</p><p id="5426" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">TCGA_ <institution-code> _ <patient-id> _ <slice-number>。标签图像文件格式。</slice-number></patient-id></institution-code></p><p id="75a2" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">相应的掩码有一个“_mask”后缀。图像在里面。每个图像有三个通道的tif格式。</p><h2 id="e51e" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">什么是图像分割？</h2><p id="d0ae" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这是将属于特定类别的每个像素分类的过程。</p><p id="2d9d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对于此任务，我们将有两个类:</p><ul class=""><li id="6979" class="lk ll hi jv b jw kr ka ks ke lm ki ln km lo kq lp lq lr ls bi translated">肿瘤部分</li><li id="9df3" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq lp lq lr ls bi translated">非肿瘤部分</li></ul><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/092fd46c80c38dfbe57795c5fd403f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*X29Tu7QZEJhW2HoEOtk-1w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">MRI扫描和分割图像</figcaption></figure></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><h1 id="20d9" class="iv iw hi bd ix iy mk ja jb jc ml je jf jg mm ji jj jk mn jm jn jo mo jq jr js bi translated">业务目标:</h1><p id="5605" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">使用核磁共振扫描为人脑中的肿瘤创建分割模板。</p><p id="d3d5" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">使用分割掩模，我们可以确定肿瘤是否存在。</p><h1 id="a1da" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">绩效指标:</h1><p id="e70d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">局灶性特沃斯基损失(FTL):是特沃斯基损失的概括。损耗的非线性特性使您可以控制在不同的Tversky指数值下损耗的表现。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/ce975f1da724af5253f55f19a304a8b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sAvNqhxEJ5gEch8Y02pCCw.png"/></div></div></figure><p id="a152" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">作为良好起点的默认参数。</p><p id="c45d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi">α = 0.7, 𝜷 = 0.3, γ = 3/4</p><p id="2a2d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">焦点特沃斯基损失用于解决阶级不平衡。</p><p id="9a95" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">γ控制损耗的非线性。当γ &lt; 1 it penalising more when TI &gt;为0.5时，这种改变模式对这类例子有更多的改进。</p><p id="966a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">至于很多扫描，扫描的只有一小部分是肿瘤。</p><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><h1 id="a91b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">探索性数据分析:</h1><p id="54ca" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们总共有3929个MRI扫描和它们各自的分段屏蔽。每次MRI扫描的尺寸为(256，256，3)。</p><p id="b130" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们将首先使用以下函数将MRI扫描分为肿瘤和非肿瘤:</p><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="684d" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">没有肿瘤的脑MRI和分割掩模的样本。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/ac0dc8339d9ac9dade09b14da047b276.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*6AwtxcwK5NgHSkFuCJcJVA.png"/></div></figure><p id="24bc" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">脑部MRI样本和带有肿瘤的分割掩模。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/8f9abd805a6682a2d4a0e85b975d4f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*ocbYwYGPS08ENFhK64346g.png"/></div></figure><h2 id="c173" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">数据扩充前MRI扫描的分布</h2><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/533463d2056878a467c5631575e969a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*LaOCVxVHhGWILU7BxYzkoQ.png"/></div></figure><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="3e00" class="kw iw hi mv b fi mz na l nb nc">Percentage of patients with no tumor 65.05472130313056<br/>Percentage of patients with  tumor 34.94527869686943</span></pre><p id="1693" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">65%的核磁共振扫描不含肿瘤。</p><h2 id="7504" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">应用数据扩充</h2><p id="830e" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">应用了三种类型的图像增强。</p><ol class=""><li id="c89c" class="lk ll hi jv b jw kr ka ks ke lm ki ln km lo kq nd lq lr ls bi translated">翻转</li><li id="8f4e" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated">旋转任意角度</li><li id="94a0" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated">模糊操作。</li></ol><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="b8e5" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我们将包括更多来自少数民族(肿瘤类)的增强图像</p><p id="d02f" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">数据扩充后的分布:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/c153fb9ea1eee4ae3f75c80fa0106e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*gaiC2bUOsFOD0nCQ-Cs0VQ.png"/></div></figure><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="a21d" class="kw iw hi mv b fi mz na l nb nc">Percentage of patients with no tumor 50.0 <br/>Percentage of patients with tumor 50.0</span></pre><p id="dc01" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我在这里通过增加更多增强后的肿瘤类图像来平衡数据。</p><p id="8ab9" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在数据扩充后，我们有5312个MRI扫描作为数据点。</p><h1 id="13c5" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">建模</h1><h2 id="118b" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">a)独立型号</h2><p id="95cd" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">最初，我尝试为分类和分段任务创建不同的模型。</p><p id="9b8b" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">使用ImageDataGenerator类的flow_from_dataframe创建了一个训练、测试和验证数据生成器。</p><p id="1e54" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> A.1)简单分类器:</strong></p><p id="1a50" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">用于两个卷积层，其次是一个平坦层，最后是一个密集层与乙状结肠作为激活。</p><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="7f52" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">随着训练和验证准确性之间的差距增大，模型开始过度拟合。</p><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="50a3" class="kw iw hi mv b fi mz na l nb nc">accuracy: 0.9604<br/>val_accuracy: 0.8540</span></pre><p id="5a64" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> A.2使用异常模型分类</strong></p><p id="2b9a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">由于例外模型有更多的可训练参数，它比简单分类器表现得更好，但此处模型也过拟合。</p><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="8ab5" class="kw iw hi mv b fi mz na l nb nc">accuracy: 0.9875 <br/>val_accuracy: 0.8728</span></pre><p id="c2c8" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">答:3)分段:</strong></p><p id="20da" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">我创建了一个定制的数据生成器来批量加载图像。</p><p id="311a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">建立了以焦特沃斯基为损失函数的Unet模型。将(256，256，3)个图像传递给模型，这产生了(256，256，1)个分段掩码。</p><p id="5f69" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">注意:该模型仅建立在包含肿瘤的MRI上。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/759090ca1af6e37e38157857477d9407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*5GzqWXgsWA70XG88z3Pu9g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Unet模型</figcaption></figure><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="a7ec" class="kw iw hi mv b fi mz na l nb nc">loss: 0.2907  - val_loss: 0.2974<br/>tversky: 0.8060 — val_tversky: 0.7994</span></pre><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/4fb87e8c3040b60440daf1abbca9cbe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*wH2D7G_QZXpbMAdWQYEkww.png"/></div></figure><p id="49cb" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">Unet模型没有过度拟合，并且在10个时期后稳定。</p><p id="d203" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">下面是样本原始分段及其各自的预测掩码。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es nh"><img src="../Images/ab0a5b8d827fa9ebb2368ac05b2f347c.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*1cnahzMvPbjwc9JpWOByJw.png"/></div></figure><p id="c530" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">最终的面具做得很好，它错过了捕捉锐利的边缘。</p><h2 id="88d4" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">b)两类数据的分段模型</h2><p id="8253" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">模型的输入和输出的维数都是(256，256，3)。</p><p id="0cd4" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> <em class="ni">注:</em> </strong>训练缓慢，如果学习率很高，最初会过拟合训练数据。</p><p id="7af8" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> <em class="ni">提示:</em> </strong>保持较低的学习率，以便更好的训练。</p><p id="489e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> B.1)带有Resblocks的Unet模型:</strong></p><p id="19b0" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">使用四级编码器-解码器Unet模型。</p><p id="a404" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对于这项任务，这是最简单的Unet模型。</p><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="13f5" class="kw iw hi mv b fi mz na l nb nc">loss: 0.1888 - tversky: 0.8880 <br/>val_loss: 0.1840 - val_tversky: 0.8925</span></pre><h2 id="87ac" class="kw iw hi bd ix kx ky kz jb la lb lc jf ke ld le jj ki lf lg jn km lh li jr lj bi translated">B.2)以EfficientNet为骨干的Unet</h2><p id="bc09" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">不使用Resnet作为主干，而是使用在Image net数据集上训练的EfficientNet。</p><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="2da9" class="kw iw hi mv b fi mz na l nb nc">loss: 0.1480 - tversky: 0.9206<br/>val_loss: 0.1513 - val_tversky: 0.9183</span></pre><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/e8a03ce9bdb53dc23f13716bb8c2e66d.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*iAAWoChXoQ89r_sZzCAS0w.png"/></div></figure><p id="0262" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">样本结果:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es nk"><img src="../Images/969a77733f08e17d1f712c756c7e7de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*tEfSY_EFbhffQVq9ZAbiZw.png"/></div></figure><p id="2095" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">失败的示例:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/0ac64bc87ddbe978b1015fda9e752bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2qNElsCmvbPWBq38CHNlHw.png"/></div></div></figure><p id="18e0" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">当肿瘤尺寸很小时，该模型未能发现肿瘤。</p><p id="c968" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj"> B.3)双网</strong></p><p id="95d7" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">是发表在<a class="ae iu" href="https://arxiv.org/pdf/2006.04868.pdf" rel="noopener ugc nofollow" target="_blank"> 2020 </a>的作品。它的目的是创建一个模型，概括各种细分数据集。</p><p id="9cf6" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这里预测了两个掩码，而不是单个掩码。</p><pre class="lz ma mb mc fd mu mv mw mx aw my bi"><span id="feeb" class="kw iw hi mv b fi mz na l nb nc">loss: 0.1539 — tversky: 0.9168<br/>val_loss: 0.1551 — val_tversky: 0.9158</span></pre><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/4b2455b06737d870540e7db499066e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*90gUU_2qKjr2iVN9as-lDQ.png"/></div></figure><h1 id="c331" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">比较不同型号的性能:</h1><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="bc27" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">高效Unet的可训练参数比Unet多10倍。Double Unet的可训练参数几乎增加了3倍。</p><p id="ea34" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">事实证明，高效的Unet表现最佳。</p><h1 id="8179" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">部署:</h1><p id="1d15" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">保存最佳模型并将其用于部署。</p><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="7242" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">该模型由一个使用streamlit的web应用程序部署。</p><h1 id="e091" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak">未来工作:</strong></h1><ol class=""><li id="3ad2" class="lk ll hi jv b jw jx ka kb ke nn ki no km np kq nd lq lr ls bi translated">可以探索不同于学术研究的深度学习架构。</li><li id="846e" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated">利用MRI的3d空间特性的网络，如3D提拉米苏网、Deep Medic。</li><li id="f4ea" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated">可以组合不同MRI扫描的集合。</li><li id="119d" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated">在医学图像上使用通用分割模型，如SegNet。</li></ol><h1 id="6d81" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">代码库和部署。</h1><p id="2c23" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated"><strong class="jv hj"> Github仓库:</strong>包含这个项目的全部代码。[ <a class="ae iu" href="https://github.com/tushifire/Brain-MRI-segmentation" rel="noopener ugc nofollow" target="_blank"> Github回购</a></p><p id="e916" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">下面是演示模型部署的视频。</p><figure class="lz ma mb mc fd ij"><div class="bz dy l di"><div class="nq mr l"/></div></figure><h1 id="db11" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">参考资料:</h1><ol class=""><li id="d1cf" class="lk ll hi jv b jw jx ka kb ke nn ki no km np kq nd lq lr ls bi translated"><a class="ae iu" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li><li id="46e9" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated"><a class="ae iu" href="https://arxiv.org/pdf/2006.04868.pdf" rel="noopener ugc nofollow" target="_blank"> DoubleU-Net:用于医学图像分割的深度卷积神经网络</a></li><li id="0fed" class="lk ll hi jv b jw lt ka lu ke lv ki lw km lx kq nd lq lr ls bi translated"><a class="ae iu" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集:脑部MRI分割</a></li></ol><p id="af0f" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated"><strong class="jv hj">联系人:</strong><a class="ae iu" href="https://www.linkedin.com/in/mr-tushar-tiwari/" rel="noopener ugc nofollow" target="_blank"><strong class="jv hj">Linkedin</strong></a>| |<a class="ae iu" href="mailto:tushi.fire@gmail.com" rel="noopener ugc nofollow" target="_blank">|<strong class="jv hj">邮箱</strong> </a></p></div></div>    
</body>
</html>