<html>
<head>
<title>You Only Look Once: Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你只看一次:物体检测</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/yolo-object-detection-70828718bc06?source=collection_archive---------15-----------------------#2021-05-13">https://medium.com/nerd-for-tech/yolo-object-detection-70828718bc06?source=collection_archive---------15-----------------------#2021-05-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9e81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你只看一次(YOLO)是一个最先进的实时物体检测系统。它使用卷积神经网络(CNN)进行对象检测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/23d9dce4ab91fad554e2a831866e5ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CYEQ_rAQjf42dke_"/></div></div></figure><p id="1f6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">图像分类vs物体检测</strong></p><p id="c0c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">图像分类</strong>通常指预测图像中存在哪个对象。因此，输入将是包含动物图片的图像集(让我们说斑马，老虎和大象)。输出将把它归类为上述动物之一。动物在图像中的确切位置并不重要。</p><p id="fd0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们采取28X28的输入图像。使用RGB比例它的输入将是28X28X3矢量。这将通过卷积神经网络-卷积、最大池和全连接层的组合来处理。最终输出将是3X1向量(它将是每一类动物的概率)。对该向量应用SoftMax函数将给出图像的准确预测分类。关于CNN的更多细节，请点击下面的链接。</p><div class="jp jq ez fb jr js"><a href="https://smverma.medium.com/introduction-to-cnn-c42ecc0ad8ff" rel="noopener follow" target="_blank"><div class="jt ab dw"><div class="ju ab jv cl cj jw"><h2 class="bd hj fi z dy jx ea eb jy ed ef hh bi translated">CNN简介</h2><div class="jz l"><h3 class="bd b fi z dy jx ea eb jy ed ef dx translated">什么是CNN</h3></div><div class="ka l"><p class="bd b fp z dy jx ea eb jy ed ef dx translated">smverma.medium.com</p></div></div><div class="kb l"><div class="kc l kd ke kf kb kg jn js"/></div></div></a></div><p id="5286" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对象检测</strong>另一方面，预测对象的位置和对象类型。使用与上面相同的例子，CNN将给出一个向量</p><ol class=""><li id="4817" class="kh ki hi ih b ii ij im in iq kj iu kk iy kl jc km kn ko kp bi translated">如果我们感兴趣的任何对象在那里或不在，即0，1。</li><li id="f8ea" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">使用对象周围的框的中心和高度和宽度的坐标来定位对象。</li><li id="6730" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">c1、c2、c3用于描述它是哪个对象(我们正在寻找老虎、大象和斑马)</li></ol><p id="46ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是参数向量。这将在<strong class="ih hj">输出矢量部分解释。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kv"><img src="../Images/2a6df34f519ae0612637703a9aab02ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/format:webp/1*wvb6pU64GxJnrB2-HgYZvQ.png"/></div></figure><p id="eb8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO:背景</p><p id="b5fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO是2015年发表的论文成果— <a class="ae kw" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的实时物体检测</a>。</p><p id="b1de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">官方实现由<a class="ae kw" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> DarkNet </a>完成，并可在<a class="ae kw" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank"> github </a>上获得。</p><p id="42e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">概述</strong></p><p id="eb42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO把图像分成不同的区域。然后，它预测该区域中存在物体的可能性。它还预测检测到的对象的边界框。然后，它会消除多个重叠的框，以确保一个对象只被包围在一个框中。</p><p id="c91e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO:步骤</p><ol class=""><li id="c75c" class="kh ki hi ih b ii ij im in iq kj iu kk iy kl jc km kn ko kp bi translated">获取输入图像。假设输入图像是256X256。因此RGB比例将被表示为矢量256X256X3</li><li id="ac3a" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">这个输入图像通过CNN。</li><li id="0583" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">要了解最终预测是如何工作的，让我们先了解我们想要的输出是什么。</li></ol><p id="b00b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输出向量:</strong></p><p id="8521" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像将被划分成多个区域。在本例中，我们将假设输出分为9个区域(即3×3)。假设我们要检测图像中的船和鸟- 2类物体</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/4d7929039f75818af8687c080ef22c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*3_FIzzviT1USI80Nvo2llg.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">船和鸟</figcaption></figure><p id="4430" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，对于上面图像网格中的9个单元格，我们需要以下输出</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lc"><img src="../Images/3e9ab1179cb3858be90b0c699ccc830e.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*GQBnBLwIPEqOa3SwB-Qrzg.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">一个单元格的输出度量</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/f08829fe65c101cfc471dbd5995a5433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WIJeA4uOvfQQoCcVa30fzg.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated">输出指标的详细信息</figcaption></figure><p id="1b01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了边界框和相关信息</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/153f8ff1df08f5d92a4ea746929985d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*ZednptItV-K4njJjeTOucA.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">带边框的网格。</figcaption></figure><p id="1339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在网格G中，由于没有图像，相关联的指标将</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/e2ad2fbf678c8673f8e1f045fd839fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:148/format:webp/1*0WUjp3CnJgK71fMQE3Tl2w.png"/></div></figure><p id="c8ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在网格D中，下图解释了这些数字</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/03d85ac979d98c4097c7123587ef6e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*6Jo9t99eZjt0MK6WE9vHuw.png"/></div></figure><p id="9285" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">h和b通过将它们作为完整图像的高度和宽度的分数来归一化。所以如果h = .15，b在归一化后是0.3</p><p id="fc61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">h(归一化)= .15/3=.05，b= .3/3=.1(图像的总尺寸为3，3)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lh"><img src="../Images/10bde5cb934f4dbc3236ae805fa21faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:196/format:webp/1*gCaM7bEEzJSxoFAUynMW6A.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">三维网格度量</figcaption></figure><p id="dbd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">盒子的高度和重量可能比它们下面的网格大，但是在使用图像的宽度和宽度进行标准化时，它总是小于1。</p><p id="bc27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上述情况下，输出的尺寸将是3X3X7。</p><p id="687e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们看到的是捕捉一个类的图像的网格。但事实并非总是如此。例如在网格e中，它既有船又有鸟。为了处理这种情况，使用了“锚箱”。</p><p id="e61d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">锚箱</strong></p><p id="9281" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们想在每个网格中预测2个对象。在这种情况下，out向量的维数将变为2X7 =14。矩阵将会像</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/a1930f6728e27319a8a0c64522fd332a.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*ViIY5McpJyRv0iU0xXarJA.png"/></div></figure><p id="835b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个网格可以定义任意数量的锚盒，但通常不超过5个。在正常情况下，我们在19X19网格中划分输出图像，因此5个锚定框是足够的。</p><p id="3d8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">总结</strong></p><ol class=""><li id="6404" class="kh ki hi ih b ii ij im in iq kj iu kk iy kl jc km kn ko kp bi translated">我们有输入图像，比如说265X256。CNN的输入向量是256X256X3</li><li id="dc93" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">这是给CNN的。</li><li id="87eb" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">假设:我们希望输出图像为3X3网格(通常为19X19的良好预测)，每个网格最多2个对象(即2个锚框)和3种要识别的对象类型</li><li id="66cd" class="kh ki hi ih b ii kq im kr iq ks iu kt iy ku jc km kn ko kp bi translated">CNN层应该产生3X3X(2X(1+4+3))= 3X3X(2X 8)= 3X3X 16的输出向量</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/53d52f6264cd3e527651d8b0f5549c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZ2qBMB8Sa4Gn0mnCnfiww.png"/></div></div></figure><p id="81ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.并集上的交集(IoU)和非最大值抑制:在进行最终消除之前，我们可以消除一些在输出层预测的边界框</p><p id="5818" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">欠条:</strong></p><p id="8810" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它使用对象的区域预测盒和对象的实际盒来消除预测。如果预测框和实际框的相交面积是<em class="lk"> i </em>，那么</p><p id="e9fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lk"> IoU= i/(预测面积+实际面积之和)</em></p><p id="3cbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果这个欠条&lt; <em class="lk">达到某个阈值</em>我们就可以剔除那个盒子。该阈值通常为0.5或更高。</p><p id="a2f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">非最大抑制</strong></p><p id="0119" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们排除概率小于某个阈值的盒子。</p><p id="0185" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于剩余盒子，我们挑选具有最高概率的盒子，并用这个最高概率的盒子消除所有具有高IoU的盒子。</p><p id="a659" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对具有下一个最高概率框的框重复相同的过程。</p><p id="c287" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样做，直到我们有一个盒子围绕着这个物体。</p><p id="eb78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO的真正威力在于它能探测到物体的速度。下面的视频展示了YOLO实时探测物体的能力。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="48a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">延伸阅读</strong></p><p id="68d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于物体探测和YOLO深潜，请浏览吴恩达的CNN课程(第三周-物体探测)</p><p id="1215" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kw" href="https://www.coursera.org/learn/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">https://www . coursera . org/learn/卷积神经网络</a></p></div></div>    
</body>
</html>