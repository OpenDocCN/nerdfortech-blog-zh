<html>
<head>
<title>Research Summary
Object Detection upto Fast-RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速RCNN目标检测研究综述</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/research-summary-object-detection-upto-fast-rcnn-43d5944f4f6f?source=collection_archive---------6-----------------------#2021-06-12">https://medium.com/nerd-for-tech/research-summary-object-detection-upto-fast-rcnn-43d5944f4f6f?source=collection_archive---------6-----------------------#2021-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/1c121223d17cf919e9d5973b0fa240aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:94/0*Fn43PnwzM2b0rV4N"/></div></figure><p id="f6fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">大家好，我是Aditya Raj，IIITA的二年级学生，在yellowbacks.com担任机器学习工程师。</p><p id="f939" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我将解释对象检测从零开始到快速RCNN。这些没有前提条件，一切从基础解释。这个故事将让你对深度学习中的对象检测的架构和工作有一个美好的见解。</p><p id="6a31" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我将在博客中介绍yolo版本和其他一些高级技术，如detectron、mask RCNN。</p><p id="8541" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们开始:</p><h1 id="3322" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">介绍</h1><p id="5b36" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated"><strong class="io hj">预先要求的部分:- </strong></p><ol class=""><li id="b867" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj kt ku kv kw bi translated">计算机视觉/深度学习中的图像</li><li id="bfd6" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">Convnets</li><li id="3245" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">图像分类与目标检测</li><li id="0f8c" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">分类目标检测</li><li id="abe4" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">RCNN</li><li id="f992" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">图像特征提取和空间金字塔池(<strong class="io hj"> SPP </strong>)</li><li id="501b" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj kt ku kv kw bi translated">SPPNet</li></ol><p id="cdd5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">主要章节:- </strong>对<strong class="io hj"> Fast-RCNN </strong>的研究总结</p><p id="84d2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">注意:- </strong>主动深度学习研究人员可以忽略预先要求的部分，可以直接阅读主要部分，只需更新即可。</p><p id="7901" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">必填部分</strong></p><h1 id="82c1" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">计算机视觉/深度学习中的图像</h1><p id="033c" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">计算机视觉或深度学习领域中的每幅图像都可以被视为某个维度(例如:224x224)的矩阵，矩阵的每个值称为像素值，表示图像中该点或部分的颜色强度。</p><p id="9aaf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果我们仔细观察旁边的黑白图像，它在矩阵形式中的像素值在白色区域接近0.255，而在黑色区域为0。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lc"><img src="../Images/277daa4f96c8d7f812b82280aca177a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l3CJtKiSA55WzoIX"/></div></div></figure><p id="7259" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——miro.medium.com</strong></p><p id="7d33" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上面的B&amp;W图像是一个2-D矩阵，矩阵的每个值作为图像部分的颜色强度表示值或像素值。在彩色图像的情况下，我们假设它们是红、绿、蓝(RGB)三种颜色的不同强度的组合，因此我们为它们中的每一个都有2D矩阵，它们的像素值代表各自的颜色强度。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/cdcc7f376d1323f0fc88fae923e7c2c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*0cPZJBN_p8L9nJUz"/></div></figure><p id="d9bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">— — 3维矩阵</p><p id="8bba" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——researchgate.net</strong></p><p id="9627" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们得到的是日常生活中使用的RGB或普通彩色图像的三维矩阵。这些是我们将在其上应用深度学习方法进行图像分类、对象检测和其他操作的矩阵。</p><p id="28dc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Convnets</p><p id="7740" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Convnets或卷积神经网络是一种神经网络体系结构，用于通过卷积运算(不是普通的矩阵乘法)、合并等从图像中提取特征。在由图像和特定技术形成的矩阵上。</p><p id="9cb9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">卷积运算</strong></p><p id="9c6c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">卷积核</p><p id="0684" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——分析Vidhya </strong></p><p id="7f8e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">核是简单的2D矩阵，其形状取决于输入图像。输入图像矩阵上的核映射，具有简单的逐元素乘法和线性加法，结果给出较低维度的矩阵。核按照滑动窗口方法沿着矩阵移动。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/1d3326c1f00a9cf20420f4f17600daa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/0*rWyuxGYXYYBibSKt"/></div></figure><p id="36d0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">请参见下图，以更好地理解内核的卷积运算。</p><p id="fa77" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——分析Vidhya </strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/d98fb29b0ba3d58e3c5056202dc86270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/0*H0yu4fz1CrpVJgfz"/></div></figure><p id="020b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上述给定卷积结果的第一项可以解释为:-</p><p id="e4c3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——分析Vidhya </strong></p><p id="e90c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><em class="lo">45 * 0+12 *(-1)+5 * 0+22 *(-1)+10 * 5+35 *(-1)+88 * 0+26 *(-1)+51 * 0 =-45</em></p><p id="7ddb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出的矩阵形状和结果也取决于内核滑动的行数/列数，称为<strong class="io hj">步距</strong>。</p><p id="3acc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">输出矩阵的形状也可以通过在输出上放置新的行和列来改变，这被称为<strong class="io hj">填充</strong>。</p><p id="32ea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果新添加的行/列的所有值都为零，则称为<strong class="io hj">补零。</strong></p><p id="fb81" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这些全核卷积、大步走、填充组合在一起称为图像矩阵上的<strong class="io hj">卷积运算</strong>。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lp"><img src="../Images/90f7e91654d0ffb11f6a26b847aa6fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*md2wRdiGlAGMgEPk"/></div></div></figure><p id="acc3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">联营</strong></p><p id="8eed" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">汇集操作通过滑动二维过滤器(或内核)来概括图像矩阵的特征图。</p><p id="7341" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">汇集的类型:-</p><p id="a9b9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">I .)最大池化:-它从过滤器覆盖的特征图中选择最大元素。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lq"><img src="../Images/11f91eb0b5de618c62b402a7e5c33601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K2HzMKe7l46_RmlV"/></div></div></figure><p id="2d24" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二。)平均池:-它选择过滤器或内核覆盖的特征映射中所有元素的平均值。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lq"><img src="../Images/e7b8a7d0d2c9c8469a6ecb491a4857cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LMlwNmAeP9EHb_xh"/></div></div></figure><p id="a914" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">三。)全局池化:-它将整个特征图缩减为单个值，(它可以是全局最大或全局平均池化)。<strong class="io hj">以上图片来源=极客对极客</strong></p><h1 id="5830" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><strong class="ak">卷积架构</strong></h1><p id="39a4" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">卷积架构由层形式的一系列卷积和池操作组成，也称为卷积层和池层。</p><p id="4077" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有许多著名的CNN架构，为每个卷积层或池层预定义了层数、内核大小、滤波器大小。</p><p id="4314" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">示例:- VGG16</p><p id="5bc3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——极客的极客</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lr"><img src="../Images/48915af94903f48d975e932d7dae49be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FoLL-c-OXFCkVbVN"/></div></div></figure><p id="8a66" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们现在可以很容易地理解这个著名的架构，有一些卷积层，一些与ReLU激活和一些最大池层与softmax作为最后一层，以提供类概率输出。</p><p id="657b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">图像分类与目标检测</p><p id="f0c5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">图像分类:-它基本上是通过在CNN架构提取的特征的帮助下对数据进行训练来对图像进行分类。</p><p id="ee7d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">图像定位:-这定位图像中存在的对象，即借助于图像矩阵上的一些操作，借助于一些计算机视觉技术，如滑动窗口、视觉单词包和选择性搜索等，将对象从背景中分离出来。。</p><p id="ad71" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对象检测:-当图像中存在多个对象时，首先在图像定位的帮助下，在给定图像中定位所有对象，然后CNN架构和分类算法利用深度学习预测该对象。<strong class="io hj">图片来源:- geeksforgeeks </strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/359262e65b8e45f217adff218156683d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/0*w3rdT4elsILIFBzV"/></div></figure><p id="7890" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">分类目标检测</p><p id="d740" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">滑动窗口:- </strong>在这个算法中，我们选择一个小尺寸的网格，并以给定的步幅在输入图像上滑动。用任何CNN算法对输入图像矩阵中被网格覆盖的部分进行卷积，以预测该部分图像的类别。它可以是任何物体或背景。网格在整个输入图像上滑动，每个部分都很复杂。【cogneethi.com】图片:</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lt"><img src="../Images/923f8ef63ffe52577b72df31843fccf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tyvJJXEhCAYSuTYt"/></div></div></figure><p id="1565" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">问题——我们需要将CNN应用于大量的位置和规模，因此计算量非常大，内存效率也非常低。</p><p id="e5f3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">区域提议:- </strong>在这里，输入图像矩阵中更有可能是任何物体的片段被一些区域提议算法定位，然后在它们上面进行CNN。</p><p id="17de" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们借助“选择性搜索”算法找到可能包含对象的“斑点”图像区域。通常会生成1000–2000个这样的区域(区域建议),然后CNN会进行分类。</p><p id="95c9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">选择性搜索:- </strong> i .)我们将使用<em class="lo"> Felzenszwalb等人</em>的论文“高效的基于图形的图像分割”中的方法生成输入图像的片段</p><p id="0fc8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二。)我们将使用下面给出的贪婪算法递归地将较小的片段组合成较大的片段。</p><p id="2c23" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">贪婪算法:</strong> 1。从该组区域中选择两个最相似的区域。2.较大的区域由这两个较小的区域组合而成。3.这些步骤重复多次。<strong class="io hj">图片来源:- geeksforgeeks </strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/84531f9092651ef9f703c22d43ee5679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/0*dvx4bejgR-C6NVJj"/></div></figure><h1 id="7358" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">美国有线电视新闻网</h1><p id="bbe8" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">区域CNN是基于CNN的图像区域分类算法，被训练来预测区域或对象的类别及其位置。让我们来理解它的工作步骤:-</p><ol class=""><li id="0e59" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj kt ku kv kw bi translated">使用基于选择性搜索算法的区域提议方法，从输入图像矩阵中取出2000个矩阵形式的提议区域(可能包含对象的图像部分)。<strong class="io hj">图片:——FAIR(Facebook AI研究)</strong></li></ol><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/a51518e9521afea69df865390f200a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/0*MpI-QlxF10is1-Jl"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lv"><img src="../Images/610951b96a7c7c9139689f73e90a928f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j1qisY6g3gXmwHXW"/></div></div></figure><p id="4a86" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.现在，所有这些感兴趣区域(RoI)矩阵都被扭曲或调整大小为具有一定尺寸的矩阵，使得它可以作为CNN的输入被给出，用于特征提取。<strong class="io hj">图片:——FAIR(Facebook AI研究)</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lw"><img src="../Images/7db3b8260951021eb05ade3f41092e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mi29m-MjfalswIuc"/></div></div></figure><p id="cb75" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.现在这些矩阵形式的扭曲图像区域被输入到convnets用于特征提取。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lx"><img src="../Images/415d9282db0bc08dc90f5466c7905865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rMksQ4dN0yW2XOZL"/></div></div></figure><p id="2c32" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4.从CNN提取的特征被进一步传递到分类器(在这种情况下是SVM ),以预测检测到的对象的类别。<strong class="io hj">图片:——FAIR(Facebook人工智能研究)</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ly"><img src="../Images/1ae05a4b82656a924fa16721c16b7a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nStkH8SsEp6bDggG"/></div></div></figure><p id="b19f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">5.除了预测对象的类别，我们还需要指定图像中对象所在的区域，即预测ROI在输入图像矩阵中的位置。这可以通过在CNN图层后添加包围盒回归器和SVM来实现。它将以方框坐标的形式给出输出(方框是表示输入矩阵中ROI的矩形)，即输出=(x1，y1，x2，y2)。为了训练它，最小平方损失(L2损失)最小化被使用。</p><p id="8df0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——FAIR(Facebook AI研究)</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lz"><img src="../Images/4fe4047eb0b9893b17905f78e2c39159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6inGTYyj7345cy6c"/></div></div></figure><p id="0782" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，在RCNN中，为了提高准确性，采取了几个步骤，如:-</p><p id="6dca" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">I .)CNN架构在区域提议而不是旧图像上进行了微调。</p><p id="a8b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二。)在训练期间，提取的最终特征也用对数损失(softmax层)以及SVM和边界框回归量进行微调。</p><p id="000a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">三。)softmax层仅在测试或对象检测期间达到训练时间，仅SVM和Bbox寄存器。都存在。</p><p id="a917" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">RCNN的弊端</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ma"><img src="../Images/6a05d1b3412abad4b97f4e44c60bb4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QkPt0Z5KLxZknSC-"/></div></div></figure><p id="cd6f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1.)这是一个三阶段的训练网络，因此速度非常慢</p><ul class=""><li id="10fc" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">使用softmax分类器(对数损失)微调网络。</li><li id="5d43" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">具有线性SVM(铰链损耗)的训练网络。</li><li id="6874" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">用包围盒回归器(最小平方损失)训练网络。</li></ul><p id="b4aa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.)CNN架构应用于每一个ROI，这使得它在内存和时间上非常低效。</p><p id="1160" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.)对于VGG 16，每幅图像的训练需要84小时，推断(检测)需要47秒，这使得它的使用非常缓慢。</p><h1 id="4ef6" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">空间金字塔池(<strong class="ak"> SPP </strong>)</h1><p id="37ec" class="pw-post-body-paragraph im in hi io b ip kj ir is it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj hb bi translated">空间金字塔池是一种在局部空间箱中维护空间信息的方法。箱柜的大小和数量是固定的。所有滤波器的响应汇集在空间箱中。在下图中，池分为三个级别。在SPPNet中，类似的三级池是这样完成的。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/60068d90fdf6d0ad04480cf4d083439d.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/0*gcqfbUspqxBKdV_U"/></div></figure><ul class=""><li id="5a66" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">第一个池是对整个输入图像的全局最大池，给出具有1×1×256D(特征深度图)的单个输出。</li><li id="01b7" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">第二个池基本上是在将输入图像矩阵分成四个象限后应用全局池，给出4x1x256 D输出。</li><li id="6786" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">第三个池也是类似的，但是图像被分成16个象限，给出输出16x1x256 D。</li><li id="b19e" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">所有三路输出连接在一起，形成一个固定的21x1x256 D输出。</li><li id="e692" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">在SPP中，我们可以看到输出的固定长度为21，与输入图像矩阵的大小和维数无关。</li></ul><p id="5a61" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SPP的另一个重要好处是图像大小调整，我们不需要扭曲ROI(这会降低精确度),因为图像大小调整会由SPP自动完成，精确度会更高。</p><p id="d3fc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——cogneethi</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/8dae64cf0a60da919b6cafe0defdec14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JgBn-eQmCN_xxrHa"/></div></div></figure><p id="1f6a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SPPNet</p><p id="320a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了克服RCNN的缺点，引入了RCNN。RCNN效率低的主要原因是CNN必须对2000个ROI中的每一个进行操作。在SPPNet中，这个问题得到了解决。</p><ul class=""><li id="03b6" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">只有一个输入图像矩阵被发送到CNN层以获得特征图。<strong class="io hj">图片来源:- FAIR </strong></li></ul><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lw"><img src="../Images/5aae44c45cc476a820440c4835698d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cSOHgo1tHu0tua2j"/></div></div></figure><ul class=""><li id="cb36" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">现在通过在特征图上应用选择性搜索算法来选择ROI。<strong class="io hj">图片来源:- FAIR </strong></li></ul><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es me"><img src="../Images/b7ec5921b77224130eb8a844fd5694ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TSWfQ7kwWx53yHFh"/></div></div></figure><ul class=""><li id="1a90" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">空间金字塔池层应用于这些感兴趣区域，以提供固定维度的输出，而与输入无关。<strong class="io hj">接下来的三张图片来源:——集市</strong></li></ul><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mf"><img src="../Images/9e78ad725feaae996d544a2089e05669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bMdxMNoaQzrFX6b6"/></div></div></figure><ul class=""><li id="9aa6" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">SPP层的固定维度输出随后被传递到密集层，并且最终提取的特征用SVM进行分类。</li></ul><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mg"><img src="../Images/7527b86bfb0e8d21e51709b35007885c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wWHAM78PXJZ9j9dz"/></div></div></figure><ul class=""><li id="5143" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">现在，除了来自某个区域的对象类，我们还需要找到对象的位置，因此还需要添加一个边界框回归器，就像在RCNN中一样。</li></ul><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mh"><img src="../Images/4c2a408de139d82f9dfe38ebdf14c838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*USjDJZC9uNfXTrBJ"/></div></div></figure><p id="4004" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">与SVM和Bbox回归器一起，softmax层也仅在训练期间使用。</p><p id="6998" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">图片来源:——cogneethi</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mi"><img src="../Images/744966919fc8847fb8cf67af3f4a1f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ETfqww4m80g8wIsS"/></div></div></figure><p id="50f2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">主要部分::研究主题</p><p id="16d8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">快速RCNN</p><p id="d8ea" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SPPNet比RCNN更好更快，但它仍有几个缺点</p><ul class=""><li id="46a1" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj mb ku kv kw bi translated">这仍然是一个三阶段的训练过程，softmax层(对数损失)，SVM(铰链损失)，Bbox回归(L2损失)，使其缓慢。</li><li id="cffd" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">它的训练时间仍然是25小时，而且内存效率低下。</li><li id="c46a" class="ko kp hi io b ip kx it ky ix kz jb la jf lb jj mb ku kv kw bi translated">我们不能在SPP之前更新convnet层。</li></ul><p id="cf17" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了解决这些问题，对SPPNet进行了一些修改和升级，以实现快速RCNN</p><p id="4f91" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SPPNet =训练速度:- 3倍，测试速度:- 10到100倍</p><p id="fb9e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">快速RCNN =训练:-快9倍，测试:- 0.3秒</p><p id="f19d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">(对比w.r.t RCNN) </strong></p><p id="d5f1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，提出了快速RCNN:一种联合学习以分类对象提议和空间位置的单阶段训练算法。</p><p id="f8c0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们了解SPPNet中导致Fast-RCNN的更改:-</p><ol class=""><li id="b9de" class="ko kp hi io b ip iq it iu ix kq jb kr jf ks jj kt ku kv kw bi translated">不使用多级SPP: L0(1x1)、L1(2x2)、L3(4x4)</li></ol><p id="9ac2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里使用了单层SPP和7x7网格:</p><p id="5799" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">接下来的3张图片来源:——cogneethi</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/0518feab9a8ae5632bb8668062b1fba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/0*eaanJ1tLLTjvy6fj"/></div></figure><p id="94bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.代替在训练中与SVM一起使用softmax和使用SVM作为分类器，我们将在训练和作为分类器两者中仅使用单个softmax分类器。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/3fbbf04fa3c9df32a60853caf09ff198.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*y5_giKgb5M0baiJd"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/460200f1330b38d58502276612e55d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/0*yRDtZ8zl35kmq2tC"/></div></figure><p id="9560" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">早先在SPPNet </strong>中<strong class="io hj">现在在Fast-RCNN </strong>中</p><p id="9364" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">3.对于边界框回归量:-</p><p id="36c2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">I .改变其架构，将两个FC层添加到特征图，从那里连接两个不同的FC层，一个通向softmax(用于分类)，另一个通向Bbox回归器(用于以[x，y，w，h]的形式预测对象的位置)<strong class="io hj">此处:- x，y =中间位置的变化。训练期间显示对象的矩形，w，h =训练期间显示对象的矩形的高度和宽度的变化。</strong></p><p id="e92c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二。在训练包围盒回归中，使用L1损失代替L2损失。</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/1eed241b1f374ec62f044d1fd8d5bd54.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/0*Vxh8eTyOhST1p4QN"/></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/545eec3dca8c24cbf768677a851f82fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*BenGhiJO_uClk0cQ"/></div></figure><p id="dbeb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">早期Bbox架构当前Bbox架构</p><p id="e63f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4.训练的阶段减少了，</p><p id="bf9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最初SVM +软最大值被减少到只有软最大值</p><p id="a139" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，</p><p id="dd2d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">classfn(对数损失)+ Bbox寄存器。(L2损失)= &gt;连接成单个损失函数，在反向传播中被最小化。</p><p id="3729" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此网络从<strong class="io hj">三级损耗fn降低。</strong>至<strong class="io hj">单级损耗fn。</strong></p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mn"><img src="../Images/01b8d87c8c677df2a2a7eb28e6304855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*30sAnw0EVFQblF7K"/></div></div></figure><p id="3c9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">5.我们知道CNN的前几层基本上是随处可见的形状和边缘检测器，因此为了进一步优化和减少时间，我们将在我们的Fast-RCNN中从第3层或第4层训练CNN层。</p><p id="bc03" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">快速RCNN体系结构</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mo"><img src="../Images/3cb2d97ef0b7f1d7cb51c1a476814618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kPlgdpWlAxiLgTmj"/></div></div></figure><p id="a538" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我希望你喜欢这一点，任何疑问，建议，感谢msg我:-</p><p id="0e80" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi">8292098293</p><p id="1385" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">adityaraj20008@gmail.com</p><p id="7adb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">不要忘记喜欢和分享我的内容，谢谢。</p></div></div>    
</body>
</html>