<html>
<head>
<title>Neural Network For Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者的神经网络</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/neural-network-for-beginners-146003991beb?source=collection_archive---------10-----------------------#2021-03-04">https://medium.com/nerd-for-tech/neural-network-for-beginners-146003991beb?source=collection_archive---------10-----------------------#2021-03-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/881b65c19933e59656063c563e8d5a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJXoRx1-WoZN2k3L14_K4A.jpeg"/></div></div></figure><h1 id="8023" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是神经网络？</h1><p id="046a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">神经网络也称为人工神经网络(ANN)。它们是机器学习的子集，也是深度学习的核心。它们的名字和结构受到人类大脑的启发，并复制了生物神经元相互发送信号的方式。</p><p id="6c3a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一个复杂的定义是，神经网络是一个具有网络架构的计算模型。这个架构是由人工神经元组成的。这种结构具有特定的参数，通过这些参数可以修改它以执行某些任务。</p><p id="6af5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">人工神经网络是深度学习的核心。它们非常强大、可伸缩和通用。他们可以处理机器学习中非常复杂的问题。</p><p id="eada" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">神经网络包含多层互连的节点。每个节点是一个感知器。感知器将多元线性回归产生的信号提供给可能是非线性的激活函数。</p><h1 id="7672" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是感知器？</h1><p id="6425" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">感知器是最简单的人工神经网络之一。它是由弗兰克·罗森布拉特在1957年发明的。它基于一种被称为线性阈值单元的人工神经元。</p><p id="5628" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">那么，感知器是如何工作的呢？</p><p id="9f28" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">感知器接受几个二进制输入，x1，x2，…，并产生一个二进制输出。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/fd1b47f87effe0fbeddea7e86976d65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*oO32DM3zMX_KjY2Hn2cY0A.png"/></div></figure><p id="64b4" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">可以看到，我们有3个输入x1、x2，所有这些输入都有随机权重“w0、w1、w2”，输出将是“x*w1+w2+b”之和，我们在其中添加了偏差。这就是感知器的工作原理。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/77f577132986f013d4ff19035dc722c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*uSrDdZTxz56OLiL06kNHPw.png"/></div></figure><p id="6ce1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如果两者(w1x1和w2x2)之和小于或等于θ，它将给出0，如果大于θ，它将给出1。所以在知道感知器是如何工作的之后，让我们看看神经网络是如何工作的。</p><h1 id="e1ee" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">神经网络是如何工作的？</h1><p id="62f0" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">神经网络基于两个概念向前传播和向后传播。在正向传播中没有学习发生，学习发生在反向传播中。</p><p id="5d6c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">神经网络有许多层，每一层都执行特定的功能，神经元越多，神经网络就越复杂。根据需要可以有很多隐藏层，但这并不意味着层数越多架构越好，只有一个隐藏层的架构可以是非常好的架构，这取决于我们是否需要增加层数的问题和需要。</p><p id="630a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一个基本的神经网络有3层。</p><ol class=""><li id="e7e8" class="kx ky hi jq b jr km jv kn jz kz kd la kh lb kl lc ld le lf bi translated">输入层</li><li id="b8f5" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">隐蔽层</li><li id="1da6" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">输出层</li></ol><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/8e64cfc17d19184840d0f694cff1b523.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*ArCnriNkRT8Pw9X0Jyy9CQ.png"/></div></figure><p id="043a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">正如你所看到的，我们有一个输入层，接受2个数字输入，然后我们有一个隐藏层，有3个神经元，然后是一个输出层。每一层都有特定的用途，这些层由节点组成。</p><p id="28d6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">输入层获取输入，然后在将权重乘以输入后传输到隐藏层。然后隐藏层进行一些计算，然后传输到输出层，然后我们得到损失值。</p><p id="4185" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">因此，在隐藏层中，一个神经元执行两个步骤。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/05b3ecbd4a560b0b761f6366c1c5f9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*63R8XucqcyDTdapcxH-L9w.png"/></div></figure><h2 id="cd66" class="ln ir hi bd is lo lp lq iw lr ls lt ja jz lu lv je kd lw lx ji kh ly lz jm ma bi translated">第一步:</h2><p id="9858" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这一步中，它将所有乘以权重和偏差的输入相加。即(x1w1+x2w2+Bias)。</p><h2 id="0359" class="ln ir hi bd is lo lp lq iw lr ls lt ja jz lu lv je kd lw lx ji kh ly lz jm ma bi translated">第二步:</h2><p id="147b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这一步中，它应用一个激活函数。节点的激活函数定义了节点的输出。激活功能最终决定给下一个神经元什么。</p><p id="1e05" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有许多类型的激活功能，但我会名称广泛使用。</p><ol class=""><li id="4a4b" class="kx ky hi jq b jr km jv kn jz kz kd la kh lb kl lc ld le lf bi translated">乙状结肠(逻辑)</li><li id="616d" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">双曲正切值</li><li id="f090" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">整流线性单元</li><li id="698d" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">泄漏ReLU</li><li id="49c9" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">参数泄漏ReLU (PReLU)</li><li id="67f2" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">指数线性单位(ELU)</li><li id="7988" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">比例指数线性单位(SELU)</li></ol><p id="3926" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在这之后，输出层给出输出，该输出被称为损耗值。然后我们通过反向传播来降低损耗值。</p><p id="fb32" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在反向传播中，它对每一个神经元进行微分，并不断改变权值，直到损失值最小。这就是梯度下降的概念。</p><h1 id="5c5c" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论:</h1><p id="6c27" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这里，我已经给出了神经网络的概述。接下来，我将深入探讨反向传播和损耗值及其计算。</p><h2 id="b069" class="ln ir hi bd is lo lp lq iw lr ls lt ja jz lu lv je kd lw lx ji kh ly lz jm ma bi translated">谢谢你</h2></div></div>    
</body>
</html>