<html>
<head>
<title>Recurrent Neural Networks From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始的递归神经网络</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/recurrent-neural-networks-3a0adb1d4515?source=collection_archive---------3-----------------------#2021-09-13">https://medium.com/nerd-for-tech/recurrent-neural-networks-3a0adb1d4515?source=collection_archive---------3-----------------------#2021-09-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b591" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个简单快捷的教程，解释了RNN是如何工作的，以及如何用Python从头开始构建自己的网络。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d2a42a78cdcf61661416453b1708de4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TCaELqHtqRGLgnyx"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Jeffrey Brandjes 在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="8e6a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated"><strong class="ak">简介</strong></h2><p id="039d" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">递归神经网络处理<strong class="ih hj">序列数据</strong>来预测下一个事件。为了理解这个模型的必要性，让我们从一个思维实验开始。</p><p id="5514" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lb">你能根据这个画面预测球的方向吗？</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lc"><img src="../Images/aeb6a105515cf2f3217ceff3fe9d9c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*YuVKZT0b4MPTEhKnYmuUHA.png"/></div></figure><p id="5a10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在没有明确了解以前的位置的情况下，这是一个随机的猜测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/880b1b71f549dc4c5f7a1c9ae37eca1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7p2VLdSUYzO81cBG8tYjzg.png"/></div></div></figure><p id="dbe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们有以前位置的历史时，问题就变得容易多了。这就是为什么序列模型在处理像语言或音频文件这样的时序数据时很方便。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="b736" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> RNN </strong>架构是分布在时间步长t上的一系列<strong class="ih hj">存储单元</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/a63879a346e305c9afbcf2b0b91cfe2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*fWkhOxOD-DgY8zfgOu6sfg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">展开的RNN建筑</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/b06ba2abd6c0e23720bd8e77d39bc701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*niUQBM9xqX7ABLTVAx6UZw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">存储单元</figcaption></figure><p id="b7ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个<strong class="ih hj">存储单元</strong>接受2个输入:</p><ul class=""><li id="0ae9" class="lg lh hi ih b ii ij im in iq li iu lj iy lk jc ll lm ln lo bi translated"><strong class="ih hj"> xt </strong> —输入(如句子中的单词)</li><li id="41bb" class="lg lh hi ih b ii lp im lq iq lr iu ls iy lt jc ll lm ln lo bi translated"><strong class="ih hj"> ht-1 </strong> —隐藏状态(包含前一单元格的上下文信息)</li></ul><p id="1876" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并返回两个值:</p><ul class=""><li id="6ee2" class="lg lh hi ih b ii ij im in iq li iu lj iy lk jc ll lm ln lo bi translated"><strong class="ih hj"> ht </strong> —下一个隐藏状态</li><li id="4397" class="lg lh hi ih b ii lp im lq iq lr iu ls iy lt jc ll lm ln lo bi translated"><strong class="ih hj"> yt </strong> —预测(如预测句子中的下一个单词)</li></ul></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="e001" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated"><strong class="ak">让我们用Python创建RNN类</strong></h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="ed87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">隐藏单元的</strong>变量是处于隐藏状态的“神经元”数量。一个时间步长大致类似于神经网络中的层。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="ec7e" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">资料组</h2><p id="e2c6" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">我们的数据集是<strong class="ih hj">一个正弦函数</strong>变成200个样本，每个样本有25个时间步长。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lu lv l"/></div></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="169b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">前进传球</h2><p id="96c2" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">正向传递包括循环样本中的每一步的<strong class="ih hj">以获得最终输出<strong class="ih hj"> yt </strong>并计算<strong class="ih hj"> MSE </strong>损失。</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lu lv l"/></div></figure><h2 id="0fd4" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">反向传播</h2><p id="c9fc" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">这就是事情变得有点棘手的地方。在RNN中，权重是跨时间步长共享的，因此权重<strong class="ih hj"> Wh </strong>取决于时间上的每个隐藏状态。类似的权重<strong class="ih hj"> Wx </strong>取决于前一时间步的每个输入。这就是为什么我们称之为穿越时间的反向传播(<strong class="ih hj"> BPTT </strong>)。我不会把所有的数学方程式都放在这里。尽管如此，如果你想知道引擎盖下到底发生了什么，我还是推荐这个视频。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lu lv l"/></div></figure><p id="6815" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还限制了渐变以防止<strong class="ih hj">消失</strong>和<strong class="ih hj">爆发</strong>渐变问题。</p><h1 id="049c" class="lw kc hi bd kd lx ly lz kh ma mb mc kl md me mf ko mg mh mi kr mj mk ml ku mm bi translated">让我们齐心协力</h1><p id="ffbd" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">因此，我们构建了向前和向后传播的代码，现在我们可以向我们的网络提供数据，并观察它的行为。完整实现可在<a class="ae jt" href="https://github.com/maciejbalawejder/DeepLearning-collection/blob/main/Sequentials/RNN/RNN.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github </strong> </a>上获得。</p><div class="je jf jg jh fd ab cb"><figure class="mn ji mo mp mq mr ms paragraph-image"><img src="../Images/8a04836f5e573c84b78ccb46949942b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*IA4UMyH4PqyrFpeEWjIJ-g.png"/></figure><figure class="mn ji mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/b38eb3bebf3885e4dba0ece2e2807ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*FNoOBn2IWBVU0pS93UVGEw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx mu di mv mw translated"><strong class="bd kd">左</strong>:损失函数<strong class="bd kd">右</strong>:绿色——预测，蓝色——地面真实</figcaption></figure></div><p id="1b09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型似乎基于之前的25个数据点准确地预测正弦函数值。平均误差在0.5%左右。</p><h1 id="a7b7" class="lw kc hi bd kd lx ly lz kh ma mb mc kl md me mf ko mg mh mi kr mj mk ml ku mm bi translated">丰富</h1><p id="c346" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">因为它是RNN的普通实现，所以有很多升级:</p><ul class=""><li id="a7b8" class="lg lh hi ih b ii ij im in iq li iu lj iy lk jc ll lm ln lo bi translated">向隐藏状态添加偏差</li><li id="63d0" class="lg lh hi ih b ii lp im lq iq lr iu ls iy lt jc ll lm ln lo bi translated">随时间截断反向传播(TBPTT) —适用于较长的序列</li><li id="fc35" class="lg lh hi ih b ii lp im lq iq lr iu ls iy lt jc ll lm ln lo bi translated">更先进的模式，如LSTM或GRU</li></ul><h1 id="3593" class="lw kc hi bd kd lx ly lz kh ma mb mc kl md me mf ko mg mh mi kr mj mk ml ku mm bi translated">结论</h1><p id="3ce5" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">理查德·费曼的名言是，“我不能创造的，我不理解。”这就是为什么我认为从零开始建立这些模型是至关重要的，以获得对内部数学、与任务相关的问题以及如何解决这些问题的更深刻的理解。</p><p id="0fa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果想看我的其他项目，可以查看我的<a class="ae jt" href="https://maciejbalawejder.medium.com/" rel="noopener"> <strong class="ih hj">中</strong> </a>和<a class="ae jt" href="https://github.com/maciejbalawejder" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Github</strong></a><strong class="ih hj"/>简介。</p><p id="7822" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lb">探索更多RNNs的宝贵资料。</em></p><div class="mx my ez fb mz na"><a href="https://victorzhou.com/blog/intro-to-rnns/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">初学者递归神经网络入门-victorzhou.com</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">递归神经网络是一种专门处理序列的神经网络。他们经常…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">victorzhou.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no jn na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9" rel="noopener follow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">递归神经网络图解指南</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">理解直觉</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">towardsdatascience.com</p></div></div><div class="nj l"><div class="np l nl nm nn nj no jn na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://towardsdatascience.com/sequence-models-and-recurrent-neural-networks-rnns-62cadeb4f1e1" rel="noopener follow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">序列模型和递归神经网络</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">理解深度递归神经网络(RNNs)</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">towardsdatascience.com</p></div></div><div class="nj l"><div class="nq l nl nm nn nj no jn na"/></div></div></a></div></div></div>    
</body>
</html>