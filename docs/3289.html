<html>
<head>
<title>Building a Basic Binary Text Classifier using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras构建一个基本的二元文本分类器</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/building-a-basic-binary-text-classifier-using-keras-4972a7c36616?source=collection_archive---------3-----------------------#2021-06-05">https://medium.com/nerd-for-tech/building-a-basic-binary-text-classifier-using-keras-4972a7c36616?source=collection_archive---------3-----------------------#2021-06-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8363" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为使用Python &amp; NLTK 的自然语言处理的延续，本文试图探索如何在不使用递归神经网络(RNN)或长短期记忆(LSTM)的情况下构建二进制文本分类器</p><h1 id="00e4" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">目录</h1><ol class=""><li id="7048" class="kc kd hi ih b ii ke im kf iq kg iu kh iy ki jc kj kk kl km bi translated">文本的人工神经网络</li><li id="ff6d" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">单词嵌入</li><li id="62ed" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">利用人工神经网络构建文本分类器</li><li id="d180" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">使用文本分类器的预测</li></ol><h1 id="6526" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">文本的人工神经网络</h1><p id="fcb1" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们知道人工神经网络善于处理数字，而自然语言处理的是文本。因此，在用文本数据训练模型之前，我们需要对输入数据进行分类，并尝试将单词表示为数字或向量。任何原始分类特征，如字符/单词标记、位置标签等。,.将被表示为一系列向量。</p><p id="6cc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">单词嵌入:</strong>一类技术，将单个单词表示为预定义向量空间中的实值向量。下面列出了一些流行的技术:</p><ol class=""><li id="de7e" class="kc kd hi ih b ii ij im in iq kv iu kw iy kx jc kj kk kl km bi translated">二进制编码(一键向量编码)</li><li id="bd08" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">术语频率—反向文档频率(TF-IDF)</li><li id="1d0a" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated">Word2Vec嵌入</li></ol><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/5832495a0401789207ac065495894f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*1WHPailNU5Nxv3gtUkbFdg.gif"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">一键矢量编码的图示</figcaption></figure><p id="bd66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，给定10，000个单词的词汇表，每个单词被分配一个整数索引值(0- 9999)。现在有了这个单词到整数的映射，每个单词都可以表示为一个向量。例如，索引值为3204 的单词<strong class="ih hj"> cat被编码为[0，0，0，…。，1，…，0，0]，其中1正好在位置3204。</strong></p><p id="c1b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这个向量可以作为神经网络的输入，用于进一步的算法处理。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es lo"><img src="../Images/4e796983feb4891e24189c905f7e12e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*UmIb1_lf7gLsbRWfZWwAQg.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">文本的人工神经网络</figcaption></figure><h1 id="5f4c" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">基于人工神经网络的文本分类器</h1><p id="36ba" class="pw-post-body-paragraph if ig hi ih b ii ke ik il im kf io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们现在将研究使用Keras的ANN文本分类器的实现。<a class="ae jd" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Keras </strong> </a> <strong class="ih hj"> : </strong>为人工神经网络提供Python接口的开源软件库。它支持多个后端神经网络计算引擎，如Tensorflow、微软认知工具包、Theano和PlaidML。</p><p id="4b70" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">导入Tensorflow和Keras API。还要导入<a class="ae jd" href="https://realpython.com/numpy-tutorial/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Numpy</strong></a><strong class="ih hj"/>—一个python库，它提供了简单而强大的数据结构:n维数组。加载Keras提供的<a class="ae jd" href="https://keras.io/api/datasets/imdb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> IMDB电影评论数据集</strong> </a> <strong class="ih hj"> </strong>。</p><h2 id="5455" class="lp jf hi bd jg lq lr ls jk lt lu lv jo iq lw lx js iu ly lz jw iy ma mb ka mc bi translated"><strong class="ak"> IMDB数据集:</strong></h2><ul class=""><li id="4aeb" class="kc kd hi ih b ii ke im kf iq kg iu kh iy ki jc md kk kl km bi translated">总体数据集规模- 50，000条评论</li><li id="9594" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">训练数据- 25，000条带有情感标签的评论(正面/负面)</li><li id="aa2b" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">测试数据- 25，000条评论</li><li id="4e13" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">审查是预处理和索引的总频率。例如:如果索引为3，则表示该数据中第三个最常用的单词。按照惯例，索引0用于编码任何未知/未识别的单词。</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es me"><img src="../Images/a8dcb801db720055f40b05fb8dbbc07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g0ZsqPsRkEi35l4wo7wgxA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">从Keras导入和加载IMDB数据集</figcaption></figure><p id="6979" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集被加载并被分成分别带有训练(<strong class="ih hj"> train_data </strong>)和测试(<strong class="ih hj"> test_data </strong>)标签的训练(<strong class="ih hj"> train_labels </strong>)和测试(<strong class="ih hj"> test_labels </strong>)数据。参数<strong class="ih hj"> num_words = 10000 </strong>保留训练数据中出现频率最高的前10k个单词。为了保持数据的大小易于管理，我们会丢弃一些不常用的单词。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mf"><img src="../Images/92166f273cbe05a6a32afbdc4c7827dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NFPBAltEFEx-_CcwcN7ufw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">培训数据和标签</figcaption></figure><p id="b2f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的图像中，样本训练数据1示出了数据集的句子1的编码向量表示，其被标记为1，指示它是正面评论。</p><p id="4590" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">填充:</strong>使所有输入序列具有相同固定大小的过程。并非数据集中的所有序列都具有相同的长度。有些长，有些短。但是我们知道ANN只处理固定的相同大小的输入。因此，必须使用<strong class="ih hj">keras . preprocessing . sequence . pad _ sequences()创建填充序列。</strong>填充中使用的参数描述如下</p><ol class=""><li id="b0b6" class="kc kd hi ih b ii ij im in iq kv iu kw iy kx jc kj kk kl km bi translated"><strong class="ih hj">训练数据/测试数据:</strong>要填充的数据集</li><li id="f94a" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj">值:</strong>表示填充发生的值。</li><li id="005d" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj">填充:</strong>需要填充的地方。当padding = 'post '时，该值追加到后缀部分。如果未指定填充，默认填充出现在前缀部分。</li><li id="93ad" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc kj kk kl km bi translated"><strong class="ih hj"> maxlen: </strong>定义了句子中的最大字数，默认的最大句子长度由最长的句子定义。当一个句子超过最大字数时，它会删除或截断单词，默认情况下，它会删除句子开头的单词。</li></ol><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mg"><img src="../Images/9873fbf756ad82df6c292959f46ad235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkS6y1sFa84QxzIMyPiCqA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">示例填充说明</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mh"><img src="../Images/c2c181cd907feeb42bf84e570acf1cf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sL90m53KX_Nhji7cjfESMQ.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">样本填充的输出</figcaption></figure><p id="9e4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">填充序列的结果非常简单。现在，您可以观察到已经填充到矩阵中的句子列表，其中矩阵中的每一行都有一个长度相同的编码句子。tokenizer中的<strong class="ih hj"> oov_token </strong>指定了无法识别的词汇外标记。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mi"><img src="../Images/78cb1b2763f1df686e779ee2732f033b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4udAFoA3j4FT4cteiDqGhw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">填充前后的数据长度</figcaption></figure><p id="2cc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码使用<strong class="ih hj"> imdb.get_word_index()获取单词索引列表。</strong>字索引值0、1、2和3分别为填充值、起始值、未知值和未使用值保留。输出显示了</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mj"><img src="../Images/8bd0314e2d2217ba9a5a4f2a45eb20fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h_oXW5b2YKeh8cX4PTF2YA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">构建人工神经网络模型</figcaption></figure><p id="93bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> vocab_size: </strong>用于定义输入形状的数据集的词汇计数(10，000)。</p><p id="2928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">喀拉斯。Sequential(): </strong>对一系列层进行分组——一个输入层、一个或多个隐藏层和一个输出层。</p><p id="e2dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">keras . layers . embedding():</strong>接受整数编码的词汇表，其中包含单词索引(vocab_size)和向量维数(16)。这些向量是在模型被训练时学习的。嵌入层的输出形状将是(批处理、序列、嵌入)</p><p id="2be6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">keras . layers . globalaveragepooling1d():</strong>通过对序列维度求平均，返回每个示例的固定长度输出向量。这使得模型能够以最简单的方式处理可变长度的输入。</p><p id="9bf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> keras.layers.Dense(): </strong>它以-隐层和输出层的神经元数目，激活函数为自变量。在上面的代码中，隐藏层有16个神经元，输出层有一个神经元。输出层中密集单元(神经元)的数量是1，因为在这种情况下，预测的输出将是0(负)或1(正)。</p><p id="600b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么ReLU为隐藏层？</strong>不<strong class="ih hj"> <em class="mk">饱和</em> </strong>为输入加权和的正值。如果输入是正数，函数返回数字本身，如果输入是负数，函数返回0。</p><p id="d574" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么输出层为Sigmoid？</strong>我们如何将一个实值(最后一个隐藏层z的线性组合)映射到一个概率，即0到1之间的一个数字？一个简单的解决方案是只考虑在0和1之间的那部分z。所有负值将被映射到0，而所有大于1的值将被映射到1。</p><p id="14be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> model.summary(): </strong>打印模型的有用摘要，包括:</p><ul class=""><li id="320d" class="kc kd hi ih b ii ij im in iq kv iu kw iy kx jc md kk kl km bi translated">模型中所有层的名称和类型。</li><li id="07d7" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">每层的输出形状。</li><li id="992d" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">每层的权重参数个数。</li><li id="88a1" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">如果模型具有一般拓扑(下面讨论)，则每层接收的输入</li><li id="c7a9" class="kc kd hi ih b ii kn im ko iq kp iu kq iy kr jc md kk kl km bi translated">模型的可训练和不可训练参数的总数。</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ml"><img src="../Images/8a295d23dda86852c4947e0a37955945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjKfSZ5BDJXsq-jsW860sg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">模型摘要</figcaption></figure><p id="6e0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">嵌入图层:</strong></p><p id="b60a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入形状:2D张量(批量大小，输入长度)。在这种情况下，(无，无)。</p><p id="2f5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出形状:3D张量(batch_size，input_length，embedded_vector_dim)。在这种情况下，(无，无，16)</p><p id="01dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">global _ average _ pooling 1d:</strong></p><p id="439d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入形状:来自嵌入层的3D张量。</p><p id="2d6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出形状:2D张量(batch_size，input_dim)。在这种情况下，(无，16)。</p><p id="678c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">致密层:</strong></p><p id="6380" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于密集层代表<strong class="ih hj">隐藏层</strong>具有16个神经元和ReLU激活功能。</p><p id="6e57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入形状:来自池层的2D张量。(无，16)</p><p id="46b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出形状:2D张量(批量大小，单位数量)。(无，16)在上面的代码中。</p><p id="59d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于密集层代表<strong class="ih hj">输出层</strong>具有1个神经元和Sigmoid激活函数。</p><p id="d5af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入形状:隐藏层的2D张量。(无，16)</p><p id="f5dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出形状:2D张量(批量大小，单位数)。在这种情况下，(无，1)</p><p id="a681" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">各层参数计算:</strong></p><p id="499d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嵌入层:vocab _ size * emb _ dim = 10000 * 16 = 160000</p><p id="bbd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">密集层，参数个数=输出大小*(输入大小+1) </strong></p><p id="b40c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">隐藏层:16 * (16+1) = 16 * 16 + 16 = 272</p><p id="5e7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出层:1 * (16+1) = 16 + 1 = 17</p><p id="903d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后使用带有ADAM优化器的<strong class="ih hj"> model.compile() </strong>编译模型，损失函数为二进制交叉熵，因为输出为0或1。参数<strong class="ih hj"> metrics </strong>是模型在训练和测试期间要评估的度量列表。</p><p id="1a77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，训练数据集被分成训练数据(0–9999)和验证数据(10000- 24999)。<strong class="ih hj">验证集</strong>是一组数据示例，用于调整分类器的超参数。模型会看到这些数据，但永远不会学习这些数据。</p><p id="eba2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后使用<strong class="ih hj"> model.fit()对模型进行固定次数的训练。batch_size </strong>指定每次梯度更新的样本数。默认值= 32。<strong class="ih hj">时期</strong>被定义为“整个数据集的一次通过”。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mm"><img src="../Images/72db551ebb35e6e0b3a7f49da1ebd2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMhSgQ2U2PQmd730_wWzWg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">模型编译和培训</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mn"><img src="../Images/3e1e67e7270bdfaa9523851eb7c65992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpPHcp-IItz4soj4VHJfxg.png"/></div></div></figure><p id="3e05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练在达到40个纪元后完成。训练准确率为97%，验证准确率为88%。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mo"><img src="../Images/8973042d37424b3a3b2c2685def57600.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r-3abOjKPPftUh9yTWdlxg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">模型评估</figcaption></figure><p id="0f14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型评估:</strong> model.evaluate()用于根据测试数据评估模型性能。这种相当简单的方法达到了大约87%的准确率。使用更先进的方法，该模型应该接近95%。</p><p id="f1e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型预测:</strong>经过训练的模型现在可以使用model.predict()来预测句子/评论的情感。以下代码显示了如何解码评论并预测测试数据中第35篇评论的情绪。0-负极&amp; 1-正极</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/41e633a2a05a96f085089a7867c27312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsBNNcSFUXYlB9CciQls2w.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">模型预测法</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mp"><img src="../Images/83fe5acb3adb8ffd2d5a95a29741d0de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-XEK67lJVoR_ejox-Thbdw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">预测产量</figcaption></figure><p id="c630" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此第35次审查的测试数据"<strong class="ih hj">这是关于最糟糕的电影之一……..</strong>被<strong class="ih hj">标记为0 </strong>，表示<strong class="ih hj">预测为负</strong>审查，预测概率为0.0029</p><p id="6029" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面这段代码使用matplot库来绘制训练与验证准确性的关系图。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mq"><img src="../Images/52246679f47b104ad7685ad6b7ddad4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jyqtTpJhdavkbaYRQE-dAA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">绘制图形的代码</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mr"><img src="../Images/972a87beeaec912fc1b616afb488daed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZeraO7l2Aq8KJ9FZY95Hw.png"/></div></div></figure><p id="ea6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Hope对使用Keras构建文本分类器有所了解。对于Colab代码，<a class="ae jd" href="https://colab.research.google.com/drive/18DlRPLIr4q_3CzLfDQfpw_SUUu2wxQ4u?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击此处</a></p><h1 id="58fd" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated"><strong class="ak">快乐学习</strong></h1><h2 id="c391" class="lp jf hi bd jg lq lr ls jk lt lu lv jo iq lw lx js iu ly lz jw iy ma mb ka mc bi translated"><strong class="ak">下一篇文章再见</strong></h2></div></div>    
</body>
</html>