<html>
<head>
<title>iMaterialist (Fashion) 2019 at FGVC6</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FGVC6上的iMaterialist(时尚)2019</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/imaterialist-fashion-2019-at-fgvc6-95a0d38ad362?source=collection_archive---------5-----------------------#2021-04-13">https://medium.com/nerd-for-tech/imaterialist-fashion-2019-at-fgvc6-95a0d38ad362?source=collection_archive---------5-----------------------#2021-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/e3b8accf2e49f0ec91c75bd93413c47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p10ovCRc2jFQNOLDNTSpTw.jpeg"/></div></div></figure><div class=""/><h1 id="5dd1" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">时尚和服装的精细细分任务</h1><h1 id="eddb" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">内容</h1><ol class=""><li id="1202" class="jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">介绍</li><li id="e920" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">问题陈述</li><li id="46e5" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">性能指标</li><li id="cbcf" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">关于数据</li><li id="cd68" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">目标</li><li id="c469" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">探索性数据分析</li><li id="ce26" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">Tf数据管道</li><li id="4bcd" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">U-Net标准架构</li><li id="038a" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">培训U-Net</li><li id="a4a0" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">预言</li><li id="ae1a" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">部署视频</li><li id="dbce" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">结论</li><li id="bec7" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">未来的工作</li><li id="ed82" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb kc kd ke kf bi translated">参考</li></ol><h1 id="1dad" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 1。简介</strong></h1><p id="62bb" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">设计师知道他们在创造什么，但是人们真的穿他们的产品吗？人们在使用哪些产品组合？在本案例研究中，我们开发了一种算法，这将有助于实现自动产品检测的重要一步，即准确分配时尚图像的分割。</p><p id="6e36" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">服装的视觉分析是近年来越来越受关注的话题。能够从图片中识别服装产品可以增强消费者的购物体验，并提高时尚专业人员的工作效率。</p><p id="75d0" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">在这个案例研究中使用了一个新的服装数据集，其目标是通过联合时尚和计算机视觉社区的力量来引入一个新的细粒度分割任务。提出的任务是对时尚服装进行分类和分割，这是走向现实应用的重要一步。</p><div class="hh hi ez fb hj lf"><a href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hu fi z dy lk ea eb ll ed ef hs bi translated">FGVC6上的iMaterialist(时尚)2019</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">时尚和服装的精细细分任务</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">www.kaggle.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt hp lf"/></div></div></a></div><h1 id="20f2" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 2。问题陈述</strong></h1><p id="cc6c" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">任务是执行时尚服装的分类和分割。给定服装图像，模型必须执行图像分割和分类。为了捕捉时尚对象的复杂结构和从网络抓取获得的描述中的模糊性，我们的标准化分类包含46个服装对象(27个主要服装项目和19个服装部分)和92个相关的细粒度属性。</p><div class="hh hi ez fb hj lf"><a href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hu fi z dy lk ea eb ll ed ef hs bi translated">FGVC6上的iMaterialist(时尚)2019</h2><div class="lm l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">时尚和服装的精细细分任务</h3></div><div class="ln l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">www.kaggle.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt hp lf"/></div></div></a></div><h1 id="92ed" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 3。性能指标</strong></h1><p id="3af5" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">欠条:</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es lu"><img src="../Images/065767be29b5d4f2a0b688499079574e.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*8hZH8uh1tB4eFVE7aQgFUg.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">借据</figcaption></figure><p id="f4c5" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">该指标在IoU阈值范围内扫描，在每个点计算平均精度值。阈值范围从0.5到0.95，步长为0.05: <code class="du md me mf mg b">(0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95)</code>。换句话说，在阈值为0.5时，如果预测对象与基础真值对象的交集大于0.5，则该预测对象被视为“命中”。</p><p id="cc85" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">来源:<a class="ae mh" href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview/evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/imate rialist-fashion-2019-fgvc 6/overview/evaluation</a></p><h1 id="b5ab" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4.关于数据</h1><p id="2937" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">在这个数据集中，为我们提供了大量的图像和相应的时尚/服装分割。图像以唯一的图像id命名。分割是以编码像素的形式。关于编码像素的更多细节，请参考<a class="ae mh" rel="noopener" href="/analytics-vidhya/generating-masks-from-encoded-pixels-semantic-segmentation-18635e834ad0">链接</a>。数据集包含以下文件:</p><ul class=""><li id="a64e" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated">训练/ —训练图像</li><li id="5c2f" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">test/-测试图像(您正在分割和分类这些图像)</li><li id="9d7c" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">train . CSV——训练注释，包含具有分段服装类别和细粒度属性的图像；和仅具有分段服装类别的图像。</li><li id="d027" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">label_descriptions.json —给出服装类别和细粒度属性描述的文件。</li></ul><p id="054e" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">train.csv中的列如下:</p><ul class=""><li id="8eb5" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated"><code class="du md me mf mg b">ImageId</code> -图像的唯一Id</li><li id="8f5c" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><code class="du md me mf mg b">EncodedPixels</code> -游程编码格式的掩码(详情请参考<a class="ae mh" href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview/evaluation" rel="noopener ugc nofollow" target="_blank">评估页</a>)。</li><li id="57b6" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><code class="du md me mf mg b">ClassId</code> -该掩码的类别id。我们将类别和属性(如果有)连接在一起。</li><li id="f999" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">高度-给定图像的高度</li><li id="389f" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">宽度-给定图像的宽度</li></ul><p id="bd22" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">来源:<a class="ae mh" href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/data" rel="noopener ugc nofollow" target="_blank">链接</a></p><h1 id="30c8" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">5.目标</h1><p id="5c6b" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">本案例研究的目的是基于服装类别的分类执行简单的图像分割。它使用图像分割概念以及用于学习目的的计算机视觉概念。案例研究基于上述kaggle问题。使用的模型是一个简单的U-Net模型，以查看其在服装图像分割中的有效性。</p><h1 id="9efd" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">6.探索性数据分析</h1><p id="8bf8" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">a.基本统计</p><p id="b289" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">In train.csv:</p><ul class=""><li id="b02f" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated">唯一图像id的数量是45，195。</li><li id="32cf" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">特征的数量是5。</li><li id="39cc" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">具有属性的类别数是11，499。</li><li id="0472" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">没有属性的类别数是319714。</li></ul><p id="81cd" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">b.计数属性与图像数量图</p><p id="5876" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们首先将train.csv中给出的ClassId分成类别和属性。图像可以包含属性。根据我们的数据集如果class_id以<code class="du md me mf mg b">35_24_51_69_88_195_210_306</code>的形式出现</p><p id="144d" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">第一个数字表示类别，其余数字表示由“_”分隔的属性。例如，上面的类别是35，属性是[24，51，69，88，195，210，306]。如果类id是单个数字的形式，那么这表示类别id，并且图像包含0个属性。</p><p id="5bf7" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们绘制了一个简单的计数属性与图像数量的柱状图。</p><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es mo"><img src="../Images/09faed7094e661a6dd52c9c8fdb15845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*vUQsCdZtXugAEepCKKJA4Q.png"/></div></figure><p id="a675" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">该图显示最大数量的图像没有属性。很少有图像具有非零属性。具有非零属性的图像的数量小于5000。我们有一个偏斜的分布。</p><p id="759c" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">每个属性的图像数量的c.kde图</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es mp"><img src="../Images/1a5d965962a6cedfe332afa906da0dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*4vst9kPWjx3ihiqWdBC6BQ.png"/></div></figure><p id="5eea" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们还绘制了KDE图，显示它是一条以0为中心的右尾正态分布曲线。</p><p id="2d84" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">d.每个类别图的图像数量</p><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><ul class=""><li id="c13f" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated">类别31(袖子)的图片数量最多，约为6000张。</li><li id="a705" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">类别12，20，26，41，45出现在最低数量的图像中。</li><li id="c896" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">类别1，10，23，32，33出现在相当多的图像中。</li></ul><p id="b047" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">e.rle到遮罩的转换:</p><p id="33b5" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">为train.csv文件中的每个图像提供rle(游程编码)。rle被转换为分段掩码并存储在磁盘上。为此，我们将具有相同image_id的图像分组，然后获得属于该特定图像的类别列表。创建的掩码使用多标签分段概念。当我们使用稀疏分类交叉熵损失函数时，掩模像素在内部被表示为类别号。例如，参考下图。多标签分割就是这么做的。</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/c0acb15d568530d527de46f8edb0918f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ibNbePAouEvsePLgRdJdqg.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">多层分割</figcaption></figure><h1 id="2c37" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">7.Tf数据管道</h1><p id="bed2" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">tf数据管道是使用tensorflow.org指南创建的。tf-data通过异步预取下一批数据来提高性能，使GPU无需等待数据。还可以并行化预处理和加载数据集的过程。</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/01480088ff0c8d0aae0f087d5bd3e1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHq0TVdnqR4F0XLTaVxV_g.png"/></div></div></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ms"><img src="../Images/e587bd045bbaeef26ce23e8215a20150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3AMuWewdVFbUZuViTmylag.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">TF-数据管道效应</figcaption></figure><p id="215d" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">a.创建数据集:</p><ul class=""><li id="e0e3" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated">tensor_slices:tensor flow数据集是使用tensor _ slices创建的，它接受单个或多个NumPy数组或张量。这里它接受存储在本地磁盘上的图像和遮罩的文件名。tensor_slices用第一维度对数据进行切片。它可用于将不同的元素组合成一个数据集，例如，将要素和标注组合成一个数据集(这也是张量的第一维应该相同的原因)。即数据集变得“更宽”。</li></ul><p id="d697" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">b.数据集上的操作:</p><ul class=""><li id="1c55" class="jo jp ht jq b jr la jt lb jv mi jx mj jz mk kb ml kd ke kf bi translated">批处理:数据集。batch()将获取第一批batch_size条目，并对它们进行批处理。它将数据集的连续元素组合成一个批处理。当想要训练更小批量的数据以避免内存不足错误时，这很有用。在这里，我们采用批量大小为5进行训练。</li><li id="8b46" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">地图:数据集。map()将把一些用户定义的函数映射到数据集上，这些函数转换数据以便能够为模型提供数据。这里，我们将parse_image函数和随机增强函数映射到训练数据集，并将parse_image函数映射到验证和测试数据集。由于输入元素相互独立，预处理可以在多个CPU内核上并行化。为了实现这一点，map转换提供了num_parallel_calls参数来指定并行级别。</li><li id="27b3" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">预取:数据集。prefetch()与训练步骤的预处理和模型执行重叠。当模型正在执行训练步骤s时，输入管道正在读取步骤s+1的数据。这样做可以将步长时间减少到训练的最大值(相对于总和)以及提取数据所需的时间。要预取的元素数量应该等于(或者可能大于)单个训练步骤消耗的批次数量。通常，在流水线的最末端添加一个小的预取缓冲器(可能只有一个元素)是最有用的，但是更复杂的流水线可以受益于额外的预取，尤其是当产生一个元素的时间可以变化时。这里，我们在预取中使用了大小为3的缓冲区。</li><li id="6c42" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">shuffle: shuffle()应该在batch()之前被调用，因为我们想要对记录进行洗牌，而不是批处理。首先通过按顺序添加记录来填充缓冲区，然后，一旦满了，就随机选择并发出一个记录，并从原始源读取一个新记录。</li></ul><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="73a6" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">类似地，我们创建tf数据集进行验证和测试。</p><p id="dc49" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">现在我们的tf。数据管道创建完毕，可以使用了！！！！让我们展示一些图片和真实的面具:</p><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mt"><img src="../Images/20a076c6134746b3fce226c815251ed5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akXCN-cFA9G0fI_OSLIRVQ.png"/></div></div></figure><h1 id="3db7" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">8.U-Net标准架构</h1><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mu"><img src="../Images/2322edcbeb3ada7df9393370bd210499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sq6oMzPp6UppGynXXCIqSw.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">u网</figcaption></figure><p id="5d17" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">U-net于2015年首次设计并应用于处理生物医学图像。在生物医学案例中，不仅需要区分是否存在疾病，还需要定位异常区域。因此，优信网服务于这一目的。它对每个像素进行分类，以便输入和输出共享相同的大小。U-Net架构是对称的。它有一条收缩路径和一条扩张路径。左边部分是正常卷积过程的收缩路径，右边部分是转置2d卷积层的扩展部分。有关架构的完整解释，请参考<a class="ae mh" href="https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47" rel="noopener" target="_blank">链接</a>。</p><p id="fd50" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">标准的U-Net架构用于图像分割。这方面的代码如下:</p><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="mm mn l"/></div></figure><h1 id="bc7e" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">9.培训U-Net</h1><p id="50aa" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">该模型被训练80个时期。该模型用Adam Optimiser编译，学习率为(1e-3)，使用的损失是稀疏分类交叉熵。我们还使用Keras回调来实现tensorboard回调，如果连续10个时期验证损失没有改善，则提前停止，以及仅保存权重的模型检查点。</p><p id="a441" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们使用128的batch_size进行训练。</p><p id="9d24" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们可以对这些参数进行超参数调整，提高模型性能。</p><p id="e59e" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">我们还计算了get_mean_iou得分，这是我们的业务指标。这是一个自定义指标。</p><p id="ba28" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">训练80个周期后获得的分数如下:</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es mv"><img src="../Images/54e9596210286f0194ef22c2c7664063.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*HBy7TMdKi-Vu2x_EQE-cTQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">得分</figcaption></figure><p id="48dd" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">get_mean_iou和loss的训练图如下:</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es mw"><img src="../Images/74547486d3aea1f376c60b00eefd7110.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*DVIgbYqYhSo3YvBWhY2vhw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">获取最近39个时期的平均值</figcaption></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div class="er es mx"><img src="../Images/4dc4bf085ba2622747003989c5287725.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*VsfPmhHz-my7dGfOiTWnlA.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">过去39个历元的历元丢失</figcaption></figure><h1 id="ae1e" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">10.预言</h1><p id="3e03" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">我们来看一些模型预测。</p><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es my"><img src="../Images/80af837c4f61108f3d40dc4c23467191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6GeC7CscvMAc4PjcTvMIw.png"/></div></div></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mz"><img src="../Images/c20670ba603f03ad4ee1a67a60096a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n5vdwKF0KgY7WYMynQoXVQ.png"/></div></div></figure><figure class="lv lw lx ly fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es na"><img src="../Images/1a1df121f098cb3a6774ba6339133a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d_HISO7qPSyscQJWO32a2Q.png"/></div></div></figure><h1 id="a7a0" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">11.部署视频</h1><p id="5fc7" class="pw-post-body-paragraph kl km ht jq b jr js kn ko jt ju kp kq jv kr ks kt jx ku kv kw jz kx ky kz kb hb bi translated">该模型是使用streamlit app部署的。看一下视频。</p><figure class="lv lw lx ly fd hk"><div class="bz dy l di"><div class="nb mn l"/></div></figure><h1 id="4f08" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">12.结论</h1><ul class=""><li id="c239" class="jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb ml kd ke kf bi translated">模型unet是一个简单的模型，易于实现。</li><li id="325b" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">我们可以更好地调整模型以给出更好的预测。</li><li id="2de5" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">用于执行分割的过程简单且易于实现。</li><li id="626d" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">tf数据管道让训练过程更快更优化。</li></ul><h1 id="3341" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">13.未来的工作</h1><ul class=""><li id="aed4" class="jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb ml kd ke kf bi translated">可以使用Mask-RCNN模型，因为它是更复杂的模型并且更稳健。</li><li id="602d" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">图像可以调整为512*512，而不是256*256。</li><li id="1fbc" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated">Tf-数据管道批量大小可以从5。</li></ul><h1 id="dfd3" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">14.参考</h1><ul class=""><li id="9d69" class="jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb ml kd ke kf bi translated"><a class="ae mh" href="https://coderoad.ru/59343661/Unet-%D0%9C%D1%83%D0%BB%D1%8C%D1%82%D0%B8%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%BE%D0%B2%D0%B0%D1%8F-%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F-%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9" rel="noopener ugc nofollow" target="_blank">https://code road . ru/59343661/Unet-% D0 % 9C % D1 % 83% D0 % BB % D1 % 8C % D1 % 82% D0 % B8 % D0 % BA % D0 % BB % D0 % B0 % D1 % 81% D1 % 81% D0 % BE % D0 % B2 % D0 % B0 % D1 % 8F-% D0 % A1 % D0 % B5 % D0 % B3 % D0 % BC % D0 % B5 % D0 % D0 % BD % D1 % 82% D0 %</a></li><li id="2095" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><a class="ae mh" href="https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview/description" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/imate rialist-fashion-2019-fgvc 6/overview/description</a></li><li id="df00" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><a class="ae mh" href="https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47" rel="noopener" target="_blank">https://towards data science . com/understanding-semantic-segmentation-with-unet-6 be 4 f 42d 4b 47</a></li><li id="6c01" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><a class="ae mh" href="https://www.kaggle.com/kimwoojeong/simple-eda-imaterialist-fashion-2019-at-fgvc6" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/kimwoojeong/simple-EDA-imate rialist-fashion-2019-at-fgvc 6</a></li><li id="9645" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><a class="ae mh" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/data</a></li><li id="7054" class="jo jp ht jq b jr kg jt kh jv ki jx kj jz kk kb ml kd ke kf bi translated"><a class="ae mh" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com</a></li></ul><p id="efef" class="pw-post-body-paragraph kl km ht jq b jr la kn ko jt lb kp kq jv lc ks kt jx ld kv kw jz le ky kz kb hb bi translated">请查看我的<a class="ae mh" href="https://github.com/rash938/Imat-2019-fashion-self-case-study2-" rel="noopener ugc nofollow" target="_blank"> Github </a>代码和<a class="ae mh" href="https://www.linkedin.com/feed/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>个人资料，以便进一步讨论。</p></div></div>    
</body>
</html>