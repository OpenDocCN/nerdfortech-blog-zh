# 为什么行为人工智能是下一个值得关注的人工智能？

> 原文：<https://medium.com/nerd-for-tech/why-behavioral-ais-are-the-next-ais-to-watch-c51b5c83da7c?source=collection_archive---------5----------------------->

像 GPT3、加托或 Lambda 这样的高级自然语言处理模型很棒，但它们仍然缺少一些重要的东西:它们没有行为智能。如果未来的人工智能也能有趣、严格或热情，会怎么样？为什么重要？

人们在生活中需要各种各样的支持，要么是人的支持，要么是技术支持。今天，由于技术的发展，我们大多数人都能找到重要的帮助，包括人工智能。人工智能机器人在帮助人们完成知识任务方面是相当新的，但如果它们有助于改善我们的福祉呢？

![](img/026fa4f6d042b4ed4ff522dcc481dab8.png)

[附身摄影](https://unsplash.com/@possessedphotography?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

# 人类有许多种情绪

作为人类，我们并不总是完全意识到，快乐，甚至沮丧。事实是，我们在许多不同的情绪和精神状态中摇摆不定。

说一个人有意识、有智慧是对的，但并不总是如此。事实上，我们会犯错误，从错误中我们会改变自己的行为，学习和提高自己，即使是这个星球上最聪明的人。

这就是为什么技术给了我们很大的帮助:因为我们并不完美，我们永远也不会完美。每一次我们用网络搜索某样东西或者和朋友讨论某件事情，都是为了提升自己或者缓解某个问题，我们不得不承认这是一种成功。

# 人工智能是一种和其他技术一样的技术

最近的事件告诉我们，人工智能可能是危险的，因为它超越了人类的能力，并且仍然容易发生事故。在许多领域，人类曾经是地球上最聪明的生物。他们现在是在创造一种工具，从他们自身的存在中去除意义吗？这是真的，但只是部分原因，因为像任何技术一样，它帮助我们，而不是相反。

更不用说我们已经拥有了远远超越我们的技术:没有人拥有谷歌的知识，没有人可以像现在的算法一样预测天气，没有人可以在没有技术的情况下与世界上的 10 个人会面。所以 AI 也是一样:它会越来越超越我们，但我们也会随之进化。

当然，每一项新技术也可能被用于不良目的，AI 也不例外。然而，公司和国家总是有技术进步来保证安全和道德。

![](img/624360672e6250d58b05fb3dca00805a.png)

照片由[布鲁斯·马尔斯](https://unsplash.com/@brucemars?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

# 我们已经被人工智能编程了

今天，我们的福祉直接或间接地与人工智能等技术联系在一起。我们已经获得了许多信息和知识，这些信息和知识的运作方式就像积极的编程一样:许多 Youtube、脸书或 Twitter 的建议都与人工智能合作，以帮助我们的个人发展，开发我们喜欢的东西，或者提醒我们注意我们可能错过的重要事情。即使它可以被视为侵入，它总是有隐私保护。人们喜欢它，因为它很有用，任何人都可以自由选择使用或不使用这些服务。

除此之外，许多人阅读书籍或视频是为了获得动力和快乐，它们的可用性也通过推荐系统和社交网络由人工智能提高。

现在，如果我们更进一步想象:人工智能会以积极的方式直接影响我们呢？

电影《Her 》( 2013)描绘了一个伟大的行为人工智能，但也具有一般化的知识。

# 特定的行为人工智能比一般的人工智能更容易开发

大型科技公司专注于非常先进和通用的人工智能，取得了令人印象深刻的成果，但需要大量的计算能力和内存。那些人工智能是像 [GPT-3](https://openai.com/blog/customized-gpt-3/) (不久 [GPT-4](https://towardsdatascience.com/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253) )、[加托](https://www.deepmind.com/publications/a-generalist-agent)或[λ](https://blog.google/technology/ai/lamda/)这样的技术。加托和拉姆达已经被编程为非常友好和明智的用户。此外，它们还回答超出人类能力的问题。然而，目前公众无法接触到它们，它们只是友好或正式的:它们不能用幽默或权威的方式讲述事情，一些特定的人类情况可能需要不同的行为信息。例如，在无人驾驶汽车中遇到紧急危险时，说“马上离开！”总比“由于系统故障，请你在短时间内离开好吗？”

请注意，谷歌已经通过 [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html) (Pathways 语言模型)对[解释笑话的幽默](https://thenextweb.com/news/google-palm-ai-sucks-at-telling-jokes-but-great-at-analyzing-them)进行了研究。

另一方面，许多公司受益于小型聊天机器人，这些机器人可以轻松获取复杂但有限的业务信息。

事实上，我们可以使用对特定目的有用的较小的人工智能，而不是拥有覆盖广泛知识的通用人工智能。

在健康领域，人工智能主要是行为方面的，并且还具有关于用户或特定主题(心理学、哲学、笑话等)的知识。).

现有的幸福行为人工智能有:

*   [雷普利卡](https://replika.com/):一个善良的 AI 伴侣。
*   Inspiro 机器人:用人工智能生成报价，创造放松的环境。
*   AIFriends :动机类、搞笑类、推理类聊天机器人。

这些人工智能建立在较小的模型上，如 Bert、GPT-2、GPT-Neo 或 XL-NET，它们已经可供公众使用。

即使它们可能会有小错误，而且不如 GPT-3、加托和 Lambda 那么强大，但用它们来以一种好的方式给我们自己编程还是很有趣的。

我们可以说它们是中立的工具，可以给我们有用的和适应的想法、建议或知识。

# 结论

先进的人工智能机器人最近取得了巨大的进步，但它们还没有向公众开放，它们只有正式或友好的行为。然而，在人工智能机器人上有越来越多的举措来帮助人们的日常生活。与传统的健康顾问、书籍或视频相比，它们的中立性和对用户需求的适应性是优势。

你认为行为人工智能在未来几年会是一个新的研究领域吗？欢迎发表评论。