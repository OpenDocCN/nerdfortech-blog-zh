<html>
<head>
<title>Data Cleaning: Inconsistent Data Entry</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据清理:不一致的数据输入</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/data-cleaning-inconsistent-data-entry-7731ac3c52c7?source=collection_archive---------3-----------------------#2021-06-24">https://medium.com/nerd-for-tech/data-cleaning-inconsistent-data-entry-7731ac3c52c7?source=collection_archive---------3-----------------------#2021-06-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/2593cb0963d70b8e3c7dec1c1a483163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*ra0utGoOQQh_P90U.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">由<a class="ae iq" href="http://www.intellspot.com/what-is-data-cleansing/" rel="noopener ugc nofollow" target="_blank">intellespot</a>拍摄的照片</figcaption></figure><p id="150d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">有几种方法可以清除数据输入的不一致性，并确保数据已被清除并准备好进行分析。当然，第一种方法是手动检查每一行，如果发现不一致的地方就修复。但是，有一种更有效的方法可以做到这一点，比如做一些初步的文本预处理。</p><h1 id="dc89" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">设置我们的环境</h1><p id="215e" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">首先需要做的是加载将要使用的库和数据集。在本笔记本中，将使用Datacamp课程中的航空公司数据帧。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="64e5" class="lb jq hi kx b fi lc ld l le lf"># import modules<br/>import pandas as pd</span><span id="3057" class="lb jq hi kx b fi lg ld l le lf"># assign url of file: url<br/>url = '&lt;https://assets.datacamp.com/production/repositories/5737/datasets/ba95dfa6d750e4bf2ddda2349cfe0af80ab765ff/airlines_final.csv&gt;'</span><span id="8cad" class="lb jq hi kx b fi lg ld l le lf"># read file airlines<br/>airlines = pd.read_csv(url, sep=',')</span><span id="c64d" class="lb jq hi kx b fi lg ld l le lf"># print the head of the DataFrame<br/>print(airlines.head())</span></pre><p id="7b89" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在我们准备好开始了！您可以像往常一样，在这里花一点时间查看数据并熟悉它</p><h1 id="fd34" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">做一些初步的文本预处理</h1><p id="f6d1" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">在本练习中，Datacamp提供了一个示例，使用了航空公司数据帧中的两个分类列，分别是dest_region和dest_size。由于分类数据和文本数据的非结构化性质，它们通常是数据集中最混乱的部分。在本章中做一些初步的文本预处理意味着如何修复类别标签中的空白和大小写不一致。</p><h1 id="2f11" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">修复大写不一致</h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9c09" class="lb jq hi kx b fi lc ld l le lf"># get all the unique values in the 'dest_region' column<br/>dest_region = airlines['dest_region'].unique()</span><span id="838b" class="lb jq hi kx b fi lg ld l le lf"># sort them alphabetically and then take a closer look<br/>dest_region.sort()<br/>dest_region</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/9e629bdec8b726528c48b058ce064483.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*da9vnf7xyJ3bCshVFqsbFw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:“目标区域”中的唯一值</figcaption></figure><p id="840c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出来看，它显示dest_region列由于大小写而具有不一致的值。例如“美国东部”和“美国东部”，“中东”和“中东”。首先可以做的就是把所有的东西都变成小写。</p><h1 id="1c70" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">小写字母</h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b928" class="lb jq hi kx b fi lc ld l le lf"># Lower dest_region column<br/>airlines['dest_region'] = airlines['dest_region'].str.lower()</span><span id="f57a" class="lb jq hi kx b fi lg ld l le lf"># Verify changes have been effected<br/>print(airlines['dest_region'].unique())</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/74460e983f9aff6ef385cdd655509ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*RhUV37JX45uykKqO5J6Feg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:使所有内容小写后,' dest_region '中的唯一值</figcaption></figure><p id="287d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出中可以看出，dest_region列没有因大写而导致的不一致值。</p><h1 id="f945" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">修复空白</h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="266d" class="lb jq hi kx b fi lc ld l le lf"># get all the unique values in the 'dest_size' column<br/>dest_size = airlines['dest_size'].unique()</span><span id="aa90" class="lb jq hi kx b fi lg ld l le lf"># sort them alphabetically and then take a closer look<br/>dest_size.sort()<br/>dest_size</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/80e1857fb38c6fcc14f459c28b680f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*GCJDw0FHLTAGRk2q7D1kZQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:“目标大小”中的唯一值</figcaption></figure><p id="3928" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出中可以看出，dest_size列只有由前导空格和尾随空格引起的不一致的值。例如“中枢”和“中枢”。可以做的第一件事是删除单元格开头和结尾的空白。</p><h1 id="5ea3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">删除空白</h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="a479" class="lb jq hi kx b fi lc ld l le lf"># Remove white spaces from `dest_size`<br/>airlines['dest_size'] = airlines['dest_size'].str.strip()</span><span id="1d1c" class="lb jq hi kx b fi lg ld l le lf"># Verify changes have been effected<br/>print(airlines['dest_size'].unique())</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/bae7d4a2e9648f1f2cf54331beffb2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*oWpJgBKJLe2UX9nqzlTFsg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:删除空白后' dest_size '中的唯一值</figcaption></figure><p id="3bb3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出中可以看出，dest_size列没有因前导空格和尾随空格而导致的不一致值。大小写不一致和尾随空白在文本数据中很常见，这样做可以修复80%的文本数据输入不一致。</p><h1 id="c7da" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">使用模糊匹配纠正不一致的数据输入</h1><p id="f86b" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">好的，让我们再看一下dest_region列，看看是否还有不一致的地方。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="b644" class="lb jq hi kx b fi lc ld l le lf"># get all the unique values in the 'dest_region' column<br/>dest_region = airlines['dest_region'].unique()</span><span id="ba0c" class="lb jq hi kx b fi lg ld l le lf"># sort them alphabetically and then take a closer look<br/>dest_region.sort()<br/>dest_region</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lp"><img src="../Images/a9ca1479ac6113ef079af76d73c74251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6mykapXAMwmvnUWUUL929A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:“目标区域”中的唯一值</figcaption></figure><p id="0025" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">看起来确实还有一些不一致的地方:“欧洲”和“欧元”应该是一样的。</p><p id="1820" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><a class="ae iq" href="https://github.com/seatgeek/fuzzywuzzy" rel="noopener ugc nofollow" target="_blank"> fuzzywuzzy </a>包来帮助识别哪些字符串彼此最接近。这个数据集足够小，我们也许可以手动纠正错误，但这种方法不能很好地扩展。(你会想要手动纠正一千个错误吗？一万呢？尽早实现自动化通常是个好主意。</p><blockquote class="lq lr ls"><p id="2847" class="ir is lt it b iu iv iw ix iy iz ja jb lu jd je jf lv jh ji jj lw jl jm jn jo hb bi translated"><strong class="it hj">模糊匹配:</strong>自动寻找与目标字符串非常相似的文本字符串的过程。一般来说，如果将一个字符串转换为另一个字符串，需要更改的字符越少，就认为该字符串与另一个字符串越“接近”。所以“apple”和“snapple”相距两个变化(加上“s”和“n”)，而“in”和“on”相距一个变化(r用“o”代替“I”)。你不可能总是100%地依赖模糊匹配，但它通常会为你节省一点时间。</p></blockquote><p id="04b3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">给定两个字符串，Fuzzywuzzy返回一个比率。比率越接近100，两个字符串之间的编辑距离就越小。在这里，我们将从dest_region列表中获取距离“欧洲”最近的五个字符串。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="2c4b" class="lb jq hi kx b fi lc ld l le lf"># get the top 5 closest matches to "europe"<br/>matches = fuzzywuzzy.process.extract("europe", dest_region, limit=5, scorer=fuzzywuzzy.fuzz.token_sort_ratio)</span><span id="230c" class="lb jq hi kx b fi lg ld l le lf"># take a look at them<br/>matches</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/9b0769892c2fa652bd976e8a66b625bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*mrjukvStj3Lq9KjiVEoukQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">输出:最接近“欧洲”的前5个匹配项</figcaption></figure><p id="aebb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出中可以看出，dest_region中的两个条目非常接近“欧洲”:“欧洲”和“欧元”。让我们用“欧洲”替换dest_region列中比率大于65的所有行。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="de25" class="lb jq hi kx b fi lc ld l le lf">def replace_matches_in_column(df, column, string_to_match, min_ratio = 65):<br/>    # get a list of unique strings<br/>    strings = df[column].unique()<br/>    <br/>    # get the top 5 closest matches to our input string<br/>    matches = fuzzywuzzy.process.extract(string_to_match, strings, <br/>                                         limit=5, scorer=fuzzywuzzy.fuzz.token_sort_ratio)</span><span id="b78a" class="lb jq hi kx b fi lg ld l le lf"># only get matches with a ratio &gt; 65<br/>    close_matches = [matches[0] for matches in matches if matches[1] &gt;= min_ratio]</span><span id="ba21" class="lb jq hi kx b fi lg ld l le lf"># get the rows of all the close matches in our dataframe<br/>    rows_with_matches = df[column].isin(close_matches)<br/>    <br/>     # replace all rows with close matches with the input matches <br/>    df.loc[rows_with_matches, column] = string_to_match<br/>    <br/>    # let us know the function's done<br/>    print("All done!")</span></pre><p id="d8d2" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在让我们再次检查dest_region列中的唯一值，确保我们已经正确地整理了欧洲。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="bf0e" class="lb jq hi kx b fi lc ld l le lf"># use the function to replace close matches to "europe" with "europe"<br/>replace_matches_in_column(df=airlines, column='dest_region', string_to_match="europe")</span><span id="d003" class="lb jq hi kx b fi lg ld l le lf"># get all the unique values in the 'dest_region' column<br/>dest_region = airlines['dest_region'].unique()</span><span id="a507" class="lb jq hi kx b fi lg ld l le lf"># sort them alphabetically and then take a closer look<br/>dest_region.sort()<br/>dest_region</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/65f44866ebcf00d73f5468c4ce33a955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*ju21v1-r9ndqvP2cYhX9LQ.png"/></div></figure><p id="45fc" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">从输出来看，dest_region列似乎没有问题。现在，我们在数据框架中只有“欧洲”,我们不需要手动更改任何内容。</p></div><div class="ab cl lz ma gp mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="hb hc hd he hf"><p id="f51c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">来源:</p><p id="8c3c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><a class="ae iq" href="https://campus.datacamp.com/courses/cleaning-data-in-python/text-and-categorical-data-problems?ex=6" rel="noopener ugc nofollow" target="_blank">数据营课程:用Python清理数据</a></p><p id="4cbd" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><a class="ae iq" href="https://www.kaggle.com/rtatman/data-cleaning-challenge-inconsistent-data-entry" rel="noopener ugc nofollow" target="_blank"> Rachael Tatman:数据清理挑战不一致的数据输入</a></p></div></div>    
</body>
</html>