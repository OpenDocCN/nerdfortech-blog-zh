<html>
<head>
<title>Convolutional Neural Network in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中的卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/convolution-neural-network-in-pytorch-81023e7de5b9?source=collection_archive---------1-----------------------#2022-02-06">https://medium.com/nerd-for-tech/convolution-neural-network-in-pytorch-81023e7de5b9?source=collection_archive---------1-----------------------#2022-02-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a868" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将解释CNN是如何工作的，并使用PyTorch实现稍微修改的<strong class="ih hj"> LeNet5 </strong>模型。以上是我关于卷积神经网络的笔记，以通俗易懂的方式总结在一起，帮助你理解这个话题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/41b7082f00e6ef41123d0f3433c4ca12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LcOKZ_YnenqjQNZq"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@mcnoble?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马特·诺布尔</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="3a89" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated"><strong class="ak">我们为什么要使用卷积神经网络？</strong></h1><p id="590c" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">CNN类似于常规的神经网络。它们有重量和偏差，但它们是专门为计算机视觉任务设计的，如对象识别或图像分割。自2012年以来，它们一直是深度学习革命的驱动力，因为它们能够利用GPU的能力和处理大量数据。</p><p id="4915" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好的，让我们看看ConvNets的构建模块是什么以及它们是如何工作的！</p><h1 id="bdfe" class="kb kc hi bd kd ke le kg kh ki lf kk kl km lg ko kp kq lh ks kt ku li kw kx ky bi translated"><strong class="ak">建筑</strong></h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/7d84187859a5a6aa0491893a1e89d32c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tml32kKyG9XRehPlgMdhKw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">通信网的总体结构</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/12b5a1931778ca2ade1700e4295d43f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CDTli8CvPwV70yA0sjNqUA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">LeNet5架构[3]</figcaption></figure><p id="1b4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特征提取器</strong>包括:</p><ul class=""><li id="daa3" class="ll lm hi ih b ii ij im in iq ln iu lo iy lp jc lq lr ls lt bi translated">卷积层</li><li id="4f8e" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated">池层(“二次采样”)</li></ul><p id="25c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分类</strong> <strong class="ih hj">块</strong>使用<strong class="ih hj">全连接层</strong>(“全连接”)给出最终预测。</p><p id="2e99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在每个卷积或全连接层之后，我们添加非线性激活函数(除了最后一层，这里我们使用<strong class="ih hj"> Softmax </strong>)。目前，<strong class="ih hj"> ReLU </strong>是一个常用函数，因为<strong class="ih hj"/><strong class="ih hj"/>计算速度更快，效果最好。</p><blockquote class="lz ma mb"><p id="851a" class="if ig mc ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">我将尝试简要介绍每一层的用途和属性，我们可以直接进入编码。</p></blockquote><h2 id="6369" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated">先说卷积层！</h2><p id="db24" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">简单来说，卷积就是随图像滑动的<strong class="ih hj">滤波器</strong>，计算乘和。那么，过滤器是什么呢？</p><p id="0339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可能使用了棕褐色的效果，给照片增加了一种温暖的棕色调。事实上，它是一个带有<strong class="ih hj">预定义的</strong>值的3x3窗口，在图片中移动。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/5f8f07bec2d680bbbfd680b6c16e8149.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/1*crY_UrQUkOIpj-rTuudTgQ.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">卷积运算[1]</figcaption></figure><p id="81fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在CNN中，我们要<strong class="ih hj">学习</strong>这些值来提取相关特征。学习过程使用反向传播算法，与常规神经网络相同。</p><p id="7aa2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积层有四个<strong class="ih hj">超参数</strong>，决定输出的大小:</p><ul class=""><li id="7d75" class="ll lm hi ih b ii ij im in iq ln iu lo iy lp jc lq lr ls lt bi translated"><strong class="ih hj">滤波器尺寸</strong> —标准选择是3x3和5x5，根据经验，3x3可产生最佳精度结果</li><li id="e631" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated"><strong class="ih hj">深度</strong> —输出中<strong class="ih hj">滤波器的数量</strong>，由于计算原因通常为2的幂。当我们得到一个更深的网络时，每一层都有更广范围的特性和抽象联系可以寻找。因此，我们在每一层增加它们的数量，通常像[64，128，256…]。</li><li id="9cea" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated"><strong class="ih hj">步幅</strong> —控制滤镜的移动。如果步长为1，我们将过滤器移动一个像素。当stride为2时，我们将过滤器移动两个像素。它减小了输出的大小，从而加快了计算速度。</li></ul><p id="c020" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了检查步数是否可行，该等式的结果必须是整数:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/19eb966d2210fa97074a290143f1ad1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/1*A3ZOiGvFVbnavNqHM0Qq2g.gif"/></div></figure><ul class=""><li id="cb60" class="ll lm hi ih b ii ij im in iq ln iu lo iy lp jc lq lr ls lt bi translated"><strong class="ih hj">填充</strong> —控制空间输出大小的另一种方法，但这次是通过在边界周围添加零。<strong class="ih hj">补零(" same") </strong>有助于保持初始大小。<strong class="ih hj">“有效”</strong>表示完全没有填充。这对更深的网络是有益的，如果没有它，交易量会下降得太快。</li></ul><p id="9674" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算<strong class="ih hj">输出尺寸</strong>的公式:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/aac2b0518802ef862f47d43f5ef4cb82.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/1*H_XYjb-ub65vYq07sz-VGw.gif"/></div></figure><h2 id="d3fa" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated"><strong class="ak">汇集层</strong></h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mx"><img src="../Images/4510d8d50f3e8d68bb457621b85efab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqslBT7Ws03rRgEKMlX3Kw.png"/></div></div></figure><p id="9619" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个下采样操作给予网络一定量的<strong class="ih hj">平移不变性。</strong>共有两种不同的联营方式:</p><ul class=""><li id="b76b" class="ll lm hi ih b ii ij im in iq ln iu lo iy lp jc lq lr ls lt bi translated"><strong class="ih hj">最大汇集</strong> —取窗口的最大值，从而提取最清晰和最明亮的特征</li><li id="235f" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated"><strong class="ih hj">平均池</strong> —取窗口的平均值，从而提取平滑特征</li></ul><blockquote class="lz ma mb"><p id="3e78" class="if ig mc ih b ii ij ik il im in io ip md ir is it me iv iw ix mf iz ja jb jc hb bi translated">如今，合并操作主要被大步取代。[2]</p></blockquote><h2 id="b68a" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated"><strong class="ak">全连通层</strong></h2><p id="6302" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">它们用于学习从不同过滤器提取的特征之间的<strong class="ih hj">连接</strong>，并输出类别预测的概率。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es my"><img src="../Images/fb31c8306e5eac73c85fa5ea5b0001cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TjsyTu0SJC5ZPZPdlY9SQQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">输出计算和超参数</figcaption></figure><h1 id="f9f6" class="kb kc hi bd kd ke le kg kh ki lf kk kl km lg ko kp kq lh ks kt ku li kw kx ky bi translated">编码</h1><p id="f240" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">最后，经过一点理论，我们准备做一些编程。如果想看完整的代码，可以看看我的<a class="ae jt" href="https://github.com/maciejbalawejder/DeepLearning-collection/blob/main/ConvNets/LeNet/LeNet5.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github </strong> </a>。</p><h2 id="7f77" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated">LeNet模型</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="db7d" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated">培训功能</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="e203" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated">资料组</h2><p id="f23b" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我使用了著名的MNIST数据集，它非常适合这样一个简单的模型。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mz na l"/></div></figure><h2 id="6de2" class="mg kc hi bd kd mh mi mj kh mk ml mm kl iq mn mo kp iu mp mq kt iy mr ms kx mt bi translated">培训和测试</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mz na l"/></div></figure><h1 id="22f0" class="kb kc hi bd kd ke le kg kh ki lf kk kl km lg ko kp kq lh ks kt ku li kw kx ky bi translated"><strong class="ak">结果</strong></h1><p id="90b4" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">经过2分钟的训练，模型达到了大约98.5%的准确率。我还绘制了特征地图，以查看过滤器如何提取特征。如果你对特征地图如何寻找不同的输入感兴趣，我推荐这个<a class="ae jt" href="https://tensorspace.org/html/playground/lenet.html" rel="noopener ugc nofollow" target="_blank">网站</a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/c0c6b55ad2c0a1a57e030a69bb2a56fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVNl_GdgfFP2ADH0Iz1maQ.png"/></div></div></figure><div class="je jf jg jh fd ab cb"><figure class="nc ji nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/ee9e8f0e19da2eee74741ac04898ac18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*2hEOQm-97F12JwQ-VjG-nQ.png"/></div></figure><figure class="nc ji nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/99d1acb44adf47eac00caff2e076678c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qJklXBxC1in00JEho_duxQ.png"/></div></figure></div><h1 id="71ea" class="kb kc hi bd kd ke le kg kh ki lf kk kl km lg ko kp kq lh ks kt ku li kw kx ky bi translated">结论</h1><p id="f960" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">卷积神经网络是深度学习的基础，在许多领域发挥着重要作用，如对象识别、图像分割或医学成像。因此，了解它们是如何优化和升级的至关重要。我希望读完这篇文章后，您能够在PyTorch中构建自己的ConvNet！</p><p id="aebf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想看我的其他项目，请查看我的<a class="ae jt" href="https://maciejbalawejder.medium.com/" rel="noopener"> <strong class="ih hj">中型</strong> </a>和<a class="ae jt" href="https://github.com/maciejbalawejder" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github </strong> </a> <strong class="ih hj"> </strong>个人资料。</p><h1 id="138c" class="kb kc hi bd kd ke le kg kh ki lf kk kl km lg ko kp kq lh ks kt ku li kw kx ky bi translated">参考</h1><p id="d7b8" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1603.07285.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a>深度学习卷积运算指南</p><p id="c80a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1412.6806.pdf" rel="noopener ugc nofollow" target="_blank">【2】</a>力求简单:全卷积网</p><p id="acec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jt" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">【3】</a>基于梯度的学习应用于文档识别</p></div></div>    
</body>
</html>