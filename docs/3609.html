<html>
<head>
<title>Batch Normalization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">批量标准化</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/batch-normalization-51e32053f20?source=collection_archive---------6-----------------------#2021-06-16">https://medium.com/nerd-for-tech/batch-normalization-51e32053f20?source=collection_archive---------6-----------------------#2021-06-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/703f313d9f2c1deee7a58b70a74b33e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iSt7OHP2l5JHF10f.jpg"/></div></div></figure><p id="34da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在开始我们的主题之前，让我们看看为什么规范化对于数据是一件重要的事情。当进入数据分析/预测部分时。</p><p id="a6d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">什么是数据规范化？</strong></p><p id="f6ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当今世界正在处理我们日常生活中的数据。比方说，从亚马逊购买产品，评论你以前购买的产品，添加到每日观看的网络系列中，所有这些都代替了数据收集。同样的数据对预测/客户推荐也很有用。好吧！。让我们从为什么要对数据进行归一化开始。在任何数据库世界中，在将数据用于分析/业务需求之前，都应该对数据进行规范化。通常，数据也可能具有冗余结构。我们还需要删除冗余数据。然后需要有表之间的键映射才能有更好的理解。这一切都是为了使数据规范化。当数据被规范化时，在表/应用程序级 CRUD 操作之间的查询获取可以更容易地完成。让我们开始理解为什么在 ML 中需要规范化。</p><p id="fedc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在 ML 中归一化</strong></p><p id="e470" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设数据集有两种类型的变量，一种以英里为单位，另一种以小时为单位。如果不应用标准化，模型不会提供最佳结果。因此，我们需要在应用模型之前将数据标准化。有一个步骤叫做‘数据预处理’。这将通过应用以下三种技术来实现数据规范化。</p><ul class=""><li id="fb58" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">重新调整:</strong>也称为“最小-最大归一化”，是所有方法中最简单的方法，计算如下:</li></ul><figure class="jy jz ka kb fd ij er es paragraph-image"><div class="er es jx"><img src="../Images/77e80c9a4bc2306b9972d9d58d50cd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/0*_nJjWPBuJH8YCmgX.png"/></div></figure><ul class=""><li id="b9bd" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">均值归一化:</strong>该方法使用转换过程中观察值的均值:</li></ul><figure class="jy jz ka kb fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/cc509ac1ddb0e80ca963461ba3473ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/0*8pylYBRjIfRLCvVo.png"/></div></figure><ul class=""><li id="1e1d" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj"> Z 分数标准化:</strong>也称为标准化，这种技术使用 Z 分数或“标准分数”。它广泛用于机器学习算法，如 SVM 和逻辑回归:</li></ul><figure class="jy jz ka kb fd ij er es paragraph-image"><div class="er es kd"><img src="../Images/d585c76cce09b34e7c55d1e1329029d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/0*jkPnAmI-8pznH9D1.png"/></div></figure><p id="1d1b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，z 是标准分数，是总体均值，ϭ是总体标准差。</p><p id="6061" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望所有的理解都到位。下面详细开始批量归一化。</p><p id="13dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">为什么需要批量标准化？</strong></p><p id="8a41" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">批量归一化适用于深度学习模型。其中输入以层的形式结构化。该层具有多个神经元，并且每个神经元被分配一个权重。增加的权重作为输入传递给另一层。第二层使用权重和流程，并为另一层提供输入。整个数据集不是作为输入传递到图层，而是作为小批传递。</p><figure class="jy jz ka kb fd ij er es paragraph-image"><div class="ab fe cl ke"><img src="../Images/cded65782955f78efef9e6346b98b1d8.png" data-original-src="https://miro.medium.com/v2/format:webp/0*eaw1POHESc--l5yR.png"/></div></figure><p id="22db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着不同的小批量数据在网络中加载和传递，各层的输入分布会发生跳跃，这使得各层的工作变得更加困难。除了拟合基础分布之外，所讨论的图层现在还必须考虑图层输入分布中的漂移。这种转移输入分布的现象被称为<strong class="is hj"> <em class="kf">内部同变量转移</em> </strong>。因此，通过使用批量标准化技术，这个问题得到解决。</p><h1 id="ccf2" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">那么，什么是内部协变量转移呢？？</h1><blockquote class="le lf lg"><p id="258b" class="iq ir kf is b it iu iv iw ix iy iz ja lh jc jd je li jg jh ji lj jk jl jm jn hb bi translated"><em class="hi">“</em><strong class="is hj"><em class="hi">内部协变移位</em> </strong> <em class="hi">是由于训练过程中网络参数的变化而引起的网络激活分布的变化。”</em></p></blockquote><figure class="jy jz ka kb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/be2afba760f4a313ae780698203e6d18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kXGMr1oiR1M3JK-s.jpeg"/></div></div></figure><p id="8962" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你的关系网越深，内部协变<em class="kf">引起的混乱</em>就越多。让我们记住，神经网络通过电话的数学游戏来学习和调整它们的权重(链中的人或“层”越多，消息就越混乱)。作为神经网络的构建者，我们的工作是<strong class="is hj">稳定</strong>并改善输出层结果和每个隐藏层节点之间的联系。</p><blockquote class="le lf lg"><p id="d66f" class="iq ir kf is b it iu iv iw ix iy iz ja lh jc jd je li jg jh ji lj jk jl jm jn hb bi translated">当我们网络的输入分布发生变化时，就会发生<strong class="is hj">内部协变量偏移</strong>。当输入分布改变时，隐藏层试图学习适应新的分布。这会减慢训练过程。如果一个过程变慢了，需要很长时间才能收敛到全局最小值。当网络输入的统计分布与以前看到的输入有很大不同时，就会出现这个问题。批处理规范化和其他规范化技术可以解决这个问题。</p></blockquote><p id="79e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你玩过用杯子和绳子打电话的游戏吗？把这个想象成，只有你可以调整你的手机，让它更清晰(例如，调整你的参数)。第一个人告诉第二个人，“去给植物浇水”，第二个人告诉第三个人，“你裤子里有水”，等等，直到最后一个人听到，“风筝砰的一声吃掉脸猴”或者其他完全错误的话。让我们说，这些问题完全是系统性的，完全是因为有缺陷的红杯子。</p><figure class="jy jz ka kb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/d5e396e0967b1a6cdee3774b492d30a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gB9WfCMRnCkdo5_T.png"/></div></div></figure><figure class="jy jz ka kb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/a870905e748e7d4dde3059371023e3a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Fh9lkZraETRvzYyb.png"/></div></div></figure><figure class="jy jz ka kb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/062ff9257314062d450216ff0a3457c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H4bluJPzahDVZ03b.png"/></div></div></figure><p id="75f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，假设我们可以修理我们的杯子(或者换个新的),这样我们可以更好地传递信息。我们告诉最后一个人正确的答案，他稍微修理了一下他的杯子，然后通过与倒数第二个人交谈来测试它。倒数第二个家伙告诉倒数第三个家伙去修理东西，然后一直回到第一个家伙。反向传播，对吗？</p><p id="13ef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">问题是，每个人都在同时修理东西。所以，当一个人告诉另一个人事情时，他是用他的新杯子，也就是参数来做的。这很糟糕，因为每个人都根据他后面的人告诉他的话得到了一部新手机/一个新杯子……只是信息变了，因为杯子变了。换句话说:您的第一层参数发生变化，因此第二层的输入分布也会发生变化。通过改变参数，你会有意地导致 Szegedy 所说的“内部协变量转移”。通常情况下，只有几层不是问题；当你有一个真正深度的神经网络时，事情会变得非常棘手。</p><p id="1fa2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这还不是结束。深度学习模型中会出现一些梯度问题。爆炸梯度和消失梯度是出现的两个问题，如果网络看起来很大，这两个问题会更严重。如果问题出现，模型效率会降低，并且各层之间的计算时间会很长。一切就绪后，我们如何解决这个问题？答案是‘批量归一化’可以解决这个问题。开始之前，让我们先介绍一下那些渐变的东西。</p><figure class="jy jz ka kb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/3835228b930fc16873aa6c69e84a9453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QJCLgucWbHZPI1Ui.png"/></div></div></figure><p id="48b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">消失渐变</strong></p><p id="e9ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">消失梯度是训练神经网络的主要问题。每层具有多个神经元。每个神经元都有一个加权值。在训练中,(随机梯度下降)SCG 计算损失相对于网络中权重的梯度。正常情况下，神经元的重量相当小。在那种情况下，对个体权重的梯度计算也导致小的。换句话说，梯度消失了。因此，这个问题被称为“消失梯度”。你认为渐变消失的问题是因为小的渐变/固定的权重引起的吗？。我们可以更好地理解它。</p><p id="bc6c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">小渐变</strong></p><ul class=""><li id="cc7b" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">通常情况下，梯度计算会产生一个非常小的值。如果任何一个值乘以一个小值，结果也是这个小值。同样的原则也适用于此。梯度是根据神经元的权重计算的。因此，神经元的加权值完全取决于小梯度的产生。</li></ul><p id="ab2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">卡住重物</strong></p><ul class=""><li id="c2b8" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">我们已经知道神经元的重量已经很小了，到了乘以学习率的时候。我们得到一个小值。因此，新的加权值是通过用学习率减去旧值和新计算的权重来计算的。最后，加权值也变小。加权值不动且停滞。不在学习阶段。我们可以说新的加权值大约等于旧的加权值。体重没有任何提高。</li></ul><p id="b214" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">爆炸渐变</strong></p><p id="53d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">术语所指的分解渐变是分解渐变。耶！在前面的例子中，我们看到梯度是如何导致一个非常小的，但是这里有点相反，比如说大的加权值导致大的梯度。因此，该模型不能很好地执行，并导致较低的准确性。此外，计算出的梯度权重达到最佳值以上。对于每一个新的加权计算，该值增加并进一步乘以学习率。新的权重会很大。新的权重将被极大地转移/快速跳高，但不会达到局部最小值。</p><p id="3894" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">批量归一化</strong></p><p id="2468" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">批量标准化是一个层，允许网络的每一层更独立地进行学习。它用于标准化先前层的输出。激活在规范化中缩放输入图层。使用批量标准化学习变得有效，它还可以用作正则化以避免模型的过拟合。该层被添加到顺序模型以标准化输入或输出。使用这种技术可以避免 ICS 和梯度问题。简而言之，将层权重归一化为均值 0，标准差 1。</p><p id="390f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">批量规范化是如何工作的？</strong></p><p id="5b6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们现在引入批量标准化的概念，它实际上是标准化一个层的输出激活，然后做更多的事情。这里有一个精确的描述。</p><figure class="jy jz ka kb fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/bbbf1a0308c4f7bf9a9c8668de31555a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*0hUjkt4jHQJoubJDzporsA.png"/></div></figure><p id="fc3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面的等式描述了批处理规范层的作用。等式 2-4 描述了如何计算小批量每次激活的平均值和方差，然后减去激活中心的平均值至零，再除以标准偏差。这是为了确定小批量单位(1)中每次激活的标准偏差。</p><p id="5002" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意，这里计算的平均值和方差是小批量的平均值和方差。</p><p id="0eb3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">等式 5 是真正神奇的地方。γ和β是所谓的批量归一化层的超参数。等式 5 的输出均值为β，标准差为γ。实际上，批量标准化层有助于我们的优化算法控制该层输出的均值和方差。</p><p id="f1e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，当我们在层之间添加批量归一化层时，一个层的统计量只受两个超参数γ和β的影响。现在，我们的优化算法只需调整两个超参数来控制任何层的统计数据，而不是控制前一层的整个权重。</p><p id="3935" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在 Python 中创建批量规范化</strong></p><p id="17cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有两种方法可以实现批量实现。我们来详细看看。</p><p id="47ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">接近 1 </strong></p><p id="c93c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，批量标准化在激活功能之后应用。</p><pre class="jy jz ka kb fd lq lr ls lt aw lu bi"><span id="5a7e" class="lv kh hi lr b fi lw lx l ly lz">LAYERS_BN = [<br/>    tf.keras.layers.Flatten(input_shape=[28, 28]),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Dense(300, activation="relu"),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Dense(100, activation="relu"),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Dense(10, activation="softmax")<br/>]</span><span id="89cf" class="lv kh hi lr b fi ma lx l ly lz">model = tf.keras.models.Sequential(LAYERS_BN)</span></pre><p id="793b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">方法 2 </strong></p><p id="57a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，批量标准化在激活函数之前应用。您可以看到 use_bias 应用为 False。基本上，BN 保持可用作偏置的恒定值。</p><pre class="jy jz ka kb fd lq lr ls lt aw lu bi"><span id="020a" class="lv kh hi lr b fi lw lx l ly lz">LAYERS_BN_BIAS_FALSE = [<br/>    tf.keras.layers.Flatten(input_shape=[28, 28]),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Dense(300, use_bias=False),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Activation("relu"),<br/>    tf.keras.layers.Dense(100, use_bias=False),<br/>    tf.keras.layers.BatchNormalization(),<br/>    tf.keras.layers.Activation("relu"),<br/>    tf.keras.layers.Dense(10, activation="softmax")<br/>]</span><span id="3b32" class="lv kh hi lr b fi ma lx l ly lz">model = tf.keras.models.Sequential(LAYERS_BN_BIAS_FALSE)</span></pre><p id="d568" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，编译并应用模型如下:</p><pre class="jy jz ka kb fd lq lr ls lt aw lu bi"><span id="1457" class="lv kh hi lr b fi lw lx l ly lz">## Model Compilation </span><span id="2805" class="lv kh hi lr b fi ma lx l ly lz">model.compile(loss="sparse_categorical_crossentropy",<br/>              optimizer=tf.keras.optimizers.SGD(lr=1e-3),<br/>              metrics=["accuracy"])</span><span id="8b42" class="lv kh hi lr b fi ma lx l ly lz">## Model Fitting</span><span id="74c0" class="lv kh hi lr b fi ma lx l ly lz">history = model.fit(X_train, y_train, epochs=10,<br/>                    validation_data=(X_valid, y_valid))</span></pre><p id="227a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望这篇文章能让您更好地理解批处理规范化。</p><p id="a7a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢您阅读这篇文章。下一篇文章再见:)</p></div></div>    
</body>
</html>