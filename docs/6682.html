<html>
<head>
<title>Decision Tree Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树算法</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/decision-tree-algorithm-3b5e8b0aed2a?source=collection_archive---------4-----------------------#2022-04-19">https://medium.com/nerd-for-tech/decision-tree-algorithm-3b5e8b0aed2a?source=collection_archive---------4-----------------------#2022-04-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2361897ff14fc4361bdaed13633f9bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VHwcFbN3SqUCV7dg08mekQ.jpeg"/></div></div></figure><p id="14b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树算法是我们在机器学习中使用的一种流行的分类算法。这种算法属于监督类。在这篇文章中，我们将看到什么是决策树算法，它的工作原理以及这种算法可以用在什么地方。</p><p id="11ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了理解算法的工作原理，需要一个合适的数据集。我拿了一个非常受欢迎的数据集，要查看数据集<a class="ae jo" href="https://www.kaggle.com/code/arya24/let-s-classifiy/data" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。</p><p id="bcfe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们先来了解一下数据。这个数据集很受欢迎，也很容易理解。它有六列。这个数据集是关于鸢尾物种的。这些属性描述了花的特征，如萼片长度、萼片宽度、花瓣长度和花瓣宽度。第一列是物种的唯一 id，最后一列是特定物种的名称。我们必须根据这些特征将数据分为三个不同的种类。</p><p id="240c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们开始处理数据。首先，我们必须导入所需的库和数据。因为我们要使用决策树算法，所以我们需要导入所需的库。Sklearn/sci-kit learn 是 python 中流行的库之一。这个库包含了很多机器学习的有效工具，包括分类、回归、聚类和降维。要了解更多关于 sci-kit learn 的信息，可以参考<a class="ae jo" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">文档</a>。代码如下:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="bb44" class="jy jz hi ju b fi ka kb l kc kd">from sklearn.model_selection import train_test_split                <br/>from sklearn.tree import DecisionTreeClassifier                     <br/>from sklearn.metrics import accuracy_score                          <br/>from sklearn.metrics import classification_report                   <br/>from sklearn import tree    <br/>from sklearn.preprocessing import LabelEncoder<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import plotly.express as px</span></pre><p id="364c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入数据和库之后，让我们来理解和清理数据。我们需要检查数据集中是否存在任何空值。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="6827" class="jy jz hi ju b fi ka kb l kc kd">df.isnull().sum()</span><span id="79e5" class="jy jz hi ju b fi ke kb l kc kd">Id               0<br/>SepalLengthCm    0<br/>SepalWidthCm     0<br/>PetalLengthCm    0<br/>PetalWidthCm     0<br/>Species          0<br/>dtype: int64</span></pre><p id="a068" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此数据中不存在空值。如果我们检查行数和列数，有 150 行和 6 列:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="9d04" class="jy jz hi ju b fi ka kb l kc kd">df.shape<br/>(150, 6)</span></pre><p id="bed5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，为了检查哪些属性对决定物种是重要的，我们将检查它们之间的相关性。虽然我们可以直接说所有属性都是决定性因素，但我们需要在统计上更强。所以让我们检查一下它们之间的相关性。在检查关系之前，我们将对最后一列进行编码。物种列包含分类数据。为了检查相关性，我们需要将分类数据转换成数字数据。标签编码有助于这种转换。因此，让我们首先执行标签编码:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="61d8" class="jy jz hi ju b fi ka kb l kc kd">df1 = df.copy(deep = True)<br/>species = LabelEncoder()<br/>df1['Species'] = species.fit_transform(df['Species'])</span></pre><p id="ff05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，在图的帮助下检查相关性:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="c83f" class="jy jz hi ju b fi ka kb l kc kd">corr1 = df1.corr()<br/>plt.figure(figsize = (12,8))<br/>sns.heatmap(corr1,annot=True)<br/>plt.show()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kf"><img src="../Images/c1388de907c72cadd4c72528e80e7c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UZ5F3s8OZgELeVSh.png"/></div></div></figure><p id="5599" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们可以看到所有的属性都与物种高度相关。花瓣宽度和花瓣长度具有. 96 和. 95 的比率，这意味着高度相关。萼片长度的比率为 0.78。萼片宽度呈负相关，暗示着相反的关系。现在，我们将开始数据建模。在此之前，借助饼图快速检查不同物种的数量:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="b951" class="jy jz hi ju b fi ka kb l kc kd">pie_df = df.Species.value_counts().reset_index()<br/>pie_df.columns = ['Species', 'count']<br/>fig = px.pie(pie_df, values='count', names='Species', title='Species',<br/>             color_discrete_sequence=['blue', 'light green'])<br/>fig.show()</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kg"><img src="../Images/9e58491ae25d324db8b4a85768a906c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dyLUgRbb2fLg8vJYryW8JQ.png"/></div></div></figure><p id="0d03" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，因变量是除 id 和物种之外的所有属性。自变量是物种列，因为我们要预测这一列中的值。</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="13da" class="jy jz hi ju b fi ka kb l kc kd"><em class="kh">#Dependent variables</em><br/>X = np.array(df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]) <br/><br/><em class="kh">#Independent variables</em><br/>y = np.array(df["Species"])</span></pre><p id="e000" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，拆分数据进行测试和训练(我已经按照 1:3 的比例进行了划分，您可以选择适合数据集的大小):</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="18ef" class="jy jz hi ju b fi ka kb l kc kd">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 1)</span></pre><p id="b9eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，使用决策树分类器并拟合数据:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="3aa0" class="jy jz hi ju b fi ka kb l kc kd">tree1 = tree.DecisionTreeClassifier(max_depth=4)<br/>tree1 = tree1.fit(X, y)</span></pre><p id="1d28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们检查分数！</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="9415" class="jy jz hi ju b fi ka kb l kc kd">tree1.score(X, y)</span><span id="c342" class="jy jz hi ju b fi ke kb l kc kd">0.9933333333333333</span></pre><p id="dbc6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">分数是 0.99。这意味着我们已经成功地对数据进行了分类，并且得分很高。现在，让我们看看我们预测的物种名称:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="1a8c" class="jy jz hi ju b fi ka kb l kc kd">y_predicted = tree1.predict(X_test)<br/>y_predicted</span></pre><p id="7c3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出将如下所示:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="d655" class="jy jz hi ju b fi ka kb l kc kd">array(['Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa',<br/>       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',<br/>       'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',<br/>       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',<br/>       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor',<br/>       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',<br/>       'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa',<br/>       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',<br/>       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',<br/>       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',<br/>       'Iris-virginica', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',<br/>       'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',<br/>       'Iris-setosa', 'Iris-virginica', 'Iris-virginica',<br/>       'Iris-versicolor'], dtype=object)</span></pre><p id="89e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以我们已经成功地根据物种对数据进行了分类。如果你想打印一个树形图，你可以使用下面的代码:</p><pre class="jp jq jr js fd jt ju jv jw aw jx bi"><span id="cec1" class="jy jz hi ju b fi ka kb l kc kd">tree.plot_tree(tree1)</span></pre><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/a7b5fc5ed7e5d2f4fef8ab8c5a01525c.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/0*56yAMS-y7hB1l0-j.png"/></div></figure><p id="fb62" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结论:</p><ol class=""><li id="6d29" class="kj kk hi is b it iu ix iy jb kl jf km jj kn jn ko kp kq kr bi translated">决策树算法对于分类非常有用。</li><li id="57d3" class="kj kk hi is b it ks ix kt jb ku jf kv jj kw jn ko kp kq kr bi translated">它过滤数据并将其分成不同的类别。</li></ol><p id="4965" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欢迎你的建议。您可以在此处查看代码:</p><ol class=""><li id="2185" class="kj kk hi is b it iu ix iy jb kl jf km jj kn jn ko kp kq kr bi translated">Kaggle 笔记本:<a class="ae jo" href="https://www.kaggle.com/code/arya24/let-s-classifiy/notebook" rel="noopener ugc nofollow" target="_blank">点击这里</a></li></ol><p id="83f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.GitHub 链接:<a class="ae jo" href="https://github.com/aryatalathi/IRIS-Data-classification" rel="noopener ugc nofollow" target="_blank">点击这里</a></p><p id="6782" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢大家！</p><p id="d0d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="kh">~ ARYA·塔拉西</em></p></div></div>    
</body>
</html>