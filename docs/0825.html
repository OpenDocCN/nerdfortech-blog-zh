<html>
<head>
<title>Why the time complexity for training K-Nearest Neighbors is O(1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么训练 K-最近邻的时间复杂度是 O(1)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/why-the-time-complexity-for-training-k-nearest-neighbors-is-o-1-5b8f417104cf?source=collection_archive---------0-----------------------#2021-02-17">https://medium.com/nerd-for-tech/why-the-time-complexity-for-training-k-nearest-neighbors-is-o-1-5b8f417104cf?source=collection_archive---------0-----------------------#2021-02-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="37a0" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">了解如何从头开始实现 K-最近邻，并了解为什么训练 K-最近邻不需要时间</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/d577c62a1a7f58655a3a24a41ba2b4bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*c-uMJniztw00HEKz"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jn" href="https://unsplash.com/@aronvisuals?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aron 视觉</a>拍摄的照片</figcaption></figure><h1 id="d09d" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">你有没有想过训练和测试一个算法的时间复杂度？</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kg"><img src="../Images/31a803dd6b3eb3d770266f3bd9dd2b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TE98EjTr7pVNRPul"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">由<a class="ae jn" href="https://unsplash.com/@anthonytran?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Anthony Tran </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9c0b" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">与测试相比，大多数算法在训练时花费大量时间。深度学习算法可能需要几个月的时间来训练，但我们有一个经典的机器学习算法，它在测试过程中需要更多的时间，在训练过程中只需要几毫秒。从技术上讲，那些不知道的人，我们称之为时间复杂度，用 O(n)表示。</p><p id="cce8" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">所以对于 KNN 来说，训练的时间复杂度是 O(1 ),这意味着它是常数，而测试的时间复杂度是 O(n ),这意味着它取决于测试实例的数量。</p><p id="f5c4" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">这篇文章的先决条件是对 KNN 算法以及面向对象编程概念有一个基本的了解，如果你还在为 K-最近邻而苦恼，可以看看我关于 KNN 的文章。</p><p id="1aae" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated"><a class="ae jn" rel="noopener" href="/analytics-vidhya/k-nearest-neighbors-part-i-9102f8f3173c?source=your_stories_page---------------------------">K-最近邻-第一部分</a></p><p id="4568" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">首先，我将向您展示分类的 KNN 的实现，然后通过代码，我将向您展示训练和测试的时间复杂性背后的直觉</p><p id="bf60" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们直接跳到代码。首先，让我们导入我们需要的依赖项:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="07bb" class="li jp hi le b fi lj lk l ll lm">import statistics<br/>import time<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.datasets import load_iris<br/>from scikitplot.metrics import plot_confusion_matrix</span></pre><p id="7ecd" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们构建一个 KNearstNeighbor 类，并定义一个构造函数来传递一个参数<strong class="kj hj"> n_neighbors </strong>来定义一些最近的邻居:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="567d" class="li jp hi le b fi lj lk l ll lm">class KNearstNeighbor():<br/>    def __init__(self, n_neighbors):<br/>        self.n= n_neighbors</span></pre><p id="d8eb" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们构建一个<strong class="kj hj"> fit() </strong>方法并传递 X 和 y，它们分别是特征张量和目标张量，它们将成为我们的训练数据集:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="a88c" class="li jp hi le b fi lj lk l ll lm">def fit(self,X,y):<br/>        self.feature = X<br/>        self.target = y</span></pre><p id="267a" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们将 X 和 y 存储到特征和目标变量中，这样就完成了训练部分。</p><p id="2f1d" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们构建一个<strong class="kj hj"> predict() </strong>方法，它将一个测试特性作为输入:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="d3bf" class="li jp hi le b fi lj lk l ll lm">def predict(self, test):<br/>        self.test_feature = test<br/>        self.test_target = np.zeros(len(self.test_feature))<br/>        <br/>        for i in range(len(self.test_target)):<br/>            distance = np.sum(np.abs((self.test_feature[i]-self.feature)), axis=1)<br/>            distance_sort= distance.argsort()[:self.n]<br/>            y_sample= []<br/>            for j in range(self.n):                        y_sample.append(self.target[distance_sort[j]])<br/>           <br/>            <br/>            self.test_target[i]=statistics.mode(y_sample)<br/>            <br/>        return  self.test_target</span></pre><p id="5930" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们更深入地研究这段代码。</p><p id="a80d" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">首先将测试张量存储在 test_feature 变量中，同时构建一个 test_target 数组作为输出目标张量。</p><p id="0c5b" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">现在，让我们运行一个循环来找出单个测试数据点和训练数据点之间的曼哈顿距离。现在对这些距离进行排序，并找到最接近测试点的 n 个训练数据点的索引。</p><p id="77c5" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">所以我使用了一个<strong class="kj hj"> argsort() </strong>方法来对距离进行排序，输出对应于这些距离的索引。</p><p id="cd81" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">现在将最接近测试点的点的“n”个索引存储在 y_sample 列表中。</p><p id="615f" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">但是为什么只有 n 个点，既然 n 是我们要考虑的最近邻的个数。现在找到这些最近点的类，并追加到 y_sample 列表中。现在，该测试点的最终标签将是相邻点的大部分类别标签</p><p id="8777" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">在统计模块的帮助下，可以使用<strong class="kj hj"> mode() </strong>方法计算 y_sample 的模式</p><p id="0be2" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">现在将类标签存储在 test_target 列表中并返回它:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="3cb3" class="li jp hi le b fi lj lk l ll lm">class KNN():<br/>    <br/>    def __init__(self, n_neighbors):<br/>        <br/>        import numpy as np<br/>        self.n= n_neighbors<br/>    <br/>    def fit(self, X,y ):<br/>        self.feature = X<br/>        self.target = y<br/>        <br/>    def predict(self, X):<br/>        self.test_feature= X<br/>        self.test_target=np.zeros(len(self.test_feature))<br/>        <br/>        for i in range(len(self.test_target)):<br/>            distance = np.sum(np.abs((self.test_feature[i]-self.feature)), axis=1)<br/>            min_values_index = distance.argsort()[:self.n]<br/>            y_sample= []<br/>            for j in range(self.n):<br/>                y_sample.append(self.target[min_values_index[j]])<br/>           <br/>            self.test_target[i]=statistics.mode(y_sample)<br/>            <br/>        return  self.test_target</span></pre><p id="f63f" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">现在让我们在 Iris 类分类数据集上测试它，看看训练和测试的时间复杂度:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="6880" class="li jp hi le b fi lj lk l ll lm">iris= load_iris<br/>X= iris['data']<br/>y= iris['target']<br/>X_train, X_test, y_train, y_test= train_test_split(X,y)</span></pre><p id="1dce" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">为了找到训练和测试的时间复杂度，我们有一个时间模块。</p><p id="2625" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">让我们计算一下 knn.fit(X_train，y_train)执行的时间。让我们借助于<strong class="kj hj"> time() </strong>方法将训练部分的开始时间存储在 start_train 变量中，将结束时间存储在 end_train 中。然后为了找出所用的时间，只需计算两者的差值。</p><p id="0834" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">对测试也重复此步骤:</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="1c4c" class="li jp hi le b fi lj lk l ll lm">knn=KNN(n_neighbors=3)<br/>start_train= time.time()<br/>knn.fit(X_train,y_train)<br/>end_train = time.time()<br/>start_test = time.time()<br/>y_pred_train= knn.predict(X_train)<br/>end_test= time.time()<br/>y_pred_test= knn.predict(X_test)<br/>print(f"Train_time: {start_train-end_train}, Test_time: {end_test-start_test}")</span></pre><p id="6650" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">结果</p><pre class="iy iz ja jb fd ld le lf lg aw lh bi"><span id="73b3" class="li jp hi le b fi lj lk l ll lm">Train_time: 0.0, Test_time: 0.00498652458190918</span></pre><p id="c20f" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">这是完整的代码。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="43ab" class="pw-post-body-paragraph kh ki hi kj b kk kl ij km kn ko im kp kq kr ks kt ku kv kw kx ky kz la lb lc hb bi translated">您可以通过更改测试和定型数据集的大小来试验不同模型的定型和测试时间。此外，尝试实现其他算法，并查看其时间复杂性的变化。</p></div></div>    
</body>
</html>