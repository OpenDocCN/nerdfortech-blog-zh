<html>
<head>
<title>How to quickly build a data lake using Amazon Web Services (AWS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Amazon Web Services (AWS)快速构建数据湖</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/how-to-quickly-build-a-data-lake-using-amazon-web-services-aws-97b85681e9ff?source=collection_archive---------1-----------------------#2019-04-30">https://medium.com/nerd-for-tech/how-to-quickly-build-a-data-lake-using-amazon-web-services-aws-97b85681e9ff?source=collection_archive---------1-----------------------#2019-04-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="7e8a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">intro—AWS中的数据湖不止<strong class="ak">只是将数据</strong>转储到<strong class="ak"/><a class="ae jd" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"><strong class="ak">【S3】</strong></a></h1><p id="a3b0" class="pw-post-body-paragraph je jf hi jg b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">在某些时候，你可能想要创建一个<a class="ae jd" href="https://en.wikipedia.org/wiki/Data_lake" rel="noopener ugc nofollow" target="_blank"> <strong class="jg hj">数据湖</strong> </a> <strong class="jg hj"> </strong>，像我一样，你<strong class="jg hj">可能想要/需要使用AWS </strong>。您可能知道，数据湖:</p><ol class=""><li id="d5a8" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb kj kk kl km bi translated">促进数据利用；</li><li id="f322" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb kj kk kl km bi translated">通过容易地提供商业见解(例如使用分析和/或可视化工具)来打开新商业机会；</li><li id="02a1" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb kj kk kl km bi translated">在我们这样做的同时，避免触及现场数据库和影响您的客户；</li><li id="69df" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb kj kk kl km bi translated">通过将分析服务暴露给应用程序(API)来增加您的产品使用；</li><li id="9b65" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb kj kk kl km bi translated">避免数据复制成本，尤其是在微服务策略中；</li><li id="319e" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb kj kk kl km bi translated">通过将数据存储在每个人(销售人员、CX、客户、开发人员等)都知道在哪里找到/搜索的集中位置，为您提供一种更简单、更安全、一致和透明的数据访问方式；)</li></ol><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es ks"><img src="../Images/fa5fc7000f8500ce9f1a17c64828d070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dI8ECTFC-tfFRYZr.jpg"/></div></div></figure><p id="4776" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">听起来很棒，对吧？然而，只要你开始做，你就会意识到在AWS   <strong class="jg hj">中创建一个<a class="ae jd" href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" rel="noopener ugc nofollow" target="_blank"> <strong class="jg hj">数据湖不仅仅是将数据转储到</strong></a><a class="ae jd" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"><strong class="jg hj">【S3】</strong></a>中，因为你应该这样做:</strong></p><ul class=""><li id="aa64" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb lh kk kl km bi translated">以某种方式使该信息能够被其目标用户访问。换句话说，要防止出现<a class="ae jd" href="https://en.wikipedia.org/wiki/Data_lake" rel="noopener ugc nofollow" target="_blank"> <strong class="jg hj">数据沼泽</strong></a><strong class="jg hj">；</strong></li><li id="ff98" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">在某种程度上，你总是可以访问原始数据(作为备份)；</li><li id="e964" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">通过加密生产数据以安全的方式；</li><li id="4bc8" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">通过限制对生产数据的访问(不是对组织内的每个人都可用)，以合规的方式；</li><li id="8b49" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">通过压缩数据以成本有效的方式；"<a class="ae jd" href="https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html" rel="noopener ugc nofollow" target="_blank"> Parquet(和ORC)是列数据格式，与JSON </a>之类的面向行的格式相比，它节省了空间并支持更快的查询"；</li><li id="68ac" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">通过将不经常访问的数据移动到更便宜的AWS存储设备，如AWS S3(不经常访问)或<a class="ae jd" href="https://aws.amazon.com/glacier/" rel="noopener ugc nofollow" target="_blank"> AWS Glacier </a>，以经济高效的方式进行；</li></ul><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es li"><img src="../Images/ea673ff1f05f94530387a143dd5ac4ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*BMlQ9hu-j7oyEuentmglqQ.jpeg"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><a class="ae jd" href="https://pt.slideshare.net/AmazonWebServices/best-practices-for-building-a-data-lake-in-amazon-s3-and-amazon-glacier-with-special-guests-airbnb-viber-stg312-reinvent-2017/65" rel="noopener ugc nofollow" target="_blank">在亚马逊S3和亚马逊冰川建立数据湖的最佳实践，特邀嘉宾，Airbnb&amp;Viber-stg 312-re:Invent 2017</a></figcaption></figure><p id="f26e" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">综上所述，<a class="ae jd" href="https://pt.slideshare.net/AmazonWebServices/best-practices-for-building-a-data-lake-in-amazon-s3-and-amazon-glacier-with-special-guests-airbnb-viber-stg312-reinvent-2017/65" rel="noopener ugc nofollow" target="_blank">我希望你认识到，从零开始构建一个数据湖涉及到大量的主题，如数据摄取、数据组织、安全性、成本等</a>。</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="e28b" class="if ig hi bd ih ii lu ik il im lv io ip iq lw is it iu lx iw ix iy ly ja jb jc bi translated">作为解决方案的实时摄取流</h1><p id="9c71" class="pw-post-body-paragraph je jf hi jg b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">有“<a class="ae jd" href="https://pt.slideshare.net/AmazonWebServices/best-practices-for-building-a-data-lake-in-amazon-s3-and-amazon-glacier-with-special-guests-airbnb-viber-stg312-reinvent-2017/9" rel="noopener ugc nofollow" target="_blank">多数据湖摄取方法</a>”但是，如果你有一个事件驱动的架构(不需要基于微服务，它可以是一个发布<a class="ae jd" rel="noopener" href="/@arleypadua/domain-events-vs-integration-events-5eb29a34fdbc">集成事件</a>的单片应用程序)，你可能会立即跳入<a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/" rel="noopener ugc nofollow" target="_blank"> Amazon Kinesis Firehose </a>。即使您在交易数据库或内部服务器中有历史数据，您可能仍然希望构建一个应用程序来查询这些数据，并以某种方式在亚马逊Kinesis Firehose中结束的集成事件的形式发布这些数据。我尽可能多地使用这种实时摄取流，因为:</p><ul class=""><li id="7cc9" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb lh kk kl km bi translated">AWS Kinesis Firehose streams <a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/features/" rel="noopener ugc nofollow" target="_blank">处理转换、压缩并自动整理您的水桶</a>；</li><li id="e856" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">提供更大的灵活性，例如，使用实时集成事件可以轻松地为其附加分析。它还允许将那些<a class="ae jd" rel="noopener" href="/@arleypadua/domain-events-vs-integration-events-5eb29a34fdbc">集成事件</a>重新用于其他目的；</li><li id="6e63" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">最佳实践的重用/更快的上市时间:如果我为AWS Kinesis Firehose设置了压缩和转换，我知道所有经过那里的数据都将被压缩和转换:)。通过后台工作(或类似于<a class="ae jd" href="https://aws.amazon.com/storagegateway/" rel="noopener ugc nofollow" target="_blank">存储网关</a>的AWS服务)来处理现有的历史数据是一种更容易出错的方法，而且成本可能更高；</li></ul><p id="4a89" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">也就是说，我只是想在AWS  中创建一个<a class="ae jd" href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" rel="noopener ugc nofollow" target="_blank"> <strong class="jg hj">数据湖，它遵循<strong class="jg hj">实时数据摄取流</strong>，即使你没有事件驱动的架构，你也可能会发现这很有用。</strong></a></p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="843e" class="if ig hi bd ih ii lu ik il im lv io ip iq lw is it iu lx iw ix iy ly ja jb jc bi translated">创建数据湖(第一部分)——架构</h1><p id="d67f" class="pw-post-body-paragraph je jf hi jg b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">为了创造这种流动，我们将:</p><ul class=""><li id="a4cc" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb lh kk kl km bi translated">创建一个使用<a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/features/" rel="noopener ugc nofollow" target="_blank"> Kinesis数据传输流</a>向S3/数据湖发送记录的工人(或者数据湖摄取微服务)。通常在真实世界的产品中，这些记录是您的产品产生的<a class="ae jd" rel="noopener" href="/@arleypadua/domain-events-vs-integration-events-5eb29a34fdbc">集成事件</a>；</li><li id="abc7" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">设置<a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/features/" rel="noopener ugc nofollow" target="_blank"> Kinesis数据传输流</a>，自动转换和压缩数据，并有组织地自动存储在S3；)</li></ul><p id="b6a4" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">总结起来，大概是这样的:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lz"><img src="../Images/b8bf0709d4f13ff9256f5a02a26ee5f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20rzq5BcA3rmnTWEDE2XWw.jpeg"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">数据湖:实时数据摄取批处理和实时分析的推荐流程</figcaption></figure><ul class=""><li id="1807" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb lh kk kl km bi translated">这不仅仅是创建数据湖的实时数据接收流程。这是使用AWS服务进行批处理和实时分析的<strong class="jg hj">推荐流程</strong>，其中数据通过<a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/features/" rel="noopener ugc nofollow" target="_blank"> Kinesis数据传输流</a>存储在数据湖/S3桶中；</li><li id="f8ae" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">数据湖摄取微服务只是一个抽象层，因此其他微服务或单片应用程序不需要了解Kinesis或如何发布事件。通过将数据湖的创建集中在一个地方，您可以很容易地改进，例如，记录Kinesis失败的请求，支持更多的事件，甚至切换<a class="ae jd" href="https://azure.microsoft.com/en-us/solutions/data-lake/" rel="noopener ugc nofollow" target="_blank">云提供商</a>；</li><li id="ff29" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated"><a class="ae jd" href="https://aws.amazon.com/glue/" rel="noopener ugc nofollow" target="_blank"> AWS Glue </a>、<a class="ae jd" href="https://aws.amazon.com/redshift/" rel="noopener ugc nofollow" target="_blank"> AWS红移</a>以及商业洞察工具如<a class="ae jd" href="https://aws.amazon.com/quicksight/" rel="noopener ugc nofollow" target="_blank"> AWS QuickSight </a>或<a class="ae jd" href="https://powerbi.microsoft.com/en-us/" rel="noopener ugc nofollow" target="_blank"> Microsoft PowerBI </a>不在本文讨论范围之内，但我只想分享(1)你可以直接从<a class="ae jd" href="https://aws.amazon.com/kinesis/data-firehose/features/" rel="noopener ugc nofollow" target="_blank"> Kinesis数据交付流</a>中填充<a class="ae jd" href="https://aws.amazon.com/redshift/" rel="noopener ugc nofollow" target="_blank"> AWS红移</a>以及(2)你不一定需要像<a class="ae jd" href="https://aws.amazon.com/redshift/" rel="noopener ugc nofollow" target="_blank"> AWS红移</a>这样的数据仓库来创建你的<a class="ae jd" href="https://aws.amazon.com/glue/" rel="noopener ugc nofollow" target="_blank">“数据湖是一种日益流行的存储和分析结构化和非结构化数据的方式。如果你想建立自己的定制亚马逊S3数据湖，AWS Glue可以让你所有的数据立即可用于分析，而无需移动数据"</a>；</li></ul><p id="d38f" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">构建它的时间:)</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="9a56" class="if ig hi bd ih ii lu ik il im lv io ip iq lw is it iu lx iw ix iy ly ja jb jc bi translated">创建数据湖(第二部分)—以S3为目标目的地设置AWS Kinesis消防软管</h1><p id="59f6" class="pw-post-body-paragraph je jf hi jg b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">登录AWS控制台并选择消防软管服务(如果您没有AWS帐户，您可以免费创建一个<a class="ae jd" href="https://aws.amazon.com/free/" rel="noopener ugc nofollow" target="_blank">帐户</a>，但请注意，Kinesis消防软管资源不在<a class="ae jd" href="https://aws.amazon.com/free/" rel="noopener ugc nofollow" target="_blank"> AWS免费等级</a>下，并且<strong class="jg hj">基于使用的费用适用于</strong>)。由于我们希望“持续收集、转换和加载流数据到亚马逊S3”，选择“<a class="ae jd" href="https://console.aws.amazon.com/firehose/home?region=eu-west-1#/wizard/nameAndSource" rel="noopener ugc nofollow" target="_blank"> <strong class="jg hj">创建交付流</strong> </a>”。</p><p id="8d4a" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated"><strong class="jg hj">第一步:名称和来源:</strong>给出一个流名称，并选择“直接上传或其他来源”，因为我们“<a class="ae jd" href="https://eu-west-1.console.aws.amazon.com/firehose/home?region=eu-west-1#/wizard/nameAndSource" rel="noopener ugc nofollow" target="_blank">想要使用Firehose PutRecord()或PutRecordBatch() API将来源记录发送到交付流</a>”；</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es ma"><img src="../Images/b84109c29399429b224caa69c42a98fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RuhfqLGHyELoTIyuD1wW7g.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><strong class="bd ih">第一步:名称和来源</strong></figcaption></figure><p id="3cb2" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated"><strong class="jg hj">步骤2:处理记录:</strong>出于演示的目的，我不需要“记录转换”，因为我们将发布一个JSON格式的事件，而Kinesis Firehose知道如何转换它，但我肯定希望启用“记录格式转换”到Apache Parquet。正如AWS所说，“Apache parquet或Apache ORC格式的数据通常比JSON更高效”。此外，转换为Apache Parquet可以确保“数据在传送到S3之前使用Snappy compression进行压缩”。很好不是吗？:)</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mb"><img src="../Images/77c2bbadf43cdacc0481534c2f9c436d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w9FpiH3UG8jrMTkprw2QfQ.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><strong class="bd ih">第二步:流程记录</strong></figcaption></figure><p id="2b5c" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">如您所见，为了让Kinesis知道如何将JSON记录转换成apache parquet，我们需要“为源记录指定一个模式”。出于演示目的，我刚刚在AWS Glue中手动创建了一个表格:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mc"><img src="../Images/7d88d9b5c0227e1254642385e504ae1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5XhxUoyJ7A6F1WGU0l6upw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><strong class="bd ih">步骤2:处理记录——为源记录指定一个模式</strong></figcaption></figure><p id="0247" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated"><strong class="jg hj">步骤3:选择目的地:“</strong>亚马逊S3是唯一可用的目的地，因为我们在步骤2:处理记录中启用了记录格式转换”，所以只需选择一个S3目的地存储桶。我将S3前缀保留为空(默认)，但将S3错误前缀设置为“/error”。尤其是在数据非常重要的情况下，您还需要启用S3备份:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es md"><img src="../Images/3edd7d6cd84e92fba18a910ab0301a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EC3qKsnlEHRB4j95mRibPw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><strong class="bd ih">第三步:选择目的地</strong></figcaption></figure><p id="d3e6" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated"><strong class="jg hj">步骤4:配置设置:</strong>除了S3加密部分，我将所有内容都保留为默认设置。<strong class="jg hj">当然，您希望在AWS S3中默认加密您的生产数据</strong>，因此请确保您已启用此功能。您还需要创建一个IAM角色，但AWS会为您预先选择一个，让您的工作更轻松:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es md"><img src="../Images/395b4a74458499e241f42e97c612bf72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjTiGiH83YOis5wK184jPw.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated"><strong class="bd ih">第四步:配置设置</strong></figcaption></figure><p id="8b7b" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">现在，只需复习并继续。需要几秒钟，但最终会在AWS控制台中显示为活动状态；)</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es me"><img src="../Images/8d4a29977ae7198e1e5d27571154afc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0iyHeNrU-NwF0aGQxXmbHw.png"/></div></div></figure><p id="be04" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">唯一缺少的是对生产数据的访问限制太多。有<a class="ae jd" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-access-control.html" rel="noopener ugc nofollow" target="_blank">多种方式可以进行</a>，但是从使用<a class="ae jd" href="https://aws.amazon.com/blogs/security/control-access-to-aws-resources-by-using-the-aws-organization-of-iam-principals/" rel="noopener ugc nofollow" target="_blank">贵组织的IAM负责人</a>开始可能就足够了，而且会更快。然而，请注意，例如使用IAM角色的<a class="ae jd" href="https://aws.amazon.com/blogs/security/how-to-restrict-amazon-s3-bucket-access-to-a-specific-iam-role/" rel="noopener ugc nofollow" target="_blank">更易维护的方法是更可取的</a>。</p><p id="31f6" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">此时，您已经建立了一个用于存储数据的Kinesis流:</p><ul class=""><li id="fca8" class="kc kd hi jg b jh ke jl kf jp kg jt kh jx ki kb lh kk kl km bi translated">以加密的方式；</li><li id="b837" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">Parquet(和ORC)是列数据格式，与JSON等面向行的格式相比，这种格式节省了空间，并且支持更快的查询。”；</li><li id="9ed0" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">以一种有组织的方式，即以日期存储，并为备份和错误添加适当的前缀。</li></ul><p id="4b12" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">填湖时间，查询数据；)</p></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="0fba" class="if ig hi bd ih ii lu ik il im lv io ip iq lw is it iu lx iw ix iy ly ja jb jc bi translated">创建数据湖(第三部分)—填充(和查询)</h1><p id="1c11" class="pw-post-body-paragraph je jf hi jg b jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">我将使用<a class="ae jd" href="https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-new?tabs=netcore21" rel="noopener ugc nofollow" target="_blank"> dotnet新命令</a>创建一个. net核心控制台应用程序来表示数据湖摄取微服务。出于演示目的，我将生成大量通用事件，并将其发送到我们刚刚使用<a class="ae jd" href="https://github.com/aws/aws-sdk-net" rel="noopener ugc nofollow" target="_blank"> AWS net SDK </a>设置的Kinesis流。在您的产品中，您可能会使用来自像<a class="ae jd" href="https://kafka.apache.org" rel="noopener ugc nofollow" target="_blank"> Kafka </a>或<a class="ae jd" href="https://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank"> RabbitMq </a>这样的消息代理的事件，并使用您喜欢的编程语言/ <a class="ae jd" href="https://github.com/aws" rel="noopener ugc nofollow" target="_blank"> AWS sdk </a>:</p><pre class="kt ku kv kw fd mf mg mh mi aw mj bi"><span id="5bf6" class="mk ig hi mg b fi ml mm l mn mo">dotnet new console --name AWSFirehosePublisher</span></pre><p id="289e" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">参考<a class="ae jd" href="https://github.com/rfpedrosa/AWSFirehosePublisher/blob/master/AWSFirehosePublisher.csproj" rel="noopener ugc nofollow" target="_blank">awsfirehosepublisher . csproj</a>中的<a class="ae jd" href="https://github.com/aws/aws-sdk-net" rel="noopener ugc nofollow" target="_blank"> AWS net SDK </a>:</p><pre class="kt ku kv kw fd mf mg mh mi aw mj bi"><span id="09a0" class="mk ig hi mg b fi ml mm l mn mo">&lt;PackageReference Include="AWSSDK.Extensions.NETCore.Setup" Version="3.3.100.1" /&gt;</span><span id="fc0b" class="mk ig hi mg b fi mp mm l mn mo">&lt;PackageReference Include="AWSSDK.KinesisFirehose" Version="3.3.100.10" /&gt;</span></pre><p id="0bab" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">并使用<a class="ae jd" href="https://github.com/rfpedrosa/AWSFirehosePublisher/blob/master/Program.cs" rel="noopener ugc nofollow" target="_blank"> Program.cs </a>上的<a class="ae jd" href="https://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/KinesisFirehose/MKinesisFirehosePutRecordAsyncStringRecordCancellationToken.html" rel="noopener ugc nofollow" target="_blank"> PutRecordAsync </a>开始发布您的精彩活动:)</p><pre class="kt ku kv kw fd mf mg mh mi aw mj bi"><span id="0af4" class="mk ig hi mg b fi ml mm l mn mo">var data = "{\"id\": \"" + id + "\"}";</span><span id="dab1" class="mk ig hi mg b fi mp mm l mn mo">......</span><span id="b40e" class="mk ig hi mg b fi mp mm l mn mo">return _firehoseClient.PutRecordAsync(putRecordRequest);</span></pre><p id="0a5a" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">et vò ila！流显示活动和数据存储在S3！</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mq"><img src="../Images/ab38edd94934a40c2d7e7146b10596a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gteWq8pZc_pj1eJUaFzVfg.png"/></div></div></figure><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mr"><img src="../Images/be6ce1a4074a4cf4c213b42fd8f87ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oJPjmWI7S3AzVqeucjbufA.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">存储在S3的数据</figcaption></figure><p id="757a" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">通过S3选择，您可以使用SQL表达式从单个CSV、JSON或Parquet文件中提取记录。S3选择支持GZIP和BZIP2压缩文件和服务器端加密文件。要在S3分析需要更复杂的SQL表达式的数据，请参见亚马逊雅典娜T20)</p><p id="6633" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">因为我只是想检查一下我是否能读取数据，以及数据是否符合我的预期，所以我将使用S3选择。要使用S3选择，只需选择文件-&gt;进入“选择”选项卡，然后按“显示文件预览”:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es mq"><img src="../Images/0169032b118cf2dacb244b9f8eb4c4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68sVJ2EqteuhFwAcOmIk9g.png"/></div></div></figure></div><div class="ab cl ln lo gp lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="hb hc hd he hf"><h1 id="530d" class="if ig hi bd ih ii lu ik il im lv io ip iq lw is it iu lx iw ix iy ly ja jb jc bi translated">下一步？</h1><ul class=""><li id="f25f" class="kc kd hi jg b jh ji jl jm jp ms jt mt jx mu kb lh kk kl km bi translated">理想情况下，您希望使用<a class="ae jd" href="https://aws.amazon.com/cloudformation/" rel="noopener ugc nofollow" target="_blank">基础设施作为代码(IaC) </a>来设置那些AWS服务；</li><li id="4528" class="kc kd hi jg b jh kn jl ko jp kp jt kq jx kr kb lh kk kl km bi translated">在<a class="ae jd" href="https://aws.amazon.com/quicksight" rel="noopener ugc nofollow" target="_blank"> AWS QuickSight </a>和<a class="ae jd" href="https://aws.amazon.com/blogs/big-data/embed-interactive-dashboards-in-your-application-with-amazon-quicksight" rel="noopener ugc nofollow" target="_blank">上创建一个漂亮的仪表盘，并嵌入到你的应用</a>中？</li></ul><p id="b076" class="pw-post-body-paragraph je jf hi jg b jh ke jj jk jl kf jn jo jp le jr js jt lf jv jw jx lg jz ka kb hb bi translated">希望你觉得有帮助:)感谢阅读！</p></div></div>    
</body>
</html>