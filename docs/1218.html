<html>
<head>
<title>Gradient Boost for Regression Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释了回归的梯度增强</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/gradient-boost-for-regression-explained-6561eec192cb?source=collection_archive---------22-----------------------#2021-03-09">https://medium.com/nerd-for-tech/gradient-boost-for-regression-explained-6561eec192cb?source=collection_archive---------22-----------------------#2021-03-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e7cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度增强是一种机器学习算法，它基于称为“增强”的集成技术工作。与其他 boosting 模型一样，梯度 boost 将许多弱学习器顺序组合起来，形成一个强学习器。通常梯度增强使用决策树作为弱学习器。</p><p id="2ae8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度增强是为分类和回归问题建立预测模型的最强大的技术之一。在这篇博客中，我们将看到梯度推进如何与回归一起工作。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/a881c3683fd201cb410dbfec71b0d805.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*FInaQuMjB9tBx0rRyUXOhg.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">形象谈思维</figcaption></figure><p id="8d6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">助推？</strong></p><p id="32b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Boosting 思想是按顺序训练弱学习者，每个人都试图纠正其前任。这意味着，算法总是会学习一些不完全准确的东西，但是朝着正确的方向迈出了一小步。随着算法通过顺序纠正先前的错误而向前推进，它提高了预测能力。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jp"><img src="../Images/75738fa722a851851679b3a1b1bbb0cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r_rQBMFLfmMRWuCXTW5Prw.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="8a94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">梯度推进</strong></p><p id="94c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解梯度增强，下面是所涉及的步骤。在梯度推进中，弱学习器是决策树。</p><p id="899f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步</strong>:构建单根节点的基树。这是所有样本的初始猜测。</p><p id="dae9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二步:根据前一棵树的错误建立一棵树。</p><p id="d8a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Step3 </strong>:按学习率(0 到 1 之间的值)缩放树。这个学习率决定了树在预测中的作用</p><p id="f511" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤 4 </strong>:将新的树与之前所有的树结合起来预测结果，重复步骤 2，直到达到最大数量的树，或者直到新的树不能提高拟合度。</p><p id="da61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终的预测模型是所有树的组合。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ju"><img src="../Images/b5728054cfa43fb444d4b22e6cd4df8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vymgKN9RgTmgIwVNuPzIg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="9d16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">回归示例</strong></p><p id="b11c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解梯度增强的工作原理，让我们看一个简单的例子。</p><p id="7284" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们有下面的样本数据表，其中身高、年龄和性别作为输入变量，体重作为输出变量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jv"><img src="../Images/f3e423569038850656df8f5d9d9a912a.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*sFAdpLzFhsurxB6g1b_ucQ.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="b49e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了预测权重，第一步是创建一个带有根节点的树。对于最初的猜测，我们可以使用平均值、均方误差、平均绝对误差等。,</p><p id="e625" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们假设所有样本的平均权重作为我们的初始猜测，那么 71.2 (88+76+56+73+77+57/6=71.2)将是我们的初始根节点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jw"><img src="../Images/3e51bb4a50f3182b9b37cd98eb1c25e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*C_-XQlisINCNFzAYPbNqEg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="66d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二步是根据前一个树的错误建立一个树。前一棵树产生的误差是实际重量和预测重量之间的差异。这种差异称为伪残差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jx"><img src="../Images/a8f0711f18da0da402a2ed33a238183e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*-7ofzBLtrVdDL0JbgIzHLw.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="a5d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们使用身高、年龄和性别来预测残差(误差)，构建一个最大叶节点为 4 的树。如果多于 1 个权重落在同一叶上，则我们取权重的平均值作为叶节点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jy"><img src="../Images/8e40c7459c704eab8eff3ea042ced41c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPbFm1hKiqYHFJv6F88_Pw.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="cbad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三步是用学习率来衡量树。假设学习率为 0.1。</p><p id="24b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第四步是合并这些树来进行新的预测。因此，我们从初始预测 71.2 开始，沿着新树运行样本数据，并对它们求和。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jz"><img src="../Images/4473024d0dc57e85cbe834078facec6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*psEdUn7BS1iCj6z9NI41kA.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="a461" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们观察新的预测权重，我们可以看到与初始假设的平均权重相比，结果有一点改进。为了进一步改善结果，我们重复步骤 2 和 3，并根据新的伪残差构建另一棵树来预测权重。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ka"><img src="../Images/21a946647ee9a70cc45e337e6c15cf97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*xL39MvaxVsqTLWGie90fPg.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="633b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">再次用新的伪残差构建新的树。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es kb"><img src="../Images/266538fc4d9f9826eb45be6adeefe5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9V1_eemM8WDBCli8MgAJgA.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="8707" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们把新的树和所有以前的树结合起来预测新的权重。因此，我们从初始预测开始，将其与第一棵树的缩放结果相加，然后与新树的缩放结果相加。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kc"><img src="../Images/8e4252663a5be042717183f8167b2c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*kdjcJ7xn-hY0w1hDIuXCpA.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="b88c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据新的预测权重，我们可以观察到结果有进一步的改进。我们再次计算伪权重，并以类似的方式构建新的树。这些步骤重复几次，直到新的树不会减少伪残值，或者直到建立了最大数量的树。</p><p id="2b50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以最终的预测模型会是</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es kd"><img src="../Images/524b1d58ba4194c3fdccb25a5b14b1e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7a3N9-DLep6mJsZ7h81kQ.jpeg"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">作者图片</figcaption></figure><p id="5f07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，如果我们得到新的数据进行测试，我们通过上面的模型来计算这个人的体重。</p><p id="a3f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论</strong></p><p id="d4d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度增强是一种强大的增强技术。它通过依次组合弱树形成强树来提高模型的准确性。这样，它实现了低偏差和低方差。</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><p id="b183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kl">原载于 2021 年 3 月 9 日</em><a class="ae km" href="https://www.numpyninja.com/post/gradient-boost-for-regression-explained" rel="noopener ugc nofollow" target="_blank"><em class="kl">【https://www.numpyninja.com】</em></a><em class="kl">。</em></p></div></div>    
</body>
</html>