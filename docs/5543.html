<html>
<head>
<title>Top Deep Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">顶级深度学习算法</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/top-deep-learning-algorithms-7b1a43a75dbc?source=collection_archive---------7-----------------------#2021-10-14">https://medium.com/nerd-for-tech/top-deep-learning-algorithms-7b1a43a75dbc?source=collection_archive---------7-----------------------#2021-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/09dc56b5eedde171c89014b050d92644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Nye4DhGmyYS9enQX"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated"><a class="ae hv" href="https://unsplash.com/@universaleye?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">万用眼</a>在<a class="ae hv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><div class=""/><p id="3224" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有很多深度学习算法被使用，但有哪些是最好的呢？我们来看看吧！！</p><p id="9ef9" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我已经在这里讨论了最基本的神经网络或者感知机<a class="ae hv" href="https://adityakumawat502.medium.com/the-most-basic-of-the-neural-networks-271bc59f6c61" rel="noopener">。如果你想知道一个神经网络在最简单的形式下是如何运作的，请看看这个。</a></p><h1 id="59dd" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">深度学习是如何工作的？</h1><p id="7eb5" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">深度学习算法使用 ann(人工神经网络的缩写)来复制我们大脑的功能。为什么呢？不想成为哲学或历史，但是我们的大脑是我们所知道的最复杂的机器。因此，即使我们能够复制“脑力”,可能性的数量也是深不可测的。</p><p id="93f1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一种算法如何处理和计算输出当然与另一种算法不同。例如，在一种类型的算法 MLPs 中，通过将基本形式的神经网络(也称为感知器)堆叠在彼此之上并处于不同的水平来处理数据。数据在这些部分之间划分、处理，并产生一个输出或多个输出。</p><h1 id="92ea" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">类型</h1><ul class=""><li id="1d4c" class="kw kx hy ix b iy kr jc ks jg ky jk kz jo la js lb lc ld le bi translated">卷积神经网络</li><li id="ff3c" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">递归神经网络</li><li id="58e9" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">长短期记忆网络</li><li id="585c" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">多层感知器</li><li id="7f64" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">径向基函数网络</li><li id="69a7" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">生成对抗网络</li><li id="b733" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">深度信念网络</li><li id="63e8" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">自组织映射(SOMs)</li><li id="234b" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">自动编码器</li><li id="0a28" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">受限玻尔兹曼机器</li></ul><p id="d3ed" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是这些算法工作原理的基本描述:</p><h1 id="901c" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">卷积神经网络</h1><p id="ce9a" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">工作:他们有处理数据特征的多层。</p><p id="7430" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些网络主要用于检测物体和处理图像。</p><p id="dc9b" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实现输出的重要层:</p><ul class=""><li id="70a6" class="kw kx hy ix b iy iz jc jd jg lk jk ll jo lm js lb lc ld le bi translated">卷积层:该层有多个执行复杂操作的过滤操作。</li><li id="d132" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">整流线性单元:简称 ReLU。该单元对元素应用一些操作，并输出校正的特征图。</li><li id="941f" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">池层:ReLU 的输出进入这个池层。进行汇集是为了减少特征图的维数。<br/>池层从 ReLU 的二维输出中输出单个长向量。</li></ul><p id="425e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，如果我们使用 CNN 进行图像分类，那么最终，在汇集完成后，来自汇集层的向量进入前馈网络或全连接层，该层将对图像进行分类。</p><h1 id="b018" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">递归神经网络</h1><p id="3cb4" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">RNNs 将它们的输出反馈为输入。由于这一特性，rnn 可以记住以前的输入，因此它们可以对数据执行非常强大的操作。</p><p id="ed74" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于喂食本身的特性，RNN 可以随时间展开。这意味着 RNN 在时间 t1 的输出将不同于在 t2 的输出。</p><p id="b5c0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">用于:</p><ul class=""><li id="2b28" class="kw kx hy ix b iy iz jc jd jg lk jk ll jo lm js lb lc ld le bi translated">图像字幕</li><li id="3e47" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">自然语言处理</li><li id="154f" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">时间序列分析</li><li id="ba10" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">语言翻译</li></ul><p id="e2b0" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">RNNs 是自然语言处理的最大突破之一。</p><h1 id="7d59" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">长短期记忆网络</h1><p id="37ed" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这是一种 RNNs，它的默认行为是回忆过去的信息<em class="ln">(听起来很像人类！)</em>相当长一段时间。</p><p id="1441" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">LSTMs 的用例与 rnn 非常相似，但更具体地说，它们可以用于音乐创作、语音识别等。</p><p id="d4a2" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自动 LSTM 的工作分三步进行:</p><ul class=""><li id="a52c" class="kw kx hy ix b iy iz jc jd jg lk jk ll jo lm js lb lc ld le bi translated">忘记过去状态的不必要信息。</li><li id="a9ae" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">更新当前单元格的值。</li><li id="3301" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated">输出单元格的特定状态。</li></ul><h1 id="b94f" class="jt ju hy bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">多层感知器</h1><p id="2474" class="pw-post-body-paragraph iv iw hy ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">如果你知道感知器，那么你只要看标题就能猜到这个算法是如何工作的。</p><p id="2da1" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它们包含各种感知器，这些感知器具有垂直堆叠和水平连接的激活功能。</p><p id="5d54" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">MLP 用于语音识别、翻译和语音识别。</p><p id="1a8e" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些是最流行的神经网络算法。如果你想更详细地了解上述网络以及其他网络，以下是相关链接:</p><ul class=""><li id="ad96" class="kw kx hy ix b iy iz jc jd jg lk jk ll jo lm js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a></li><li id="cb6f" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank">递归神经网络</a></li><li id="5299" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Long_short-term_memory#:~:text=Long%20short%2Dterm%20memory%20(LSTM)%20is%20an%20artificial%20recurrent,the%20field%20of%20deep%20learning.&amp;text=LSTM%20networks%20are%20well%2Dsuited,events%20in%20a%20time%20series." rel="noopener ugc nofollow" target="_blank">长短期记忆</a></li><li id="c619" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="noopener ugc nofollow" target="_blank">多层感知器</a></li><li id="2f1e" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Radial_basis_function_network" rel="noopener ugc nofollow" target="_blank">径向基函数网络</a></li><li id="999b" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a></li><li id="5f59" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Deep_belief_network" rel="noopener ugc nofollow" target="_blank">深度信念网络</a></li><li id="6407" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Self-organizing_map" rel="noopener ugc nofollow" target="_blank">自组织映射</a></li><li id="f821" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a></li><li id="785d" class="kw kx hy ix b iy lf jc lg jg lh jk li jo lj js lb lc ld le bi translated"><a class="ae hv" href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine" rel="noopener ugc nofollow" target="_blank">受限玻尔兹曼机</a></li></ul><p id="3ae2" class="pw-post-body-paragraph iv iw hy ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">非常感谢你的阅读！！！在<a class="ae hv" href="https://twitter.com/AdityaK50037212" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我，在<a class="ae hv" href="http://www.linkedin.com/in/aad1tya" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上联系我，帮助我拓展我的人脉！</p></div></div>    
</body>
</html>