<html>
<head>
<title>Building Transformer-Based Entity Linking System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建基于变压器的实体链接系统</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/building-bi-encoder-based-entity-linking-system-with-transformer-6c111d86500?source=collection_archive---------3-----------------------#2021-03-26">https://medium.com/nerd-for-tech/building-bi-encoder-based-entity-linking-system-with-transformer-6c111d86500?source=collection_archive---------3-----------------------#2021-03-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="7f3c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">历史和逐步指南。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/f07269cdcd9bdb20811d0152125dbaf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E7cukmdtQvx5-lk6"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">具有双编码器的实体链接系统</figcaption></figure><p id="ef3f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">【<strong class="jp hj">更新于 2021 年 4 月 18 日</strong>】你可以在自己的 Colab-Pro 环境下运行实验。详情见<a class="ae kj" href="https://github.com/izuna385/Entity-Linking-Tutorial/blob/main/docs/Colab_Pro_Tutorial.md" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hj">此处</strong> </a>。</p><h1 id="80d8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">历史</strong></h1><p id="5eec" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated"><strong class="jp hj">实体链接(EL) </strong>是将文档中的一系列文本(称为提及)映射到知识图中的实体的任务，被认为是自然语言理解和应用中最重要的任务之一。</p><p id="1ed1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">例如，当一个用户在聊天机器人对话中说，“我今天看到了独立日，它非常令人兴奋，”没有人会认为这是周年纪念日。</p><p id="9776" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这只是一个例子，但是实体链接对于后续与 NLP 相关的问题是一个非常重要的任务。</p><p id="f60a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在本文中，我们将创建两个简单的基于双编码器的实体链接系统。前者基于基于表面的候选生成(CG)，后者基于近似最近邻搜索(ANNSearch)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lh"><img src="../Images/f4366e2e3bcdc1569b08041bb2a6784e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UrTa5HdMffwklwcHJtvXdw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">基于表面基 CG 的双编码器实体链接系统</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b14e4296011ee6fab05fa2180f83a2e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*962vbJ1zYGub61C1"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">基于人工神经网络搜索 CG 的双编码器系统</figcaption></figure><p id="b971" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">直到 2019 年，实体链接模型都是通过向神经网络输入提及和实体之间的字符串相似度、维基百科中的共现统计数据(早期论文中称为<em class="li"> priors </em>的功能)、提及存在的上下文等来训练的。</p><p id="0ba8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于将知识库中的所有实体与每个提及进行比较需要很高的计算成本，因此先前的工作使用这样的统计，或<em class="li">别名表</em>来生成候选项；即过滤实体以考虑每个提及。(山田等，2016；加内亚和霍夫曼，2017；乐和蒂托夫，2018；曹等，2018)。</p><p id="d4ca" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为了使别名表有效，它必须包含目标文档中出现的大量提及。由于 Wikipedia 及其丰富的锚文本注释可用于创建别名表，这对于从通用文档链接实体来说不是问题。相比之下，在专业领域建立有效的别名表既困难又昂贵，因为维基百科对这些领域的覆盖范围往往不够，而且很难找到大型的特定领域锚文本语料库。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lj"><img src="../Images/61507a4fe989e0b65c00a0470d2fd0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-PUfi-SYkeC3SEsZRLoAaA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">如果目标提及/文档在一般领域中，则有可能从来自维基百科和网络爬行的大量成员-实体对统计地构建大型别名表。</figcaption></figure><p id="0553" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">当别名表不可用或覆盖范围有限时，可以通过提及和实体之间的表面相似性来生成候选项(Murty et al .，2018；朱等，2019)。然而，通过其表面相似性来捕获所有可能的提及实体是极其困难的，如果不是不可能的话，尤其是在生物医学文献中，其中实体通常表现出不同的表面形式(Tsuruoka 等人，2008)。例如，出现在 St21pv 数据集中的提及 rs2306235 的黄金实体(Mohan 和 Li，2019)是 PLEKHO1 基因。然而，这个实体在基于表面的候选生成中很可能被忽略，因为它不与 rs2306235 共享单个字符。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lk"><img src="../Images/2cf1f85a906f09784813bd180e8e9a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfd6zAiC_wS15dXvJWlDxg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">基于双编码器的检索。</figcaption></figure><p id="84e2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">为了减轻对别名表的依赖，Gillick 等人(2019)提出使用近似最近邻(ANN)搜索。虽然他们的方法成功地避免了使用别名表，但它需要大量上下文化的提及实体对来进行训练，这在专业领域中很少见。Wu 等人(2019)证明了双编码器在类似的设置下仍然适用于实体候选生成，例如 Logeswaran 等人(2019)提出的零炮实体，但精度仍然远远低于一般领域，在这种设置下需要进一步的研究。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ll"><img src="../Images/7561368d10deaf597e08794a46229b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DlYDiBLnD1RvJyjTQ5acIQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">引自<a class="ae kj" href="https://arxiv.org/abs/1911.03814" rel="noopener ugc nofollow" target="_blank">吴等，19 年</a>。</figcaption></figure></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><p id="081b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在本文中，我们将使用双编码器实现实体链接。我们将实现两种类型的候选生成，一种基于表面形式，另一种使用近似邻域搜索。</p><h1 id="f1cc" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">源代码</strong></h1><p id="005d" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">源代码在这里。【https://github.com/izuna385/Entity-Linking-Tutorial】T5<br/>T6】</p><h1 id="13d8" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">数据预处理</strong></h1><p id="3cef" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">写在上面的源代码。本文使用 BC5CDR(李等(2016))数据集对模型进行训练和评估。</p><p id="a0fa" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">BC5CDR 是为 BioCreative V 化学和疾病提及识别任务创建的数据集。它包含 1，500 篇文章，其中包括 15，935 篇化学文章和 12，852 篇疾病文章。参考知识库是 MeSH，几乎所有的提及在参考知识库中都有一个黄金实体。</p><p id="89f8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在本文中，我们在并行处理中使用 scispacy 对 Pubtator 格式的文档进行预处理。这是用于预处理的工具。<br/>T10】https://github.com/izuna385/PubTator-Multiprocess-Parser<br/>T13】https://github.com/izuna385/ScispaCy-Candidate-Generator</p><h1 id="2dcb" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">模型和评分</strong></h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lt"><img src="../Images/07841b284ff53d969f53a06b80c5425e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w2BVlW6FCz1-kWeHzEAB7Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">转换器用于对提及和实体进行编码。引自<a class="ae kj" href="https://arxiv.org/abs/1905.01969" rel="noopener ugc nofollow" target="_blank"> Humeau 等人，2010 年</a>。</figcaption></figure><p id="b7a1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">模型和候选实体的编码器是一个非常简单的结构。我们将使用从链接目标范围和周围单词块编码的嵌入。我们还将使用从实体名称和描述中生成的嵌入。</p><h1 id="4e3a" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">候选人生成</strong></h1><p id="0c93" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">对于基于表面的 CG，我们使用 ScispaCy 有两个原因。第一是我们正在研究的数据集 BC5CDR 属于生物医学领域，第二是 ScispaCy 本身有一个表面的基于表单的候选生成功能。对于基于人工神经网络的 CG，我们将使用 faiss。</p><h1 id="92fa" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">训练</strong></h1><p id="f2a6" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">为了在用 BERT 训练时保存负样本，我们在这里使用批内负采样。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lu"><img src="../Images/ca68ec5b8957af415a135c84d79df58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7r4-4aHdug78wHIo"/></div></div></figure><p id="1e33" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这种学习方法中，可以通过增加批量来更严格地训练编码器，但这也增加了所需的 GPU 资源。在这个实验中，我们已经证实，即使批量大小为 16，训练也是可能的🙂。</p><h1 id="5793" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">评估和结果</strong></h1><p id="edc1" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">我们使用两种方法生成候选项:表面形式和近似邻域搜索，但最终预测使用两者的提及和实体嵌入的内积。</p><ul class=""><li id="506f" class="lv lw hi jp b jq jr jt ju jw lx ka ly ke lz ki ma mb mc md bi translated">基于表面的 CG</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/47a5edc189b8b166b1507e2a95286798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ek5zemojXmpclu_itj1AGw.png"/></div></div></figure><ul class=""><li id="e177" class="lv lw hi jp b jq jr jt ju jw lx ka ly ke lz ki ma mb mc md bi translated">基于人工神经网络的 CG</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/62886b18d59fa7165f2b026501ea88bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MI7X5PDgw2XGgQ5Mb9fyBQ.png"/></div></div></figure><h1 id="7e95" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">讨论和进一步指示</strong></h1><p id="d780" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">基于表面形式的候选生成的最终正确答案率约为 50%。在这种情况下，我们使用内积进行最终预测，但实际上，曲面相似性是预测中的另一个重要特征。除了嵌入之间的评分之外，还可以考虑准备一个考虑字符相似性的评分函数。</p><p id="747d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">此外，本研究使用的数据集只有 10000 个左右，仅为 Gillick 等人使用的数据数量的 1/10000，由此可以推断，我们的模型成功地将上下文和实体信息编码到嵌入中。</p><h1 id="cf3a" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak"> GitHub 库</strong></h1><ul class=""><li id="a60d" class="lv lw hi jp b jq lc jt ld jw mg ka mh ke mi ki ma mb mc md bi translated"><a class="ae kj" href="https://github.com/izuna385/Entity-Linking-Tutorial" rel="noopener ugc nofollow" target="_blank">https://github.com/izuna385/Entity-Linking-Tutorial</a></li><li id="331c" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki ma mb mc md bi translated">另外，如果你对实体链接更感兴趣，你可能也会喜欢<br/><a class="ae kj" href="https://github.com/izuna385/Entity-Linking-Recent-Trends" rel="noopener ugc nofollow" target="_blank">https://github.com/izuna385/Entity-Linking-Recent-Trends</a></li></ul><p id="45d6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请随时联系或提出问题！</p></div><div class="ab cl lm ln gp lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="hb hc hd he hf"><h2 id="0503" class="mo kl hi bd km mp mq mr kq ms mt mu ku jw mv mw kw ka mx my ky ke mz na la nb bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="2d42" class="lv lw hi jp b jq lc jt ld jw mg ka mh ke mi ki nc mb mc md bi translated"><a class="ae kj" href="https://www.aclweb.org/anthology/K16-1025.pdf" rel="noopener ugc nofollow" target="_blank">用于命名实体消歧的单词和实体嵌入的联合学习</a></li><li id="6591" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://www.aclweb.org/anthology/D17-1277.pdf" rel="noopener ugc nofollow" target="_blank">深度联合实体消歧与局部神经关注</a></li><li id="93c5" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://www.aclweb.org/anthology/P18-1148/" rel="noopener ugc nofollow" target="_blank">通过对提及之间的潜在关系建模来改进实体链接</a></li><li id="eaaf" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1811.08603" rel="noopener ugc nofollow" target="_blank">神经集体实体链接</a></li><li id="a3cc" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://www.aclweb.org/anthology/P18-1010/" rel="noopener ugc nofollow" target="_blank">用于细粒度实体分类和链接的分层损失和新资源</a></li><li id="4007" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1911.09787" rel="noopener ugc nofollow" target="_blank"> LATTE:生物医学实体链接的潜在类型建模</a></li><li id="c5c9" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2352870/" rel="noopener ugc nofollow" target="_blank">通过最小化模糊性和可变性来规范生物医学术语</a></li><li id="54b2" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1909.10506" rel="noopener ugc nofollow" target="_blank">学习实体检索的密集表示</a></li><li id="92f1" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1906.07348" rel="noopener ugc nofollow" target="_blank">通过读取实体描述进行零炮实体链接</a></li><li id="4f1c" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1911.03814" rel="noopener ugc nofollow" target="_blank">可扩展零炮实体链接与密集实体检索</a></li><li id="12f8" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626/" rel="noopener ugc nofollow" target="_blank"> BioCreative V CDR 任务语料库:化学疾病关系抽取资源</a></li><li id="9294" class="lv lw hi jp b jq mj jt mk jw ml ka mm ke mn ki nc mb mc md bi translated"><a class="ae kj" href="https://arxiv.org/abs/1905.01969" rel="noopener ugc nofollow" target="_blank">多编码器:快速准确的多句子评分的变压器架构和预训练策略</a></li></ol></div></div>    
</body>
</html>