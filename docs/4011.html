<html>
<head>
<title>Understanding Convolutional Neural Network (CNN).</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解卷积神经网络(CNN)。</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/understanding-convolutional-neural-network-cnn-9f5ec8a308ac?source=collection_archive---------7-----------------------#2021-07-03">https://medium.com/nerd-for-tech/understanding-convolutional-neural-network-cnn-9f5ec8a308ac?source=collection_archive---------7-----------------------#2021-07-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="80c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN背后的整个想法始于我们的大脑。人脑很容易处理图像，图像通过视网膜作为电信号传递到由大量密集细胞层组成的初级视觉皮层。它提取图像的各种信息，如图像的边缘、部分，相关地，CNN使用各种滤波器从输入图像中提取信息。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/0f621ff5d11c421b487d6d2a2349b19d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/0*89XRm_ZCLv5RaymH.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">卷积神经网络vs人脑</figcaption></figure><h2 id="cabf" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">图像内核/过滤器:</h2><p id="9a25" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">如果你曾经使用过照片编辑软件，你可能见过滤镜，比如模糊滤镜。但是这些是如何工作的呢？</p><p id="5b62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">滤镜本质上是一个<strong class="ih hj">图像内核，</strong>是一个应用于整个图像的小矩阵。滤波器允许我们通过识别边缘从图像中提取信息来转换图像，其中在神经网络中使用多个核来识别边缘。内核以滑动窗口的方式应用于元素。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es kp"><img src="../Images/c78fe3f80256510affb7615369adfa0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0QSqD453M9DQaP1HgYN1w.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">过滤</figcaption></figure><p id="d4e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们本质上是在输入矩阵上滑动核，即图像乘以滤波器权重和这些结果的总和以获得最终特征。注意分辨率是如何降低的，因为我们取9个输入值，输出到一个值。参考这个网站来了解内核如何工作<a class="ae ku" href="https://deeplizard.com/resource/pavq7noze2" rel="noopener ugc nofollow" target="_blank">深蜥蜴</a>。这些滤波器被称为<strong class="ih hj">卷积核。将它们传递到图像上的过程被称为卷积。内核在步中的运动叫做<strong class="ih hj">大步</strong>一般是一步。如果步幅增大，图像尺寸将减小。卷积的主要用途是使用特征检测器在图像中找到特征，将它们放在特征图中，这仍然保留了原始图像的重要性。</strong></p><div class="je jf jg jh fd ab cb"><figure class="kv ji kw kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/e8a3f165a553796dd7836c78c3b3d74c.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*lx8AkX7ir8kL5XuSR9K6Mg.png"/></div></figure><figure class="kv ji lb kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/e927cef075b94d8c66081843eaa4d197.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*Mb9g7SfMvABDm_2CkBO7tw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx lc di ld le translated">进展</figcaption></figure></div><p id="31e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在卷积过程中，我们会丢失边界信息。所以我们可以用更多的值填充图像。零填充是非常常见的做法，这样我们就不会丢失边界上的信息。在图像周围添加零以正确捕捉边缘称为<strong class="ih hj">零填充。</strong></p><p id="f31a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">→知道不加填充的卷积矩阵大小的一般公式是<strong class="ih hj">(N×N)*(F×F)=(N-F+1)x(N-F+1)。</strong>这可以通过为参数填充赋予“有效”来实现。</p><p id="4dc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">→带填充的卷积矩阵大小公式为<strong class="ih hj"> (N+2p-F+1)x(N+2p-F+1)。</strong>如果填充大小为1，则结果矩阵大小与输入矩阵相同。这可以通过为参数填充赋予“相同”来实现。</p><p id="dc1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">→为了描述什么是正确的填充尺寸，使用这个公式<strong class="ih hj"> p = (F-1)/2。</strong></p><div class="je jf jg jh fd ab cb"><figure class="kv ji lf kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/fcb318b03a0b3f0919cbcdf8b5b4c6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*ZsIUIqBhF-urAVoWjII28Q.png"/></div></figure><figure class="kv ji lg kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/089d06ca7b66448c5c515c6c925a648c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*7YhB0vsuNpjKoJxZ3acjig.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx lh di li le translated">无填充与有填充。</figcaption></figure></div><h2 id="5deb" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">将人工神经网络用于图像的缺点:</h2><p id="6467" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">人工神经网络导致参数爆炸，训练神经网络的参数过大。在拼合图像时，ANN会丢失信息。人工神经网络更适合类似的图像。ANN只捕捉图像的中心，而CNN不考虑任何位置。</p><p id="f066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN使用卷积层来帮助缓解这些问题。当我们对输入图像应用多个图像滤波器时，就创建了一个卷积层。然后，将对该层进行训练，以计算出最佳过滤器权重值。CNN还通过关注本地连通性来帮助减少参数。在卷积层中，并非所有神经元都完全连接。相反，神经元仅连接到下一层中的局部神经元的子集，下一层最终成为过滤器。</p><p id="bb84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积侧重于局部滤波，这里不同的滤波器开始识别图像的不同部分。将滤波器堆叠在一起会产生卷积层。对于彩色图像，我们有RGB的强度值，它被表示为<strong class="ih hj"> (1280，720，3) </strong>(高度，宽度，颜色)。在彩色图像中，我们以3D过滤器结束，其中通常卷积层被馈送到另一个卷积层，这允许网络发现模式中的模式，通常对于后面的卷积层来说更复杂。</p><h2 id="f974" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">池层:</h2><p id="d01b" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">为什么我们需要共用？</p><p id="4667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们拍摄猎豹的图像，每张图像的不同位置都有人脸。汇集从图像中提取重要的特征，这有助于识别图像，而不管图像处于什么位置。</p><p id="3609" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即使有本地连接，当处理彩色图像和可能的数十或数百个过滤器时，我们将有大量的参数。我们可以使用池层来减少这种情况。池层接受卷积层作为输入。池层中的神经元没有权重或偏差。池层只是将一些聚合函数应用于所有输入。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/4e018c07dfd6992896deebc9daa6b3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*hj7-b4AwBhnz6q6O-9Ek6Q.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">CNN架构</figcaption></figure><p id="4282" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有几种类型的池可用，如最大池，平均池，总和池。</p><p id="2caf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最大池取在矩阵中移动的盒子的最大值，过滤器大小为(2 x 2)，步长为2。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es lk"><img src="../Images/71bb30f392191a916affc6a0ab5f6019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-1ekjWg-JHEutfiHuVAZwg.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">最大池化。</figcaption></figure><p id="3386" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上图中可以看出，应用合并图层后，重要信息仍然保留，而16个元素减少为4个元素，这有助于神经网络识别与位置无关的特征(位置不变性)。平均池是简单地取出盒子矩阵的平均值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es ll"><img src="../Images/e953d63f8572683e6e195fee12abd574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXf_eiwsq1OQbbz_Jnm3Lg.png"/></div></div></figure><p id="1d83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">池大大减少了我们的参数数量。这个池层最终将删除大量信息，甚至一个跨度为2的(2x2)小池“内核”也将删除75%的输入数据。然而，总的趋势将是真实的，通过汇集层，它创建了通用模型，减轻过度拟合。</p><h2 id="9098" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">扁平化:</h2><p id="98e8" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">在将汇集的特征映射馈送到密集连接的人工神经网络之前，将其展平为列向量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es kp"><img src="../Images/40707f6595a909ca19e13dbc262619f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sjRkhX5hyxXQjLoLiuEjVA.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">CNN架构</figcaption></figure><p id="262b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入图像由卷积层处理，卷积层由内核和激活层组成，以使图像非线性，然后通过池层以最小化图像的大小，然后将其传输到完全连接的层，图像被展平。</p><p id="6e36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CNN可以报道所有类型的建筑。没有设计架构的经验法则，它完全基于错误度量和用例。</p><div class="je jf jg jh fd ab cb"><figure class="kv ji lm kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/32978aa4868dfeccca12aeaafec9432f.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*9TrNsnNnVP81uDJ-UVXxMA.png"/></div></figure><figure class="kv ji ln kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/fe908fcd7d17f90016095d7fef4fd498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*hSbLvbKde8NSIbRpQVllvw.png"/></div></figure></div><p id="ca62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不管CNN的结构如何，最后的特征图将被展平并送到全连接层，以合并所有提取的特征。</p><div class="je jf jg jh fd ab cb"><figure class="kv ji lo kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/3be3f8fa8ae025018aedec2ce7c4ce9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*BhaPyIwejZCKkmFUWPtbYw.png"/></div></figure><figure class="kv ji lp kx ky kz la paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/10cf100768f1301f70e72efd530f6755.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*5J4_XVvTPPy31Eii45biyA.png"/></div></figure></div><p id="0af7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每组卷积之后是也输出图像的激活层。然而，连续的输出越来越小(由于汇集层)以及越来越深(由于卷积层中的特征映射)。这一整套层被送入常规前馈神经网络，最后被送入SoftMax预测层。</p><p id="a4fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考这个网站来了解CNN架构如何运作</p><p id="344b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你对CNN的工作有了基本的了解，并参考<a class="ae ku" href="https://github.com/Rishikumar04/Deep-Learning/blob/main/CNN/01-Keras-CNN-MNIST.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a>使用python构建CNN。</p></div></div>    
</body>
</html>