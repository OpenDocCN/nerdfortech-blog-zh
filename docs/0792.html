<html>
<head>
<title>Predicting Food Cuisine using Natural Language Processing and Machine Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 中的自然语言处理和机器学习预测食物烹饪</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/predicting-food-cuisine-using-natural-language-processing-and-machine-learning-in-python-a00c859a8ac7?source=collection_archive---------3-----------------------#2021-02-14">https://medium.com/nerd-for-tech/predicting-food-cuisine-using-natural-language-processing-and-machine-learning-in-python-a00c859a8ac7?source=collection_archive---------3-----------------------#2021-02-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="a738" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">数据科学能否根据菜谱中的食材预测美味佳肴？</p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/9eecd87c84424fb4d71506f5ce33a6cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VKbLdu6_w_7zCZP2V6rrXQ.png"/></div></div></figure><p id="e4db" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">当我过去从事机器学习分类项目时，我总是想知道如果我的独立专栏是文本而不是数字会怎么样，所以我遇到了一个我非常喜欢的数据集，它由美食和食谱组成。你可以从<a class="ae jw" href="https://github.com/sahasourav1522/Cuisine-Data.git" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集和代码。除了对数据科学感兴趣之外，我还是一名美食家，所以我很高兴能参与这个项目。</p><p id="9100" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">从这篇文章中得到的关键是，当你有文本中的数据并且你需要做机器学习分类问题时，对这个场景有一个基本的理解。</p><p id="cff7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">让我们首先导入所有必需的库</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="c5b5" class="kc kd hi jy b fi ke kf l kg kh">from nltk.corpus import stopwords <br/>import re<br/>from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>import pandas as pd</span></pre><h1 id="b066" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">了解数据集</strong></h1><p id="3975" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jt lh iw ix ju li ja jb jv lj je jf jg hb bi translated">让我们看看下面的数据集:</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="bd1e" class="kc kd hi jy b fi ke kf l kg kh">data = pd.read_csv(“cuisine_data.csv”)<br/>data.head()</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lk"><img src="../Images/ed40f40fa3e087451664a33b75e3e520.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*_C8e6Gslb3BRIc7YxVjRlw.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">数据的前 5 行</figcaption></figure><p id="9acf" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在上面的数据集快照中，<strong class="il hj">美食 _ 描述</strong>是独立特征，<strong class="il hj">美食</strong>是我们需要预测的目标。它由 39，774 行组成。</p><p id="1c07" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">所以在这个问题陈述中，我们将使用烹饪描述来预测食物的烹饪。由于我们在这个数据中有一个标签/目标，我们将做监督学习模型。</p><p id="d71c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">让我们检查一下目标变量中有多少个类？</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="73e6" class="kc kd hi jy b fi ke kf l kg kh">len(data.cuisine.value_counts())</span><span id="ee9b" class="kc kd hi jy b fi lp kf l kg kh">#20</span></pre><p id="8ef7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">从上面的输出中，我们可以看到目标变量(Cuisine)中有 20 个类。现在，我们将在下面看到这 20 种美食中有哪些出现在目标栏中</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="adbf" class="kc kd hi jy b fi ke kf l kg kh">data.cuisine.unique()</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es lq"><img src="../Images/89b512a3e7c7d30eec708622c32158a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7Rm7Gp9TwIuHHRJv2vVFw.png"/></div></div></figure><h1 id="9639" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">检查缺少的值</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="4961" class="kc kd hi jy b fi ke kf l kg kh">data.isnull().sum()</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lr"><img src="../Images/04654f5c2e2eafa2fc4e9bb7f554e2a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*lbwzphAe_NQFl7GafBfhkw.png"/></div></figure><p id="5df7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">从上面的输出中，我们可以看到数据集中没有丢失的值。</p><h1 id="931e" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">删除重复项</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="3060" class="kc kd hi jy b fi ke kf l kg kh">data.drop_duplicates(inplace = True)<br/>data.shape</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ls"><img src="../Images/d4dcfaf3610768f40ab338fc5e859989.png" data-original-src="https://miro.medium.com/v2/resize:fit:218/format:webp/1*4ivLDGSkCb0c4jaweTShxA.png"/></div></figure><p id="e879" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">最初，数据集由 39774 行组成，现在它有 39677 行，因此<strong class="il hj"> 97 个重复行</strong>已从数据集中删除。</p><h1 id="3a0b" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">预处理文本</h1><p id="5334" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jt lh iw ix ju li ja jb jv lj je jf jg hb bi translated">检查“菜肴描述”一栏中有多少单词</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="dc67" class="kc kd hi jy b fi ke kf l kg kh">print(data[‘cuisine_description’].apply(lambda x: len(x.split(‘ ‘))).sum())<br/>#806112</span></pre><p id="fb72" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因此，我们在“美食描述”一栏中共有 8，06112 个单词</p><p id="7958" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">现在，在 8，06，112 个单词中，我们将删除无意义的单词，如“the”、“is”、“of”等。</p><p id="5c5d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们还将删除由于不同的数据源和编码问题而通常出现在数据集中的特殊字符和不需要的符号。</p><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="4d21" class="kc kd hi jy b fi ke kf l kg kh">special_character_remover = re.compile(‘[/(){}\[\]\|@,:]’) <br/>extra_symbol_remover = re.compile(‘[^-9a-z #+_]’)<br/>STOPWORDS = set(stopwords.words(‘english’))</span><span id="6fa4" class="kc kd hi jy b fi lp kf l kg kh">def clean_text(text):<br/> text = text.lower()<br/> text = special_character_remover.sub(‘ ‘, text) # Replacing these characters with spaces<br/> text = extra_symbol_remover.sub(‘’, text)<br/> text = ‘ ‘.join(word for word in text.split() if word not in STOPWORDS)<br/> return text</span><span id="611a" class="kc kd hi jy b fi lp kf l kg kh">data[‘cuisine_description’] = data[‘cuisine_description’].apply(clean_text)</span><span id="2dc3" class="kc kd hi jy b fi lp kf l kg kh">print(data[‘cuisine_description’].apply(lambda x: len(x.split(‘ ‘))).sum())</span></pre><p id="cd8c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因此，经过预处理后，大约 2775 个单词被删除。所以现在我们将在这些干净的文本上建立一个模型。</p><h1 id="3035" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">列车测试分离</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="7386" class="kc kd hi jy b fi ke kf l kg kh">x = data.cuisine_description<br/>y = data.cuisine<br/>x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 42)</span></pre><h1 id="29c6" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">为模型构建准备数据</h1><p id="5032" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jt lh iw ix ju li ja jb jv lj je jf jg hb bi translated">在构建任何模型之前，我们将使用 CountVectorizer 和 TfidfTransformer。然而，这篇文章的目的不是学习 NLP 教程，而是用外行的术语解释这些概念。</p><p id="e01d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在 CountVectorizer 和 TfidfTransformer 的帮助下，由于模型理解数字，因此在建立模型之前，将根据整个文本中出现的每个单词的频率(计数)将整个文本转换为数字形式。因此，根据我们将从 CountVectorizer 和 TfidfTransformer 获得的数字输出，我们将在下面建立机器学习模型。</p><h1 id="a144" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">应用逻辑回归算法</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="f966" class="kc kd hi jy b fi ke kf l kg kh">from sklearn.linear_model import LogisticRegression<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.feature_extraction.text import TfidfTransformer</span><span id="5b12" class="kc kd hi jy b fi lp kf l kg kh">lr = Pipeline([(‘vect’, CountVectorizer()),<br/> (‘tfidf’, TfidfTransformer()),<br/> (‘clf’, LogisticRegression())<br/> ])</span><span id="e738" class="kc kd hi jy b fi lp kf l kg kh">lr.fit(x_train, y_train) # Training the model<br/>y_pred1 = lr.predict(x_test) # Predicting on test data</span><span id="f889" class="kc kd hi jy b fi lp kf l kg kh"># Calculating Accuracy<br/>print(f”Accuracy is : {accuracy_score(y_pred1,y_test)}”)</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lt"><img src="../Images/72d35791e5ad66576ce0eee8d8b5f2f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*K4S1ow-OCWdZJQIraOU2MA.png"/></div></figure><h1 id="8cfa" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">应用朴素贝叶斯分类算法</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="36b0" class="kc kd hi jy b fi ke kf l kg kh">from sklearn.naive_bayes import MultinomialNB</span><span id="6fca" class="kc kd hi jy b fi lp kf l kg kh">naivebayes = Pipeline([(‘vect’, CountVectorizer()),<br/> (‘tfidf’, TfidfTransformer()),<br/> (‘clf’, MultinomialNB())<br/> ])<br/>naivebayes.fit(x_train, y_train)<br/>y_pred = naivebayes.predict(x_test)</span><span id="e941" class="kc kd hi jy b fi lp kf l kg kh">print(f”Accuracy of Naive Bayes Classifier is: {accuracy_score(y_pred,y_test)}”)</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lu"><img src="../Images/4e5d8c70587dbba0b9e1f268e8ae1d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*r3Tb8lxUXfVviwN-XfB4oQ.png"/></div></figure><h1 id="dddc" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">应用 XGBoost 分类器算法</h1><pre class="ji jj jk jl fd jx jy jz ka aw kb bi"><span id="2d8f" class="kc kd hi jy b fi ke kf l kg kh">from xgboost import XGBClassifier</span><span id="a7fc" class="kc kd hi jy b fi lp kf l kg kh">xgboost = Pipeline([(‘vect’, CountVectorizer()),<br/> (‘tfidf’, TfidfTransformer()),<br/> (‘clf’, XGBClassifier())<br/> ])<br/>xgboost.fit(x_train, y_train)</span><span id="cf90" class="kc kd hi jy b fi lp kf l kg kh">y_pred = xgboost.predict(x_test)</span><span id="3332" class="kc kd hi jy b fi lp kf l kg kh">print(f”Accuracy of XGBoost Classifier is : {accuracy_score(y_pred,y_test)}”)</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lv"><img src="../Images/b7e755c30e96eed8525b586df89220d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*zn1Wrlp_r3QEz9zcRlNlKQ.png"/></div></figure><p id="76f8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">从以上结果可以看出，Logistic 回归的准确性更好。</p><h1 id="f139" class="ki kd hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">结束注释</strong></h1><p id="30f9" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jt lh iw ix ju li ja jb jv lj je jf jg hb bi translated">使用更高级的 NLP 技术和 ML/DL 模型可以提高精确度，但我的目的是让初学者对做这个项目有一个基本的了解，这样你就可以开始处理文本数据并建立分类模型。</p></div></div>    
</body>
</html>