<html>
<head>
<title>Why RudderStack Used Postgres Over Apache Kafka for Streaming Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么RudderStack使用Postgres而不是Apache Kafka作为流引擎</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine-cccfa2dda0f2?source=collection_archive---------10-----------------------#2021-06-03">https://medium.com/nerd-for-tech/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine-cccfa2dda0f2?source=collection_archive---------10-----------------------#2021-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7627053b2765d6c948c16c17668b4edc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fTrPu_7QCy0JKaxLDnVAaQ.png"/></div></div></figure><h1 id="6266" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">概观</h1><p id="e47f" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这篇文章中，我们回答了一个非常重要的问题——“为什么我们不喜欢Apache Kafka而不是PostgreSQL来构建RudderStack。”我们讨论了在使用PostgreSQL的已实现解决方案上使用Apache Kafka的一些挑战。</p><h1 id="3c5d" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">方向舵堆栈是一个队列</h1><p id="c192" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">RudderStack的核心是一个排队系统。它从多个来源获取事件，持久化它们，然后将它们发送到不同的目的地。持久化事件是至关重要的，因为RudderStack需要能够处理不同类型的故障。</p><p id="28ed" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们来看一个例子—由于某种原因，目标可能会停机任意长的时间。在这种情况下，RudderStack应该理想地保留事件，然后在目的地再次运行时重试发送事件。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/a45b68f4229f01d81194a87e30761a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*up3AXK40J_poJrLT.png"/></div></div></figure><p id="81e5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">方向舵堆栈——一个事件队列</strong></p><p id="8517" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">自然，构建这种排队解决方案的工具的流行选择是Apache Kafka。Kafka提供了持久性、有序性、去杜平、极致性能、横向可伸缩性等特性。任何排队系统都需要的。</p><p id="e1af" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一个简单的基于Kafka的系统看起来像这样:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/fc319cbba8290c05368d1292f973e6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*g9epnpxIaP0Eql4T.png"/></div></figure><p id="42a1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">一个简单的基于卡夫卡的系统</strong></p><p id="c9f1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在我们的排队系统中，我们需要为每个目的地创建一个单独的主题。来自源的事件可以排队到特定于目的地的主题中，而一个消费者使用来自目的地主题的事件。消费者本身可能会将发送事件的工作分散到多个线程中进行并行处理。</p><p id="02db" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">每个目的地有一个单独的主题是理想的，因为如果一个特定的目的地不可用(例如停机)，我们不想阻止其他目的地的事件。然而，正如我们将在下一节中看到的，失败可能是其他类型的，这导致了这个设置的复杂性。</p><p id="5ac0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">虽然这种架构看起来很简单，但Apache Kafka有它自己的一系列挑战，我们将在下面的部分中重点讨论这些挑战。</p><h1 id="184f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">管理挑战</h1><p id="2916" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Apache Kafka不是最容易部署和分发的产品。此外，它对Apache Zookeeper——一种分布式配置和同步服务——的依赖使它成为一个相当大的<a class="ae kw" rel="noopener" href="/@anuradha.neo/kafka-is-not-the-best-anymore-meet-pulsar-9eb435c9fc0b">管理挑战</a>。</p><p id="a9bf" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们不想运输和支持我们自己都不是专家的产品。</p><h1 id="6e6d" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">许可问题</h1><p id="4ae7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">许可是阿帕奇卡夫卡的另一个问题。我们希望在开源许可(AGPLv3)下发布全部代码。但是，由Apache基金会管理的Apache Kafka的核心是在<a class="ae kw" href="https://www.apache.org/licenses/LICENSE-2.0" rel="noopener ugc nofollow" target="_blank"> Apache-2许可</a>下发布的。此外，由合流积极管理的版本仅在非OSI许可(合流社区许可)下可用。</p><p id="7fe0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">一些特定的Kafka特性，比如kSQL(对于调试作业非常有用)，在Apache许可下是不可用的。</p><p id="cd22" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们构建的排队系统的一个关键特性是能够查看未决事件，并更新它们的状态，即，将它们的失败状态设置为重试。使用OSS许可证不可能实现这一点。</p><h1 id="03cc" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">处理多个客户</h1><p id="aa5a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在我们的托管、多租户产品中，我们在同一个RudderStack实例上有多个客户。虽然他们可以使用与上述相同的架构，每个目的地有一个主题，但这可能会导致一个客户的大量事件阻塞来自另一个客户的事件，如下图所示:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/14989975298a2996e12f7dc40f97ce68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*c4VZyQ7DZIhO5WwW.png"/></div></figure><p id="c57e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">来自多个客户的事件</strong></p><p id="5d15" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">理想情况下，我们希望将客户分开，以提供每个客户的QoS保证。</p><p id="b05a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">方法是为每个目的地/客户组合创建一个单独的Kafka主题。不幸的是，卡夫卡与主题的数量不相称。这最终会阻碍我们客户群的增长。我们在Segment的朋友面临着类似的问题，并就此写了一篇<a class="ae kw" href="https://segment.com/blog/introducing-centrifuge/" rel="noopener ugc nofollow" target="_blank">博客</a>。</p><h1 id="a244" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">错误处理</h1><p id="d135" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">对于Kafka中的数据，错误处理变得复杂。如果某个事件未能交付，我们希望采用以下工作流程:</p><ul class=""><li id="46fa" class="kx ky hi jq b jr km jv kn jz kz kd la kh lb kl lc ld le lf bi translated">记录一些元数据，如错误代码、失败次数等。</li><li id="bff2" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">将它放回队列的顶部，以便随后重试。</li><li id="5a6b" class="kx ky hi jq b jr lg jv lh jz li kd lj kh lk kl lc ld le lf bi translated">阻止来自该用户的进一步事件，以保留订单，直到事件成功交付(或中止)。</li></ul><p id="bcb9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">下图显示了系统在任一点的“逻辑”状态示例:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/c3578a8331e4c2e5b01701c7d7d243ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*_ppNHyysmoZsu1Tx.png"/></div></figure><p id="8c0c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">系统的逻辑状态</strong></p><p id="26d6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">事件#1已失败，必须重试。除了事件之外，我们还想记录重试的次数、失败错误代码等。事件#3来自同一个终端用户，因此在事件#1成功或中止之前，它不能被发送。然而，事件#2是不相关的，应该被处理并成功。</p><p id="1a4c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">如上图所示，队列正在处理事件，并将它们标记为成功、失败或等待。一个单独的过程(或主过程的一次扫描)可以从顶部开始。队列总是一致的，所以如果发生崩溃，我们总是可以从头开始。</p><p id="c96f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">不幸的是，使用Apache Kafka实现上述逻辑语义并不简单。Kafka不允许更新事件，所以我们不能将顶层事件标记为失败，也不能将任何元数据与它相关联。</p><p id="2eb2" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">移除事件并将其排队返回(在最后)也不起作用，因为这将打破排序约束—事件#3将在事件#1之前结束，如上面的示例所示。</p><h1 id="93a2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">使用两个队列</h1><p id="e90e" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">另一个解决方案是使用两个队列——主队列和失败队列。主队列中失败的作业和跳过的作业(来自同一用户ID)可以放入失败队列中。下图演示了这一点:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/99c464769c4b4b806f4b3b5e5ce4a1ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*TcyY0CqfsbZALTef.png"/></div></figure><p id="d416" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">使用两个队列</strong></p><p id="6bc6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这种方法的问题是它只对第一次失败有效。我们如何处理失败队列中发生的失败？我们仍然需要更新元数据并对事件重新排队，因此我们需要第二个失败队列来存储第一个失败队列中的失败事件。</p><p id="a4f6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">我们希望在事件过期之前重试事件几十次，所以这不是一个很好的解决方案。</p><h1 id="27ab" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">可调试性</h1><p id="3427" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">能够在事件在队列中等待时查询事件和/或更新元数据(围绕故障)以强制立即重试是我们在RudderStack构建的一个很好的调试功能。拥有一个类似SQL的持久化事件查询接口对此很有帮助。</p><p id="3c66" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">虽然Kafka的SQL提供了查询接口，但它不允许更新。此外，正如我们前面提到的，SQL还存在许可问题。</p><h1 id="aea0" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">最后</h1><p id="4ac8" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这篇文章中，我们探讨了为什么我们决定构建自己的队列库，而不是采用基于Kafka的解决方案。我们会写一篇关于实现的博客，但是如果你好奇，你可以在<a class="ae kw" href="https://github.com/rudderlabs/rudder-server" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上探索实现。</p><p id="f061" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">有了PostgreSQL支持的排队系统，我们可以很容易地改变事件排序和调试的逻辑。此外，我们只需运行一个SQL查询，就可以完全了解来自源、用户或目的地的所有事件——这是Apache Kafka无法做到的。</p><h1 id="0e26" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">免费注册并开始发送数据</h1><p id="bac4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">测试我们的事件流、ELT和反向ETL管道。使用我们的HTTP源在不到5分钟的时间内发送数据，或者在您的网站或应用程序中安装我们12个SDK中的一个。<a class="ae kw" href="https://app.rudderlabs.com/signup?type=freetrial" rel="noopener ugc nofollow" target="_blank">上手</a>。</p><p id="4c77" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">本博客最初发表于</strong><a class="ae kw" href="https://rudderstack.com/blog/why-rudderstack-used-postgres-over-apache-kafka-for-streaming-engine" rel="noopener ugc nofollow" target="_blank"><strong class="jq hj">https://rudder stack . com/blog/why-rudder stack-used-postgres-over-Apache-Kafka-for-streaming-engine</strong></a><strong class="jq hj">。</strong></p></div></div>    
</body>
</html>