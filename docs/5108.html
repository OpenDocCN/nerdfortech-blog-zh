<html>
<head>
<title>K means clustering using scala spark and mllib</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k 表示使用 scala spark 和 mllib 进行聚类</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/k-means-clustering-using-scala-spark-11c1f82394a7?source=collection_archive---------1-----------------------#2021-08-29">https://medium.com/nerd-for-tech/k-means-clustering-using-scala-spark-11c1f82394a7?source=collection_archive---------1-----------------------#2021-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5733" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">k 均值聚类是一种矢量量化的方法，用于将<strong class="ih hj"> n </strong>个观察值划分为<strong class="ih hj"> k </strong>个簇，每个观察值属于具有最近均值的簇。</p><p id="d6a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将演示</p><ul class=""><li id="4cdf" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">使用 mllib 训练 k 均值聚类模型，ml lib 是作为 apache spark 项目的一部分开发的。</li><li id="b0e1" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">在 HDFS 拯救我们训练有素的模特。</li><li id="c65a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">使用这个经过训练的模型进行预测。</li></ul><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jr"><img src="../Images/ffbfc6975ab56732e4d8ed1d172dc520.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvdDqOZdSyvTWjSEi0iT5g.png"/></div></div></figure><p id="8d03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> K 表示聚类</strong></p><p id="c24b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面的例子</p><p id="ec0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于房地产公司，我们需要将他们的潜在客户分为两类。</p><p id="eb4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">A 类:愿意花高价购买一处房产。</p><p id="6de3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">B 类</strong>:不想花大价钱买房产。</p><p id="370e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决上述问题(将所有客户分为两组)，我们收集了以下数据。</p><ul class=""><li id="6c0f" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">家庭成员年收入。</li><li id="b9f7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">房子的大小。</li><li id="b829" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">远离市区。</li></ul><p id="bab8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据上述特征(收集的数据),所有客户将被分为 A 类或 b 类。</p><p id="7ad8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">聚类</strong></p><p id="31a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">聚类是一种无监督的学习方法，在这种方法中，我们试图找到<strong class="ih hj"> n </strong>个观察值之间的关系。在上面的例子中，我们试图找出这三个特征之间的关系，并根据这些特征将所有的顾客归为两个组中的一组。</p><p id="3bfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> K 表示算法</strong></p><p id="5fcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">K means 是一种无监督聚类算法，它将给定的数据点划分为一个聚类，其中数据点和质心之间的平方距离最小。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es kd"><img src="../Images/6b5891ea7fa7a4178519ed159eac2990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fz-rjYPPRlGEMdTI-RLbDg.png"/></div></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">k 表示聚类</figcaption></figure><p id="ac6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">K 步表示聚类</strong></p><ul class=""><li id="e11d" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">初始化</strong></li></ul><p id="2eac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将任意随机点初始化为群集的质心。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es ki"><img src="../Images/26ac32ba8651c951ca2c341e014b9924.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*GyKQY59yxCp9Oab_FeoANg.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">初始化</figcaption></figure><ul class=""><li id="d4fa" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">集群分配</strong></li></ul><p id="2fee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">初始化质心后，以质心和数据点之间的距离最小的方式分配数据点。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es kj"><img src="../Images/5b7e4bc6e60890f4357111cc53f39a0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*Fuc5lZ7ubypYLFS5cx0D-g.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">集群分配</figcaption></figure><ul class=""><li id="b170" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">移动质心</strong></li></ul><p id="d0e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们计算的 centriod 可能没有优化。计算数据点的平均值并移动质心。重复聚类分配，直到质心停止移动，如果质心移动已经停止，我们可以说我们的算法是优化的。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es kk"><img src="../Images/42c41a6a11e7554c66ce4b6e74775a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*13ja2g7Kb_IKRqBq4FW-1Q.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">移动质心</figcaption></figure><ul class=""><li id="c0cd" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">收敛</strong></li></ul><p id="1eff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们可以说算法是收敛的，可以给出一个清晰的结果。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es kl"><img src="../Images/2f7d6ae9f9ff1b70b0590c20e56e85e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*2OOblVsCiiFxc1Zin32VPQ.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">趋同；聚集</figcaption></figure><p id="528e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用 spark 和 Mlllib 训练和保存模型</strong></p><p id="b44b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">出于培训目的，我们采用了上述功能。样本训练集应该是这样的。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es km"><img src="../Images/b807fce0fc939faa11f5182f3c1cf3b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*YLslXpUePNJwUaaZZUNydA.png"/></div><figcaption class="ke kf et er es kg kh bd b be z dx translated">使用的样本训练集</figcaption></figure><blockquote class="kn ko kp"><p id="d141" class="if ig kq ih b ii ij ik il im in io ip kr ir is it ks iv iw ix kt iz ja jb jc hb bi translated">mllib 算法将输入类型作为 type <strong class="ih hj">向量</strong>，因此最初我们需要提取所有需要的特征。</p></blockquote><p id="c64e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上述训练集中提取特征后，我们可以使用这些数据来训练我们的 K 均值聚类模型。这里我们取 2 作为我们的集群数。</p><pre class="js jt ju jv fd ku kv kw kx aw ky bi"><span id="8f3d" class="kz la hi kv b fi lb lc l ld le"><strong class="kv hj">import</strong> <strong class="kv hj">org.apache.spark.mllib.clustering.KMeans</strong><br/><strong class="kv hj">import</strong> <strong class="kv hj">org.apache.spark.mllib.linalg.Vectors</strong></span><span id="35f3" class="kz la hi kv b fi lf lc l ld le"><strong class="kv hj">object</strong> <strong class="kv hj">KMeansClustering</strong> {<br/>  <strong class="kv hj">def</strong> main(args<strong class="kv hj">:</strong> <strong class="kv hj">Array</strong>[<strong class="kv hj">String</strong>])<strong class="kv hj">:</strong> <strong class="kv hj">Unit</strong> = {<br/>    <strong class="kv hj">val</strong> conf <strong class="kv hj">=</strong> <strong class="kv hj">new</strong> <strong class="kv hj">SparkConf</strong>().setMaster("local").setAppName("testApp")<br/><br/>    <strong class="kv hj">val</strong> sc <strong class="kv hj">=</strong> <strong class="kv hj">new</strong> <strong class="kv hj">SparkContext</strong>(conf)<br/>    <strong class="kv hj">val</strong> rdd <strong class="kv hj">=</strong> sc.parallelize(<strong class="kv hj">List</strong>(<br/>      <strong class="kv hj">Vectors</strong>.dense(<strong class="kv hj">Array</strong>(<strong class="kv hj">100000.0</strong>, <strong class="kv hj">15000.0</strong>, <strong class="kv hj">10.0</strong>)),<br/>      <strong class="kv hj">Vectors</strong>.dense(<strong class="kv hj">Array</strong>(<strong class="kv hj">1500000.0</strong>, <strong class="kv hj">30000.0</strong>, <strong class="kv hj">2.0</strong>)),<br/>      <strong class="kv hj">Vectors</strong>.dense(<strong class="kv hj">Array</strong>(<strong class="kv hj">1500000.0</strong>,  <strong class="kv hj">30000.0</strong>, <strong class="kv hj">1.0</strong>))))<br/>    <strong class="kv hj">val</strong> numClusters <strong class="kv hj">=</strong> <strong class="kv hj">2</strong><br/>    <strong class="kv hj">val</strong> numIterations <strong class="kv hj">=</strong> <strong class="kv hj">20</strong><br/>    <strong class="kv hj">val</strong> clusters <strong class="kv hj">=</strong> <strong class="kv hj">KMeans</strong>.train(rdd, numClusters, numIterations)<br/>}</span></pre><p id="3291" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">逐步解释</strong></p><ul class=""><li id="3842" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">从 mllib 库中导入 K 均值。</li><li id="f11d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将提取的要素转换为弹性分布式数据集(RDD)。</li><li id="768c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将分类数设置为两个(在训练期间，K 均值算法会将训练数据划分为这两个分类中的任何一个)。</li><li id="877f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">使用训练集训练模型。</li></ul><p id="803e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用<strong class="ih hj"> spark-submit </strong>运行上面的代码，我们的模型将被训练并准备好使用。现在让我们看看我们可以用这个训练好的模型做些什么。</p><p id="557d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">应用样本预测</strong></p><pre class="js jt ju jv fd ku kv kw kx aw ky bi"><span id="a492" class="kz la hi kv b fi lb lc l ld le"><strong class="kv hj">val</strong> testSet<strong class="kv hj">=Vectors</strong>.dense(<strong class="kv hj">Array</strong>(<strong class="kv hj">100000.0</strong>, <strong class="kv hj">15000.0</strong>, <strong class="kv hj">10.0</strong>))<br/><strong class="kv hj">val</strong> samplePrediction<strong class="kv hj">=</strong>clusters.predict(testSet)</span></pre><p id="4cb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">定义一个包含样本数据的测试数据集。对这些样本数据应用预测。</p><p id="26a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">将训练好的模型保存在 HDFS 并加载以备将来使用</strong></p><pre class="js jt ju jv fd ku kv kw kx aw ky bi"><span id="f188" class="kz la hi kv b fi lb lc l ld le">clusters.save(sc,"sample_model")</span></pre><ul class=""><li id="46ab" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">save 函数将两个参数作为输入</li><li id="b9d3" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj"> sc </strong>是 sparkcontext。</li><li id="927b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">下一个参数是 HDFS 路径</li></ul><pre class="js jt ju jv fd ku kv kw kx aw ky bi"><span id="368b" class="kz la hi kv b fi lb lc l ld le"><strong class="kv hj">import</strong> <strong class="kv hj">org.apache.spark.ml.clustering.KMeansModel</strong><br/><strong class="kv hj">val</strong> model<strong class="kv hj">=KMeansModel</strong>.load("sample_model")</span></pre><p id="5fed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用以 HDFS 路径为参数的加载函数来加载保存的模型。</p><p id="eb96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">火花流</strong></p><p id="ca7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark stream 用于从各种数据源读取流，如 apache kafka、HDFS、kinesis。我们还可以使用我们训练好的模型对流式数据进行预测。</p><pre class="js jt ju jv fd ku kv kw kx aw ky bi"><span id="a66c" class="kz la hi kv b fi lb lc l ld le"><strong class="kv hj">val</strong> inputDF<strong class="kv hj">=</strong> spark.read.option("header",<strong class="kv hj">true</strong>).csv("/project/test/sample.csv").toDF()<br/><strong class="kv hj">val</strong> k<strong class="kv hj">=</strong>model.transform(inputDF)</span></pre></div></div>    
</body>
</html>