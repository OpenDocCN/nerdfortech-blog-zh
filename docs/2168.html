<html>
<head>
<title>PySpark — Let’s count products</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">py spark——让我们数数产品</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/pyspark-lets-count-products-a19e611c582e?source=collection_archive---------18-----------------------#2021-04-24">https://medium.com/nerd-for-tech/pyspark-lets-count-products-a19e611c582e?source=collection_archive---------18-----------------------#2021-04-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="eb8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大数据领域日益发展，支持大数据的技术也日益发展。Spark 是另一个有趣的分布式计算平台。Spark 的出现是为了改善 Hadoop MapReduce 的缺点。在这篇简短的文章中，我们将使用 pyspark 解决一个简单的大数据问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e8fc9220baad03c6ec5b48277003b35a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J6KrvFPnjyfjCaHa.png"/></div></div></figure><h2 id="c052" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">问题</h2><p id="b691" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">我们有一个公司 2009 年 1 月的销售数据集，我们需要计算全国的产品销售额。数据集可在<a class="ae kp" href="https://github.com/isurunuwanthilaka/pyspark-product-count/blob/main/SalesJan2009.csv" rel="noopener ugc nofollow" target="_blank">处获得。</a></p><p id="4b77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">头的数据集如下。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kq kr l"/></div></figure><p id="f180" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们在第 8 列中有 country。</p><h2 id="1577" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">解决办法</h2><p id="210a" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">我们将创建一个 mapreduce 作业来用 spark 解决这个问题。完全码👇</p><p id="083a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们一行一行地讨论代码。</strong></p><p id="65d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du ks kt ku kv b">L0</code>表示第 0 行。</p><p id="aea1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L11 创建一个 SparkSession</p><p id="0942" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L16 存储输出路径，这里是 s3 存储桶位置。</p><p id="6f7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L17 读取文件并将数据放入 RDD，这里我们解析了上传数据集的 S3 存储桶位置。</p><p id="8c87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L19-L21 定义了映射函数。在这里，我们分割线，得到国家，并将<code class="du ks kt ku kv b">(K,V)</code>解析为<code class="du ks kt ku kv b">(Country,1)</code>，即<code class="du ks kt ku kv b">(US,1)</code>。</p><p id="5a95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L23 是实际的 mapreduce 作业运行程序。它会大量减少。<code class="du ks kt ku kv b">add</code>功能取自运营商套餐。</p><p id="4227" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在映射器中我们返回<code class="du ks kt ku kv b">(K,V)</code>，在缩减器中我们有<code class="du ks kt ku kv b">(K, list(V))</code>。因此<code class="du ks kt ku kv b">add</code>功能会减少<code class="du ks kt ku kv b">list(v)</code>。举个例子，如果我们得到<code class="du ks kt ku kv b">key:US</code>和<code class="du ks kt ku kv b">values:1,1,1,1,...,1</code>，那么首先 1，1 将被解析为<code class="du ks kt ku kv b">add</code>，结果 2 将是下一次迭代的第一个值。因此，2，1 将被再次解析为<code class="du ks kt ku kv b">add</code>和<code class="du ks kt ku kv b">3,1</code>、<code class="du ks kt ku kv b">4,1</code>、<code class="du ks kt ku kv b">5,1</code>，最终<code class="du ks kt ku kv b">sum</code>将作为<code class="du ks kt ku kv b">(US,sum)</code>返回。</p><p id="58f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L26 创建一个模式以形成数据帧，从而将结果保存到文件中。这里我们有两个类型为<code class="du ks kt ku kv b">StringType()</code>的列。</p><p id="b713" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">L30 将数据帧作为 CSV 写入 s3 存储桶位置。</p><p id="089d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常小的 pyspark 工作，演示了我们如何简单地解决大数据问题的工作流程。外面有很多资源。我在 youtube 上创建了一个视频指南。如果你有兴趣，可以去看看。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kw"><img src="../Images/90f66d3c696d24012ae033cf97511d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/0*VRZolpam2R-s9I6i.jpg"/></div></figure><p id="23b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意安全，远离新冠肺炎，快乐编码！</p><p id="416a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kx">原载于 2021 年 4 月 24 日</em><a class="ae kp" href="https://isurunuwanthilaka.github.io/software-engineering/2021/04/24/spark-product-count.html" rel="noopener ugc nofollow" target="_blank"><em class="kx">https://isurunuwanthilaka . github . io</em></a><em class="kx">。</em></p></div></div>    
</body>
</html>