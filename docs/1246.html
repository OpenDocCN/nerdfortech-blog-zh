<html>
<head>
<title>Pyspark + Spark Operator + Amazon EKS = Big Data On Steroids!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark + Spark运营商+亚马逊EKS =类固醇大数据！</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/pyspark-spark-operator-amazon-eks-big-data-on-steroids-7d1ccedb765b?source=collection_archive---------1-----------------------#2021-03-11">https://medium.com/nerd-for-tech/pyspark-spark-operator-amazon-eks-big-data-on-steroids-7d1ccedb765b?source=collection_archive---------1-----------------------#2021-03-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/2f24bcee2537f304d4acda1b4ab78749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*rBTciefvuUUbEQmDrf_mUg.png"/></div></figure><p id="9355" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">本文结束时，你将能够:</p><ul class=""><li id="9091" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">使用AWS推荐的工具创建一个EKS集群作为代码</li><li id="e88b" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">通过正确使用Spot实例降低成本并提高可用性</li><li id="ee3e" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">通过在EKS集群上安装一些功能强大的附加组件，进一步降低成本并提高可扩展性</li><li id="52f8" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">在EKS执行任何星火任务</li><li id="6d08" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">创建一个简单但功能强大的PySpark应用程序来读取/写入弹性对象存储，并应用一些很酷的技术来准备和优化您的数据湖。</li></ul><h1 id="ad4c" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">介绍</h1><p id="b1ec" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">在这篇文章中，我们将向您展示如何在kubernetes集群中安装和运行Spark作业，更准确地说，我们将使用亚马逊EKS作为我们的Kubernetes“风味”。</p><p id="7d71" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">此外，我们将创建一个非常简单的python作业(<a class="ae jy" href="https://spark.apache.org/docs/latest/api/python/" rel="noopener ugc nofollow" target="_blank"> pyspark </a>)，它将用于从<a class="ae jy" href="https://aws.amazon.com/s3/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"> S3桶</a>中读取<a class="ae jy" href="https://www.json.org/json-en.html" rel="noopener ugc nofollow" target="_blank"> JSON </a>事件，按年/月/日/小时重新划分这些事件，并将它们转换为一个名为<a class="ae jy" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Parquet </a>的优化列格式，最后将这些事件写回到另一个S3桶中。</p><p id="5d15" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">作为我们的火星车，我们将使用K8s操作器上的<a class="ae jy" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">火星车。例如，我们可以在EKS </a>上使用<a class="ae jy" href="https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/emr-eks.html" rel="noopener ugc nofollow" target="_blank"> EMR，但是对于本教程，我们选择了spark操作符，因为它提供了对Spark作业、重启策略、保存执行日志的能力的良好控制，并且是免费的=)。</a></p><p id="5213" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在我们动手之前，让我们稍微谈一下这两项令人惊叹的技术(Spark和亚马逊EKS)。</p><p id="ac91" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>，通常被称为MapReduce的<em class="lc">继承者</em>，是一个并行分布式数据处理的框架，能够执行并发作业(支持编程语言:Python、Java、Scala、SQL和R)，轻松处理海量数据，具有弹性、速度和可扩展性。Spark主要用于批处理用例(有界数据，如<a class="ae jy" href="https://en.wikipedia.org/wiki/Extract,_transform,_load" rel="noopener ugc nofollow" target="_blank"> ETL </a>作业、分析、数据集成等。)，但它也提供了对流用例的支持(无界数据，比如使用来自Apache Kafka主题的消息来训练ML模型，执行流ETL等。).</p><p id="d334" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://aws.amazon.com/eks" rel="noopener ugc nofollow" target="_blank">亚马逊EKS </a>是亚马逊网络服务提供的托管Kubernetes，它提供了一个完全托管的Kubernetes控制平面，具有许多安全和管理功能，还提供了与其他AWS服务的轻松集成。亚马逊EKS也可以作为开源发行版获得，称为<a class="ae jy" href="https://aws.amazon.com/blogs/opensource/introducing-amazon-eks-distro/" rel="noopener ugc nofollow" target="_blank"> EKS开放发行版</a>。</p><p id="a930" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://helm.sh/" rel="noopener ugc nofollow" target="_blank"> Helm </a>是<a class="ae jy" href="https://kubernetes.io" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>的一个包管理器，提供对Kubernetes工作负载的管理，比如共享应用、模板化、执行升级、安装第三方软件等。没有Helm，我们需要手动创建清单，并通过复制粘贴的方式与其他团队/环境共享，有了Helm，我们可以拥有不同的存储库，其中包含安全且经过验证的应用程序版本。</p><p id="791f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是跟帖的要求:</p><ul class=""><li id="650d" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">AWS账户</li><li id="0733" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">具有足够权限的有效访问密钥/秘密密钥(对于本教程，管理员权限可以做到这一点，但是对于真实世界的场景，我们强烈建议遵循最小特权原则)。</li><li id="0c6a" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><a class="ae jy" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html" rel="noopener ugc nofollow" target="_blank"> AWS Cli已安装</a>和<a class="ae jy" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html" rel="noopener ugc nofollow" target="_blank">已配置</a></li><li id="83d4" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">安装了Eksctl Cli】</li><li id="a9f9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><a class="ae jy" href="https://kubernetes.io/docs/tasks/tools/" rel="noopener ugc nofollow" target="_blank">已安装的Kubectl Cli</a></li><li id="ba33" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated"><a class="ae jy" href="https://helm.sh/docs/intro/install/" rel="noopener ugc nofollow" target="_blank">舵Cli安装完毕</a></li></ul><blockquote class="ld le lf"><p id="9636" class="im in lc io b ip iq ir is it iu iv iw lg iy iz ja lh jc jd je li jg jh ji jj hb bi translated">不幸的是，亚马逊不提供EKS的免费版本，所以请注意，创建一个EKS集群将产生你的AWS帐户费用！</p></blockquote><h1 id="1e45" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">创建EKS集群</h1><p id="750e" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">为了创建我们的集群，我们将使用真正方便的<a class="ae jy" href="https://eksctl.io/" rel="noopener ugc nofollow" target="_blank"> eksctl </a>工具，这是提供EKS集群的官方CLI(命令行界面)。</p><p id="31df" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Eksctl支持创建/配置集群的命令式和声明式方式，因此让我们定义配置文件，该文件将指定新集群的每个重要配置:</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">sedsed</figcaption></figure><p id="1944" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">关于我们的配置文件，需要考虑一些事情/技巧:</p><ul class=""><li id="f4ea" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">我们使用的是EKS版本1.18</li><li id="38c9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们的集群和所有必要的资源(VPC、子网、NAT网关等。)将在美国东部-2(俄亥俄州)地区创建，因为那里的现货保险甚至更便宜。</li><li id="0430" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们使OIDC能够将<a class="ae jy" href="https://aws.amazon.com/blogs/opensource/introducing-fine-grained-iam-roles-service-accounts/" rel="noopener ugc nofollow" target="_blank"> IRSA </a>与<a class="ae jy" href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler" rel="noopener ugc nofollow" target="_blank">集群自动缩放器</a>组件一起使用。集群自动缩放器将使我们的集群能够自动缩放: )</li><li id="7ec3" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">因为我们将运行弹性工作负载，所以我们可以使用混合池的Spot实例，以便在成本和可用性之间取得良好的平衡。</li><li id="d469" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们相应地标记所有内容，以便<a class="ae jy" href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler" rel="noopener ugc nofollow" target="_blank">集群自动缩放器</a>能够根据需要缩放我们的集群。</li><li id="9103" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">请注意，我们只使用一个可用性区域，但是请等一下，让我解释一下，我们的集群被设计为短暂的，或者换句话说，被创建、运行我们的作业和被销毁，从而降低了在单个可用性区域中运行的风险。通过在一个可用性区域中运行，我们可以避免az之间的网络传输成本。此外，我们建议使用VPC S3端点，以避免不必要的NAT网关流量成本。</li><li id="541a" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们在我们的worker节点中安装了<a class="ae jy" href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html" rel="noopener ugc nofollow" target="_blank"> SSM代理</a>，以便能够在没有SSH密钥对的情况下访问它们！</li><li id="4650" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">请注意，我们为我们的工作组附加了一些托管策略，其中一个类似于<em class="lc">arn:aws:iam::XXXXXXXXXXX:policy/back end-analytics policy-XXXXXXX</em>，显然这是一个假的策略arn，应该替换为有效策略的ARN，该策略授予访问我们希望spark作业访问的任何AWS服务的权限，例如，从/向AWS S3读取/写入文件，或者将其用作<a class="ae jy" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html#checkpointing" rel="noopener ugc nofollow" target="_blank"> Spark检查点</a>位置。但这是为什么呢？因为这(仍然)是为EKS上的Spark操作员管理的Spark作业提供对AWS资源的访问的最简单和安全的方式，因为Hadoop(由Spark s3a文件系统使用)附带AWS SDK的捆绑版本，我们不能使用<a class="ae jy" href="https://aws.amazon.com/blogs/opensource/introducing-fine-grained-iam-roles-service-accounts/" rel="noopener ugc nofollow" target="_blank"> IRSA </a>来启用WebIdentity凭据提供者，并且使用固定访问/秘密密钥从来都不是一个好主意。</li></ul><p id="4bec" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要创建我们的集群(我假设您已经检查了前面提到的所有需求)，请执行以下命令:</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="c605" class="ly ka hi lu b fi lz ma l mb mc">eksctl create cluster -f eks-cluster.yaml</span></pre><p id="bf51" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果一切正常，恭喜你！现在，您已经拥有了一个运行良好(且经济高效)的EKS集群！</p><h1 id="39a9" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">安装火花操作器</h1><p id="bf10" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">现在，我们可以使用以下命令在全新的集群中安装Spark Operator:</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="a571" class="ly ka hi lu b fi lz ma l mb mc">helm repo add spark-operator <a class="ae jy" href="https://googlecloudplatform.github.io/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">https://googlecloudplatform.github.io/spark-on-k8s-operator</a></span><span id="8d36" class="ly ka hi lu b fi md ma l mb mc">helm repo update</span><span id="9553" class="ly ka hi lu b fi md ma l mb mc">helm install spark-operator spark-operator/spark-operator --namespace spark-operator --create-namespace <!-- -->--set sparkJobNamespace=default</span></pre><p id="11db" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以在这里我们只是:</p><ul class=""><li id="27ac" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">使用helm CLI添加新的公共存储库</li><li id="6a2d" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">更新了我们所有本地配置的存储库</li><li id="0e39" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">再次使用helm CLI在Kubernetes名称空间<strong class="io hj"> spark-operator </strong>上安装spark操作符图表(认为该图表是一个应用程序，在本例中是Spark操作符本身)，使用最新版本的图表(如果我们没有指定版本，这是默认行为)并在名称空间<strong class="io hj"> default </strong>上查看我们的Spark作业(我们将很快创建)。</li></ul><p id="7501" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">几分钟后，运行以下命令检查Spark Operator是否安装成功(您应该看到列出的spark-operator窗格):</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="32e3" class="ly ka hi lu b fi lz ma l mb mc">kubectl get po -n spark-operator</span></pre><h1 id="8213" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">安装集群自动缩放器</h1><p id="9f29" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">让我们安装集群自动缩放器，这样我们的集群就可以扩展以满足我们的大数据需求！</p><p id="75de" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">就像我们之前做的那样，使用helm按照命令安装CA:</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="6d47" class="ly ka hi lu b fi lz ma l mb mc">helm repo add autoscaler <a class="ae jy" href="https://kubernetes.github.io/autoscaler" rel="noopener ugc nofollow" target="_blank">https://kubernetes.github.io/autoscaler</a></span><span id="0137" class="ly ka hi lu b fi md ma l mb mc">helm repo update</span><span id="d096" class="ly ka hi lu b fi md ma l mb mc">helm install cluster-autoscaler autoscaler/cluster-autoscaler --namespace kube-system --set 'autoDiscovery.clusterName'=analytics-k8s --version 1.1.1</span></pre><h1 id="95ae" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">安装并运行Python Spark作业</h1><p id="1bf1" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">现在我们应该已经准备好安装和运行我们的第一个Spark作业了！所以让我们开始吧。</p><p id="df1e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">还记得我们提到过让我们的Spark作业能够访问AWS服务的政策吗？因此，对于我们的示例，假设我们希望我们的Spark作业从S3存储桶读取文件并将文件发布到另一个S3存储桶，让我们假设我们创建了以下IAM托管策略并将其附加到我们的EKS工作节点(这只是来自<a class="ae jy" href="https://aws.amazon.com/cloudformation/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"> Cloudformation </a>的一个简单片段):</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="3278" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该策略授予对桶<strong class="io hj"> taxi-events </strong>(我们的源桶)和<strong class="io hj"> taxi-stage </strong>(我们的目的桶)的完全访问权。</p><p id="51a4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的spark作业将用于按年、日、月和小时重新划分来自出租车司机的<a class="ae jy" href="https://www.json.org/json-en.html" rel="noopener ugc nofollow" target="_blank"> JSON </a>格式的事件。此外，这项工作将转换这个事件，以使用一个更优化的列格式，称为<a class="ae jy" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Parquet </a>。</p><p id="47ba" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面是我们JSON事件的一个例子:</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="9196" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的pyspark重新分区工作的源代码如下所示:</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="3f88" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了让Spark Operator可以使用这个作业，我们将把文件复制到一个S3存储桶中(对于本教程，我们使用一个假的存储桶，用您的存储库存储桶替换它):</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="96b4" class="ly ka hi lu b fi lz ma l mb mc">aws s3 cp repartition-job.py s3://my-awesome-jobs/</span></pre><p id="7ff2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是我们的作业定义，因此Spark Operator可以运行我们的作业:</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="a266" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个清单几乎是不言自明的，但是这里有一些事情/技巧需要考虑:</p><ul class=""><li id="3233" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">我们选择了InstanceProfile凭据提供程序，因此将使用我们附加的IAM托管策略。</li><li id="4c4f" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们的作业将在集群模式下运行，有6个实例，3个CPU和10 GB内存。</li><li id="3d69" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">Spark使用ivy缓存下载依赖项(包)时有一些技巧。</li><li id="645a" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">这项工作将使用Spark版本3.0.1的预建映像，可在我们的<a class="ae jy" href="https://hub.docker.com/u/3bittechs" rel="noopener ugc nofollow" target="_blank"> Docker Hub </a>中获得。如果您想生成自己的图像(推荐)，请遵循本指南<a class="ae jy" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html#submitting-applications-to-kubernetes" rel="noopener ugc nofollow" target="_blank"/>。</li></ul><p id="9619" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">要提交此作业并查看结果，请执行以下命令:</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="4325" class="ly ka hi lu b fi lz ma l mb mc">kubectl apply -f repartition-job.yaml</span><span id="14f1" class="ly ka hi lu b fi md ma l mb mc">kubectl get sparkapplication -w -n default</span></pre><p id="7223" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的工作需要一段时间才能可用和运行，因为工作节点将不得不提取Spark Docker映像，并且集群自动缩放器可能需要横向扩展工作节点的数量来满足需求。</p><p id="47ec" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">伙计们，在现实世界中，我们会添加监控/日志记录、良好的持续集成管道、安全性和其他一些东西。</p><h1 id="e546" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">清理</h1><p id="77ec" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">请不要忘记删除本教程创建的资源！按照命令删除eksctl创建的所有资源:</p><pre class="lj lk ll lm fd lt lu lv lw aw lx bi"><span id="b596" class="ly ka hi lu b fi lz ma l mb mc">eksctl delete cluster -w -f eks-cluster.yaml</span></pre></div><div class="ab cl me mf gp mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hb hc hd he hf"><p id="fae4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们希望你和我们一样喜欢这篇文章，如果你有任何疑问，请随时联系我们！</p><p id="ab82" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">想了解更多？别忘了去https://3bit.com.br/<a class="ae jy" href="https://3bit.com.br/" rel="noopener ugc nofollow" target="_blank">拜访我们</a></p></div></div>    
</body>
</html>