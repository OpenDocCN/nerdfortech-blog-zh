<html>
<head>
<title>Concept of Machine Learning | Optimization using Gradient Descend Method to find best values of coefficients 😉</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的概念|使用梯度下降法寻找系数的最佳值的优化😉</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/gradient-descend-method-d6e2a9d906be?source=collection_archive---------11-----------------------#2021-04-23">https://medium.com/nerd-for-tech/gradient-descend-method-d6e2a9d906be?source=collection_archive---------11-----------------------#2021-04-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="43d1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在这篇文章中，你将学习最大值，最小值的概念，凹凸函数，使用爬山法寻找最大值最小值，梯度下降算法。</h2></div><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="jc jd l"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">机器学习的概念|使用梯度下降法寻找系数的最佳值的优化😉</figcaption></figure><h1 id="bdb2" class="ji jj hi bd jk jl jm jn jo jp jq jr js io jt ip ju ir jv is jw iu jx iv jy jz bi translated">梯度下降法</h1><p id="7f0e" class="pw-post-body-paragraph ka kb hi kc b kd ke ij kf kg kh im ki kj kk kl km kn ko kp kq kr ks kt ku kv hb bi translated">梯度下降是机器/深度学习算法中使用的优化算法，使用迭代来最小化目标凸函数 f(x)。它寻找目标函数的全局最小值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es kw"><img src="../Images/e61d87c195253fe101574ee39b699cd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*IhecwGNFQ4ghppBeeWMYPA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">用梯度下降法寻找最优解</figcaption></figure><p id="325b" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">在开始之前，你必须知道下面的数学概念。</p><h2 id="e37c" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">凹凸函数</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ls"><img src="../Images/2f83a01623c0489faa2c3f04948e5a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*-WqK82EI8xEOrPOEBTF1jA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">凹面功能</strong></figcaption></figure><p id="7fce" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">在凹函数中，连接曲线任意两点的直线总是位于曲线下方。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lt"><img src="../Images/0142e2bd601b7fd84127ac55f6a2b37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*mq--KXhw2knnB_nG5-DBcw.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">凸函数</strong></figcaption></figure><p id="0d66" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">在凸函数中，连接曲线任意两点的直线总是位于曲线的上方。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lu"><img src="../Images/9476d68182032e70efa462bf5eb2b7c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*PnMylDilwmZybzzJCSJQ_Q.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">不凹不凸</strong></figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lv"><img src="../Images/aec01da0ec2180b4e0f6cc897af00780.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*9zWSJVSDGMzbah3ymzpoTg.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">既不凹也不凸</strong></figcaption></figure><p id="f02d" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">有一些曲线，其中连接曲线上任意两点的直线可能位于上方，可能位于下方，可能位于两者都有，也可能没有。</p><h2 id="605d" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">最大值和最小值</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lw"><img src="../Images/2814a7a4cbe6b0c42313a0f0f0282e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*Or271ZnaL7LnXiUYSr_RmA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">千里马</strong></figcaption></figure><p id="e7dc" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">如果最大值存在于 a 点，那么对于 a&gt;a+e 和 a&gt;a-e，其中 e 极小。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lx"><img src="../Images/d1fa1cfdcaa04e71a089e76e2139b3b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*CamaTddoxNKHNPayyl02AA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">最小值</strong></figcaption></figure><p id="cbb8" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">如果最小值存在于 a 点，那么对于 a 点<a and="" a="" where="" e="" is="" extremely="" small.=""/></p><h2 id="b1b3" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">Finding Max/Min by hill climbing :</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/83a177c0fd1dfc5c0dc448100f1b2134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6kma0Z96aw6cetB8wj3pSw.jpeg"/></div></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">通过爬山</strong>找到最大值/最小值</figcaption></figure><h2 id="711e" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">n 的选择:</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es md"><img src="../Images/da057b76fbbf398270fca57498033ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xfFxp3qB7GJR4ByQuUmHbA.jpeg"/></div></div></figure><p id="54ca" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">如果 n 太小，下降速度会变慢。如果 n 太大，克服最大值或最小值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es me"><img src="../Images/16005bcecb201cce45e6206934d19dbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*j4HNYHuuU8DIzaqW-rMg2g.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">n 的常用选择</strong></figcaption></figure><p id="b722" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">这是正确的选择。</p><h2 id="7717" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">收敛标准:</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mf"><img src="../Images/596ee95a86a04979eeb1b6b31a78ddbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*MRuLZp4DxeinAwD6ft3jUA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk">收敛标准</strong></figcaption></figure><p id="e33f" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">其中 E(ε)是要设置的阈值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mg"><img src="../Images/07bcc7d3dccbe3cdfd565c6759fb5e87.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*iDYuAOgV1LIMLweOPFmHCQ.gif"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">可视化梯度下降</figcaption></figure><h2 id="066a" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">机器学习中的梯度下降；</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mh"><img src="../Images/a1f0122e29b69c81fabea0c392f50e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9WCdtcd80kXy50EvlrVtw.png"/></div></div><figcaption class="je jf et er es jg jh bd b be z dx translated">B0、B1 与 J 的关系</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mi"><img src="../Images/624a433deaa28ada3d9e4c9cb0fe58e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*hs0vMe0uICAcHKCTMWbHGA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">上图的俯视图</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mj"><img src="../Images/2f72184379aed2cadc0d3dedb6b61a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*7dVEOZhUq0TzwD_oYkO9gw.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">对于两个不同的点 J1 和 J2 画出不同的图。</figcaption></figure><h2 id="1a65" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">梯度下降算法</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mk"><img src="../Images/d4aaef8dbbd21b7789211a1e083b0fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*7HAN9N0IcV88kOX5tE25uw.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">梯度下降算法</figcaption></figure><h2 id="bbec" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">哪个是正确的？</h2><h2 id="7c26" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">方法 1:</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ml"><img src="../Images/5e8bdb4e2cd2883cae10aec14449da53.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*gJWMqMkqwlP_i9TQPQ5sDg.png"/></div></figure><p id="c7d5" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated"><strong class="kc hj">方法二:</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mm"><img src="../Images/f04c5aa223cbccdfa2285b607034d436.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*XW20o1xglV2aK_ELg_3ryQ.png"/></div></figure><p id="8250" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">方法 2 不对。因为当我们找到 B1 时，B0 的值已经改变了，所以 J(B0，B1)已经改变了。所以方法 1 是正确的。</p><h2 id="d13e" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">RSS 的梯度</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mn"><img src="../Images/971a364f0799760f4d06ed60f591c33c.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*LCsXx0A4nhHapEQFDj9SXQ.png"/></div></figure><p id="e9ed" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated"><strong class="kc hj">方法 1 : </strong></p><p id="d16c" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">RSS 的梯度= 0</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mo"><img src="../Images/30ddc862dd805c2f409d51a902f81e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*RNcW7nhhTwxY5cM8Su15_Q.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">RSS 的梯度= 0</figcaption></figure><p id="c4da" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated"><strong class="kc hj">方法二:</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mg"><img src="../Images/4efc8d89c6dbdd13987c979888c31817.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*arFI9Lp2sk6u5P0dTnWuHg.png"/></div></figure><p id="7741" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">用这种方法我们计算梯度下降。</p><p id="563c" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated">对于大多数机器学习问题，不可能计算出梯度=0。对于那些我们必须使用第二种方法。</p><h2 id="cdcd" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated"><strong class="ak">重要的</strong></h2><p id="a5cd" class="pw-post-body-paragraph ka kb hi kc b kd ke ij kf kg kh im ki kj kk kl km kn ko kp kq kr ks kt ku kv hb bi translated"><strong class="kc hj"> <em class="mp">特征比例:</em> </strong>确保特征比例相似。如果我们不缩放数据，水平曲线(等高线)会更窄更高，这意味着需要更长的时间来收敛</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mq"><img src="../Images/93c45b8f9190cc2e3604dfa15ca31f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_n3dm8hoGISqpWR-.png"/></div></div><figcaption class="je jf et er es jg jh bd b be z dx translated">标准化与非标准化曲线上的梯度下降</figcaption></figure><p id="7346" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated"><strong class="kc hj"> <em class="mp">表示归一化:</em> </strong>为了归一化数据，我们必须用(xᵢ — uᵢ)代替 xᵢ，并将其除以特征范围(最大值—最小值)，其中 uᵢ是平均值。xᵢ在训练集中的价值。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mr"><img src="../Images/cec7e3526fb749a7ebe058769e14c025.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/format:webp/1*u7H90nU3Z2Gj5cffAh69WA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">均值归一化</figcaption></figure><p id="5a4a" class="pw-post-body-paragraph ka kb hi kc b kd kz ij kf kg la im ki kj lb kl km kn lc kp kq kr ld kt ku kv hb bi translated"><strong class="kc hj"> <em class="mp">确保梯度下降有效:</em> </strong> J(B)在每次迭代后减少。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ms"><img src="../Images/a71fa69d8157aba4a1a3d70cf99f05ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*5d7F6X6-udS4Wh6gmERmDA.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated"><strong class="bd jk"> <em class="mt">确保梯度下降正在工作</em> </strong></figcaption></figure><h2 id="67f3" class="le jj hi bd jk lf lg lh jo li lj lk js kj ll lm ju kn ln lo jw kr lp lq jy lr bi translated">全文系列:</h2><div class="mu mv ez fb mw mx"><a href="https://ujjwalkar.netlify.app/post/concept-of-machine-learning-tutorial-series/" rel="noopener  ugc nofollow" target="_blank"><div class="my ab dw"><div class="mz ab na cl cj nb"><h2 class="bd hj fi z dy nc ea eb nd ed ef hh bi translated">机器学习的概念文章系列| Ujjwal Kar</h2><div class="ne l"><h3 class="bd b fi z dy nc ea eb nd ed ef dx translated">回归入门|使用梯度下降的简单线性回归优化…</h3></div><div class="nf l"><p class="bd b fp z dy nc ea eb nd ed ef dx translated">ujjwalkar.netlify.app</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl kx mx"/></div></div></a></div></div></div>    
</body>
</html>