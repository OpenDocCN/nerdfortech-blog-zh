<html>
<head>
<title>Image Classification Of Gastrointestinal tract Disorders using Keras and handling imbalanced labels using StratifiedKFoldSplit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras对胃肠道疾病进行图像分类并使用StratifiedKFoldSplit处理不平衡标签</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/image-classification-of-gastrointestinal-tract-disorders-using-keras-and-handling-imbalanced-labels-313722d7e422?source=collection_archive---------5-----------------------#2021-07-13">https://medium.com/nerd-for-tech/image-classification-of-gastrointestinal-tract-disorders-using-keras-and-handling-imbalanced-labels-313722d7e422?source=collection_archive---------5-----------------------#2021-07-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0a1067cba3d9603421339262e556e112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O0mZdltwAqzZIYClTTLCLA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://researchdata.springernature.com/posts/a-dataset-for-next-level-capsule-endoscopy-ai-methods" rel="noopener ugc nofollow" target="_blank">https://research data . springer nature . com/posts/a-dataset-for-next-level-capsule-endoscope-ai-methods</a></figcaption></figure><h1 id="95c0" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">问题陈述</h1><p id="027d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">人工智能(AI)预计将对视频胶囊内窥镜(VCE)技术的未来产生深远的影响。潜力在于改进异常检测，同时减少人工劳动。然而，医学数据通常很少，研究团体无法获得，合格的医务人员很少有时间进行繁琐的标签工作。</p><p id="3a4c" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对人体内部的视觉检查称为内窥镜检查，是几种医学专业中常用的诊断技术。当检查胃肠道内部时，可以从上方进入，称为食管胃十二指肠镜检查，用于可视化食管、胃和小肠上部(称为十二指肠)。</p><p id="f615" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这里使用的数据集是“<strong class="jv hj"> Kvasir-Capsule </strong>”数据集，它是胶囊内窥镜镜头的最大图像和视频集合之一，可用于开发检测胃肠道疾病的方法。</p><p id="a27a" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">Kvasir-Capsule由117个视频组成，可用于提取超过470万个图像帧。我们已经对47，238帧进行了标记和医学验证，并在代表14个不同类别的发现周围添加了边框。除了这些标记的图像，数据集中还包括4，694，266个未标记的帧。他们可以探索无监督或自我监督的学习。</p><p id="84f6" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在这里，我们将执行监督学习。</p><h1 id="3a5e" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">目标</h1><p id="f8bc" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">建立机器学习模型来识别各个图像的疾病标签。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/38269bce0ffba72afdb0097da4f47fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*JKdRa0t02OMLVt97qpHxwQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">【https://paperswithcode.com/dataset/kvasir-capsule T4】</figcaption></figure><h1 id="aa3a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">内容</h1><p id="bd23" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">小肠构成胃肠道的中部，位于胃和大肠之间。它有三到四米长，有大约30米的表面，包括绒毛的表面，在吸收营养方面起着至关重要的作用。因此，小肠疾病可能会导致儿童严重发育迟缓以及儿童和成人营养缺乏。</p><p id="371e" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这个器官可能会受到<strong class="jv hj">慢性病</strong>的影响，比如</p><ul class=""><li id="22ea" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">克罗恩病，</li><li id="8cb7" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">腹腔疾病，和</li><li id="f002" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">血管扩张</li></ul><p id="8b68" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">或者像恶性疾病一样</p><ul class=""><li id="e960" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">淋巴瘤和</li><li id="e120" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">腺癌。</li></ul><p id="0eb2" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">这些疾病对患者和社会都是一个巨大的健康挑战，为了诊断和治疗这些疾病，经常需要对管腔进行彻底的检查。然而，由于小肠的解剖位置，通常用于上消化道和大肠的柔性内窥镜不太容易检查到小肠。自2000年初以来，视频胶囊内镜(VCE)已被使用，通常作为消化道出血患者的补充检查。</p><p id="47c5" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">VCE由一个小胶囊组成，里面有广角相机、光源、电池和其他电子设备。患者吞下胶囊，然后在胶囊被动通过胃肠道时拍摄视频。由患者携带或包含在胶囊中的记录器存储视频，然后医学专家在手术后对其进行评估。</p><p id="7c94" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">[信息来源:<a class="ae iu" href="https://www.nature.com/articles/s41597-021-00920-z" rel="noopener ugc nofollow" target="_blank">研究论文:Kvasir-Capsule，一个视频胶囊内窥镜数据集</a></p><h1 id="d18a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">图像分类发展模型</h1><h1 id="d031" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">下载图片</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="3227" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">from google_drive_downloader import GoogleDriveDownloader as gdd</strong></span><span id="5e80" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">gdd.download_file_from_google_drive(file_id=’1yDcNMTI-8Zq2Mvs8qe7pLNpPx4BW5Yta’,</strong></span><span id="c3ad" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">dest_path=’/content/drive/MyDrive/dphi/Kvasir/The Kvasir-Capsule.zip’,unzip=True)</strong></span></pre><h1 id="d325" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">导入所需的包以读取培训数据</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="8b6a" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">import os<br/>import pandas as pd<br/>import numpy as np<br/>import PIL<br/>import cv2<br/>#<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>#<br/>import warnings<br/>warnings.filterwarnings(“ignore”)<br/>#<br/>%matplotlib inline</strong></span></pre><h1 id="57d3" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">将数据加载到数据框架中</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="61c4" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">train_data = pd.read_csv(“/content/drive/MyDrive/dphi/Kvasir/The Kvasir-Capsule/Training_set.csv”)</strong></span><span id="f9cc" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">test_data = pd.read_csv(“/content/drive/MyDrive/dphi/Kvasir/The Kvasir-Capsule/Testing_set.csv”)</strong></span><span id="db7e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">train_data.head()</strong></span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/1b4257ccc2ee274426e95bfc87ed4378.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*dkFG_h21HUukJ9hjM30OnA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix">样本数据</strong></figcaption></figure><h1 id="34bb" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">添加训练图像的完整路径</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="3296" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">paths = [os.path.join(“/content/drive/MyDrive/dphi/Kvasir/The Kvasir-Capsule/train”, x) for x in train_data[‘filename’]]</strong></span><span id="64df" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">test_paths = [os.path.join(“/content/drive/MyDrive/dphi/Kvasir/The Kvasir-Capsule/test”, x) for x in test_data[‘filename’]]</strong></span><span id="ff97" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">train_data[‘image_path’] = paths</strong></span><span id="5b8f" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">test_data[‘image_path’] = test_paths</strong></span><span id="f8bb" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">train_data.drop([‘filename’], axis = 1, inplace=True)</strong></span><span id="be3e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">test_data.drop([‘filename’], axis = 1, inplace=True)</strong></span><span id="9355" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">file_paths = train_data.image_path.values.tolist()</strong></span><span id="204e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">labels = train_data.label.values.tolist()<br/>train_data = train_data[['image_path','label']]<br/>train_data.head()</strong></span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/8280135b31cfbed27638fd88bbbea005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*yfP71OHn3ByQ0WeQl9W9DA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix">处理后的训练数据</strong></figcaption></figure><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="2999" class="lu iw hi lq b fi lv lw l lx ly">test_data.head()</span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/a9247a016af2ded8ea66570d2433e6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ErkQj8abhlMnGMgegb-Qow.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix">处理后的测试数据</strong></figcaption></figure><h1 id="b1f4" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">标签的分发</h1><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es md"><img src="../Images/2e36c8eec744bb077ceae01dcd9fb999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*8TT8w_osiEEItwnVRPzT8Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图像平衡数据集</figcaption></figure><h1 id="7870" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">图像标签</h1><ul class=""><li id="a51d" class="lb lc hi jv b jw jx ka kb ke me ki mf km mg kq lg lh li lj bi translated"><em class="mh">‘正常清洁黏膜’，</em></li><li id="8361" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘异物’，</em></li><li id="a204" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">“减少的粘膜视图”，</em></li><li id="bf23" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘回盲瓣’，</em></li><li id="df6b" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">“淋巴管扩张症”，</em></li><li id="c0ef" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘溃疡’，</em></li><li id="a0fd" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘血管扩张’，</em></li><li id="a30c" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘幽门’，</em></li><li id="c84c" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘糜烂’，</em></li><li id="70b1" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘新鲜血液’，</em></li><li id="719f" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘红斑’，</em></li><li id="7ac6" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘息肉’，</em></li><li id="d628" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘壶腹_ of _ Vater’，</em></li><li id="cf92" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><em class="mh">‘血——血红素’</em></li></ul><h1 id="5c96" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">检查训练数据中的某些图像文件是否为空(0KB)</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="63ce" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">import tqdm<br/>import os<br/>img_list = train_data.image_path.values.tolist()<br/>empty_images = []<br/>empty_index = []<br/>for i,img in tqdm.tqdm(enumerate(img_list)):<br/>   if os.stat(img).st_size == 0:<br/>      try:<br/>          empty_images.append(img)<br/>          empty_index.append(i)<br/>      except:<br/>           pass</strong></span></pre><p id="7724" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">有14个这样的大小为0KB的图像。从训练数据集中移除那些图像</p><h1 id="d303" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">导入深度学习包</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="6209" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">from sklearn.model_selection import KFold, StratifiedKFold<br/>import tensorflow as tf<br/>from tensorflow.keras.preproce0ssing.image import ImageDataGenerator<br/>from tensorflow.keras import backend as K</strong></span><span id="54ca" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization<br/>from tensorflow.keras.optimizers import Adam, Adamax<br/>from tensorflow.keras.metrics import categorical_crossentropy<br/>from tensorflow.keras import regularizers<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>from tensorflow.keras.models import Model, load_model, Sequential</strong></span><span id="f6a9" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">from tensorflow.keras.layers import Dense, Dropout, Conv2D, Input, Lambda, Flatten, TimeDistributed, Activation, MaxPool2D<br/>from tensorflow.keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector, BatchNormalization<br/>from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau<br/>from keras.regularizers import *</strong></span><span id="0b59" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#<br/>import matplotlib.pyplot as plt<br/>from matplotlib.pyplot import imshow<br/>import seaborn as sns<br/>sns.set_style(‘darkgrid’)</strong></span><span id="75a2" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#</strong></span><span id="d1ef" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">import os<br/>import shutil<br/>import cv2<br/>import glob</strong></span><span id="13a6" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">from tqdm.notebook import tqdm<br/>from tqdm import tqdm<br/>from PIL import Image</strong></span><span id="07a8" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#<br/>import gc<br/>#</strong></span><span id="308a" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">import warnings<br/>warnings.filterwarnings(‘ignore’)</strong></span></pre><h1 id="7b8a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">创建ImageDataGenerator类的培训实例</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="7f51" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">generator = ImageDataGenerator(rescale=1./255)</strong></span></pre><h1 id="2234" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">创建ImageDataGenerator类的测试实例</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="c9cd" class="lu iw hi lq b fi lv lw l lx ly">test_datagen=ImageDataGenerator(rescale=1./255)</span><span id="4d53" class="lu iw hi lq b fi lz lw l lx ly">test_generator=test_datagen.flow_from_dataframe(<br/>                 dataframe=test_data,               <br/>                 directory=None,<br/>                 x_col=”image_path”,<br/>                 y_col=None,<br/>                 batch_size=1,<br/>                 seed=42,<br/>                 shuffle=False,<br/>                 class_mode=None,<br/>                 target_size=(229,229))</span><span id="63ea" class="lu iw hi lq b fi lz lw l lx ly">STEP_SIZE_TEST=test_generator.n//test_generator.batch_size</span></pre><h1 id="67eb" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">用于在k次迭代中获取模型名称的辅助函数</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="df81" class="lu iw hi lq b fi lv lw l lx ly">def get_model_name(k):<br/>      return ‘model_’+str(k)+’.h5'</span></pre><h1 id="b467" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">定义一个函数来校准F1分数</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="f3cf" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">import keras.backend as K</strong></span><span id="8a8d" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">def get_f1(y_true, y_pred): #taken from old keras source code<br/>     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))              possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))<br/>     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))<br/>     precision = true_positives / (predicted_positives + K.epsilon())<br/>     recall = true_positives / (possible_positives + K.epsilon())<br/>     f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())</strong></span><span id="9307" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">return f1_val</strong></span></pre><h1 id="00a8" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">创建模型</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="9e54" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">def create_model():</strong></span><span id="497c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">    model = Sequential()</strong></span><span id="fda4" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">    conv_base = tf.keras.applications.DenseNet121(input_shape=     (229,229,3), include_top=False, pooling=’max’,weights=’imagenet’)</strong></span><span id="d2a3" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">    model.add(conv_base)</strong></span><span id="e77e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">    model.add(BatchNormalization())</strong></span><span id="b27a" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">    model.add(Dense(2048, activation=’relu’,  kernel_regularizer=l1_l2(0.01)))</strong></span><span id="7071" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">   model.add(BatchNormalization())</strong></span><span id="5b9c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">   model.add(Dense(14, activation=’softmax’))</strong></span><span id="4b7e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">   train_layers = [layer for layer in conv_base.layers[::-1][:5]]</strong></span><span id="0b19" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">   for layer in conv_base.layers:</strong></span><span id="8e4c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">      if layer in train_layers:</strong></span><span id="04ba" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">         layer.trainable = True</strong></span><span id="e180" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">   return model</strong></span></pre><h1 id="b0f1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">模型摘要</h1><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/45eebc7954abe639724dfdd8f79dd972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ajzup3vQvwoychtG3Uoivg.png"/></div></div></figure><h1 id="2a0e" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">生成折叠并创建数据生成器，我们将使用这些生成器来训练和评估模型</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="7dd6" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">VALIDATION_ACCURACY = []</strong></span><span id="9563" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">VALIDAITON_LOSS = []</strong></span><span id="b717" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">all_preds = []</strong></span><span id="62a2" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">dropout=.3</strong></span><span id="8381" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">lr=.001</strong></span><span id="4052" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">num_epochs = 15</strong></span><span id="9377" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">save_dir = ‘/content/drive/MyDrive/dphi/Kvasir/saved_models/’</strong></span><span id="5947" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">fold_var = 2</strong></span><span id="accd" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">n_class = 14</strong></span><span id="9a00" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">for train_index, val_index in skf.split(train_data,train_data.label):</strong></span><span id="299b" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">training_data = train_data.iloc[train_index]</strong></span><span id="f5ac" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">validation_data = train_data.iloc[val_index]</strong></span><span id="3550" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">train_data_generator = generator.flow_from_dataframe(training_data,</strong></span><span id="d5c5" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">directory = None,</strong></span><span id="3cc7" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">x_col = “image_path”,</strong></span><span id="6d3d" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">y_col = “label”,</strong></span><span id="3224" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">class_mode = class_mode,</strong></span><span id="9a55" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">batch_size = 32,</strong></span><span id="ea13" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">seed = 42,</strong></span><span id="96a8" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">shuffle = True,</strong></span><span id="3b52" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">target_size=(229,229))</strong></span><span id="a4e4" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">valid_data_generator = generator.flow_from_dataframe(validation_data,</strong></span><span id="f79b" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">directory = None,</strong></span><span id="f2ea" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">x_col = “image_path”,</strong></span><span id="f499" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">y_col = “label”,</strong></span><span id="1a51" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">class_mode = class_mode,</strong></span><span id="31d2" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">batch_size = 32,</strong></span><span id="8a67" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">seed = 42,</strong></span><span id="991c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">shuffle = True,</strong></span><span id="8e9d" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">target_size=(229,229))</strong></span><span id="2f91" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># CREATE NEW MODEL</strong></span><span id="18bf" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">model = create_model()</strong></span><span id="6669" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># COMPILE NEW MODEL</strong></span><span id="b2fe" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.001,decay=0.0001),</strong></span><span id="3f72" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">metrics=[“accuracy”,get_f1],</strong></span><span id="3094" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">loss= tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1))</strong></span><span id="91f0" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># CREATE CALLBACKS</strong></span><span id="7d46" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">my_callbacks = [</strong></span><span id="e0d0" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), monitor = ‘val_loss’,verbose = 1,save_weights_only=True, save_best_only = True),</strong></span><span id="780a" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">EarlyStopping(monitor=’val_loss’, patience=5, verbose=0, mode=’min’),</strong></span><span id="2310" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">ReduceLROnPlateau(monitor=’val_loss’, factor=0.1, patience=5, verbose=1, mode=’min’,min_delta=1e-4)</strong></span><span id="b2c0" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">]</strong></span><span id="cfa5" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># There can be other callbacks, but just showing one because it involves the model name</strong></span><span id="2f02" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># This saves the best model</strong></span><span id="4692" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># FIT THE MODEL</strong></span><span id="1a2f" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">STEP_SIZE_TRAIN = train_data_generator.n//train_data_generator.batch_size</strong></span><span id="c1fe" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">STEP_SIZE_VALID = valid_data_generator.n//valid_data_generator.batch_size</strong></span><span id="d808" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">history = model.fit(</strong></span><span id="b85e" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">train_data_generator,</strong></span><span id="2f3d" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">steps_per_epoch= STEP_SIZE_TRAIN,</strong></span><span id="8837" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">epochs=10,</strong></span><span id="d5f6" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">validation_data=valid_data_generator,</strong></span><span id="e834" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">validation_steps= STEP_SIZE_VALID,</strong></span><span id="add4" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">callbacks=[my_callbacks],</strong></span><span id="d691" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">)</strong></span><span id="921c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#PLOT HISTORY</strong></span><span id="dbbc" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># :</strong></span><span id="c081" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.plot(history.history[‘accuracy’],label=’Training Accuracy’)</strong></span><span id="5a34" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.plot(history.history[‘val_accuracy’],label=’Validation Accuracy’)</strong></span><span id="4b11" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.xlabel(‘Epochs’)</strong></span><span id="7ea0" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.ylabel(‘Accuracy’)</strong></span><span id="54e8" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.title(‘Training Accuracy Vs Validation Accuracy’)</strong></span><span id="6a54" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.legend()</strong></span><span id="5217" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.show()</strong></span><span id="f7a0" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#</strong></span><span id="aded" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.plot(history.history[‘loss’],label=’Training Loss’)</strong></span><span id="f162" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.plot(history.history[‘val_loss’],label=’Validation Loss’)</strong></span><span id="dd90" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.xlabel(‘Epochs’)</strong></span><span id="0600" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.ylabel(‘Loss’)</strong></span><span id="4d5b" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.title(‘Training Loss Vs Validation Loss’)</strong></span><span id="2806" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.legend()</strong></span><span id="e3bb" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">plt.show()</strong></span><span id="be2b" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># :</strong></span><span id="dc57" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj"># LOAD BEST MODEL to evaluate the performance of the model</strong></span><span id="524b" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">model.load_weights(“/content/drive/MyDrive/dphi/Kvasir/saved_models/model_”+str(fold_var)+”.h5")</strong></span><span id="3f6c" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">results = model.evaluate(valid_data_generator)</strong></span><span id="a773" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">results = dict(zip(model.metrics_names,results))</strong></span><span id="ffb7" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">VALIDATION_ACCURACY.append(results[‘accuracy’])</strong></span><span id="f28f" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">VALIDAITON_LOSS.append(results[‘loss’])</strong></span><span id="c731" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">preds = model.predict(test_generator,steps=STEP_SIZE_TEST,verbose=1)</strong></span><span id="f9f1" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">all_preds.append(preds)</strong></span><span id="8143" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">#clear cache</strong></span><span id="28de" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">tf.keras.backend.clear_session()</strong></span><span id="0d57" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">gc.collect()</strong></span><span id="8eba" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">fold_var += 1</strong></span></pre><h1 id="c23a" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">各个折叠的训练准确度与验证准确度以及训练损失与验证损失</h1><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/0683199da9fa220edd4bb76f43243056.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*dZRSZYkpNpCZ9gTxQiJYAg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix"> KFOLD-0 </strong></figcaption></figure><ul class=""><li id="fda7" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">发现了30220个经过验证的图像文件名，属于14个类别。</li><li id="b435" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">发现7556个有效的图像文件名属于14类。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/c3b0b36e69ff7fb5117d2747f7e928fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AO3HrLFGBX8BydRfVThhFg.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/b8aa329dbae79c11fd755f3839d49642.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*yEaGQZIRj-Ug3C240jkGdw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix"> KFOLD-1 </strong></figcaption></figure><ul class=""><li id="6770" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">发现30221个验证的图像文件名属于14类。</li><li id="ffd6" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">找到了7555个有效的图像文件名，属于14个类别。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/c4e1e727ec11c5a93e32770ff2f9c8bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xe8fkkiRseSqVhek-S5Nw.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/c7f461726b91bc85ce77c0bffde05282.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*Ssm5z84ZhBpRTDFBq0GCzw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix"> KFOLD -2 </strong></figcaption></figure><ul class=""><li id="6991" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">发现30221个验证的图像文件名属于14类。</li><li id="aaf9" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">找到了7555个有效的图像文件名，属于14个类别。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/28f6a7240eab8debc67bd3c20bfb0f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H1YOvvMmIwc2L6StFWgExA.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/4e75f1ed82e503f74718d07c9b4b17cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*jXAuk9FyDPwwKb69niNiXA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix"> KFOLD-3 </strong></figcaption></figure><ul class=""><li id="3492" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">发现30221个验证的图像文件名属于14类。</li><li id="c70f" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">找到了7555个有效的图像文件名，属于14个类别。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/b505d2a4fbba0c5e0241d8ddf0811f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ecriezg8ey9NyCimRH1Ltw.png"/></div></div></figure><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/8131e97d8c2e6157acf3c35a2562c581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*pRQa9C49rRRMl1XmHb38XQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix"> KFOLD-4 </strong></figcaption></figure><ul class=""><li id="a851" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated">发现30221个验证的图像文件名属于14类。</li><li id="9547" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated">找到了7555个有效的图像文件名，属于14个类别。</li></ul><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/2dfaf74efed8bc227ef49bc6726b4bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HbFWXEnqx142l5ZDRjsK0Q.png"/></div></div></figure><h1 id="8e17" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">最终预测</h1><p id="c202" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">平均所有折叠的预测，并校准最终预测</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="74ce" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">final_pred = (all_preds[0] + all_preds[1] + all_preds[2] + all_preds[3] + all_preds[4])/5</strong></span><span id="78d8" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">predictions = np.argmax(final_pred,axis=1)</strong></span><span id="dbbb" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">prediction_mapper = { v: k for k,v in valid_data_generator.class_indices.items()}</strong></span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/be3cfbe04a252c70938a7dda7d9b5689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*jirYt4TqCoxPoE0K-SI8hQ.png"/></div></figure><h1 id="bc94" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">格式化预测</h1><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="87a5" class="lu iw hi lq b fi lv lw l lx ly"><strong class="lq hj">test['label'] = predictions</strong></span><span id="6c84" class="lu iw hi lq b fi lz lw l lx ly"><strong class="lq hj">test['label'] = test['label'].map(prediction_mapper)</strong></span></pre><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/b442d4372bdd7cd78ee823bf26b35441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ci3CMiJZz-1CHBjPtEWZ8A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd ix">测试图像的预测</strong></figcaption></figure><h1 id="f866" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">结论</h1><p id="7e73" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">在这里，由于标签的分布是严重偏斜的，很可能一个或多个折叠将很少或没有来自少数类的样本。这意味着一些或者可能许多模型评估将是误导的，因为模型只需要正确地预测多数类。</p><p id="7187" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">使用StartifiedKFoldSplit有助于按类别标签对采样进行分层，因此所有标签将在折叠中按比例分布，并且模型将学习与相应标签相关的所有可能的数据组合</p><h1 id="23e9" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated"><strong class="ak"> <em class="mv">参考文献</em> </strong></h1><div class="mw mx ez fb my mz"><a href="https://dphi.tech/challenges/data-sprint-38-the-kvasir-capsule-dataset/129/overview/about" rel="noopener  ugc nofollow" target="_blank"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hj fi z dy ne ea eb nf ed ef hh bi translated">A.信息和数据科学挑战| DPhi</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">通过解决模拟现实世界问题的数据科学和人工智能挑战来竞争和展示您的技能。组织…</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">dphi.tech</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn io mz"/></div></div></a></div><ul class=""><li id="e4dd" class="lb lc hi jv b jw kr ka ks ke ld ki le km lf kq lg lh li lj bi translated"><a class="ae iu" href="https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/cross-validation-for-unbalanced-class ification/</a></li><li id="a154" class="lb lc hi jv b jw lk ka ll ke lm ki ln km lo kq lg lh li lj bi translated"><a class="ae iu" rel="noopener" href="/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1"><em class="mh">https://medium . com/@ vijayabhaskar 96/tutorial-on-keras-imagedata generator-with-flow-from-data frame-8bd 5776 e45 c 1</em></a></li></ul></div></div>    
</body>
</html>