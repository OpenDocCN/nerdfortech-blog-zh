<html>
<head>
<title>An introduction to machine learning with Unity ML-Agents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Unity ML-agent机器学习导论</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/an-introduction-to-machine-learning-with-unity-ml-agents-af71938ca958?source=collection_archive---------8-----------------------#2021-08-03">https://medium.com/nerd-for-tech/an-introduction-to-machine-learning-with-unity-ml-agents-af71938ca958?source=collection_archive---------8-----------------------#2021-08-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b4b1" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Unity ML-Agents入门并培训一名代理来推动数据块。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/7712056cf8f1f264db33534ee97652f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkXryII1VyQyub8jtK6FCw.png"/></div></div></figure><p id="1b7f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在本教程中，你将学习如何设置Unity的<a class="ae kf" href="https://github.com/Unity-Technologies/ml-agents" rel="noopener ugc nofollow" target="_blank"> ML-Agents toolkit </a>，并使用强化学习训练你自己的代理。不需要以前的统一经验。</p><h1 id="8f33" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">什么是Unity ML-Agents？</h1><p id="fcf5" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">ML-Agents是现有Unity平台的附件。它为研究人员和游戏开发人员提供了构建复杂3D环境和在其中培训智能代理的能力，同时利用强大的Unity引擎和UI。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/0c242613d8b138f2ab7445010c4ef940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*PW2nKPNtoLw4b2qT.gif"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">足球环境来自Unity ML-Agents</figcaption></figure><h1 id="2af8" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">在我们开始之前…</h1><p id="028e" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">如果你正在寻找一些强化学习的背景，请查看:</p><ul class=""><li id="d43b" class="li lj hi jl b jm jn jp jq js lk jw ll ka lm ke ln lo lp lq bi translated"><a class="ae kf" href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">一(长)窥强化学习</a></li><li id="3447" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ln lo lp lq bi translated"><a class="ae kf" href="https://www.gocoder.one/blog/rl-tutorial-with-openai-gym" rel="noopener ugc nofollow" target="_blank">使用OpenAI Gym开始强化学习</a></li></ul><p id="cdf8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">接下来，您需要安装Unity和ML-Agents插件。<a class="ae kf" href="https://github.com/Unity-Technologies/ml-agents/blob/release_18_docs/docs/Installation.md" rel="noopener ugc nofollow" target="_blank">遵循此处的安装说明</a>。</p><p id="721b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您将需要遵循可选的指令来克隆ML-Agents Toolkit存储库<a class="ae kf" href="https://github.com/Unity-Technologies/ml-agents/blob/release_18_docs/docs/Installation.md#clone-the-ml-agents-toolkit-repository-optional" rel="noopener ugc nofollow" target="_blank">，因为它将包含我们将在本教程中使用的示例环境。</a></p><h1 id="3a6f" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">熟悉Unity ML-代理</h1><p id="f7b2" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">一旦所有东西都安装好了，加载由<code class="du lw lx ly lz b">ml-agents</code>提供的Unity项目样本。</p><ol class=""><li id="dabe" class="li lj hi jl b jm jn jp jq js lk jw ll ka lm ke ma lo lp lq bi translated">在Unity Hub浏览器中，转到<code class="du lw lx ly lz b">Projects &gt; Add</code></li><li id="d8e6" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">导航到您克隆或下载了<code class="du lw lx ly lz b">ml-agents</code>库的地方</li><li id="df9c" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">选择“项目”文件夹，然后在文件浏览器中单击“选择文件夹”</li></ol><p id="70ab" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">提供的项目包括18+ <a class="ae kf" href="https://github.com/Unity-Technologies/ml-agents/blob/release_18_docs/docs/Learning-Environment-Examples.md" rel="noopener ugc nofollow" target="_blank">示例环境</a>供我们开箱即用。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/d78b6f2361fc9aca293be609eafcabb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*El_fyZ0GlwyA8VNk.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">基础Unity ML-Agents项目中提供的示例环境</figcaption></figure><p id="c925" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">首先加载提供的<a class="ae kf" href="https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#push-block" rel="noopener ugc nofollow" target="_blank">推块环境</a>。</p><ol class=""><li id="ce5c" class="li lj hi jl b jm jn jp jq js lk jw ll ka lm ke ma lo lp lq bi translated">找到<strong class="jl hj">项目标签</strong></li><li id="e86c" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">导航到<strong class="jl hj">资产&gt; ML-Agents &gt;示例&gt;推块&gt;场景。</strong></li><li id="4b92" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">双击<code class="du lw lx ly lz b">PushBlock.unity</code>场景进行加载。</li></ol><p id="0c62" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您应该会看到这样的场景:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/865a7cde70ea6baefb1e79658de8d59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*t-ap8JdxNXHDspjY.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">💡选择工具栏中的<strong class="bd ki">手形</strong>工具，点击并拖动鼠标在视图中移动。按住<strong class="bd ki"> Alt (Windows)或Option (macOS)并左键单击</strong>以围绕一个对象旋转。</figcaption></figure><blockquote class="mc md me"><p id="d948" class="jj jk mf jl b jm jn ij jo jp jq im jr mg jt ju jv mh jx jy jz mi kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="hi">场景说明:</em> </strong></p><p id="dd70" class="jj jk mf jl b jm jn ij jo jp jq im jr mg jt ju jv mh jx jy jz mi kb kc kd ke hb bi translated"><em class="hi">在Unity中，场景是包含部分游戏或应用程序的资产。在我们的例子中，这个场景包含32个“区域”对象。每个“区域”对象包含一个“代理”对象以及组成我们的推块环境的其他对象。<br/>这些代理都独立工作，但共享相同的模型。这样做是为了加快训练速度，因为所有代理都同时参与训练。</em></p></blockquote><p id="4e86" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们场景中的代理已经预装了一个训练有素的模型。点击场景面板上方的▶️按钮，观看它们的运行。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/d792874f74f3e469001e64ad67fcf693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*p1E2h2QaWnHZzgrJ.gif"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">推块环境中训练有素的代理</figcaption></figure><h1 id="6685" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">训练代理解决推送阻塞</h1><p id="fc61" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">在推块环境中，目标是将块推到绿色目标区域。奖励函数是:</p><ul class=""><li id="1cae" class="li lj hi jl b jm jn jp jq js lk jw ll ka lm ke ln lo lp lq bi translated">每步+0.0025</li><li id="684d" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ln lo lp lq bi translated">如果方块触及目标，则+1.0。</li></ul><p id="38ca" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">从<code class="du lw lx ly lz b">ml-agents</code>存储库的根目录在您的终端中运行:</p><pre class="iy iz ja jb fd mj lz mk ml aw mm bi"><span id="4802" class="mn kh hi lz b fi mo mp l mq mr">mlagents-learn config/ppo/PushBlock.yaml --run-id=pb_01</span></pre><p id="4db5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">该命令将使用一些默认配置启动训练过程。如果你打开路径<code class="du lw lx ly lz b">config/ppo/PushBlock.yaml</code>下的<code class="du lw lx ly lz b">PushBlock.yaml</code>文件，你会看到:</p><pre class="iy iz ja jb fd mj lz mk ml aw mm bi"><span id="cbc5" class="mn kh hi lz b fi mo mp l mq mr">behaviors:<br/>  PushBlock:<br/>    trainer_type: ppo<br/>    hyperparameters:<br/>      batch_size: 128<br/>      buffer_size: 2048<br/>      learning_rate: 0.0003<br/>      beta: 0.01<br/>      epsilon: 0.2<br/>      lambd: 0.95<br/>      num_epoch: 3<br/>      learning_rate_schedule: linear<br/>    network_settings:<br/>      normalize: false<br/>      hidden_units: 256<br/>      num_layers: 2<br/>      vis_encode_type: simple<br/>    reward_signals:<br/>      extrinsic:<br/>        gamma: 0.99<br/>        strength: 1.0<br/>    keep_checkpoints: 5<br/>    max_steps: 2000000<br/>    time_horizon: 64<br/>    summary_freq: 60000</span></pre><p id="bf24" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您可以通过简单地修改这个文件来试验不同的超参数。你可能还会注意到提供了其他算法，即PPO、SAC、POCA(由ML-Agents团队开发)和模仿学习。</p><p id="2265" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果你已经正确安装了<code class="du lw lx ly lz b">ml-agents</code>，你将会看到如下信息:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ms"><img src="../Images/9310488f7c907f9430f74ce38ca3cee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/0*fH54Z1kZU3ZE5n49.png"/></div></figure><p id="1ddd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在转到你的Unity项目，点击▶️按钮开始培训过程。您可以点击▶️按钮停止训练过程。通过添加<code class="du lw lx ly lz b">--resume</code>标志，您可以随时恢复训练:</p><pre class="iy iz ja jb fd mj lz mk ml aw mm bi"><span id="35da" class="mn kh hi lz b fi mo mp l mq mr">mlagents-learn config/ppo/PushBlock.yaml --run-id=pb_01 --resume</span></pre><p id="784c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">训练时，您将从控制台收到有关训练进度的信息。您还可以通过在单独的终端中运行来可视化培训:</p><pre class="iy iz ja jb fd mj lz mk ml aw mm bi"><span id="4375" class="mn kh hi lz b fi mo mp l mq mr">tensorboard --logdir results</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/ab5b324882f5bb2c325f145237fa03e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/0*1JgXV13jRQP3u87o.png"/></div></figure><p id="8dcc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">您还可以在Unity中实时观看我们的代理培训:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/8ca4d5c050a764d3226206f5b5a95d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*_0-XoEY5F87x8ybx.gif"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">未经培训的代理人计算出推块</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/0ec28782cdea218ec979419879cd128d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*VvCVbHEOJpQkTTGa.gif"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">我们的代理人开始学习如何在大约100，000步后推动积木。</figcaption></figure><p id="7f18" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">训练完成后，您的模型将位于<code class="du lw lx ly lz b">results/pb_01/PushBlock.onnx</code>。要加载此模型:</p><ol class=""><li id="1143" class="li lj hi jl b jm jn jp jq js lk jw ll ka lm ke ma lo lp lq bi translated">将其重命名，以免与提供的<code class="du lw lx ly lz b">PushBlock.onnx</code>型号混淆。</li><li id="9bce" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">将这个<code class="du lw lx ly lz b">.onnx</code>文件拖到<strong class="jl hj">资产&gt; ML-Agents &gt;示例&gt;推块</strong>下的<strong class="jl hj"> TFModels </strong>文件夹中</li><li id="6979" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">在<strong class="jl hj">项目面板</strong>中，转到<strong class="jl hj">资产&gt;ML-代理&gt;示例&gt;推块&gt;预设</strong></li><li id="9305" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">双击<strong class="jl hj">推块区域预置</strong>。</li><li id="8646" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">在<strong class="jl hj">层次面板</strong>中，选择<strong class="jl hj">代理对象</strong>。</li><li id="af38" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">将您的模型拖到检查器面板中<strong class="jl hj">行为参数</strong>下的<strong class="jl hj">模型</strong>字段中。</li><li id="e8c2" class="li lj hi jl b jm lr jp ls js lt jw lu ka lv ke ma lo lp lq bi translated">将推理设备设置为<strong class="jl hj"> CPU </strong>(对于大多数使用ML-Agents工具包生成的模型，CPU将比GPU更快)</li></ol><blockquote class="mc md me"><p id="53fb" class="jj jk mf jl b jm jn ij jo jp jq im jr mg jt ju jv mh jx jy jz mi kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="hi">关于序跋:</em> </strong></p><p id="c256" class="jj jk mf jl b jm jn ij jo jp jq im jr mg jt ju jv mh jx jy jz mi kb kc kd ke hb bi translated">在Unity中，预置是一个可以在场景中使用的可重复使用的资产。在我们的例子中，我们之前加载的推块场景包含32个推块区域预设的实例。</p></blockquote><p id="8177" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">通过更新预设中的模型而不是场景，这个代理的所有32个实例的设置将被一次更新。像以前一样点击▶️，看看你训练有素的代理人！</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ld"><img src="../Images/3e5c88ac3fcb73da5826603e95d1d7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*cNkGpkFZ_LuXw36l.gif"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">加载我们新训练的模型</figcaption></figure><h1 id="ddd4" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">后续步骤</h1><p id="7a94" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">Unity ML-Agents是一个强大的工具，它使强化学习算法的训练和实验变得容易。</p><p id="6139" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然而，使ML-Agents成为强大工具包的是利用Unity引擎和创建复杂、物理和图形丰富的3D环境的能力。创建您自己的定制环境需要您更加熟悉Unity。</p><p id="7017" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">接下来，我们将向您展示如何在Unity中为培训强化学习代理创建您自己的定制环境。</p></div></div>    
</body>
</html>