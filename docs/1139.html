<html>
<head>
<title>Regular Dose of Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">常规剂量的机器学习</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/regular-dose-of-machine-learning-2cdae2b99e46?source=collection_archive---------28-----------------------#2021-03-05">https://medium.com/nerd-for-tech/regular-dose-of-machine-learning-2cdae2b99e46?source=collection_archive---------28-----------------------#2021-03-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="5c4e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><strong class="ak">第二章</strong></h2></div><p id="3a50" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上次在<a class="ae jt" href="https://adityak2804.medium.com/regular-dose-of-machine-learning-f19d46bab0c9" rel="noopener">第 1 章</a>中，我们讨论了什么是机器学习，它有哪些类型，如果你还没有读过，我建议你去看看之前的文章。好的，今天我们继续讨论一些概念。</p><p id="0fbe" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们开始吧。</p><p id="f274" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以在开始之前，我想先介绍一下什么是<strong class="iz hj">机器学习模型</strong>。机器学习模型是用数据集训练的文件或程序，因此它可以找出给定数据之间的某种模式或关系。在模型被训练之后，它被输入一些它不知道的数据，然后模型被期望根据它在训练时观察到的逻辑或模式提供输出。</p><p id="cc74" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，假设您想要一个识别水果的应用程序。因此，您将使用一个巨大的带标签数据集(已经为训练模型标记/贴标签的样本集合)来训练您的模型，然后您可以在可以识别任何水果的应用程序中使用该模型。</p><h1 id="2157" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated"><strong class="ak">线性回归</strong></h1><p id="5cdc" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">所以，线性回归的定义如下:</p><blockquote class="kr ks kt"><p id="3619" class="ix iy ku iz b ja jb ij jc jd je im jf kv jh ji jj kw jl jm jn kx jp jq jr js hb bi translated">“线性回归是一种<strong class="iz hj">线性模型</strong>，例如，假设输入变量<strong class="iz hj"> (x) </strong>和单个输出变量<strong class="iz hj"> (y) </strong>之间存在线性关系的模型。更具体地说，<strong class="iz hj"> (y) </strong>可以从输入变量<strong class="iz hj"> (x) </strong>的线性组合中计算出来</p></blockquote><p id="f3ae" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在统计学中，线性回归是一种形成标量响应(因变量)和一个或多个解释变量(自变量)之间关系的线性方法。</p><p id="e4aa" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数学上它可以表示为 E[Y] = β₀+ β₁X</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/26dbfb8a48551ca65db592f5da83b3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Hplc0vCh0kBy8PX5.png"/></div></div></figure><p id="41b9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个解释变量的情况也称为简单线性回归，当有<strong class="iz hj">多个输入变量</strong>时，统计文献通常将该方法称为多元线性回归。</p><p id="cd53" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有人一定会问为什么要用线性回归回答是因为它容易表示。在线性回归中，使用线性预测函数对关系进行建模，该线性预测函数的未知模型参数根据数据进行估计。这种类型的模型被称为线性模型。</p><h2 id="d164" class="lk jv hi bd jw ll lm ln ka lo lp lq ke jg lr ls kg jk lt lu ki jo lv lw kk lx bi translated">线性回归假设</h2><p id="8c5c" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">线性回归模型可以由下面的等式表示</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ly"><img src="../Images/1fa2d0d2180b473e183a9a09ef27c72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/0*-UAczbQqaq-JUv3U.png"/></div></figure><ul class=""><li id="af2d" class="lz ma hi iz b ja jb jd je jg mb jk mc jo md js me mf mg mh bi translated"><em class="ku"> Y </em>是预测值</li><li id="a2d7" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><em class="ku"> θ </em> ₀是偏差项。</li><li id="f511" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><em class="ku"> θ </em> ₁,…，<em class="ku"> θ </em> ₙ为模型参数</li><li id="933c" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><em class="ku"> x </em> ₁，<em class="ku"> x </em> ₂,…，<em class="ku"> x </em> ₙ为特征值。</li></ul><p id="4570" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上述假设也可以表示为</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mn"><img src="../Images/2b056acce6cd01909195959f0bf81c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:162/format:webp/0*5n81uKchpAfTIQRj.png"/></div></figure><p id="0448" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在哪里</p><ul class=""><li id="37ea" class="lz ma hi iz b ja jb jd je jg mb jk mc jo md js me mf mg mh bi translated"><em class="ku"> θ </em>是模型的参数向量，包括偏差项<em class="ku"> θ </em> ₀</li><li id="dae5" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><em class="ku"> x </em>是<em class="ku"> x </em> ₀ =1 的特征向量</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mo"><img src="../Images/888c3b34ae74d26d1168dcdfe30b7dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IIW70MIUM1wCsV6Y.png"/></div></div></figure><h2 id="67ea" class="lk jv hi bd jw ll lm ln ka lo lp lq ke jg lr ls kg jk lt lu ki jo lv lw kk lx bi translated"><strong class="ak">线性回归中的假设</strong></h2><p id="a1c1" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">线性回归中有一些假设，如下所示:</p><ul class=""><li id="d25e" class="lz ma hi iz b ja jb jd je jg mb jk mc jo md js me mf mg mh bi translated"><strong class="iz hj">线性</strong>:认为<strong class="iz hj"> <em class="ku"> X </em> </strong>与<strong class="iz hj"> <em class="ku"> Y </em> </strong>的均值之间的关系应该始终是线性的。</li><li id="e674" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><strong class="iz hj">同异方差</strong>:在统计学中，同异方差意味着同质不变性。所以在线性回归中，我们认为残差的方差对于<strong class="iz hj"><em class="ku"/></strong>的任意值都是相同的</li><li id="f058" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><strong class="iz hj">独立性:</strong>认为没有观测是相关的，每个观测本身都是独立的。</li><li id="e447" class="lz ma hi iz b ja mi jd mj jg mk jk ml jo mm js me mf mg mh bi translated"><strong class="iz hj">正态性:</strong>对于<strong class="iz hj"> <em class="ku"> X </em> </strong>和<strong class="iz hj"> <em class="ku"> Y </em> </strong>的任何一个定值都是正态分布的。</li></ul><h2 id="e11c" class="lk jv hi bd jw ll lm ln ka lo lp lq ke jg lr ls kg jk lt lu ki jo lv lw kk lx bi translated">价值函数</h2><p id="964f" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">该函数主要用于测量我们假设函数的准确性(在第 1 章的<a class="ae jt" href="https://adityak2804.medium.com/regular-dose-of-machine-learning-f19d46bab0c9" rel="noopener">中讨论)，因此我们可以得到一条最佳拟合线。因此，当我们最终使用我们的预测模型时，它将针对<em class="ku"> X </em>的输入值预测<em class="ku"> Y </em>的值。因此，更新θ₁和θ₂值非常重要，以达到使预测的<em class="ku"> Y </em>值(predᵢ)和真实的<em class="ku"> Y </em>值(<em class="ku"> Y </em> ᵢ).)之间的误差最小的最佳值</a></p><p id="53b0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数学上，</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mp"><img src="../Images/06dee02529cc4bf7a64172ce905120cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*4Us-pyJPSyf74qPw.jpg"/></div></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mq"><img src="../Images/05efbd95b341f6ca8a3b6e360702c180.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/0*994DH9nHrJcLwYDT.jpg"/></div></figure><p id="18a2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个函数也被称为“平方误差函数”或“均方误差”。</p><p id="9b5a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">平均值减半( )，以便于计算梯度下降，因为平方函数的导数项将抵消( )项。</p><p id="20b2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以我们的想法是选择θ₁和θ₂，使'predᵢ'的价值尽可能接近'Yᵢ'。</p><h1 id="ae30" class="ju jv hi bd jw jx jy jz ka kb kc kd ke io kf ip kg ir kh is ki iu kj iv kk kl bi translated">先说“梯度下降”。</h1><h2 id="8cfe" class="lk jv hi bd jw ll lm ln ka lo lp lq ke jg lr ls kg jk lt lu ki jo lv lw kk lx bi translated">什么是梯度？</h2><p id="4d28" class="pw-post-body-paragraph ix iy hi iz b ja km ij jc jd kn im jf jg ko ji jj jk kp jm jn jo kq jq jr js hb bi translated">“梯度是对我们稍微改变输入时输出变化多少的度量”——Lex frid man。简单地说，这是对输入改变时输出偏差的观察。</p><p id="8606" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">梯度下降</strong>是一种寻找可微函数局部最小值的优化算法。梯度下降简单地用于找到尽可能最小化函数成本的函数参数(系数)的值。</p><p id="0f0b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数学上，</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mr"><img src="../Images/430e346b0f79ea360800ff9e6186643f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*nlh0Mei5wM23OdPg.jpg"/></div></figure><p id="0edf" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的'<strong class="iz hj"> α' </strong>称为学习率。因此，如果'<strong class="iz hj"> α' </strong>较大，则学习步长较大，反之亦然。</p><p id="a653" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了更新θ₁和θ₂值以降低成本函数(最小化 RMSE 值)并获得最佳拟合线，模型使用梯度下降。想法是从随机的θ₁和θ₂值开始，然后迭代地更新这些值，达到最小成本。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ms"><img src="../Images/89ab5e9ba574684cc385a098a284b8a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cXvuqMLZGTBHno8w.png"/></div></div></figure><p id="c22d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以今天我们讨论了线性回归和一些更多的概念。我希望你们能和我一起享受学习新概念的乐趣。但是，如果你有任何疑问或困惑，请随时通过评论区联系我。如果你想让我在某些方面有所改进，请留下你宝贵的反馈。</p><p id="7f46" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢，学习愉快！！！</p></div></div>    
</body>
</html>