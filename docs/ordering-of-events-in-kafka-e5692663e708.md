# 卡夫卡事件的排序

> 原文：<https://medium.com/nerd-for-tech/ordering-of-events-in-kafka-e5692663e708?source=collection_archive---------0----------------------->

![](img/048492d604a94eb4d86805157300c636.png)

图片来源:【https://www.dealsshutter.com 

C 某些用例要求在数据管道中的生产者和消费者之间维护严格的事件排序(带有数据负载和/或状态的消息/记录)。例如，在金融机构中，需要保持交易顺序以正确计算账户余额。本文主要关注生产者和消费者在维护这种秩序时可以考虑的方面。

# **制作人:**

根据卡夫卡[担保](https://kafka.apache.org/documentation/#producerapi):

> 由生产者发送到特定主题分区的消息将按照发送的顺序被附加。

为了确保所有事件的严格排序，主题应该是单个分区的。嗯，扩展性不太好。此外，可能不需要在所有事件中保持顺序。对于上面的用例，我们喜欢保留每个账户的交易顺序(而不是跨账户)。这就是我们在发布事件时使用按键分区的地方。

Kafka 选择将哪个事件分配给主题中的哪个分区。然而，我们可以选择分区键。Kafka 中的每个事件都由一个键、一个值和一个时间戳组成。Kafka 的默认分区器使用事件键的散列来选择分区，即，具有相同键的记录被分配到相同的分区。以下是如何用 Python 实现:

a)首先导入库——我们计划在这个例子中使用一个 json 事件。

b)要发布的示例事件:

c)启动生产者:确认被设置为全部，以保证只要代理列表中的至少一个同步复制品保持活动，记录就不会丢失。

注意:如果您使用的是`confluent_kafka` 库，我建议您也设置`'enable.idempotence': True` ,以确保消息的一个副本被写入代理。

d)定义键和 post 事件—这里我们选择 key1 作为分区键:

在上面的例子中，Kafka 会将 key1 = 1 的所有事件发送到同一个分区。它很容易包含在我们选择的任何编码语言中。对于生产者来说，还有其他的考虑要记住。

1.  键的选择可能导致“热分区”，或者换句话说，根据键，一些分区可能比其他分区更忙。
2.  事件的处理应该保持事件创建的顺序。例如，生产者程序中的多线程进程可能会扰乱排序。
3.  某些边缘条件可能会导致 Kafka 保证被违反(以及修复)，如[Kamil charampowicz](https://medium.com/u/cb4c80dc21de?source=post_page-----e5692663e708--------------------------------)[此处](https://blog.softwaremill.com/does-kafka-really-guarantee-the-order-of-messages-3ca849fd19d2)所述。

# 消费者

卡夫卡[担保](https://kafka.apache.org/documentation/#producerapi):

> 使用者实例按照记录在日志中的存储顺序查看记录。

那么，如果 Kafka 做了这项工作，为什么消费者程序还要费心订购呢？好吧，消费者不会，直到它遇到一个异常。对于异常，我们可能希望在故障点暂停消费，并在异常解决后继续消费，以保持严格的排序。为此，我们可以使用 Kafka 的以下 [api 的](http://kafka.apache.org/documentation.html#theconsumer):

> `PUT /connectors/{name}/pause` -暂停连接器及其任务，这将停止消息处理，直到连接器恢复
> 
> `PUT /connectors/{name}/resume` -恢复暂停的连接器(如果连接器未暂停，则不执行任何操作)

用 Python 实现将包括以下步骤(不用说，可以用我们选择的其他语言实现):

a)包括库:

b)启动消费者:

c)事件轮询:

d)过程事件:

让我们来看看上面的片段。消费者试图使用`fnPostDB(data)`将每个事件发布到数据库。如果数据库端点不可用，它使用`fnPostException(data)`通知异常，并暂停来自主题分区的消费。

下一步是检查异常是否已解决(在这种情况下端点是可用的)。`fnResume()`可能会以固定的时间间隔检查端点，并在可用时返回 True。当异常被解决时，我们想要重试失败的任务`fnPostDB(data)`并从分区恢复消耗。

消费者的其他注意事项:

1.  并非所有异常都与接口相关。虽然在生产应用程序中不太可能，但我们可能会遇到与有效负载相关的异常(例如，反序列化失败或所需的数据元素丢失)。在这种情况下，没有必要重试失败的任务。相反，我们可能希望在恢复消费者之前从重放主题中读取已更正的事件。
2.  一旦发出暂停命令，使用者组中的使用者实例将停止来自主题分区的处理。这可能适合我们的例子。然而，如果不同的帐号使用不同的端点(作为一个参数)，那么在我们的用例中，我们最终会暂停分区中所有帐号的消费。可以通过增加主题分区和消费者实例的数量来最小化这种影响，但是可能无法匹配分区键的基数。因此，建议的解决方案将增加数据管道内的延迟。

# 总结:

有几种技术可以解决分布式系统中的事件排序问题——上面是一种“Kafka-native”的方法，可能需要最少的编码。