<html>
<head>
<title>Apache spark: optimization techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache spark:优化技术</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/apache-spark-optimization-techniques-b982e71153ff?source=collection_archive---------1-----------------------#2021-08-21">https://medium.com/nerd-for-tech/apache-spark-optimization-techniques-b982e71153ff?source=collection_archive---------1-----------------------#2021-08-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4c1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache spark 是广泛用于大数据处理的引擎之一。使用大数据时遇到的最大障碍不是完成任务，而是用最少的资源完成任务。这就是优化发挥作用的地方，优化旨在用最少的资源解决大数据问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6e6b8f0d706870ed76172d8ed2e567ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M4hcYO2hPv3hzhkcuz8QuQ.png"/></div></div></figure><p id="3a8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们将讨论以下优化技术。</p><ul class=""><li id="42b4" class="jp jq hi ih b ii ij im in iq jr iu js iy jt jc ju jv jw jx bi translated"><strong class="ih hj">拿</strong>不如<strong class="ih hj">收</strong></li><li id="3db3" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated"><strong class="ih hj">尽可能坚持</strong></li><li id="26ec" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">避免<strong class="ih hj"> groupByKey </strong>而使用<strong class="ih hj"> reduceBykey </strong></li><li id="a5cf" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated"><strong class="ih hj"> Coalace </strong>优于数据的重新分区</li><li id="318b" class="jp jq hi ih b ii jy im jz iq ka iu kb iy kc jc ju jv jw jx bi translated">明智地使用<strong class="ih hj">广播</strong></li></ul><p id="984b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们用一个例子来看看这些方法。</p><p id="b726" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">拿比收好</strong></p><p id="d3cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下示例<strong class="ih hj"> df.collect() </strong>对数据集应用的操作，以及对同一作业的执行细节。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="90ed" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">var</strong> df <strong class="ke hj">=</strong> spark.read.option("header",<strong class="ke hj">true</strong>).csv("/user/test/olympic-summary/Summer-Olympic-medals-1976-to-2008.csv")</span><span id="e83b" class="ki kj hi ke b fi ko kl l km kn">df.collect()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kp"><img src="../Images/694e78c25c42ed1fbb1fc0b016ee752d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_hJs6MbNqpn7EmzxenTNA.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">收集的执行详细信息</figcaption></figure><p id="bfba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行持续时间为 0.1 秒。如果我们用 take 替换 collect 动作，而不是将整个数据集转换成一个数组，那么它将只从第一个<strong class="ih hj">分区</strong>中获取数据，这就简单而容易了。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="f0fc" class="ki kj hi ke b fi kk kl l km kn">df.take(15433)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ku"><img src="../Images/d424fb03cdf07d8c304bb28eac9258aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s1ahJ4PiYtwBSap26Nd8xg.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">拍摄的执行细节</figcaption></figure><p id="cce1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">坚持是关键</p><p id="ee5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有火花变换，如分组、过滤，本质上都是懒惰的。这意味着 spark 不会立即应用这些转换，而是继续等待计数、保存等操作。这种懒惰的执行策略有时也是一个问题，让我们看看下面的例子。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="adea" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">var</strong> l1<strong class="ke hj">=Seq</strong>(<strong class="ke hj">1</strong>,<strong class="ke hj">2</strong>,<strong class="ke hj">3</strong>,<strong class="ke hj">4</strong>)<br/><strong class="ke hj">val</strong> rdd1 <strong class="ke hj">=</strong> sc.parallelize(l1)<br/><strong class="ke hj">val</strong> rdd2 <strong class="ke hj">=</strong> rdd1.map(x<strong class="ke hj">=&gt;</strong> x*x)<br/><strong class="ke hj">val</strong> rdd3 <strong class="ke hj">=</strong> rdd2.map(x<strong class="ke hj">=&gt;</strong> x+<strong class="ke hj">2</strong>)<br/>rdd3.collect()<br/>rdd3.count()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kv"><img src="../Images/05a3a414ff3a718a579efbdabc9396ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*H_75AKWJIPoxX-T4KQY9zg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">收集的执行历史记录</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kw"><img src="../Images/a75dc32fa6a71b0d46ea33a355251336.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*IB5LisPjMxMt7vOljzPrBA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">计数的执行历史记录</figcaption></figure><blockquote class="kx ky kz"><p id="8bf6" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated">应用于收集动作的所有转换再次应用于计数动作，这在大型操作中可能是一个大问题。</p></blockquote><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="c597" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">import</strong> <strong class="ke hj">org.apache.spark.storage.StorageLevel._</strong><br/><strong class="ke hj">val</strong> dfPersist <strong class="ke hj">=</strong> rdd2.persist(<strong class="ke hj">MEMORY_ONLY</strong>)<br/><strong class="ke hj">val</strong> rdd4 <strong class="ke hj">=</strong> rdd3.persist(<strong class="ke hj">MEMORY_ONLY</strong>)<br/>rdd4.count()<br/>rdd4.collect()</span></pre><p id="3151" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解决方案是将转换存储在内存或磁盘中，存储可以是 memory、disk_only 和 memory_and_disk。</p><p id="98b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> reduceByKey 比 groupBykey 好</strong></p><p id="d6a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面给出的例子按空格分割句子，并计算单词出现的次数。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="6b66" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">val</strong> text_list <strong class="ke hj">=</strong> <strong class="ke hj">Seq</strong>("this is a sample sentence", "this is another sample sentence", "sample for a sample test")<br/><strong class="ke hj">val</strong> rdd <strong class="ke hj">=</strong> sc.parallelize(text_list)<br/><strong class="ke hj">val</strong> rdd_word <strong class="ke hj">=</strong> rdd.flatMap(x<strong class="ke hj">=&gt;</strong> x.split(" "))<br/><strong class="ke hj">val</strong> rdd_pair <strong class="ke hj">=</strong> rdd_word.map(x<strong class="ke hj">=&gt;</strong> (x, <strong class="ke hj">1</strong>)<br/><strong class="ke hj">val</strong> wordCount <strong class="ke hj">=</strong> rdd_pair.groupBy(w <strong class="ke hj">=&gt;</strong> w).mapValues(<strong class="ke hj">_</strong>.size)<br/>wordCount.collect()</span></pre><p id="930b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种方法的问题是分组洗牌的次数会更高。因此，如果我们使用 reduce by key，而不是 group by，它最初会在分区内减少，因此实际上洗牌的次数会更少。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="b13e" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">val</strong> reducedata <strong class="ke hj">=</strong> rdd_pair.reduceByKey(<strong class="ke hj">_</strong>+<strong class="ke hj">_</strong>)</span></pre><p id="4877" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Coalace 优于 re-partition </strong></p><p id="5893" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">重新分区</strong>用于增加分区数量，但是<strong class="ih hj">重新分区</strong>会导致大量数据跨集群移动。Coalace 是一个更好的方法。Coalace 算法在内部以一种减少数据传输次数的方式工作。</p><p id="dbc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">广播变量</strong></p><p id="3327" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看我关于 spark 连接策略的文章，了解如何有效地使用广播连接。</p><p id="4b8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们也可以将变量广播到不同的节点中，因此这些变量将被<strong class="ih hj">缓存在每个节点的</strong>中。可以类似地广播频繁使用的查找表以提高效率。</p><pre class="je jf jg jh fd kd ke kf kg aw kh bi"><span id="5010" class="ki kj hi ke b fi kk kl l km kn"><strong class="ke hj">val</strong> country <strong class="ke hj">=</strong> <strong class="ke hj">Seq</strong>(("Ind"-&gt;"India"),("US"-&gt;"USA"),("UK"-&gt;"United Kingdom"))<br/><strong class="ke hj">val</strong> broadcaster <strong class="ke hj">=</strong> sc.broadcast(country)</span></pre><p id="8d0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，将国家代码转换成国家名称的国家查找表被广播到每个节点。</p></div></div>    
</body>
</html>