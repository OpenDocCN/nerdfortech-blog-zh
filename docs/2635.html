<html>
<head>
<title>Simple Linear Regression: A layman’s explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单线性回归:外行人的解释</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/simple-linear-regression-a-laymans-explanation-d60f1f2fc41b?source=collection_archive---------6-----------------------#2021-05-14">https://medium.com/nerd-for-tech/simple-linear-regression-a-laymans-explanation-d60f1f2fc41b?source=collection_archive---------6-----------------------#2021-05-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="08cb" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">分解回归技术背后的基本概念</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/caaa8d133906d226e3eae1958f0b6173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ymL7Pm_Kasv4CmpN7dqVA.jpeg"/></div></div></figure><h1 id="2ce6" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">介绍</h1><p id="f86c" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">机器学习和统计学在商业和社会科学中有许多应用。然而，这一理论往往令人生畏，不易理解。在这一系列文章中，我的目的是从线性回归开始，揭开数据科学和机器学习中常用工具背后的概念。</p><h1 id="dcb8" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated"><strong class="ak">概述</strong></h1><p id="c232" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">线性回归是一种统计方法，允许我们描述变量之间的关系(可以测量或记录的不同事物，如身高、体重和头发颜色)。它是<strong class="kd hj">一般线性模型</strong>的扩展，这是一个描述如何使用其他预测变量对感兴趣的变量建模的框架。</p><p id="4dce" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="lc">数据=模型+误差</em> </strong></p><p id="2d72" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在简单线性回归(SLR)中，我们关注两个连续变量x和y之间的关系(<strong class="kd hj">因此，简单的</strong>)。</p><p id="8f0c" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">x和y有许多可互换的术语:y可以被称为<strong class="kd hj">响应、依赖、结果或目标</strong>，而x可以被称为<strong class="kd hj">预测器、独立、解释性或特征</strong>。</p><p id="427e" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">为了一致起见，我将x和y分别称为自变量和因变量。记住哪一个是被依赖者的一个有用的方法是，把被依赖者y想成“依赖于”独立者x，而x不受y的影响，因而是“独立的”。例如，我们可以假设考试成绩取决于花在学习上的时间(注意，这种关系不是反过来的)。</p><h1 id="000d" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">案例研究:考试</h1><p id="7acf" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">我们先前的假设似乎直觉上说得通；为了测试这种关系在现实世界中的存在，我们可以收集一些数据，并尝试使用SLR对这种现象进行建模。</p><p id="4ffd" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">一般来说，如果你有两个连续的变量，并且你想知道它们之间是否有联系，SLR是一个有用的起点。</p><p id="feb1" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">在运行任何类型的模型之前，最好绘制数据图，以便直观地检查数据中的异常值和趋势。使用15名学生的样本数据集，我们可以使用散点图直观地表示我们的数据。</p><p id="0117" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">即使没有SLR，我们也可以确定一个线性的积极趋势:根据我们的样本数据集，似乎学习更多的学生可能会做得更好。注意，在剧情中，我设置了y =考试成绩，x =学习时间。习惯上把因变量标在y轴上。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/fb761f194331756c7c557deb1f55d5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ykadandgecHpZtwVImD0AA.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">虽然很难从数字中找出学习时间和考试成绩之间的任何关系，但一旦这些数字被绘制出来，这种关系就会变得更加明显</figcaption></figure><p id="7f7c" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">由于考试和学习时间之间的关系呈线性，单反是一个很好的候选对象。如果散点图揭示的关系似乎不是线性的，我们可以考虑使用非线性模型或转换变量。</p><h1 id="5986" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">模型分解</h1><p id="1f08" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">我们可以用下面的等式来表示简单的线性回归:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/4f6c16be6aa1e698d70ccd381cda3d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTXAPLXaCYzuocaalZOt3g.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">如果这看起来很可怕，请记住，我们实际上只关注三个主要成分——我们的y相关(<strong class="bd jl">数据</strong>)、线性成分(<strong class="bd jl">模型</strong>)和误差成分(<strong class="bd jl">误差</strong>)</figcaption></figure><p id="971b" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">让我们从左到右分解这个等式。</p><p id="641c" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">我们感兴趣的是估计y。我们给y戴上帽子，是因为我们根据现有数据对y进行了有根据的猜测(用统计学的话说，我们是从样本中估计总体均值)。</p><p id="5b3b" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">等式中那些长相怪异的<em class="lc"> βs </em>？这些被称为贝塔。背后的直觉可以用我们对考试结果和学习时间影响的案例研究来解释。记住SLR的目标是量化两个变量之间的关系。我们可能会认为，花更多时间埋头读书的学生往往会在考试中取得更好的成绩，但是从到<strong class="kd hj">有多少</strong>？β_1本质上回答了这个问题:星等越大，x和y之间的关联越强。</p><p id="d1e8" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">当x为0时，<em class="lc"> β_1 </em>乘以x得到0，因此<em class="lc"> β_0 </em>描述了一个基线期望。在我们的案例研究中，<em class="lc"> β_0 </em>描述了假设一个人根本不学习，他应该得到多少分。</p><p id="414a" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">给定<em class="lc"> β_0 </em>和<em class="lc"> β_1 </em>，我们可以绘制一条在<em class="lc"> β_0 </em>处与y轴相交并且斜率为<em class="lc"> β_1的直线。</em></p><p id="c1cd" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">这条线(下面用绿色表示)是我们的考试结果模型相对于学习时间的直观表示，计算如下</p><p id="ad62" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="lc">考试成绩= 57.46+2.18×学时</em> </strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/cfbcce226218480b17b0ab545375a771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i86vqJ3JWZR6HpBp78Buew.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">另一种表述问题的方式是:假设x增加一个单位(<strong class="bd jl">多学习</strong>一个小时)，一个人应该期望他们的考试成绩平均提高多少？</figcaption></figure><p id="9797" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">最后，我们得出SLR方程中的误差分量(ε)。需要注意的是，数据点并不正好位于直线上。在处理真实世界的数据时，这并不奇怪:不是每个为考试学习10小时的人都会得到相同的分数。可能还有其他因素，如个人记忆信息的能力或前一天晚上的休息时间，可能会在最终决定考试结果方面发挥作用。</p><p id="2640" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">这些因素没有包含在我们的线性分量中，构成了我们的ε的一部分，它还包括其他随机或无法解释的变化和测量误差。</p><p id="02f2" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> ε <em class="lc"> =测量误差+遗漏变量+随机变化</em>T3】</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/868cd6f2807fa1522eede933666c224e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S8osXU33Kw1oAMT8MYR7yA.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">本质上，误差项描述了我们的模型离现实有多远。较差的模型拟合会导致较大的误差</figcaption></figure><h1 id="b195" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">普通最小二乘法</h1><p id="6492" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">概括地说，我们有y(考试结果)和x(学习时间)的值。给定我们的数据，我们估计<em class="lc"> β_0 </em>和<em class="lc"> β_1的值。</em>我们如何选择“理想”的价值观？我们想要最小化残差平方和(RSS)的<em class="lc"> βs </em>。我们可以使用以下公式计算模型的RSS:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/e7d0bb5b5a7de7f8ecf64d1d736354bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*txtnv-WfXLjT10VnM1ahWQ.png"/></div></div></figure><p id="a3a5" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">术语时间-这种拟合模型的方法被称为<strong class="kd hj">普通最小二乘法(或OLS)。在某些假设下，</strong> OLS将为SLR提供最好的估计。使用这种方法的模型拟合也被称为最佳拟合的<strong class="kd hj">线。</strong></p><p id="0873" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">使用线性代数也有一个方便的解决方案来寻找来自OLS的最佳<em class="lc"> β </em>估计值:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ld"><img src="../Images/f09e2a18429fae22e2fb09d3971a1e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-u_AasAcplf0_ig7V1GNw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">在矩阵形式中，最佳<em class="li"> β </em>估计值等于X转置乘以X的倒数乘以X转置乘以y</figcaption></figure><p id="e4e4" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">随着统计软件的广泛使用，我们通常不会手动计算<em class="lc"> βs </em>。</p><h1 id="765a" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">解释模型结果</h1><p id="8c19" class="pw-post-body-paragraph kb kc hi kd b ke kf ij kg kh ki im kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">回想一下，单反坚持的是一般线性模型的框架。在哪里</p><p id="9cb2" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="lc">数据=模型+误差</em> </strong></p><p id="904a" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">由于数据中的变化可以大致分为由模型“解释”的变化和无法解释的变化，我们可以使用一种称为R的统计来量化我们的模型强度。</p><p id="0598" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">R是一个拟合优度指标——它是一个使用我们的独立变量的预测与我们的真实世界数据拟合程度的指标。R通常在0到1之间，1表示我们模型的预测完美地解释了数据中的所有变化。相反，低R值表明一个模型可能有更多无法解释的变异，导致更宽的置信区间和我们预测中更多的不确定性。</p><p id="4e46" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">R通常用于验证我们的模型的“强度”，因为它量化了一个模型与基线“模型”相比有多好(使用依赖y的平均值估计值)。然而，拟合优度只是验证我们模型的一种方式——高R并不自动意味着我们的模型是好的。在模型评估过程中，考虑背景和假设也很重要。如果从模型结构和导出的<em class="lc"> β </em>值得出的推论没有意义，那么R为0.98的模型就没有用。</p><h1 id="cbab" class="jj jk hi bd jl jm jn jo jp jq jr js jt io ju ip jv ir jw is jx iu jy iv jz ka bi translated">回顾</h1><ul class=""><li id="2e95" class="lj lk hi kd b ke kf kh ki kk ll ko lm ks ln kw lo lp lq lr bi translated">现实世界的关系通常不是完美的线性关系。然而，平均而言，它们可能是线性的。</li><li id="9f1e" class="lj lk hi kd b ke ls kh lt kk lu ko lv ks lw kw lo lp lq lr bi translated">我们可以通过建立最佳拟合线来量化这种关系，该模型可以用数学方法表示为:</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/49383c2eca32c38b3c04fb015980ad42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bAjAXap_3KyDuAg_YTcZDg.png"/></div></div></figure><ul class=""><li id="4266" class="lj lk hi kd b ke kx kh ky kk ly ko lz ks ma kw lo lp lq lr bi translated"><em class="lc"> β_0 </em>和<em class="lc"> β_1，</em>分别是直线的截距和斜率，通过最小化模型的残差平方和(RSS)来估计——这种估计<em class="lc"> βs </em>的方法被称为普通最小二乘法。</li><li id="f935" class="lj lk hi kd b ke ls kh lt kk lu ko lv ks lw kw lo lp lq lr bi translated">在任何形式的分析中,“相关性并不意味着因果关系”这句格言都适用——在选择x和y并确定因果关系时要谨慎。</li></ul><p id="95ee" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated"><strong class="kd hj"> <em class="lc">延伸阅读</em> </strong></p><p id="4752" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">[1]欲了解更多关于GLMs和OLS简单解释的信息，请查看斯蒂芬妮·格伦关于statisticshowto.com的文章</p><p id="b032" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">[2]为了更深入地探究这个主题，请查阅宾夕法尼亚州立大学关于应用回归分析的免费笔记</p><p id="fba4" class="pw-post-body-paragraph kb kc hi kd b ke kx ij kg kh ky im kj kk kz km kn ko la kq kr ks lb ku kv kw hb bi translated">[3]关于OLS回归假设的更多信息，请查阅吉姆·弗罗斯特的这篇文章</p></div></div>    
</body>
</html>