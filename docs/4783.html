<html>
<head>
<title>Joining Strategies in Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark 中的加入策略</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/joining-strategies-in-apache-spark-f802a7dab150?source=collection_archive---------2-----------------------#2021-08-07">https://medium.com/nerd-for-tech/joining-strategies-in-apache-spark-f802a7dab150?source=collection_archive---------2-----------------------#2021-08-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="97d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache spark 是广泛用于数据处理的分析引擎之一。Spark 为执行分析和查询提供了广泛的 API。<strong class="ih hj">连接</strong>是数据帧上最重要的操作之一，取决于数据帧的性质或 spark 在不同类型的连接策略之间选择的查询基础。</p><p id="4d20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">节点间的通信</strong></p><p id="4a63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark 集群由驱动程序和许多执行器节点组成，由于数据将被划分到不同的执行器上，因此需要在不同的执行器之间共享数据，主要有两种类型的节点通信方法。</p><p id="00a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在节点通信中</strong>:在这种方法中，数据将在不同的集群中被混洗，混洗数据可能成为 spark 中最昂贵的操作之一。</p><p id="a165" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中数据被转换的广泛转换导致数据在各种群集中的混洗是节点内通信策略的一个例子。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/89b0dc60534981bb4d0967ace4245a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*Ok9Mh_-w-CLK04qf6IuXTQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">宽窄转换</figcaption></figure><p id="2ae3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">每个节点的通信策略:</strong>在这种通信方法中，数据将从一个节点广播到所有其他节点，而不是在各个集群之间洗牌。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/928ba0c1f6d8acbb08e4465977aceec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*-nGv8i41Tiuy2A708agxxQ.jpeg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">spark 中的广播示例</figcaption></figure><p id="c9cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">广播连接是 spark 中每节点通信的例子，其中较小的数据帧将被广播给不同的执行器。</p><p id="e8da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">不同的加入策略</strong></p><p id="5bd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">排序合并联接</strong></p><p id="daf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一种重要且最常用的连接策略，主要用于无法广播到不同节点的大型数据帧(spark 数据帧的广播限制为 8 GB)。排序合并联接分三个阶段执行。</p><ul class=""><li id="6791" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated"><strong class="ih hj">phase 1:Shuffle phase</strong>——用于执行连接的两个表按照集群中的连接键重新分区。</li><li id="62e7" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated"><strong class="ih hj"> Phase2:Sort phase </strong> -并行排序每个分区内的数据。</li><li id="e9e4" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated"><strong class="ih hj"> Phase3:Merge phase </strong> -在这个阶段，每个数据集都将被迭代，并连接具有相同连接键值的行。​</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ke"><img src="../Images/a9315c0350dec59f87cf9f3f779c5234.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*LU5El9qa4kr3Ss2H3WNAIQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">排序合并联接示例</figcaption></figure><p id="e593" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">排序合并连接的理想条件</strong></p><ul class=""><li id="f142" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">确保分区已经在同一位置。这导致较少的数据混洗。</li><li id="5f8c" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">数据帧应均匀分布。</li><li id="b095" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">更多的唯一键意味着更好的并行性。</li></ul><p id="9470" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">广播加入</strong></p><p id="5dd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">广播连接是 spark 中最有效的连接策略之一，因为节点间的数据交换最少。仅与小于 8 GB 的较小数据集相关。</p><pre class="je jf jg jh fd kf kg kh ki aw kj bi"><span id="4d51" class="kk kl hi kg b fi km kn l ko kp"><strong class="kg hj">val</strong> items<strong class="kg hj">=Seq</strong>((<strong class="kg hj">0</strong>, "Tomato", <strong class="kg hj">2.0</strong>),(<strong class="kg hj">1</strong>, "Watermelon", <strong class="kg hj">5.5</strong>),(<strong class="kg hj">2</strong>, "pineapple", <strong class="kg hj">7.0</strong>))<br/><strong class="kg hj">val</strong> rdditem <strong class="kg hj">=</strong> spark.sparkContext.parallelize(items)<br/><strong class="kg hj">val</strong> <strong class="kg hj">ItemsDF=</strong>rdditem.toDF("id" , "name", "price")</span><span id="2947" class="kk kl hi kg b fi kq kn l ko kp"><strong class="kg hj">val</strong> orders<strong class="kg hj">=Seq</strong>((<strong class="kg hj">100</strong>, <strong class="kg hj">0</strong>, <strong class="kg hj">1</strong>),(<strong class="kg hj">100</strong>, <strong class="kg hj">1</strong>, <strong class="kg hj">1</strong>), (<strong class="kg hj">101</strong>, <strong class="kg hj">2</strong>, <strong class="kg hj">3</strong>), (<strong class="kg hj">102</strong>,<strong class="kg hj">2</strong>,<strong class="kg hj">8</strong>))<br/><strong class="kg hj">val</strong> rddorder <strong class="kg hj">=</strong> spark.sparkContext.parallelize(orders)<br/><strong class="kg hj">val</strong> <strong class="kg hj">OrdersDF=</strong>rddorder.toDF("id" , "itemid", "count")</span><span id="e80c" class="kk kl hi kg b fi kq kn l ko kp"><strong class="kg hj">ItemsDF</strong>.join(broadcast(<strong class="kg hj">OrdersDF</strong>)).where((<strong class="kg hj">OrdersDF</strong>("itemid")===<strong class="kg hj">ItemsDF</strong>("id")) ).filter(<strong class="kg hj">ItemsDF</strong>("id")===<strong class="kg hj">2</strong>).groupBy("name","price").agg(sum("count")).show()</span></pre><p id="a2d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，数据帧<strong class="ih hj"> itemsDF </strong>被广播给所有的执行器，这导致下面给出的 DAG。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kr"><img src="../Images/690dbff1c8c104f5155f71dd2a6d2a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*nO0e9Q4iDdjCKr48xkVhyg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">广播加入示例</figcaption></figure><p id="4de6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">洗牌加入</strong></p><p id="3cff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">spark 连接的另一个最重要的策略是混合散列连接，它基于 map reduce 的概念工作。</p><ul class=""><li id="e832" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated"><strong class="ih hj">第一步:</strong>使用连接 ID 作为关键字映射数据帧</li><li id="aaa7" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated"><strong class="ih hj">步骤 2: </strong>执行混洗操作，在不同节点间传输数据</li><li id="db46" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated"><strong class="ih hj">第三步:</strong>根据关键点减少。</li></ul><blockquote class="ks kt ku"><p id="a78e" class="if ig kv ih b ii ij ik il im in io ip kw ir is it kx iv iw ix ky iz ja jb jc hb bi translated">将 preferSortmergejoin 的值设置为 false 并设置 autobroadcastjoinThreshold limit 将阻止 spark 执行广播和 Sortmergejoin</p></blockquote><pre class="je jf jg jh fd kf kg kh ki aw kj bi"><span id="f8e5" class="kk kl hi kg b fi km kn l ko kp">spark.conf.set("spark.sql.autoBroadcastJoinThreshold", <strong class="kg hj">2</strong>)<br/>spark.conf.set("spark.sql.join.preferSortMergeJoin", "false")</span><span id="b0f0" class="kk kl hi kg b fi kq kn l ko kp"><strong class="kg hj">val</strong> data1 <strong class="kg hj">=</strong> <strong class="kg hj">Seq</strong>(<strong class="kg hj">10</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">30</strong>, <strong class="kg hj">40</strong>, <strong class="kg hj">10</strong>, <strong class="kg hj">40</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">50</strong>)<br/><strong class="kg hj">val</strong> df1 <strong class="kg hj">=</strong> data1.toDF("id1")</span><span id="ed8a" class="kk kl hi kg b fi kq kn l ko kp"><strong class="kg hj">val</strong> data2 <strong class="kg hj">=</strong> <strong class="kg hj">Seq</strong>(<strong class="kg hj">30</strong>, <strong class="kg hj">20</strong>, <strong class="kg hj">40</strong>, <strong class="kg hj">50</strong>)<br/><strong class="kg hj">val</strong> df2 <strong class="kg hj">=</strong> data2.toDF("id2")</span><span id="ef33" class="kk kl hi kg b fi kq kn l ko kp"><strong class="kg hj">val</strong> dfJoined <strong class="kg hj">=</strong> df1.join(df2, $"id1" === $"id2")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/78ef387e2821d52b0eea13bedd2854aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*jiXOh8Gg4K8OVc4HfJrk2A.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">混合散列连接 DAG 示例</figcaption></figure></div></div>    
</body>
</html>