<html>
<head>
<title>Programming an AI to Recognize Sign Language with Tensorflow and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Tensorflow和Keras编程人工智能识别手语</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/coding-an-ai-to-recognize-sign-language-with-tensorflow-and-keras-6cf8180c5f45?source=collection_archive---------8-----------------------#2021-02-20">https://medium.com/nerd-for-tech/coding-an-ai-to-recognize-sign-language-with-tensorflow-and-keras-6cf8180c5f45?source=collection_archive---------8-----------------------#2021-02-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f3e171eb81901aacff50adc224ab1f37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vvmh8_oFvUi62hG1.png"/></div></div></figure><h1 id="3c53" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">语境</h1><p id="a3e6" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了好玩，我决定编写一个深度学习模型来识别美国手语(ASL)的字母。你可以从Kaggle的这里找到数据集<a class="ae km" href="https://www.kaggle.com/grassknoted/asl-alphabet" rel="noopener ugc nofollow" target="_blank">。让我们进入代码！</a></p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h1 id="77d5" class="iq ir hi bd is it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn bi translated">密码</h1><p id="cff1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">注意，我在这个项目中使用了Google Colab，所以我必须在前几行代码中从我的Google Drive导入数据集。如果您没有使用Google Colab，请忽略前两行代码。</p><p id="d65f" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">记得修改你的<em class="le"> train_path </em>和<em class="le"> test_path </em>变量，因为它们在我将要向你展示的代码中是我的计算机特有的。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="41f8" class="lo ir hi lk b fi lp lq l lr ls">from google.colab import drive<br/>drive.mount('/content/drive')</span><span id="c497" class="lo ir hi lk b fi lt lq l lr ls"># imports<br/>import tensorflow as tf<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout<br/>from tensorflow.keras.losses import sparse_categorical_crossentropy<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>import tensorflow_hub as hub<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="668e" class="lo ir hi lk b fi lt lq l lr ls"># setting variables and directories for training and testing paths<br/>img_size = 224<br/>batch_size = 32<br/>epochs = 5<br/>train_path = '/content/drive/My Drive/ASL-recognition/asl_alphabet_train/asl_alphabet_train'<br/>test_path = '/content/drive/My Drive/ASL-recognition/asl_alphabet_test/asl_alphabet_test'</span><span id="6b09" class="lo ir hi lk b fi lt lq l lr ls"># define image data generators for data augmentation and rescaling<br/>augment_train_data = ImageDataGenerator(horizontal_flip=True,<br/>                                        rotation_range=50,<br/>                                        zoom_range=0.2,<br/>                                        width_shift_range=0.2,<br/>                                        height_shift_range=0.2,<br/>                                        rescale=1./255)</span><span id="d2b1" class="lo ir hi lk b fi lt lq l lr ls">augment_test_data = ImageDataGenerator(rescale=1./255)</span><span id="b346" class="lo ir hi lk b fi lt lq l lr ls"># run image data generators on training and testing dataset<br/>train_dataset = augment_train_data.flow_from_directory(train_path,<br/>     shuffle=True,<br/>     classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',<br/>     'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing'],<br/>     target_size=(img_size, img_size),<br/>     batch_size=batch_size)</span><span id="db41" class="lo ir hi lk b fi lt lq l lr ls">test_dataset = augment_train_data.flow_from_directory(test_path,<br/>     classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',<br/>     'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing'],<br/>     target_size=(img_size, img_size),<br/>     batch_size=batch_size)</span><span id="5906" class="lo ir hi lk b fi lt lq l lr ls"># showing 8 images from training dataset<br/>fig = plt.figure(figsize=(15, 10))<br/>for i in range(1,9):<br/>    plt.subplot(4,2,i)<br/>    plt.imshow(train_dataset[0][0][i-1])<br/>plt.show()</span><span id="6e5d" class="lo ir hi lk b fi lt lq l lr ls"># getting pretrained model for transfer learning and defining model<br/>url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2  /classification/4"<br/>download_model = hub.KerasLayer(url,input_shape=(img_size,img_size,3))<br/>model = Sequential([<br/>     download_model,<br/>     Dense(29),<br/>     Activation("softmax")<br/>])</span><span id="83ac" class="lo ir hi lk b fi lt lq l lr ls"># compiling model<br/>model.compile(optimizer=Adam(1e-3),<br/>loss="categorical_crossentropy",<br/>metrics=['accuracy'])</span><span id="4740" class="lo ir hi lk b fi lt lq l lr ls">#training model<br/>print("\n Model summary: ")<br/>print(model.summary())<br/>print("\n Model Training: ")<br/>model.fit(train_dataset,<br/>batch_size=batch_size,<br/>epochs=epochs)</span><span id="3020" class="lo ir hi lk b fi lt lq l lr ls"># evaluating model<br/>print("\n Model Evaluation: ")<br/>model.evaluate(test_dataset)</span><span id="03af" class="lo ir hi lk b fi lt lq l lr ls"># saving model<br/>model.save("/content/drive/My Drive/ASL-recognition/h5/asl_model.h5")</span><span id="1a7e" class="lo ir hi lk b fi lt lq l lr ls"># loading saved model<br/>load_model = tf.keras.models.load_model("/content/drive/My Drive/ASL-recognition/h5/asl_model.h5",custom_objects={"KerasLayer":hub.KerasLayer})<br/>print(load_model.summary())</span></pre></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h2 id="88aa" class="lo ir hi bd is lu lv lw iw lx ly lz ja jz ma mb je kd mc md ji kh me mf jm mg bi translated">这个代码是什么意思？我来解释一下:</h2><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="0ae7" class="lo ir hi lk b fi lp lq l lr ls">from google.colab import drive<br/>drive.mount('/content/drive')</span><span id="1e21" class="lo ir hi lk b fi lt lq l lr ls"># imports<br/>import tensorflow as tf<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout<br/>from tensorflow.keras.losses import sparse_categorical_crossentropy<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>import tensorflow_hub as hub<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span></pre><p id="58c5" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">在这里，我们从Tensorflow、Keras、Numpy和Matplotlib中导入所有必要的库和模块，我们将在程序的其余部分需要它们。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="dc20" class="lo ir hi lk b fi lp lq l lr ls"># setting variables and directories for training and testing paths<br/>img_size = 224<br/>batch_size = 32<br/>epochs = 10<br/>train_path = '/content/drive/My Drive/ASL-recognition/asl_alphabet_train/asl_alphabet_train'<br/>test_path = '/content/drive/My Drive/ASL-recognition/asl_alphabet_test/asl_alphabet_test'</span></pre><p id="32b2" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">我们设置训练和测试深度学习模型所需的变量，例如训练模型时所需的图像大小、批量大小和时期数。批量大小是在更新我们的模型的权重之前将通过网络传播的图像的数量。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="6158" class="lo ir hi lk b fi lp lq l lr ls"># define image data generators for data augmentation and rescaling<br/>augment_train_data = ImageDataGenerator(horizontal_flip=True,<br/>                                        rotation_range=50,<br/>                                        zoom_range=0.2,<br/>                                        width_shift_range=0.2,<br/>                                        height_shift_range=0.2,<br/>                                        rescale=1./255)</span><span id="7cb4" class="lo ir hi lk b fi lt lq l lr ls">augment_test_data = ImageDataGenerator(rescale=1./255)</span><span id="f368" class="lo ir hi lk b fi lt lq l lr ls"># run image data generators on training and testing dataset<br/>train_dataset = augment_train_data.flow_from_directory(train_path,<br/>     shuffle=True,<br/>     classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',<br/>     'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing'],<br/>     target_size=(img_size, img_size),<br/>     batch_size=batch_size)</span><span id="25c7" class="lo ir hi lk b fi lt lq l lr ls">test_dataset = augment_train_data.flow_from_directory(test_path,<br/>     classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',<br/>     'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing'],<br/>     target_size=(img_size, img_size),<br/>     batch_size=batch_size)</span></pre><p id="fdd4" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">我们定义了2个图像数据生成器(1个用于训练，1个用于测试)来对我们的图像进行数据扩充，然后将这些数据馈送到我们的深度学习模型中。我们将通过水平翻转、旋转、垂直/水平移动来处理我们的图像，并重新缩放我们的图像，使每个像素的值在0和1之间。如果它正常工作，您应该会分别在训练和测试图像数据生成器中看到以下内容:</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/a6bd1953b416fca299884254a3080503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hyTUFSD7WHK9tEwzhIWjHA.png"/></div></div></figure><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/ea763525360b4d5b615c849dde81a111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*5_nh1qkoxCPnFeSJlM3Scg.png"/></div></div></figure></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="5747" class="lo ir hi lk b fi lp lq l lr ls"># showing 8 images from training dataset<br/>fig = plt.figure(figsize=(15, 10))<br/>for i in range(1,9):<br/>    plt.subplot(4,2,i)<br/>    plt.imshow(train_dataset[0][0][i-1])<br/>plt.show()</span></pre><p id="1051" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">使用matplotlib简单地设置一个图形并显示我们训练数据集中的前8幅图像。如果一切正常，您应该会看到类似这样的内容，尽管各个图像会有所不同。</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/cb6b48da875d0a9180a1495c0c2384ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wO8Au_IMOgA0CvZ_lwEFA.png"/></div></div></figure></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="37f4" class="lo ir hi lk b fi lp lq l lr ls"># getting pretrained model for transfer learning and defining model<br/>url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2  /classification/4"<br/>download_model = hub.KerasLayer(url,input_shape=(img_size,img_size,3))<br/>model = Sequential([<br/>     download_model,<br/>     Dense(29),<br/>     Activation("softmax")<br/>])</span></pre><p id="9be3" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">我们使用ImageNet分类CNN模型(由Google发布)进行迁移学习，并重新定义最后一个密集层，以输出我们定义的29个类别中每个类别的概率。你可以在这里了解更多关于迁移学习<a class="ae km" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">的知识。</a></p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="58ff" class="lo ir hi lk b fi lp lq l lr ls"># compiling model<br/>model.compile(optimizer=Adam(1e-3),<br/>loss="categorical_crossentropy",<br/>metrics=['accuracy'])</span></pre><p id="bd6a" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">我们编译我们的模型，并决定如何计算它的损失(分类交叉熵)，我们用来更新权重的优化器(Adam)，以及我们如何衡量模型的成功(准确性)。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="9bed" class="lo ir hi lk b fi lp lq l lr ls">#training model<br/>print("\n Model summary: ")<br/>print(model.summary())<br/>print("\n Model Training: ")<br/>model.fit(train_dataset,<br/>batch_size=batch_size,<br/>epochs=epochs)</span></pre><p id="f330" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">最后，我们开始训练我们的模型。首先，我们查看模型的摘要，然后我们使用指定的批量大小和时期数在训练数据集上训练模型(model.fit())。如果您的所有代码都是正确的，它应该看起来像这样(除了将有10个纪元，而不是5个):</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/f49698b256a659390f1fdc43196dcc9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vf7WlGZaMCIteNQJT7jEtw.png"/></div></div></figure></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="5d7c" class="lo ir hi lk b fi lp lq l lr ls"># evaluating model<br/>print("\n Model Evaluation: ")<br/>model.evaluate(test_dataset)</span></pre><p id="740c" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">一旦我们的模型被训练到令人满意的精度，我们就可以在测试数据集上对其进行评估，以确定我们的模型是否过度拟合。您应该会看到类似这样的内容:</p><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/a467cc9b1d0dff5ff749fb64fcf8a55a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5NPgc-46HVX9DWI9FIePg.png"/></div></div></figure></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="78b0" class="lo ir hi lk b fi lp lq l lr ls"># saving model<br/>model.save("/content/drive/My Drive/ASL-recognition/h5/asl_model.h5")</span></pre><p id="0561" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">如果我们对模型满意，我们可以将它保存到指定的目录中以备后用。我决定用h5格式保存它，因为它很小，不需要很大的存储空间。</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="5e2a" class="lo ir hi lk b fi lp lq l lr ls"># loading saved model<br/>load_model = tf.keras.models.load_model("/content/drive/My Drive/ASL-recognition/h5/asl_model.h5",custom_objects={"KerasLayer":hub.KerasLayer})<br/>print(load_model.summary())</span></pre><p id="4299" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">如果我们想在以后访问我们的模型，我们将能够从上面指定的目录中加载它，并做一个正常模型能够做的所有事情(例如，训练、预测、显示摘要、评估等)。).</p></div><div class="ab cl kn ko gp kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hb hc hd he hf"><h1 id="6879" class="iq ir hi bd is it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn bi translated">结论</h1><p id="18e3" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">如果你想看完整的代码，你可以在我的Github库<a class="ae km" href="https://github.com/AlexanderChow9333/ASL-Recognition" rel="noopener ugc nofollow" target="_blank">这里</a>查看。</p><p id="acf0" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">话虽如此，我希望你喜欢我的文章！请随意查看我的其他文章，更多文章即将发布！</p><p id="4d76" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">如果你有任何问题或想联系，随时给我发电子邮件:alexander.chow911@gmail.com</p><p id="4534" class="pw-post-body-paragraph jo jp hi jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hb bi translated">了解我更多:<a class="ae km" href="https://www.linkedin.com/in/alexander-chow-6539771b3/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a></p></div></div>    
</body>
</html>