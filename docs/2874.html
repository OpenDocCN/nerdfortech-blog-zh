<html>
<head>
<title>Review — SFA: Simplified-Fast-AlexNet (Blur Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾 SFA:简化-快速-AlexNet(模糊分类)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/review-sfa-simplified-fast-alexnet-blur-classification-4121e6d813f9?source=collection_archive---------13-----------------------#2021-05-22">https://medium.com/nerd-for-tech/review-sfa-simplified-fast-alexnet-blur-classification-4121e6d813f9?source=collection_archive---------13-----------------------#2021-05-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="b364" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用简化的<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>进行模糊图像分类</h2></div><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es iy"><img src="../Images/8b634add436dedc7a82731cfa61a888a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*Gc-_pxvR-4fAM0znlg0sbw.png"/></div><figcaption class="jg jh et er es ji jj bd b be z dx translated"><strong class="bd jk">模糊图像样本</strong></figcaption></figure><p id="68b0" class="pw-post-body-paragraph jl jm hi jn b jo jp ij jq jr js im jt ju jv jw jx jy jz ka kb kc kd ke kf kg hb bi kh translated"><span class="l ki kj kk bm kl km kn ko kp di">在</span>这个故事里，<strong class="jn hj">基于深度学习的模糊图像分类</strong>，(SFA)，被回顾。在本文中:</p><ul class=""><li id="4ffc" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated"><strong class="jn hj">简化-快速-AlexNet (SFA) </strong>设计用于分类图像是否被<strong class="jn hj">散焦模糊</strong>、<strong class="jn hj">高斯模糊</strong>、<strong class="jn hj">模糊</strong>或<strong class="jn hj">运动模糊</strong>模糊。</li></ul><p id="5ced" class="pw-post-body-paragraph jl jm hi jn b jo jp ij jq jr js im jt ju jv jw jx jy jz ka kb kc kd ke kf kg hb bi translated">这是<strong class="jn hj"> 2017 IST </strong>的一篇论文。(<a class="kz la ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----4121e6d813f9--------------------------------" rel="noopener" target="_blank">曾植和</a> @中)</p></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="8d90" class="li lj hi bd jk lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">概述</h1><ol class=""><li id="516c" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg me kw kx ky bi translated"><strong class="jn hj">图像模糊建模的简要概述</strong></li><li id="b76d" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg me kw kx ky bi translated"><strong class="jn hj">简化快速 AlexNet (SFA):网络架构</strong></li><li id="da45" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg me kw kx ky bi translated"><strong class="jn hj">数据集</strong></li><li id="6e7f" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg me kw kx ky bi translated"><strong class="jn hj">实验结果</strong></li></ol></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="d271" class="li lj hi bd jk lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated"><strong class="ak"> 1。图像模糊建模概述</strong></h1><ul class=""><li id="c1c3" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">图像模糊问题可视为从高质量图像到低质量模糊图像的<strong class="jn hj">图像退化过程</strong>:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mk"><img src="../Images/d9b09c17c60f58d82cc067543768b7e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*tcj1M956s_lOJmRmrJfEzg.png"/></div></figure><ul class=""><li id="a3f9" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">其中<em class="ml"> F </em>表示退化图像，<em class="ml"> f </em>为无损图像，<strong class="jn hj"> <em class="ml"> h </em> </strong>备注<strong class="jn hj">模糊核</strong>又名<strong class="jn hj">点扩散函数</strong>，*表示卷积算子，<em class="ml"> n </em>表示附加噪声，这里<em class="ml"> n </em>为高斯白噪声。</li></ul><h2 id="c324" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">1.1.高斯模糊</h2><ul class=""><li id="5494" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">在遥感和卫星成像等许多实际应用中，高斯核函数被视为<strong class="jn hj">大气湍流</strong>的核函数:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es na"><img src="../Images/09e046154ca1d537b3a9cf9020782f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*kSJbF3_Aacmv3JE1oTFaPQ.png"/></div></figure><ul class=""><li id="c9df" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">其中，<em class="ml"> σ </em>为核半径，<em class="ml"> R </em>为通常满足 3 <em class="ml"> σ </em>准则的支撑区域。</li></ul><h2 id="79da" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">1.2.运动模糊</h2><ul class=""><li id="e849" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">运动模糊是另一个要考虑的模糊，它是由目标和摄像机之间的<strong class="jn hj">相对线性运动引起的:</strong></li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es nb"><img src="../Images/73d117383e28b3f4b912e3d6b440a842.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*TFtRhib9q1KVtL_k6E2s7Q.png"/></div></figure><ul class=""><li id="ad66" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">其中<em class="ml"> M </em>表示以像素为单位的运动长度，而<em class="ml"> ω </em>表示运动方向和<em class="ml"> x </em>轴之间的角度。</li></ul><h2 id="adc1" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">1.3.散焦模糊</h2><ul class=""><li id="7c10" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">散焦模糊是日常生活中最常见的，可以用<strong class="jn hj">柱面函数</strong>来建模:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es nc"><img src="../Images/ccc0a65b0eff31d4c322a05e9be96321.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*JLYnIzPh1bqdtaO8eWFv_g.png"/></div></figure><ul class=""><li id="2b2d" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">其中<em class="ml"> r </em>表示与散焦程度成比例的<strong class="jn hj"> </strong>模糊半径。</li></ul><h2 id="d5b4" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">1.4.薄雾模糊</h2><ul class=""><li id="49e4" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">雾霾模糊是由<strong class="jn hj">自然雾气</strong>的干扰造成的。由于现实生活中存在大量的样本，并且易于收集用于实验应用，因此本文没有使用任何 PSF 来模拟雾霾模糊。</li></ul></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="f9b7" class="li lj hi bd jk lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated"><strong class="ak"> 2。简化快速 AlexNet (SFA):网络架构</strong></h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="er es nd"><img src="../Images/aa8e47dd917e617fc5d2e6691911c920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i96QZD2G57Tu4uz3y6A13w.png"/></div></div><figcaption class="jg jh et er es ji jj bd b be z dx translated"><strong class="bd jk">简化快速 AlexNet (SFA):网络架构</strong></figcaption></figure><ul class=""><li id="0ca4" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">有<strong class="jn hj"> 5 个卷积层</strong>和<strong class="jn hj"> 1 个全连通层</strong>。</li><li id="4e8f" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"/><a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"><strong class="jn hj">Alex net</strong></a><strong class="jn hj">每个卷积层的输出数按 0.5 的比例压缩。</strong>这样做的原因是，在 2012 年 ImageNet 分类竞赛中，四种模糊类型分类是一项比较数千个图像类别的相对简单的任务。</li><li id="5aa9" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">另一方面，<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"><strong class="jn hj">【Alex net</strong></a><strong class="jn hj"/>的原模型去掉了<strong class="jn hj">的前两个 FCs，以增强快速性和实时性，因为 FCs 中存储了 80%以上的参数。</strong></li><li id="e671" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><a class="ae ix" href="https://sh-tsang.medium.com/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener"> <strong class="jn hj">批量归一化</strong> </a> <strong class="jn hj">在 1、2、5 层使用</strong>代替原来的局部响应归一化。</li><li id="1c65" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">输入</strong>:输入图像尺寸为 227×227×3。</li><li id="1044" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第一层</strong> : Conv_1: 48 个大小为 11×11 的核，步长为 4 个像素，填充为 0；MaxPool_1:大小为 3×3 的内核，步幅为 2 个像素，pad 为 0。得到 48×27×27 的特征图作为输出。</li><li id="22e2" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第二层</strong> : Conv_2 使用 5×5 的内核，1 像素的步长和 2 像素的填充；MaxPool_2:大小为 3×3 的内核，步长为 1 个像素，填充为 0。</li><li id="a5fe" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第三层</strong> : Conv_3:大小为 5×5 的内核，步长为 1 像素，填充为 2 像素。</li><li id="a718" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第四层</strong> : Conv_4 为:大小为 3×3 的内核，步长为 2 个像素，填充为 0。</li><li id="0a43" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第五层</strong> : Conv_5:大小为 3×3 的内核，步长为 1 像素，填充为 1；MaxPool_5:大小为 3×3 的内核，步幅为 2 个像素，pad 为 0。</li><li id="415f" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">第 6 层</strong>:全连通层和 ReLU。</li><li id="0cbd" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">因此，SFA 的不同隐藏层的数据流如下:227×227×3 &gt; 27×27×48 &gt; 13×13×128 &gt; 13×13×192 &gt; 13×13×192 &gt; 6×6×128 &gt; 1×1×4。</li><li id="a924" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">用的是 Caffe </strong>。</li></ul></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="a36e" class="li lj hi bd jk lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">3.数据集</h1><h2 id="f0f9" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">3.1.训练数据集</h2><ul class=""><li id="f71e" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated"><strong class="jn hj"> 20 万个 128×128×3 的全局模糊面片</strong>用于训练。</li><li id="593a" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">简而言之，这些补丁是从应用于牛津建筑数据集和加州理工学院 101 数据集的合成高斯模糊、运动模糊和散焦模糊中裁剪出来的，也是从在线网站收集的真实薄雾模糊图像中裁剪出来的。</li></ul><h2 id="dc4b" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">3.2.测试数据集 1</h2><ul class=""><li id="9899" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">选择 Berkeley 数据集 200 图像和 Pascal VOC 2007 数据集作为测试数据集。</li><li id="d085" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">总共<strong class="jn hj">获得 22，240 个全局模糊测试样本片</strong>，其中 5560 个雾度模糊图像片具有与训练样本相同的来源。</li></ul><h2 id="f2c0" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">3.3.测试数据集 2</h2><ul class=""><li id="15b1" class="kq kr hi jn b jo lz jr ma ju mb jy mc kc md kg kv kw kx ky bi translated">构建由<strong class="jn hj"> 10，080 个自然全局模糊图像片</strong>组成的数据集。这些样本都是从与训练数据集中的模糊样本相同的网站上收集的。</li></ul></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h1 id="76f5" class="li lj hi bd jk lk ll lm ln lo lp lq lr io ls ip lt ir lu is lv iu lw iv lx ly bi translated">4.实验结果</h1><h2 id="b072" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">4.1.损耗曲线和精度曲线</h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="er es ni"><img src="../Images/13ed50b82b9166c3cace9fb12687ba83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eTHyGoUHCzAz0DhVin9kUg.png"/></div></div><figcaption class="jg jh et er es ji jj bd b be z dx translated"><strong class="bd jk">损耗曲线&amp;</strong><a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"><strong class="bd jk">AlexNet</strong></a><strong class="bd jk">和 SFA </strong>的精度曲线</figcaption></figure><ul class=""><li id="08c0" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated"><strong class="jn hj">虽然</strong><a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"><strong class="jn hj">Alex net</strong></a><strong class="jn hj">和 SFA 两个模型的细节不同，但是损失和精度都达到了相近的值</strong>，这表明两个模型的性能在分类精度标准上是相当的。</li></ul><h2 id="4d89" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">4.2.与<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>的比较</h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es nj"><img src="../Images/0a504e4d0583b41daec45fa58328736d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*NAaVNxocl3DV-Oi4lWD1vw.png"/></div><figcaption class="jg jh et er es ji jj bd b be z dx translated"><strong class="bd jk">与</strong> <a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> <strong class="bd jk">的对比 AlexNet </strong> </a></figcaption></figure><ul class=""><li id="62f8" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated"><strong class="jn hj"> P_N </strong>:型号参数编号。</li><li id="c992" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"> L_N </strong>:模型深度。</li><li id="3257" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"> F_T </strong>:单幅图像的正向传播时间。</li><li id="2d28" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"> B_T </strong>:单幅图像的误差反向传播时间。</li><li id="8f7d" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"> CLF_T </strong>:识别单幅图像的时间。</li><li id="a9f6" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj"> Tr_T </strong>:模型训练时间。</li><li id="d1c4" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">错误</strong>:测试数据集 1 的分类错误率。</li></ul><blockquote class="nk nl nm"><p id="2d76" class="jl jm ml jn b jo jp ij jq jr js im jt nn jv jw jx no jz ka kb np kd ke kf kg hb bi translated"><a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>的 P_N 大约是 SFA 的 1000 倍。</p><p id="7111" class="jl jm ml jn b jo jp ij jq jr js im jt nn jv jw jx no jz ka kb np kd ke kf kg hb bi translated">SFA 的 CLF T 比<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>节省 0.5s，表明 SFA 更适合实际应用。</p><p id="ec33" class="jl jm ml jn b jo jp ij jq jr js im jt nn jv jw jx no jz ka kb np kd ke kf kg hb bi translated">SFA 的总训练时间不到一天，然而，<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>需要大约两天。</p><p id="038d" class="jl jm ml jn b jo jp ij jq jr js im jt nn jv jw jx no jz ka kb np kd ke kf kg hb bi translated">SFA 的分类错误率只比<a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"> AlexNet </a>大 0.0105。</p></blockquote><h2 id="6eaa" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">4.3.SOTA 比较</h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es nq"><img src="../Images/7ae65e2f914642b1539753dfba536d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*V4EMWQ4QOSbiEwcMc6fCtQ.png"/></div></figure><ul class=""><li id="7104" class="kq kr hi jn b jo jp jr js ju ks jy kt kc ku kg kv kw kx ky bi translated">两步法[4]、单层神经网络[8]和 DNN [9]的分类精度来自原始文章。(这很奇怪，因为数据集是不同的。但可以理解的是，重新实施可能是不可能的。)</li><li id="ef5b" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">精度 1 是对测试数据集 1 的测试，精度 2 是对测试数据集 2 的测试。</li><li id="9d39" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">基于特征的学习方法的预测准确率(&gt; 90%)总体上优于基于特征的学习方法(&lt;90%) whose features are handcrafted.</li><li id="5f79" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated"><strong class="jn hj">)。SFA 在模拟测试数据集上的分类准确率为 96.99% </strong>，略低于 AlexNet 的 97.74%，但仍优于 DNN 模型的 95.2%。</li><li id="12df" class="kq kr hi jn b jo mf jr mg ju mh jy mi kc mj kg kv kw kx ky bi translated">此外，SFA 在自然模糊数据集上的最佳性能为 93.75%，略低于 94.10%，但<strong class="jn hj">SFA 的快速性和实时性明显优于</strong><a class="ae ix" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=post_page---------------------------"><strong class="jn hj">Alex net</strong></a><strong class="jn hj">。</strong></li></ul></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><h2 id="71a4" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">参考</h2><p id="c476" class="pw-post-body-paragraph jl jm hi jn b jo lz ij jq jr ma im jt ju nr jw jx jy ns ka kb kc nt ke kf kg hb bi translated">【2017 ISA】【SFA】<br/><a class="ae ix" href="https://ieeexplore.ieee.org/document/8261503/" rel="noopener ugc nofollow" target="_blank">基于深度学习的模糊图像分类</a></p><h2 id="61ef" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated">模糊分类</h2><p id="073e" class="pw-post-body-paragraph jl jm hi jn b jo lz ij jq jr ma im jt ju nr jw jx jy ns ka kb kc nt ke kf kg hb bi translated">[ <a class="ae ix" href="https://sh-tsang.medium.com/review-sfa-simplified-fast-alexnet-blur-classification-4121e6d813f9" rel="noopener"> SFA </a></p><h2 id="2a01" class="mm lj hi bd jk mn mo mp ln mq mr ms lr ju mt mu lt jy mv mw lv kc mx my lx mz bi translated"><a class="ae ix" rel="noopener" href="/@sh.tsang/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e">我以前的其他读物</a></h2></div></div>    
</body>
</html>