<html>
<head>
<title>Brief Introduction to Spark SQL Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark SQL引擎简介</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/brief-introduction-to-spark-sql-engine-6339810a3ee1?source=collection_archive---------5-----------------------#2022-02-03">https://medium.com/nerd-for-tech/brief-introduction-to-spark-sql-engine-6339810a3ee1?source=collection_archive---------5-----------------------#2022-02-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6e47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark SQL允许开发人员/管理员以编程方式对带有模式的结构化数据发出ANSI SQL:2003兼容的查询。Spark SQL是在1.3版本中引入的。从那时起，已经在它的基础上建立了几个更高级别的功能</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/0f7ded913522cc27b5e3ff890fb27fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oa7Bpfvtd_VHuy9N"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jt" href="https://unsplash.com/@sunder_2k25?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Sunder Muthukumaran </a>拍摄</figcaption></figure><h2 id="5748" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated">Spark SQL功能概述</h2><ul class=""><li id="dfb7" class="kp kq hi ih b ii kr im ks iq kt iu ku iy kv jc kw kx ky kz bi translated">生成优化的查询计划和精简JVM代码的最终执行。</li><li id="ad2f" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc kw kx ky kz bi translated">作为使用数据库ODBC/JDBC连接器的外部工具的桥梁。</li><li id="47b6" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc kw kx ky kz bi translated">增加了读写JSON、CSV或Avro等各种格式的结构化文件并将它们转换成临时表的能力。</li><li id="57eb" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc kw kx ky kz bi translated">连接到Apache配置单元metastore和表。</li><li id="7a82" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc kw kx ky kz bi translated">引入了一个交互式Spark SQL shell，用于即席和快速数据浏览。</li><li id="dc41" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc kw kx ky kz bi translated">统一了Spark的各种组件，并允许用Spark支持的语言(Java、Scala、Python和R)创建数据帧/数据集抽象。</li></ul><h1 id="51ce" class="lf jv hi bd jw lg lh li ka lj lk ll ke lm ln lo kh lp lq lr kk ls lt lu kn lv bi translated">Spark SQL的两个主要组件</h1><p id="51b3" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq lw is it iu lx iw ix iy ly ja jb jc hb bi translated">Spark SQL的核心是以下两个组件:</p><h2 id="ac5d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated"><strong class="ak">钨项目</strong></h2><p id="762d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq lw is it iu lx iw ix iy ly ja jb jc hb bi translated">由几项旨在提高Spark应用程序的内存和CPU效率的工作组成。它的一个特性是使用快速紧凑的定制格式将数据帧和数据集存储在内存中，而不是使用占用更多内存且操作缓慢的JVM对象。</p><h2 id="925f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke iq kf kg kh iu ki kj kk iy kl km kn ko bi translated"><strong class="ak">催化剂优化器</strong>:</h2><p id="9762" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq lw is it iu lx iw ix iy ly ja jb jc hb bi translated">这提供了一个计算查询，并为它输出一个执行计划。我们将在下面简要讨论四个转型阶段:</p><ol class=""><li id="035a" class="kp kq hi ih b ii ij im in iq lz iu ma iy mb jc mc kx ky kz bi translated"><strong class="ih hj">分析</strong>:该步骤解析SQL/DataFrame查询中引用的列和表名，并为查询生成抽象语法树(AST)。对于列名和表名的解析，将参考内部目录。catalog是Spark SQL的编程接口，它包含列、数据类型、函数、表、数据库等的名称列表。</li><li id="c46b" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc mc kx ky kz bi translated"><strong class="ih hj">逻辑优化</strong>:在这个阶段，通过应用基于规则的优化方法生成一组计划，每个计划都有一个指定的成本。这些计划包括优化，如常数折叠、谓词下推、投影修剪或布尔表达式简化的过程。逻辑计划是下一阶段的输入。</li><li id="0e18" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc mc kx ky kz bi translated"><strong class="ih hj">物理规划</strong>:该阶段为选择的逻辑规划生成物理规划。</li><li id="37de" class="kp kq hi ih b ii la im lb iq lc iu ld iy le jc mc kx ky kz bi translated"><strong class="ih hj">代码生成</strong>:在最后阶段，生成Java字节码，以便在集群中的每台机器上执行。Spark SQL还可以对已经加载到内存中的数据集进行操作，并可以利用先进的编译器技术来生成代码，以加快执行速度。在这个阶段的上下文中，您会经常听说<strong class="ih hj"> <em class="md">整个代码生成</em> </strong>的概念，这是一个物理查询优化阶段，它将整个查询折叠成一个函数，同时删除虚函数调用并使用CPU寄存器来获得中间结果。Spark 2.0附带的第二代钨引擎使用了这种方法，这种简化极大地提高了CPU性能和效率。</li></ol></div><div class="ab cl me mf gp mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="hb hc hd he hf"><p id="01ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经对Spark SQL引擎及其两个核心组件Catalyst Optimizer和钨进行了高度概述，我们将在接下来的博客中涉及更多更深入的Spark主题，下次再见！</p></div></div>    
</body>
</html>