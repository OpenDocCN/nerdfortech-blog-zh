<html>
<head>
<title>Detecting Sentiments in Tweets with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用机器学习检测推文中的情感</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/detecting-sentiments-in-tweets-with-machine-learning-376a5010b4dc?source=collection_archive---------22-----------------------#2021-06-14">https://medium.com/nerd-for-tech/detecting-sentiments-in-tweets-with-machine-learning-376a5010b4dc?source=collection_archive---------22-----------------------#2021-06-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/72f326f5b6f5694d9f9f50ece3d64963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*osEdMG2tONBE4lH5jC_H0A.jpeg"/></div></div></figure><p id="095f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想要在深度学习的帮助下检查Twitter上人们的情绪吗？你来对地方了，因为这就是我们在这个项目中要做的。</p><p id="fcdd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">先决条件:对Python、Tensorflow/Keras有很好的了解，对神经网络如何工作有基本的了解。</p><p id="858d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Twitter是一个如此疯狂的地方。人们分享他们的生活，公开表达他们对政治、娱乐、教育等的看法。你可以通过从这个应用程序抓取信息来了解正在发生的事情，另一个好处是这个应用程序给你充分的自由来抓取它的内容。</p><p id="045c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">我们的项目将如何进行的简要概述</strong>:首先，我们将在包含句子及其情感作为标签的数据集上训练我们的神经网络。然后，我们将使用我们训练有素的网络来检测推文中的情绪，我们将从twitter中收集这些情绪。</p><p id="3695" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以，没有任何进一步的麻烦，让我们开始吧。</p><p id="7819" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">指数</strong></p><ol class=""><li id="a2d4" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">读出数据</li><li id="cf33" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">数据清理和分析</li><li id="68c9" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">数据预处理</li><li id="b520" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">文本转换</li><li id="cf5a" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">建立神经网络</li><li id="1266" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">训练神经网络</li><li id="e9ab" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">抓取文本(收集Twitter数据)</li><li id="971f" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">清理和处理twitter数据</li><li id="a62d" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">使用训练的模型来检测推文中的情绪</li></ol><h2 id="06f4" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated">数据</h2><p id="e6b3" class="pw-post-body-paragraph iq ir hi is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">对于数据，你可以使用互联网上的任何数据集，这些数据集包含句子和标签，这些标签分别说明了句子中的情感，如爱、恨、悲伤等。</p><h1 id="8023" class="lc kd hi bd ke ld le lf ki lg lh li km lj lk ll kp lm ln lo ks lp lq lr kv ls bi translated">数据清理和分析</h1><p id="c1e7" class="pw-post-body-paragraph iq ir hi is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated"><strong class="is hj">由于我们将处理包含标点符号、特殊字符等的文本数据，数据清理和处理是项目</strong>的一个非常重要的部分，必须仔细完成以确保我们的模型给我们最好的结果。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/657582ceb47bd10b8d13e896eaf406ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*Shcug_4VxUc9nJiwaYTHcw.jpeg"/></div></figure><p id="0aa4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将使用Python中的正则表达式库删除不必要的东西，如逗号、标点符号和特殊关键字，因为它们不会影响句子的情感。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="a674" class="kc kd hi lz b fi md me l mf mg"><strong class="lz hj">import</strong> <strong class="lz hj">time</strong><br/><em class="mh"># Text Processing Libraries<br/></em><strong class="lz hj">import</strong> <strong class="lz hj">spacy</strong><br/><strong class="lz hj">import</strong> <strong class="lz hj">re</strong><br/><strong class="lz hj">import</strong> <strong class="lz hj">string</strong><br/><br/><strong class="lz hj">def</strong> clean_text(text):<br/>    <em class="mh">'''Make text lowercase, remove text in square brackets, remove       links, remove punctuation and remove words containing numbers.'''</em><br/>    <br/>    text = re.sub('\[.*?\]', '', text)<br/>    text = re.sub('https?://\S+|www\.\S+', '', text)<br/>    text = re.sub('&lt;.*?&gt;+', '', text)<br/>    text = re.sub('[<strong class="lz hj">%s</strong>]' % re.escape(string.punctuation), '', text)<br/>    text = re.sub('<strong class="lz hj">\n</strong>', '', text)<br/>    text = re.sub('\w*\d\w*', '', text)<br/>    <strong class="lz hj">return</strong> text.lower()</span></pre><p id="9dda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">删除停用词</strong></p><p id="c045" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通常，英语句子中有许多停用词，如“to”、“the”、“this”等，它们几乎无助于句子的情感，所以我们将从所有句子中删除它们。</p><p id="dcff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图会让你对去掉停用词后的句子有所了解。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/1893c4700064e82b266d89866cac57ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*stHkMgObWRdGHRLlKMXIZg.png"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">Sentences_clean是去掉停用词后的句子。</figcaption></figure><h2 id="9710" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated">把…按屈折变化形式进行归类</h2><p id="67a0" class="pw-post-body-paragraph iq ir hi is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">在处理文本数据时，这是一个非常重要的步骤，但是很多人都没有这样做。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/c4aa901d2d6a23008dee341be7cdb45d.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*zX9Lr6pCY53rmZsVgL6mnw.png"/></div></figure><p id="e4bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">到底什么是引理化？出于语法原因，文档将使用一个单词的不同形式，如<em class="mh">组织</em>、<em class="mh">组织</em>和<em class="mh">组织，但我们知道它们都有类似的意思。因此，对于词汇化，我们只是将它们规范化为单词organize的最常见形式。</em></p><p id="71f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要更深入地了解词汇化，请点击这里的<a class="ae mo" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20." rel="noopener ugc nofollow" target="_blank"><strong class="is hj"/></a><strong class="is hj">。</strong></p><figure class="lu lv lw lx fd ij"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h2 id="d4e2" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated">文本转换</h2><p id="c8ce" class="pw-post-body-paragraph iq ir hi is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">在将我们的数据输入模型之前，需要将其转换成模型可以理解的格式。所以我们必须将所有的文本数据转换成数字形式。</p><p id="940e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在有很多方法可以做到这一点，如矢量化，一键编码等。我们还有高级的单词向量表示，如Glove vectors等，其中单词被表示为多维向量，它们有助于根据单词在句子中的出现情况理解不同单词之间的相似性，如Boy-King、Girl-Queen。你可以在这里  <strong class="is hj">了解更多<a class="ae mo" href="https://towardsdatascience.com/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010" rel="noopener" target="_blank"> <strong class="is hj">。</strong></a></strong></p><p id="6e62" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我用了一个简单的方法。Keras为准备文本提供了一个更复杂的API，可以适合和重用来准备多个文本文档。。它提供了<a class="ae mo" href="https://keras.io/preprocessing/text/#tokenizer" rel="noopener ugc nofollow" target="_blank">标记器类</a>，用于准备深度学习的文本文档。必须构造记号赋予器，然后使其适合原始文本文档或整数编码的文本文档。</p><p id="64eb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们将使用Keras Tokenizer API将句子转换为长度相等的整数序列。关于我在下面代码块中所做的更多详细信息，你可以查看这个<a class="ae mo" href="https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">博客</strong> </a> <strong class="is hj">。</strong></p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="ff3a" class="kc kd hi lz b fi md me l mf mg">tokenizer = Tokenizer(num_words = 20000, oov_token= 'OOV')<br/>tokenizer.fit_on_texts(sentences_list)<br/><br/><br/>#convert text to sequence <br/>train_sequences = tokenizer.texts_to_sequences(sentences_list)</span><span id="85fd" class="kc kd hi lz b fi mr me l mf mg">#pad all sentences to equal length<br/>train_padded = pad_sequences(train_sequences, maxlen=30, padding= 'post', truncating='post')</span></pre><p id="0bae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以上是将文本转换成序列的简单方法。但它有很多缺点，因为它只是给词汇中的单词分配唯一的整数值，而没有显示出像男孩王、女孩王这样的单词之间的任何关系，所以有更多更好的方法来做标记化，如我之前所说的，例如使用word2vec、Glove vectors等。但是初学者使用Keras文本对API进行排序是一个很好的开始。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/58123a8e324196885f2012f48d231514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*rsWKtPMawArG5U_kUQfonQ.png"/></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">文本清理和处理中重要步骤的简短可视化</figcaption></figure><h2 id="6969" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated"><strong class="ak">将我们的标签转换为独热码编码向量</strong></h2><p id="7c34" class="pw-post-body-paragraph iq ir hi is b it kx iv iw ix ky iz ja jb kz jd je jf la jh ji jj lb jl jm jn hb bi translated">在我们的数据集中，我们有“愤怒”、“爱”等标签，所以首先我们必须将这些字符串转换成整数值。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="9e40" class="kc kd hi lz b fi md me l mf mg"><em class="mh">#converting the emotion labels into numbers.</em><br/>dic = {'joy':0, 'anger': 1, 'love':2, 'fear':3, 'surprise':4, 'sadness' :5}</span><span id="a35a" class="kc kd hi lz b fi mr me l mf mg">#labels list is the list of all sentiments.<br/>labels_list_to_num = [dic.get(n, n) <strong class="lz hj">for</strong> n <strong class="lz hj">in</strong> labels_list]</span></pre><p id="4f32" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">标签的一次热编码</strong></p><p id="c9c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在将标签转换成整数值之后，将它们转换成一个热编码向量，因为这是一个多分类问题(多于2个标签)。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="8dd9" class="kc kd hi lz b fi md me l mf mg"><em class="mh">#Converting integer labels to One hot encoded vectors to fit in the model.</em><br/><strong class="lz hj">from</strong> <strong class="lz hj">keras.utils.np_utils</strong> <strong class="lz hj">import</strong> to_categorical   <br/><br/>categorical_labels = to_categorical(np.array(labels_list_to_num), num_classes=6)</span></pre><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/7caf64f85ce76e8bf5de6a38b940ac47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cf3IECI9csW9kFv51Dkewg.png"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">一个热编码做什么</figcaption></figure><h2 id="3db1" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated">神经网络(双向LSTM)</h2><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/6e2d0d672995c6813e9c8d140ad4c9e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfdbrxPv3DJfrBwJNcBE4A.png"/></div></div></figure><p id="f374" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们的数据得到了很好的清理、分析和转换。所以，是时候建立神经网络了。</p><p id="a76f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我使用了流行的双向LSTMS架构。我更喜欢这种架构的原因是，它比简单的rnn和单向lstm更好地理解上下文，因为使用它们(双向lstm)将以两种方式运行您的输入，一种是从过去到未来，另一种是从未来到过去，因此它还可以获得短语或句子的未来单词的上下文，而不像普通的rnn只能获得过去的上下文。</p><p id="7a3b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我不会深入他们实际做什么，因为这不是这个项目的重点。如果你想了解这个架构的深入运作，你可以阅读这个<strong class="is hj"> </strong> <a class="ae mo" rel="noopener" href="/@raghavaggarwal0089/bi-lstm-bc3d68da8bd0"> <strong class="is hj">博客</strong> </a>，里面一切都解释得很好。</p><figure class="lu lv lw lx fd ij"><div class="bz dy l di"><div class="mp mq l"/></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">我的模型的代码示例</figcaption></figure><p id="308d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">训练模型</strong></p><p id="9e2e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的LSTM模型建立后，我们将在我们清理和转换的数据上训练它。我已经训练它15个纪元了。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="5372" class="kc kd hi lz b fi md me l mf mg"><em class="mh">#train </em><br/>history = model.fit(train_padded, categorical_labels,validation_data = (val_padded, categorical_labels_val) epochs=15)</span></pre><p id="be01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在训练模型，并获得良好的准确性后，现在是时候使用它进行一些预测了。</p><h2 id="ea87" class="kc kd hi bd ke kf kg kh ki kj kk kl km jb kn ko kp jf kq kr ks jj kt ku kv kw bi translated">是时候使用我们训练好的模型对一些真实的twitter数据进行预测了。</h2><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/5f53e58168da48f5faf479a16057595b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*v-XSPyNu8BrCt3O7d_Q1ag.jpeg"/></div></div></figure><p id="60f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将使用经过训练的模型来检测测试数据中的情感。首先，我们将从twitter上抓取推文。</p><p id="1f2f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从twitter中提取数据有多种方法，比如使用beautifulsoup库、Python中的twitter_scrapper库等。你可以从你朋友的账户、名人或任何随机的人那里搜集数据。</p><pre class="lu lv lw lx fd ly lz ma mb aw mc bi"><span id="3723" class="kc kd hi lz b fi md me l mf mg"><strong class="lz hj">from</strong> <strong class="lz hj">twitter_scraper</strong> <strong class="lz hj">import</strong> get_tweets<br/>test_list = []<br/>clean_test_list = []<br/><br/><em class="mh">#scraping some of your friends tweets</em><br/><strong class="lz hj">for</strong> tweet <strong class="lz hj">in</strong> get_tweets('your_friends_account', 5):<br/>       <em class="mh">#list oh his/her recent tweets.</em><br/>       test_list.append(tweet['text'])<br/><br/>       <em class="mh">#clean and then lemmatize text.</em><br/>                      clean_test_list.append(lemmatizer.lemmatize(clean_text(tweet['text'].replace("<strong class="lz hj">\n</strong>"," ").strip())))</span></pre><p id="e7f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，我们从twitter上搜集的推文会有很多标点符号、特殊字符和我们不需要的东西。因此，就像我们在训练数据中所做的一样，在将句子放入模型之前，我们也将处理和清理文本。</p><p id="0601" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，首先抓取推文，按照我们之前的步骤(清理、词汇化、转换)，然后将这些清理过的句子(推文)放入模型中进行预测，您将获得结果。</p><p id="64fa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong>您将不会得到以字符串形式显示情感的输出，如爱、愤怒等，而是会得到一个值数组，因为我们在将标签放入模型进行训练之前对它们进行了一次性编码。然后，您必须使用np.argmax将数组解码为整数值，然后将这些整数转换为我们之前分配给字典的反向情感。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/25f61643e603881ea9f71f90be9cc778.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*UlBTJAFdaHIkGjBRhjggZA.jpeg"/></div></div></figure><p id="7370" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以，这就是全部了。整个项目的github库就是这里的<a class="ae mo" href="https://github.com/Kaif10/Emotion_Detection_in_Tweets" rel="noopener ugc nofollow" target="_blank"><strong class="is hj"/></a><strong class="is hj">。</strong>如有任何疑问，欢迎在<a class="ae mo" href="https://www.linkedin.com/in/kaif-kohari-a34433190/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> LinkedIn </strong> </a>联系我。在那之前，保重。</p></div></div>    
</body>
</html>