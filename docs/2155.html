<html>
<head>
<title>Review — AAE: Adversarial Autoencoders (GAN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述— AAE:对抗性自动编码器(GAN)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/review-aae-adversarial-autoencoders-gan-e8fda9160542?source=collection_archive---------5-----------------------#2021-04-24">https://medium.com/nerd-for-tech/review-aae-adversarial-autoencoders-gan-e8fda9160542?source=collection_archive---------5-----------------------#2021-04-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="dd28" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75"> <strong class="ak">【甘】</strong></a> <strong class="ak"> </strong>与自动编码器组合<strong class="ak"/></h2></div><p id="8680" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi ju translated">在这个故事中，简要回顾了多伦多大学、谷歌大脑和 OpenAI 的<strong class="ja hj">对抗性自动编码器</strong>(AAE)。仅描述了 AAE 变体。这是 Ian Goodfellow 的论文，他也是<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75"> GAN </a>的第一作者。在本文中:</p><ul class=""><li id="e2eb" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">AAE 是一个使用<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75"><strong class="ja hj">GAN</strong></a><strong class="ja hj">的概率自动编码器。</strong></li><li id="209e" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated"><strong class="ja hj">敌对自动编码器<strong class="ja hj">的解码器</strong>学习深度生成模型，该模型在数据分发之前映射强加的。</strong></li></ul><p id="d5fc" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这是一篇发表在<strong class="ja hj"> 2016 ICLR </strong>的论文，引用超过<strong class="ja hj"> 1600 次</strong>。(<a class="kr ks ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----e8fda9160542--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="aaf8" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">概述</h1><ol class=""><li id="1366" class="kd ke hi ja b jb ls je lt jh lu jl lv jp lw jt lx kj kk kl bi translated"><strong class="ja hj"> AAE:网络架构</strong></li><li id="e7e1" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt lx kj kk kl bi translated"><strong class="ja hj"> AAE vs VAE </strong></li><li id="7ed6" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt lx kj kk kl bi translated"><strong class="ja hj">监督 AAE </strong></li><li id="bdf3" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt lx kj kk kl bi translated"><strong class="ja hj">半监督 AAE </strong></li><li id="e25f" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt lx kj kk kl bi translated"><strong class="ja hj">无人监管的 AAE </strong></li><li id="9d4b" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt lx kj kk kl bi translated"><strong class="ja hj">使用 AAE 进行数据可视化的降维</strong></li></ol></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="806e" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated"><strong class="ak"> 1。AAE:网络架构</strong></h1><figure class="lz ma mb mc fd md er es paragraph-image"><div class="er es ly"><img src="../Images/2cdfd529e738dfab561559cbc3a9048f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*7WFD7gtpYmFXwIIyTsFB1w.png"/></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc"> AAE:网络架构(+:正样本，-:负样本)</strong></figcaption></figure><ul class=""><li id="29f5" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated"><strong class="ja hj">最上面一行</strong>是一个标准的<strong class="ja hj">自动编码器</strong>，它<strong class="ja hj">从一个潜在代码<em class="mk"> z </em>重建一个图像<em class="mk"> x </em>。</strong></li><li id="0bd3" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated"><strong class="ja hj">最下面一行</strong>图示了第二个网络，该网络被训练来有区别地<strong class="ja hj">预测样本是来自自动编码器的隐藏代码还是来自用户指定的采样分布。</strong></li><li id="2bf0" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">设<em class="mk"> p </em> ( <em class="mk"> z </em>)为我们想要对代码施加的先验分布，<em class="mk">q</em>(<em class="mk">z</em>|<em class="mk">x</em>)为编码分布，<em class="mk">p</em>(<em class="mk">x</em>|<em class="mk">z</em>)为解码分布。</li><li id="0540" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">也设<em class="mk"> pd </em> ( <em class="mk"> x </em>)为数据分布，<em class="mk"> p </em> ( <em class="mk"> x </em>)为模型分布。自动编码器<em class="mk">q</em>(<em class="mk">z</em>|<em class="mk">x</em>)的编码函数将自动编码器的隐藏代码向量上的<em class="mk"> q </em> ( <em class="mk"> z </em>)的聚合后验分布定义为:</li></ul><figure class="lz ma mb mc fd md er es paragraph-image"><div class="er es ml"><img src="../Images/115fe658651c021ed9427bffa1066442.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*UvZ4o4SWRNTNJJVIbujvgQ.png"/></div></figure><ul class=""><li id="f36b" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">是对抗性网络引导<em class="mk"> q </em> ( <em class="mk"> z </em>)匹配<em class="mk"> p </em> ( <em class="mk"> z </em>)。</li></ul><blockquote class="mm mn mo"><p id="d926" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated"><strong class="ja hj">自动编码器试图最小化重建误差。</strong></p><p id="b0a0" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">对抗网络的生成器也是<strong class="ja hj">自动编码器<em class="hi">q</em>(<em class="hi">z</em>|<em class="hi">x</em>)的编码器。</strong>编码器确保聚合后验分布能够<strong class="ja hj">欺骗区别对抗网络，使其认为隐藏代码 q(z)来自真实的先验分布 p(z)。</strong></p></blockquote><ul class=""><li id="19c0" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">对抗网络和自动编码器都与 SGD 一起在两个阶段<strong class="ja hj">进行训练:重建阶段和正则化阶段。</strong></li><li id="9818" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">重建阶段训练自动编码器。</li><li id="0e69" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">正则化阶段训练<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75"> GAN </a>。</li></ul></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="5132" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">2.AAE 对 VAE</h1><figure class="lz ma mb mc fd md er es paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="er es ms"><img src="../Images/2727ff7cd453da3770f9ca678aa40399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWBAz9WsmdUKjTmG3-20jw.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">AAE vs VAE MNIST</strong></figcaption></figure><ul class=""><li id="9b05" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">保留图像的隐藏代码<em class="mk"> z </em>符合(A/C)一个 2-D 高斯和(B/D)10 个 2-D 高斯的混合。</li><li id="b043" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated"><strong class="ja hj"> A </strong>:由<strong class="ja hj"> AAE </strong>学习到的流形呈现出<strong class="ja hj">尖锐过渡</strong>表示编码空间已被填充且没有呈现出“孔洞”。</li><li id="8151" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated"><strong class="ja hj"> C </strong> : <strong class="ja hj"> VAE </strong>大致符合二维高斯分布的形状。然而，<strong class="ja hj">没有数据点映射到编码空间的几个局部区域</strong>，这表明 VAE 可能没有像 AAE 一样捕获数据流形。</li><li id="ad5e" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">B  : AAE 成功地将聚合后验概率与先验分布进行了匹配。</li><li id="41cf" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">相反，VAE 表现出与混合物 10 高斯的系统差异。</li></ul></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="84a9" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">3.监督 AAE</h1><figure class="lz ma mb mc fd md er es paragraph-image"><div class="er es mx"><img src="../Images/49fd7cb229c20c4d3b7ab1e55c36f3a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*1ZuKVnCCB_irBaUfFn8FsA.png"/></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">监督 AAE </strong></figcaption></figure><ul class=""><li id="0743" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">在进入半监督 AAE 之前，尝试监督 AAE，其中<strong class="ja hj">该架构将类别标签信息与图像样式信息分开。</strong></li><li id="dfbb" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">解码器利用标识标签的独热码矢量和隐藏代码<em class="mk"> z </em>来重建图像。</li></ul><blockquote class="mm mn mo"><p id="e775" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">这种架构迫使网络在隐藏代码<em class="hi"> z </em>中保留所有独立于标签的信息。</p></blockquote></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="9404" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">4.半监督 AAE</h1><figure class="lz ma mb mc fd md er es paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="er es my"><img src="../Images/1ecefccbcabf52b9fb721017cd17883a.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*ozNqeu0FcP5XlPTdZZJaXw.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">半监督 AAE </strong></figcaption></figure><ul class=""><li id="0c8c" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">监督 AAE 进一步修改为上述半监督 AAE。</li></ul><blockquote class="mm mn mo"><p id="bde9" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">AAE 的推理网络使用编码器<em class="hi"> q </em> ( <em class="hi"> z </em>，<em class="hi"> y </em> | <em class="hi"> x </em>)预测离散类变量<em class="hi"> y </em>和连续潜变量<em class="hi"> z </em>。</p></blockquote><ul class=""><li id="0fa3" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">第一个敌对网络在标签表示上强加了分类分布。这个对立的网络确保了潜在的类变量<em class="mk"> y </em>不携带任何样式信息。</li><li id="f96f" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">第二个对抗网络对风格表示施加高斯分布，这确保了潜在变量<em class="mk"> z </em>是连续的高斯变量。</li><li id="d3c2" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">对抗网络和自动编码器都在<strong class="ja hj">三个阶段</strong>中与 SGD 联合训练——重建阶段、正则化阶段和半监督分类阶段。</li><li id="ea5f" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">在<strong class="ja hj">重建阶段</strong>，自动编码器<strong class="ja hj">更新编码器<em class="mk"> q </em> ( <em class="mk"> z </em>，<em class="mk"> y </em> | <em class="mk"> x </em>)，解码器</strong>至<strong class="ja hj"> </strong>最小化未标记小批量上输入的重建误差。</li><li id="729e" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">在<strong class="ja hj">正则化阶段</strong>中，每个敌对网络首先<strong class="ja hj">更新它们的判别网络</strong>，以将真实样本与生成的样本区分开。</li><li id="d21d" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">然后，敌对网络<strong class="ja hj">更新它们的生成器</strong>以混淆它们的区别网络。</li><li id="e74e" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">在<strong class="ja hj">半监督分类阶段</strong>，自动编码器更新<strong class="ja hj"><em class="mk">q</em>(<em class="mk">y</em>|<em class="mk">x</em>)</strong>到<strong class="ja hj">最小化已标记小批量上的交叉熵成本</strong>。</li></ul><figure class="lz ma mb mc fd md er es paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="er es mz"><img src="../Images/89cfd2fc76b37ce0da562c74f4fccaf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BCfMT2tjUBqr7BoPBK7wg.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">MNIST 和 SVHN 上的半监督分类性能(错误率)</strong></figcaption></figure><ul class=""><li id="16da" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">值得一提的是<strong class="ja hj">所有的 AAE 模型都是端到端训练</strong>，而半监督 VAE 模型必须一次训练一层。</li></ul><blockquote class="mm mn mo"><p id="bb4a" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">在具有 100 和 1000 个标签的 MNIST 数据集上，AAEs 的性能明显优于 VAEs。</p></blockquote></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="cf7b" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">5.无人监管的 AAE</h1><figure class="lz ma mb mc fd md er es paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="er es na"><img src="../Images/7eca455342217a183bd6a8eb538e1ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*562aZiAUj0maQ4FUWK0VLA.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">使用具有 16 个聚类的 AAE 对 MNIST 进行无监督聚类</strong></figcaption></figure><blockquote class="mm mn mo"><p id="0657" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">该架构是半监督 AAE，不同之处在于<strong class="ja hj">半监督分类阶段被移除</strong>，因此不再在任何标记的小批量上训练网络。</p></blockquote><ul class=""><li id="5ace" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">如上所述，倾斜的数字 1 和 6(群 16 和 11)与直的 1 和 6(群 15 和 10)放在不同的群中。</li></ul><figure class="lz ma mb mc fd md er es paragraph-image"><div class="er es nb"><img src="../Images/d3488b7d78084ba3b97ae03cd9cfa54e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*st_NJ0b8l4WMgiLPYrnvnQ.png"/></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">MNIST AAE 的无监督聚类性能(错误率)</strong></figcaption></figure><ul class=""><li id="c003" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">一旦训练完成，对于每个聚类<em class="mk"> i </em>，主正确标签被分配给聚类<em class="mk"> i </em>中的所有点。然后，可以基于分配给每个聚类的类别标签来估计测试误差。</li></ul><blockquote class="mm mn mo"><p id="3352" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated">如上表所示，AAE 在总共 16 个和 30 个标签的情况下分别达到了 9.55%和 4.10%的分类错误率。</p></blockquote></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="725d" class="la lb hi bd lc ld le lf lg lh li lj lk io ll ip lm ir ln is lo iu lp iv lq lr bi translated">6.<strong class="ak">使用 AAE 进行数据可视化的降维</strong></h1><figure class="lz ma mb mc fd md er es paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="er es nc"><img src="../Images/452eba219819eb3f889969fe25f4c6be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*X-DtfqZgdaX1TItM4iz-Rw.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">使用对立的自动编码器进行降维</strong></figcaption></figure><blockquote class="mm mn mo"><p id="0135" class="iy iz mk ja b jb jc ij jd je jf im jg mp ji jj jk mq jm jn jo mr jq jr js jt hb bi translated"><strong class="ja hj">最终的<em class="hi"> n </em>维度表示</strong>通过首先<strong class="ja hj">将独热标签表示映射到<em class="hi"> n </em>维度簇头表示</strong>和<strong class="ja hj">来构建，然后将结果添加到<em class="hi"> n </em>维度样式表示。</strong></p></blockquote><ul class=""><li id="bb8d" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated"><em class="mk"> n </em> =2 或 3 用于数据可视化。</li><li id="bd93" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">SGD 通过附加的代价函数学习簇头，该代价函数惩罚每两个簇头之间的欧几里德距离。</li></ul><figure class="lz ma mb mc fd md er es paragraph-image"><div class="er es nd"><img src="../Images/d238b5aeb17178af48dcf85edea381d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*wkCmIP6ur7cmQfc8QPSolA.png"/></div><figcaption class="mg mh et er es mi mj bd b be z dx translated"><strong class="bd lc">半监督和无监督的 MNIST AAE 降维。</strong></figcaption></figure><ul class=""><li id="7d83" class="kd ke hi ja b jb jc je jf jh kf jl kg jp kh jt ki kj kk kl bi translated">(这部分有详细内容，可以直接看论文。)</li><li id="58bd" class="kd ke hi ja b jb km je kn jh ko jl kp jp kq jt ki kj kk kl bi translated">总的来说，我们可以看到 AAE 可以实现一个<strong class="ja hj">干净的</strong> <strong class="ja hj">数字集群的分离。</strong></li></ul></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><p id="31e4" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">本文是<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a>使用自动编码器的早期论文。在本文中使用 VAE 的主要目的是进行半监督或无监督的学习，而不是纯粹的图像到图像的翻译或使用潜在向量合成图像。</p></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h2 id="e3d1" class="ne lb hi bd lc nf ng nh lg ni nj nk lk jh nl nm lm jl nn no lo jp np nq lq nr bi translated">参考</h2><p id="5534" class="pw-post-body-paragraph iy iz hi ja b jb ls ij jd je lt im jg jh ns jj jk jl nt jn jo jp nu jr js jt hb bi translated">【2016 ICLR】【AAE】<br/><a class="ae ix" href="https://arxiv.org/abs/1511.05644" rel="noopener ugc nofollow" target="_blank">对抗性自动编码器</a></p><h2 id="ccb4" class="ne lb hi bd lc nf ng nh lg ni nj nk lk jh nl nm lm jl nn no lo jp np nq lq nr bi translated">生成对抗网络</h2><p id="770c" class="pw-post-body-paragraph iy iz hi ja b jb ls ij jd je lt im jg jh ns jj jk jl nt jn jo jp nu jr js jt hb bi translated"><strong class="ja hj">图像合成</strong> [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a> ] [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-cgan-conditional-gan-gan-78dd42eee41"> CGAN </a> ] [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-lapgan-laplacian-generative-adversarial-network-gan-e87200bbd827">拉普甘</a>[<a class="ae ix" href="https://sh-tsang.medium.com/review-aae-adversarial-autoencoders-gan-e8fda9160542" rel="noopener">AAE</a>][<a class="ae ix" rel="noopener" href="/@sh.tsang/review-dcgan-deep-convolutional-generative-adversarial-network-gan-ec390cded63c">DCGAN</a>][<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener">CoGAN</a>][<a class="ae ix" href="https://sh-tsang.medium.com/review-simgan-learning-from-simulated-and-unsupervised-images-through-adversarial-training-gan-86a7003add50" rel="noopener">SimGAN</a>]<br/><strong class="ja hj">图像到图像翻译</strong>[<a class="ae ix" href="https://sh-tsang.medium.com/review-pix2pix-image-to-image-translation-with-conditional-adversarial-networks-gan-ac85d8ecead2" rel="noopener">pix 2 pix</a>[<a class="ae ix" href="https://sh-tsang.medium.com/review-unit-unsupervised-image-to-image-translation-networks-gan-4a25ced6d078" rel="noopener">单元</a> <br/> <strong class="ja hj">模糊检测</strong><a class="ae ix" href="https://sh-tsang.medium.com/review-dmenet-deep-defocus-map-estimation-using-domain-adaptation-blur-detection-20fdcaf5e384" rel="noopener">DMENet</a><br/><strong class="ja hj">摄像头篡改检测</strong><a class="ae ix" href="https://sh-tsang.medium.com/review-mantinis-visapp-19-generative-reference-model-and-deep-learned-features-camera-f608371c9854" rel="noopener">曼蒂尼的 VISAPP’19</a><strong class="ja hj"><br/>视频编码</strong><a class="ae ix" rel="noopener" href="/@sh.tsang/reading-vc-lapgan-video-coding-oriented-laplacian-pyramid-of-generative-adversarial-networks-74daa2d23d3c">VC-lap gan</a><a class="ae ix" href="https://sh-tsang.medium.com/review-zhu-tmm20-generative-adversarial-network-based-intra-prediction-for-video-coding-c8a217c564ea" rel="noopener">朱 TMM’20</a><a class="ae ix" href="https://sh-tsang.medium.com/review-zhong-elecgj21-a-gan-based-video-intra-coding-hevc-intra-9e3486dbca78" rel="noopener">钟 ELECGJ’21</a></p><h2 id="cfe5" class="ne lb hi bd lc nf ng nh lg ni nj nk lk jh nl nm lm jl nn no lo jp np nq lq nr bi translated"><a class="ae ix" href="https://sh-tsang.medium.com/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e" rel="noopener">我以前的其他论文阅读材料</a></h2></div></div>    
</body>
</html>