<html>
<head>
<title>How to convert Tensorflow2 Model to ONNX using tf2onnx when there is Custom Ops</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有自定义Ops时如何使用tf2onnx将Tensorflow2模型转换为ONNX</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20?source=collection_archive---------1-----------------------#2021-09-09">https://medium.com/nerd-for-tech/how-to-convert-tensorflow2-model-to-onnx-using-tf2onnx-when-there-is-custom-ops-6e703376ef20?source=collection_archive---------1-----------------------#2021-09-09</a></blockquote><div><div class="dt gx gy gz ha hb"/><div class="hc hd he hf hg"><figure class="hi hj fa fc hk hl es et paragraph-image"><div role="button" tabindex="0" class="hm hn di ho bf hp"><div class="es et hh"><img src="../Images/61a059aa65117b90f91ea6660640d769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjqxoGsHLgLKg1DGlcYgWg.png"/></div></div></figure><div class=""/><div class=""><h2 id="49ef" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji dy translated">使用CustomOps / Extra Opset将Tensorflow (PB)转换为ONNX</h2></div><h1 id="6838" class="jj jk hu bd jl jm jn jo jp jq jr js jt ja ju jb jv jd jw je jx jg jy jh jz ka bi translated">介绍</h1><p id="e32a" class="pw-post-body-paragraph kb kc hu kd b ke kf iv kg kh ki iy kj kk kl km kn ko kp kq kr ks kt ku kv kw hc bi translated">转换模型时，在以UserObjects错误结束时，转换的tensorflow端检测到ONNX转换模型元描述中没有实现自定义操作。</p><p id="82cf" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated">我们通常的转换方法是遵循命令行实用程序<code class="dv lc ld le lf b">tf2onnx.convert</code></p><blockquote class="lg"><p id="a81d" class="lh li hu bd lj lk ll lm ln lo lp kw dy translated">这是必须避免的！！！！！！</p></blockquote><h1 id="094e" class="jj jk hu bd jl jm jn jo jp jq jr js jt ja lq jb jv jd lr je jx jg ls jh jz ka bi translated">出路</h1><p id="c83e" class="pw-post-body-paragraph kb kc hu kd b ke kf iv kg kh ki iy kj kk kl km kn ko kp kq kr ks kt ku kv kw hc bi translated">按照教程将Tensorflow模型转换成ONNX，描述在:<a class="ae lt" href="https://github.com/onnx/tensorflow-onnx" rel="noopener ugc nofollow" target="_blank"> @tf2onnx </a></p><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="6209" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">python -m tf2onnx.convert --saved-model tensorflow-model-path --output model.onnx</strong></span></pre><h1 id="1547" class="jj jk hu bd jl jm jn jo jp jq jr js jt ja ju jb jv jd jw je jx jg jy jh jz ka bi translated">定制操作</h1><p id="10fe" class="pw-post-body-paragraph kb kc hu kd b ke kf iv kg kh ki iy kj kk kl km kn ko kp kq kr ks kt ku kv kw hc bi translated">使用自定义Ops需要采用试错法来转换模型。</p><p id="a73f" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated">首先，尝试命令行选项。</p><h2 id="7330" class="mc jk hu bd jl mh mi mj jp mk ml mm jt kk mn mo jv ko mp mq jx ks mr ms jz mt bi translated">命令行选项</h2><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="a9ab" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">python -m tf2onnx.convert --saved-model tensorflow-model-path --output model.onnx --extra-ops 'ai.onnx.contrib:1'</strong></span></pre><p id="1493" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated">然后，在笔记本中尝试，从字面上看，打开一个笔记本来转换为@ <a class="ae lt" href="https://github.com/openvinotoolkit/openvino_notebooks/" rel="noopener ugc nofollow" target="_blank"> OpenVINO Notebooks </a>存储库地址总是更好。</p><p id="fdfd" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated">在笔记本中遵循以下简单步骤:</p><blockquote class="mu mv mw"><p id="d638" class="kb kc mx kd b ke kx iv kg kh ky iy kj my kz km kn mz la kq kr na lb ku kv kw hc bi translated"><strong class="kd hv">关注本笔记本:</strong><a class="ae lt" href="https://github.com/microsoft/onnxruntime-extensions/blob/main/tutorials/tf2onnx_custom_ops_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="kd hv">https://github . com/Microsoft/onnx runtime-extensions/blob/main/tutorials/TF 2 onnx _ custom _ ops _ tutorial . ipynb</strong></a></p></blockquote><ol class=""><li id="2dab" class="nb nc hu kd b ke kx kh ky kk nd ko ne ks nf kw ng nh ni nj bi translated"><strong class="kd hv"> <em class="mx">加载张量流模型</em> </strong></li></ol><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="c068" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">model = tf.keras.models.load_model("path/to/model")</strong></span></pre><p id="b023" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated"><strong class="kd hv">②<em class="mx">。将模型转换为具体函数</em> </strong></p><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="39a8" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">full_model = tf.function(lambda inputs: model(inputs))    </strong></span><span id="a372" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">full_model = full_model.get_concrete_function([tf.TensorSpec(model_input.shape, model_input.dtype) for model_input in model.inputs])</strong></span></pre><p id="3e12" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated"><strong class="kd hv"> <em class="mx"> 2.1持久化输入输出参数</em> </strong></p><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="d9ac" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">input_names = [inp.name for inp in full_model.inputs]<br/>output_names = [out.name for out in full_model.outputs]<br/>print("Inputs:", input_names)<br/>print("Outputs:", output_names)</strong></span></pre><p id="4403" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated"><strong class="kd hv"> <em class="mx"> 3。冻结模型</em>和</strong></p><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="5e1c" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2</strong></span><span id="7614" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">frozen_func = convert_variables_to_constants_v2(full_model)<br/>frozen_func.graph.as_graph_def()</strong></span></pre><p id="12e0" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated"><strong class="kd hv"> <em class="mx"> 4。使用额外的op set[关键代码] </em> </strong>单步转换模型</p><pre class="lu lv lw lx fe ly lf lz ma aw mb bi"><span id="7708" class="mc jk hu lf b fj md me l mf mg"><strong class="lf hv">from tf2onnx import tf_loader<br/>from tf2onnx.tfonnx import process_tf_graph<br/>from tf2onnx.optimizer import optimize_graph<br/>from tf2onnx import utils, constants<br/>from tf2onnx.handler import tf_op</strong></span><span id="9825" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">extra_opset = [utils.make_opsetid(constants.CONTRIB_OPS_DOMAIN, 1)]</strong></span><span id="6eca" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">with tf.Graph().as_default() as tf_graph:<br/>    tf.import_graph_def(frozen_func.graph.as_graph_def(), name='')</strong></span><span id="2ecf" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">with tf_loader.tf_session(graph=tf_graph):<br/>    g = process_tf_graph(tf_graph, input_names=input_names, output_names=output_names, extra_opset=extra_opset)</strong></span><span id="699d" class="mc jk hu lf b fj nk me l mf mg"><strong class="lf hv">onnx_graph = optimize_graph(g)<br/>model_proto = onnx_graph.make_model("converted")<br/>utils.save_protobuf("model2b.onnx", model_proto)<br/>print("Conversion complete!")</strong></span></pre><p id="652a" class="pw-post-body-paragraph kb kc hu kd b ke kx iv kg kh ky iy kj kk kz km kn ko la kq kr ks lb ku kv kw hc bi translated">谢谢你。</p></div></div>    
</body>
</html>