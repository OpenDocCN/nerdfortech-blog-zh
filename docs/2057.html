<html>
<head>
<title>HR Analytics in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的人力资源分析</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/hr-analytics-in-python-2a29a4eb3625?source=collection_archive---------5-----------------------#2021-04-19">https://medium.com/nerd-for-tech/hr-analytics-in-python-2a29a4eb3625?source=collection_archive---------5-----------------------#2021-04-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0a57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Python中的损耗分析和预测</p><h1 id="c353" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">介绍</h1><p id="74fb" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在本文中，我们将使用Python进行人力资源流失分析。我们将要使用的数据集是一个非常受欢迎的数据集，可以在以下链接中找到:<a class="ae kg" href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/pavansubhasht/IBM-HR-analytics-attraction-dataset</a></p><p id="9607" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本练习的目的是识别导致流失的因素，然后使用多种机器学习算法预测员工流失。该数据集有32个自变量，范围从任期到离工作场所的距离。像这样的综合数据集需要大量的EDA过程，然后才能建立机器学习算法。</p><p id="f0f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">任何EDA过程中最重要的部分是通过不同的数据可视化程序来识别模式。我们将从计算每个部门的流失率开始。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="64f3" class="kq je hi km b fi kr ks l kt ku">df.groupby('Department').mean()['Attrition'].plot(kind='bar',color=['Green','Blue','Pink'])<br/>plt.title("Attrition Rate by Department")</span></pre><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es kv"><img src="../Images/d00343c9c71f67d1b9416d734dd1f72f.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*0BCKwswFZnWT8XCayLpSQw.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">按部门分列的自然减员率</figcaption></figure><p id="1e97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的条形图可以看出，销售部门是公司人员流失率最高的部门。现在让我们来看看影响损耗率的因素。</p><figure class="kh ki kj kk fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/5c3927c0c4c9ca1f34659cd0772808ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlhgYhKQfSDfziZZELzEBw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">损耗率/离家的距离</figcaption></figure><p id="2370" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图表明，与离家较近的员工相比，距离较远的员工流失率更高。</p><figure class="kh ki kj kk fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es li"><img src="../Images/756ff37d3af2a9e3a93b3f753263a7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cj673qc_NTzOf1n-wDRg8w.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">自然减员/工作年限</figcaption></figure><p id="a262" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图表明，与老员工相比，新员工更有可能离开公司。有很多因素需要考虑，所以让我们向前看，通过创建所有变量之间的关联矩阵来获得一个整体视图。</p><figure class="kh ki kj kk fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lj"><img src="../Images/f6bda026372bd9d7731da942e88bba65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_a19cNs3rWpMoyrw666Fw.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">相关矩阵</figcaption></figure><p id="1a34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相关矩阵并不表明与因变量有任何高度的相关性。然而，它确实为我们提供了所有因素的整体视图。让我们继续构建一个算法</p><h1 id="4e34" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">特征工程</h1><p id="74b6" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">该算法的第一部分是分离分类和数字特征。下面的代码可用于分离分类特征，并使用虚拟变量。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="c003" class="kq je hi km b fi kr ks l kt ku">cat_var=['BusinessTravel','Department','EducationField','Gender','JobRole', 'MaritalStatus', 'Over18','OverTime']<br/>X=pd.get_dummies(df,columns=cat_var,drop_first=<strong class="km hj">True</strong>)</span><span id="138b" class="kq je hi km b fi lk ks l kt ku">num_var=[]<br/><strong class="km hj">for</strong> i <strong class="km hj">in</strong> X.columns:<br/>    <strong class="km hj">if</strong> X[i].nunique()&gt;3:<br/>        num_var.append(i)</span></pre><h1 id="3bbe" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">逻辑回归</h1><p id="be30" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">逻辑回归是一种非常流行的分类算法，它使用sigmoid函数构建S曲线来预测结果的概率。它有几个特点，使它适合于大量的分类问题</p><ol class=""><li id="65fb" class="ll lm hi ih b ii ij im in iq ln iu lo iy lp jc lq lr ls lt bi translated">与其他机器学习算法相比，它更容易训练、实现和高效</li><li id="f698" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated">与过去的机器学习算法相比，它对变量的假设少得多</li><li id="e7cb" class="ll lm hi ih b ii lu im lv iq lw iu lx iy ly jc lq lr ls lt bi translated">它具有相当高的精确度，尤其是在特征数量低于观测数量的情况下</li></ol><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="cfa5" class="kq je hi km b fi kr ks l kt ku">lr=LogisticRegression(C=100,max_iter=10000)<br/>lr.fit(X_train,y_train)<br/>y_pred=lr.predict(X_test)<br/>print(accuracy_score(y_test,y_pred))<br/>print(classification_report(y_test,y_pred)</span></pre><p id="5c99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据分类报告，该模型的准确率为87%,然而其召回率较低，为阳性病例的43%。逻辑回归模型提供了极好的结果，然而问题的目的是识别可能离开的雇员。这就是召回成为一项非常重要的措施的原因。回忆衡量被正确识别的值的百分比。它通过以下公式计算</p><p id="3180" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">真阳性/(真阳性+假阴性)</strong></p><p id="68fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本例中，我们希望限制误报，因为我们希望识别所有可能离职的员工。在这个例子中，假阴性的成本远远高于假阳性的成本，这就是为什么建立一个可以提高回忆的模型是重要的。</p><p id="8ea7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在将构建一个决策树分类器，看看我们是否可以提高模型性能。决策树分类器的优点在于它易于解释，并且不需要其特征的任何特定分布。让我们看看决策树分类器告诉我们什么问题。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="0dda" class="kq je hi km b fi kr ks l kt ku"><strong class="km hj">from</strong> <strong class="km hj">sklearn.tree</strong> <strong class="km hj">import</strong> DecisionTreeClassifier<br/>dc=DecisionTreeClassifier()<br/>dc.fit(X_train,y_train)<br/>dc.predict(X_test)<br/>print(classification_report(y_test,y_pred)</span></pre><p id="2afc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，准确率从87%下降到了66%,但积极的一面是阳性结果的总召回率提高到了0.66。这是一个非常好的结果，因为我们的模型现在比以前的模型更有用。使用功能重要性功能，我们可以看到每个功能与流失的关系。</p><figure class="kh ki kj kk fd kw er es paragraph-image"><div class="er es lz"><img src="../Images/d8ce34c336201f021b7903e5d8fcf38d.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*oogLng1SHN3bFfqpK98aew.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">特征对损耗的重要性</figcaption></figure><p id="fa53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上图可以看出，员工的工作经验和月收入是与流失相关的最大因素。从学习的角度来看，这是很重要的，因为它可以被人力资源部门用来指导未来的政策和决策。</p><h1 id="6761" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">助推</h1><p id="efdf" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在，我们将应用boosting算法，看看我们是否可以进一步改进模型。我们将使用梯度推进分类器来建立一个机器学习算法，以查看模型的性能可以提高到什么程度。</p><p id="e36f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">from</strong><strong class="ih hj">sk learn . ensemble</strong><strong class="ih hj">import</strong>GradientBoostingClassifier gbc = AdaBoostClassifier(n _ estimators = 100)gbc . fit(X _ test，y _ test)y_pred = gbc . predict(X _ test)print(classification _ report(y _ test，y _ pred))</p><p id="37b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果有了很大的改善。准确率现在是98%，阳性结果的召回率是88%。该示例展示了使用boosting算法的强大功能，以及它们如何提高整体模型性能。</p><p id="2e0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们看到了如何使用数据科学来识别模式和预测未来。数据驱动的组织可以利用这些数据来改善决策和组织绩效</p></div></div>    
</body>
</html>