<html>
<head>
<title>Getting started with Logistic Regression 🤔</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归入门🤔</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/logistic-regression-18c126a94460?source=collection_archive---------2-----------------------#2019-07-06">https://medium.com/nerd-for-tech/logistic-regression-18c126a94460?source=collection_archive---------2-----------------------#2019-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="5aba" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">逻辑回归算法简介</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/48e9029c9204464f0012bcc9ffcdf590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*K032Sp2mnC-oop2oEIJxPA.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">卢克·切瑟在<a class="ae jj" href="https://unsplash.com/s/photos/charts?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="a7d2" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated">介绍</h1><p id="8a7e" class="pw-post-body-paragraph kc kd hi ke b kf kg ij kh ki kj im kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">逻辑回归是一种<strong class="ke hj">监督学习算法，广泛用于分类。</strong>它用于<strong class="ke hj">预测给定一组独立变量的二元结果(1/ 0，是/否，真/假)。</strong>为了表示二元/分类结果，我们使用<strong class="ke hj">虚拟变量。</strong></p><p id="d55e" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">逻辑回归使用一个方程作为表示，非常像线性回归。它与线性回归没有太大的不同，除了在线性回归方程中拟合了一个<strong class="ke hj"><em class="ld">s 形</em> </strong> <strong class="ke hj">函数</strong>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es le"><img src="../Images/be6445436555f0cee356edd560bd30c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/0*o36qPSVlsCCo4NFc.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">逻辑回归</figcaption></figure><p id="eea7" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated"><strong class="ke hj">一元线性和多元线性回归方程:</strong></p><pre class="iy iz ja jb fd lf lg lh li aw lj bi"><span id="da9d" class="lk jl hi lg b fi ll lm l ln lo">y = b0 + b1x1 + b2x2 + ... + e</span></pre><p id="620b" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated"><strong class="ke hj">乙状结肠功能:</strong></p><pre class="iy iz ja jb fd lf lg lh li aw lj bi"><span id="3ca7" class="lk jl hi lg b fi ll lm l ln lo"><em class="ld">p</em> = 1 / (1 + e ^ -(y))</span></pre><p id="d4df" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated"><strong class="ke hj">逻辑回归方程:</strong></p><pre class="iy iz ja jb fd lf lg lh li aw lj bi"><span id="1707" class="lk jl hi lg b fi ll lm l ln lo">p = 1 / (1 + e ^ -(b0 + b1x1 + b2x2 +... + e))</span></pre><p id="a6a1" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">在哪里，</p><p id="2739" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">p 是<strong class="ke hj">结果的概率</strong></p><p id="562e" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">y 是<strong class="ke hj">预测输出</strong></p><p id="eb57" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">b0 是<strong class="ke hj">偏差或截距项</strong></p><p id="da3c" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">输入数据中的每一列都有一个关联的 b <strong class="ke hj">系数</strong>(一个常量实值)，必须从训练数据中学习。</p><h1 id="deae" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak">线性回归和逻辑回归的区别:</strong></h1><ul class=""><li id="7775" class="lp lq hi ke b kf kg ki kj kl lr kp ls kt lt kx lu lv lw lx bi translated">在线性回归中，目标是一个<strong class="ke hj">连续(实值)</strong>变量，而在逻辑回归中，目标是一个<strong class="ke hj">离散(二元或有序)</strong>变量。</li><li id="8b49" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx lu lv lw lx bi translated">线性回归情况下的预测值是目标变量在输入变量给定值下的<strong class="ke hj">平均值。而逻辑回归中的预测值是在输入变量的给定值下目标变量的特定水平的<strong class="ke hj">概率</strong>。</strong></li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es md"><img src="../Images/09929041ccdfb8ab125392342f5df089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JCXCw2RHK21NZgw-.jpg"/></div></div></figure><h1 id="10ac" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak">逻辑回归的类型:</strong></h1><p id="c026" class="pw-post-body-paragraph kc kd hi ke b kf kg ij kh ki kj im kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">1.<strong class="ke hj">二元逻辑回归</strong>:目标变量只有<strong class="ke hj">两种可能的结果。</strong>例如，将电子邮件分类为垃圾邮件或非垃圾邮件。</p><p id="3b57" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">2.<strong class="ke hj">多项逻辑回归:</strong>目标变量有<strong class="ke hj">三个或三个以上类别，没有排序。</strong>例如，预测哪种食物更受欢迎(素食、非素食、纯素食)</p><p id="95f2" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">3.<strong class="ke hj">有序逻辑回归:</strong>目标变量<strong class="ke hj">有三个或三个以上有排序的类别。</strong>例如，从 1 到 5 的电影分级。</p><h1 id="3347" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak"> <em class="mi">决定边界</em> </strong></h1><p id="552b" class="pw-post-body-paragraph kc kd hi ke b kf kg ij kh ki kj im kk kl km kn ko kp kq kr ks kt ku kv kw kx hb bi translated">为了预测数据属于哪一类，可以设置一个<strong class="ke hj">阈值</strong>。基于该阈值，将所获得的估计概率分类。这个阈值被称为<strong class="ke hj">决策边界</strong>。</p><p id="64d8" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated">比如说，如果 predicted_value ≥ 0.5，那么将邮件归类为垃圾邮件，否则归类为非垃圾邮件。</p><p id="79b4" class="pw-post-body-paragraph kc kd hi ke b kf ky ij kh ki kz im kk kl la kn ko kp lb kr ks kt lc kv kw kx hb bi translated"><strong class="ke hj">决策边界可以是线性的，也可以是非线性的。</strong>多项式阶数可以增加，以得到复杂的决策边界。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/c10272d437523d64758a57b35dbe4775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/0*f_lNith4gdqvmmMO.jpg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">逻辑回归中的决策边界</figcaption></figure><h1 id="c093" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak">线性回归的优点:</strong></h1><ol class=""><li id="2119" class="lp lq hi ke b kf kg ki kj kl lr kp ls kt lt kx mk lv lw lx bi translated">它使得<strong class="ke hj">没有关于类别</strong>在特征空间中的分布的假设。</li><li id="9df1" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated"><strong class="ke hj">容易扩展到多个类</strong>(多项式回归)。</li><li id="27c6" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">类别预测的自然概率观点。</li><li id="9b6b" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated"><strong class="ke hj">训练快，对未知记录分类非常快。</strong></li><li id="8fe4" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">对于许多简单的数据集具有良好的准确性。</li><li id="b05e" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">抗过度拟合。</li></ol><h1 id="673b" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak">逻辑回归的缺点:</strong></h1><ol class=""><li id="2d13" class="lp lq hi ke b kf kg ki kj kl lr kp ls kt lt kx mk lv lw lx bi translated">它<strong class="ke hj">不能处理连续变量</strong>。</li><li id="61ad" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">如果自变量与目标变量不相关，那么逻辑回归不起作用。</li><li id="b760" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated"><strong class="ke hj">需要大样本量</strong>才能获得稳定的结果。</li></ol><h1 id="f588" class="jk jl hi bd jm jn jo jp jq jr js jt ju io jv ip jw ir jx is jy iu jz iv ka kb bi translated"><strong class="ak">逻辑回归假设:</strong></h1><ol class=""><li id="3205" class="lp lq hi ke b kf kg ki kj kl lr kp ls kt lt kx mk lv lw lx bi translated">二元逻辑回归<strong class="ke hj">要求因变量为二元</strong>。</li><li id="fb11" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">因变量不是用比率来衡量的。</li><li id="14dc" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">应该只包括有意义的变量。</li><li id="cc69" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated"><strong class="ke hj">自变量应该是相互独立的。</strong>也就是说，模型应该很少或没有多重共线性。</li><li id="ed4c" class="lp lq hi ke b kf ly ki lz kl ma kp mb kt mc kx mk lv lw lx bi translated">逻辑回归<strong class="ke hj">需要相当大的样本量。</strong></li></ol></div></div>    
</body>
</html>