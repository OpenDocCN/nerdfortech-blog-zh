<html>
<head>
<title>E-commerce Customer Satisfaction Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">电子商务客户满意度预测</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/e-commerce-customer-satisfaction-prediction-abc9bd31d70f?source=collection_archive---------1-----------------------#2021-08-26">https://medium.com/nerd-for-tech/e-commerce-customer-satisfaction-prediction-abc9bd31d70f?source=collection_archive---------1-----------------------#2021-08-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="e99a" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><strong class="il hj">科学预测电子商务客户评论评分</strong></p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/66f9cff4e11e27d80d1c1a21e2700ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tehmrrg0EvKbaWS4UIik1w.jpeg"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">【https://images.app.goo.gl/6gPjPaZkrNxc59Qc6 T2】号</figcaption></figure><h1 id="56d5" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">目录:</h1><ol class=""><li id="316c" class="kw kx hi il b im ky iq kz la lb lc ld le lf jg lg lh li lj bi translated">介绍</li><li id="dc9a" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">商业问题</li><li id="a5c7" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">商业问题的ML公式</li><li id="0831" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">业务限制</li><li id="5095" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">可能的指标</li><li id="1f92" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">数据概述</li><li id="a5d3" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">探索性数据分析</li><li id="1dac" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">特征工程</li><li id="f782" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">ML模型</li><li id="4f29" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">未来的改进</li><li id="b08c" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">部署</li><li id="9dac" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg lg lh li lj bi translated">参考</li></ol></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="830f" class="jy jz hi bd ka kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv bi translated"><strong class="ak"> 1。简介:</strong></h1><p id="415b" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">电子商务是我们日常生活的必需品。电子商务是一个平台，卖家可以销售产品，客户可以购买产品。这意味着电子商务平台通过在线方式将大量卖家与客户联系起来。为客户提供更好的服务是电子商务卖家成功的主要关键之一。<br/> <em class="ik">如何衡量服务的好坏？</em> <br/>答案是:服务的好坏是建立在顾客满意的基础上的。如果顾客对销售者提供的服务不满意，那么销售者必须注重服务质量来吸引顾客，从而改善业务。因此，基本上客户反馈在电子商务业务中起着至关重要的作用。</p><h1 id="de32" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">2.业务问题:</h1><p id="0142" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">在目前的系统中，电子商务平台将在产品交付后向客户发送反馈邮件。顾客可以给出5分制的评分，也可以写下一些关于他/她所购买产品的评论/评论。使用这些评论和评级，电子商务平台将对产品进行评级，这有助于其他人了解产品的质量。但从卖家的角度来看，这些评论将对改善业务起到至关重要的作用。但很多时候，客户不会给任何评级或评论。如何预测客户可能给出的点评分数？这就是电商业务中的问题。此外，该问题可以扩展为“在客户实际给出评价之前，是否有可能预测他可能给出的评论评价？”。如果这个问题得到解决，那么也有可能预测客户没有给出任何评级的评级。在本案例研究中，我的目的就是试图解决这个问题，即预测电子商务客户满意度。<br/>在这个案例研究中，我采用了巴西电子商务平台<a class="ae jx" href="https://www.kaggle.com/olistbr/brazilian-ecommerce" rel="noopener ugc nofollow" target="_blank"> Olist </a>给出的<a class="ae jx" href="https://www.kaggle.com/olistbr/brazilian-ecommerce" rel="noopener ugc nofollow" target="_blank">数据集</a>。Olist通过一份合同将巴西各地的小型企业与客户联系起来。Olist提供了超过10万条2016年至2018年间的订单信息。与所有其他电子商务平台类似，Olist也在预计交付日期后向客户发送反馈表，以获得评论和评级。现在，Olist希望通过使用客户满意度信息来改善业务并为客户提供更好的服务。为此，它需要在用户给出实际评级之前预测评论评级。所以，我的方法是使用数据科学来解决这个业务问题，这是解决这个业务问题的科学方法。</p><h1 id="5f40" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">3.商业问题的ML公式:</h1><p id="01d1" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">为了使用数据科学来解决商业问题，需要将该问题作为经典的机器学习问题来提出。首先，由于数据有目标变量，所以是有监督的ML问题。此外，我们需要预测客户的满意度，也就是预测评级。等级从1到5不等。因此，这是一个多类分类问题。我们有5个类标签，所以，我们可以把这个问题看作5类分类最大似然问题。</p><p id="d1f9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们的目标是在用户给出评分/评论之前预测评分。因此，我们不应该考虑关于评论消息、评论等的数据。作为功能</p><h1 id="f610" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">4.业务限制:</h1><ul class=""><li id="05e8" class="kw kx hi il b im ky iq kz la lb lc ld le lf jg me lh li lj bi translated">没有严格的低延迟要求。但是模型不应该花费太多的时间来预测，因为我们应该在用户给出之前得到预测。</li><li id="621a" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">像1、2、3这样的低评分对于业务改进非常重要。因此，低评级的错误分类会导致客户流失。因此，错误分类是至关重要的。</li></ul><h1 id="3e43" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">5.可能的指标:</h1><ul class=""><li id="840e" class="kw kx hi il b im ky iq kz la lb lc ld le lf jg me lh li lj bi translated">多类混淆矩阵</li><li id="b1de" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">宏观F1分数</li><li id="8d64" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">多级原木损失</li><li id="b5e7" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">平衡精度</li></ul><h1 id="8ddc" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">6.数据概述:</h1><p id="d94a" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">数据取自ka ggle:<a class="ae jx" href="https://www.kaggle.com/olistbr/brazilian-ecommerce" rel="noopener ugc nofollow" target="_blank"><em class="ik"/></a><em class="ik">。</em>数据有9个csv文件，分别是<em class="ik"> olist_customers_dataset，olist_geolocation_dataset，olist_order_items_dataset，olist_order_payments_dataset，olist_order_reviews_dataset，olist_orders_dataset，olist_products_dataset，olist_sellers_dataset，product _ category _ name _ translation</em>。<br/>这些文件包含有关客户、客户位置、订单、产品、付款、卖方、卖方位置的信息。我们可以使用pandas将这些文件加载到python中，如下所示:</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="7e15" class="mk jz hi mg b fi ml mm l mn mo">#loading all csv files <br/>import pandas as pd</span><span id="29c0" class="mk jz hi mg b fi mp mm l mn mo">customer = pd.read_csv(“olist_customers_dataset.csv”)<br/>geo_location = pd.read_csv(“olist_geolocation_dataset.csv”)<br/>items = pd.read_csv(“olist_order_items_dataset.csv”)<br/>payments = pd.read_csv(“olist_order_payments_dataset.csv”)<br/>reviews = pd.read_csv(“olist_order_reviews_dataset.csv”)<br/>orders = pd.read_csv(“olist_orders_dataset.csv”)<br/>products = pd.read_csv(“olist_products_dataset.csv”)<br/>sellers = pd.read_csv(“olist_sellers_dataset.csv”)<br/>translation = pd.read_csv(“product_category_name_translation.csv”)</span></pre><p id="9e1c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们需要合并这些文件来获得整个数据集。为了合并所有文件，数据贡献者给出了数据模式，如下所示。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mq"><img src="../Images/a1e422ef131c3b160833137bc3072406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6K3chNhNIJ8WTJTZtH33g.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated"><a class="ae jx" href="https://www.kaggle.com/olistbr/brazilian-ecommerce" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ka">数据模式</strong> </a></figcaption></figure><p id="7dfb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，根据数据模式，我合并所有数据文件以创建数据集。</p><p id="f412" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">合并数据帧的形状是，</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mr"><img src="../Images/11769ba6046191cc7b52c2d7c4fc27e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fmnl5h-qt2ZAcLMpw52Fyg.png"/></div></div></figure><p id="c4fc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">但是，我们应该在数据集中检查空值和对我们的问题无用的列。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="fa62" class="mk jz hi mg b fi ml mm l mn mo">All the column names in the data : <br/> Index(['order_id', 'payment_sequential', 'payment_type',<br/>       'payment_installments', 'payment_value', 'customer_id', 'order_status',<br/>       'order_purchase_timestamp', 'order_approved_at',<br/>       'order_delivered_carrier_date', 'order_delivered_customer_date',<br/>       'order_estimated_delivery_date', 'review_id', 'review_score',<br/>       'review_comment_title', 'review_comment_message',<br/>       'review_creation_date', 'review_answer_timestamp', 'customer_unique_id',<br/>       'zip_code_prefix_customer', 'customer_city', 'customer_state',<br/>       'geolocation_lat_customer', 'geolocation_lng_customer',<br/>       'geolocation_city_customer', 'geolocation_state_customer', 'product_id',<br/>       'product_category_name', 'product_name_lenght',<br/>       'product_description_lenght', 'product_photos_qty', 'product_weight_g',<br/>       'product_length_cm', 'product_height_cm', 'product_width_cm',<br/>       'order_item_id', 'seller_id', 'shipping_limit_date', 'price',<br/>       'freight_value', 'zip_code_prefix_seller', 'seller_city',<br/>       'seller_state', 'geolocation_lat_seller', 'geolocation_lng_seller',<br/>       'geolocation_city_seller', 'geolocation_state_seller'],<br/>      dtype='object')<br/></span></pre><p id="47fd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这些是合并数据集中的要素。但是根据我们的问题，我们必须在他/她给出评价之前预测顾客的评价。为此，我们应该只考虑产品交付给客户之前的信息来预测评审分数。因此，从合并的数据集中，我将删除review_comment_title '，' review_comment_message '，' review_creation_date '，' review_answer_timestamp '，review_id '。</p><p id="e89b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们必须检查数据集中的空值。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="13b3" class="mk jz hi mg b fi ml mm l mn mo">#Checking for null values<br/>data.isnull().sum()</span><span id="d0be" class="mk jz hi mg b fi mp mm l mn mo">order_id                            0<br/>payment_sequential                  0<br/>payment_type                        0<br/>payment_installments                0<br/>payment_value                       0<br/>customer_id                         0<br/>order_status                        0<br/>order_purchase_timestamp            0<br/>order_approved_at                  15<br/>order_delivered_carrier_date     1254<br/>order_delivered_customer_date    2588<br/>order_estimated_delivery_date       0<br/>review_score                        0<br/>customer_unique_id                  0<br/>zip_code_prefix_customer            0<br/>customer_city                       0<br/>customer_state                      0<br/>geolocation_lat_customer          317<br/>geolocation_lng_customer          317<br/>geolocation_city_customer         317<br/>geolocation_state_customer        317<br/>product_id                          0<br/>product_category_name            1709<br/>product_name_lenght              1709<br/>product_description_lenght       1709<br/>product_photos_qty               1709<br/>product_weight_g                   20<br/>product_length_cm                  20<br/>product_height_cm                  20<br/>product_width_cm                   20<br/>order_item_id                       0<br/>seller_id                           0<br/>shipping_limit_date                 0<br/>price                               0<br/>freight_value                       0<br/>zip_code_prefix_seller              0<br/>seller_city                         0<br/>seller_state                        0<br/>geolocation_lat_seller            265<br/>geolocation_lng_seller            265<br/>geolocation_city_seller           265<br/>geolocation_state_seller          265<br/>dtype: int64</span></pre><p id="7639" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们在一些特征中有一些空值。但是空值的数量不是很大。因此，让我们删除这些空实例，看看我们从中抛出了多少数据。此外，我只考虑交付产品的预测。不应删除交付状态不是<em class="ik">已交付</em>的任何实例。所以在这个过程之后，</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="c398" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Total number of orders which are not delivered :  2587<br/>percentage of orders which are not delivered :  2.187 %</strong></span><span id="59c4" class="mk jz hi mg b fi mp mm l mn mo"><em class="ik"># % of data that we have drooped</em><br/>print("Percentage of data that we have dropped is : ",round((num_tot_rows-data.shape[0])*100/num_tot_rows,3),"%")</span><span id="b47e" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Percentage of data that we have dropped is :  4.062 %</strong></span></pre><p id="7414" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们只丢失了<em class="ik"> 4% </em>的数据，剩下<em class="ik"> 96% </em>的干净、非空的有用数据。与此同时，我检查了重复的条目，并删除了重复的行。有3个实例的分期付款值为0，这很奇怪，我删除了这3个实例。<br/>经过预处理后，我们剩下<em class="ik"> 113105 </em>个实例。<br/>之后，我将翻译数据集与合并后的数据集进行映射，以获得产品类别的英文翻译。在这里，我发现有两个类别在翻译文件中没有翻译，即“porta teis _ cozi NHA _ e _ preparadores _ de _ alimentos”和“pc_gamer”。使用谷歌我找到了这些词的英文翻译，并用于映射翻译文件。<br/>现在，最终数据集已准备好进行分析。我们最终的数据集是这样的形状，</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="66be" class="mk jz hi mg b fi ml mm l mn mo">Shape of the final dataset is : (113105, 38)</span></pre><h1 id="b37e" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">7.探索性数据分析:</h1><p id="a5f4" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">EDA是任何数据科学项目中最重要的部分。EDA将给出关于数据集和每个特征的正确理解，以便我们可以得到进一步进行特征工程和应用模型的途径。而EDA要根据目标变量来做，这里是复习分数。所以第一步我们会看到复习分数是如何分布的，这样就知道数据平衡了。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es ms"><img src="../Images/b1dab48ad6199f4c44c229925378aa55.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*_Ao9QeeNhGYS6a5obGrYEw.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">评审分数分布</figcaption></figure><p id="9c8f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们可以清楚地看到，数据是不平衡的。审查分数为5的实例数量非常高，而审查分数为2的实例数量非常低。分布呈<strong class="il hj"> J </strong>型。电商客户评分研究说点评评分在任何电商平台都会呈<strong class="il hj"> J </strong>形分布。<br/>这里也可以看到相同的趋势，评级5的数量非常高，其次是评级4，然后是评级1，评级2和评级3与其他评级相比数量较少。<br/>我们要记住，我们的问题是<strong class="il hj"> <em class="ik">不平衡多类分类</em> </strong>问题。让我们进一步分析。</p><p id="eb0f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们有37个特征需要分析。</p><p id="8855" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从数值变量的相关热图可以看出，没有一个特征与复习得分高度相关。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mt"><img src="../Images/1b9795b4efab25706afbd9df0a6df2eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*al0wwCKFjmYQY0NMgVpyqA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">相关热图</figcaption></figure><p id="c019" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">此外，要素之间存在多重共线性。所有特征之间的相关性较小。现在让我们对每个特征进行单变量分析。</p><p id="59f2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们可以看到，支付型信用卡是最常见的(73.8%)，baleto是19%。其他支付类型非常少。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="f606" class="mk jz hi mg b fi ml mm l mn mo">credit_card    0.737854<br/>boleto         0.194580<br/>voucher        0.053225<br/>debit_card     0.014341</span></pre><p id="80b4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们还可以看到付款类型在每个审核分数中的分布。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mu"><img src="../Images/73c2618773830913b094ef063c812466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMElIfr_PWCdAlmymE63yQ.png"/></div></div></figure><p id="2d02" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">不同支付类型在每个评审得分中的分布几乎相同。</p><p id="3b98" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我进行了卡方检验，以检查支付类型和审查分数是否相关。</p><p id="8966" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><em class="ik">零假设:</em> <strong class="il hj">缴费类型和审核分数独立</strong> <em class="ik"> <br/>备选假设:</em> <strong class="il hj">缴费类型和审核分数相依</strong></p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="3842" class="mk jz hi mg b fi ml mm l mn mo">#reference: <a class="ae jx" href="https://machinelearningmastery.com/chi-squared-test-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machinelearningmastery.com/chi-squared-test-for-machine-learning/</a><br/>from scipy.stats import chi2_contingency,chi2</span><span id="46af" class="mk jz hi mg b fi mp mm l mn mo">#creating contengency table<br/>table = pd.crosstab(data[“payment_type”],data[“review_score”],margins=False)</span><span id="f7dd" class="mk jz hi mg b fi mp mm l mn mo">#chi_square test using scipy.stats library<br/>chi_2,p_value,dof,expected = chi2_contingency(table)</span><span id="2ff9" class="mk jz hi mg b fi mp mm l mn mo">alpha = 0.05<br/>print("Level of significance : ",alpha)<br/>print("p-value is : ",p_value)</span><span id="9f0b" class="mk jz hi mg b fi mp mm l mn mo">if p_value &lt; alpha:<br/>    print("Reject null hypothesis")<br/>else:<br/>    print("Failed to reject null hypothesis")<br/>print("*"*30)    <br/>#interpreting test statistic    <br/>prob=0.95<br/>critical = chi2.ppf(prob, dof)</span><span id="882f" class="mk jz hi mg b fi mp mm l mn mo">print("Critical value is : ",critical)<br/>print("chi2(test statistic) value is : ",chi_2)</span><span id="c6eb" class="mk jz hi mg b fi mp mm l mn mo">if chi_2&gt;=critical:<br/>    print("Reject null hypothesis")<br/>else:<br/>    print("Failed to reject null hypothesis")</span><span id="0f39" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj"><em class="ik">Level of significance :  0.05<br/>p-value is :  0.00027649502286312483<br/>Reject null hypothesis<br/>******************************<br/>Critical value is :  21.02606981748307<br/>chi2(test statistic) value is :  36.42753432616247<br/>Reject null hypothesis</em></strong></span></pre><p id="eb14" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，我们可以得出结论，审查分数对支付类型的依赖性在统计上是显著的。</p><p id="4dcb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">对分期付款进行分析，并绘制关于每个审核分数的分期付款pdf。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mv"><img src="../Images/d9a7970a3d7f7927e1e37ab517d84e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*k20Z96vv5qBo_ToX8asRlw.png"/></div></figure><p id="c286" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从分布可以看出，地块并不是明显可分的。因此，我们不能从中得出多少有用的推论。同样，我分析了pdf的支付价值，支付顺序。复习成绩之间也没有明显的区别。</p><p id="ec31" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">谈到客户状态分析，我问大多数客户来自哪5个州。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="6d2c" class="mk jz hi mg b fi ml mm l mn mo">(data[“customer_state”].value_counts(normalize=True)*100)[:5]</span><span id="0c2f" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">SP    42.284603<br/>RJ    12.943725<br/>MG    11.682949<br/>RS     5.551479<br/>PR     5.109412</strong></span></pre><p id="0d26" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">SP是拥有42%客户的州。与SP相比，所有其他州的客户都较少。所以我分析了复习分数在州SP是如何分布的。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mw"><img src="../Images/7e38c9fe7adb7754bd1bade2b9ff2d69.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*xK6f4vHZAXWMLTAlehejEQ.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">SP中复习分数的分布</figcaption></figure><p id="cc9d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">与总数据集中一样，在SP中，审查分数5也很高，其次是4、1、3、2。</p><p id="12d8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">在第二高的州RJ，复习分数分布略有不同。得分5最高，其次是得分1、4、3、2。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mw"><img src="../Images/607c5c28594920b1451ee7be86959439.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*gCw2HLkNzPh5gUUsW9NROA.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">RJ的评论分数分布</figcaption></figure><p id="ba83" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从客户状态中还可以得出一些有趣的观察结果:</p><ul class=""><li id="f2d7" class="kw kx hi il b im in iq ir la mx lc my le mz jg me lh li lj bi translated">在所有评估得分中，州SP拥有更多客户，SP拥有%以上的客户份额。</li><li id="8fd2" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">此外，60%的SP客户表示满意，并给出了5分。大约19%的顾客给了4级。</li><li id="4ae1" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">SP更满意的客户背后的原因目前还不清楚。我们需要更多的分析来获得这方面的信息。</li><li id="aee1" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">没有一个州有超过20%的客户不满意并给出1级。</li><li id="70c1" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">与其他评级相比，在所有州中，给予5级评级的客户比例明显更高。这个结论是因为我们分析的州中，只有不到50%的客户给出了5分的评价。</li></ul><p id="02e0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">大部分客户来自SP，大部分卖家来自SP。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="5c44" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj"># seller state shares<br/>SP    0.707873<br/>MG    0.078918<br/>PR    0.078414<br/>RJ    0.043756<br/>SC    0.038371</strong></span><span id="1a53" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj"><em class="ik">- State SP has the highest number of customers(42%), aas well as highest sellers(58.5%). <br/>- This could be the reason for most of the customers from state SP are satisfied and gave rating 5, and most of the sellers got rating 5.<br/>- review rating 5 is dominant in all the customer states as well as seller states. <br/>- General trend is star: 5 &gt;&gt; star 4 &gt;= star 1 &gt; star 2 &gt;= star 3.</em></strong></span></pre><p id="a721" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在我们必须分析产品类别。在这里我问的是每个评论分数前10名的类别。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="2177" class="mk jz hi mg b fi ml mm l mn mo"># code for top 10 categories in review score 5<br/>rate_5[“product_category_name”].value_counts([:10].plot.bar(figsize=(10,5),color=”green”).legend()<br/>plt.xlabel(“product category name”)<br/>plt.ylabel(“Counts”)<br/>plt.title(“Top 10 product categroy in review score 5”)<br/>plt.show()</span><span id="32ed" class="mk jz hi mg b fi mp mm l mn mo">print(“Percentage cover of top 10 categories in review 5 : “)<br/>print((rate_5[“product_category_name”].value_counts(normalize=True)[:10].sum()*100).round(3),”%”)</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es na"><img src="../Images/70cd8c9cfa33016a9d8801433d0723f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*SNfQIhBiX1GLLiiqZ1FkrQ.png"/></div></div></figure><p id="3515" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">类似地，我在每个评论得分中标出了前10个类别。而床浴表在所有复习评分中出现的频率更高。</p><p id="4170" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">所以我根据评论分数分析了这个类别。我得到的推论如下。</p><ul class=""><li id="5194" class="kw kx hi il b im in iq ir la mx lc my le mz jg me lh li lj bi translated">床_洗澡_桌子类别是所有评论得分中出现频率最高的类别，也涵盖了所有评论得分中超过60%的类别</li><li id="3e3f" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">52%的次数bed_bathing_table得到评论分数5。14%的情况下，它的评论得分为1。</li><li id="fada" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">健康美容是在评论等级为5的类别中具有几乎相同%份额的类别之一。在得分4的情况下，它也是第二个最常见的类别。</li><li id="c1ff" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">61%的情况下health_beauty得分为5，18%的情况下得分为4。大多数顾客对这类产品非常满意。只有10%的情况下它会得到1分。</li><li id="1b71" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">很少有类别的评论得分超过20%。这些类别的订单也很少。</li><li id="4a19" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">在所有类别中，评论分数为5的百分比较高，评论分数为4和评论分数为1的百分比次之。得分2、3在所有类别中都很少。</li><li id="ea98" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">当然，在整个数据集中，评论分数为5的百分比非常高。但是在分析了产品类别之后，我们没有发现任何重要的产品类别比其他产品类别得分高。</li></ul><p id="4fc0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">以同样的方式，我分析了所有的特征，在这个分析结束时，我没有得到任何单独区分评论分数的特征。一些特征倾向于在评论分数中显示一些分离，但是没有明显的分离。</p><p id="e45f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在我考虑选择特征的配对图来分析双变量行为。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es nb"><img src="../Images/1ea95d1d99149438d7e5d3528ca23807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7I7nxBooDBXcSHEBufO0g.png"/></div></div></figure><p id="8ae1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">成对的特征也不能清楚地分类评论分数。从配对图中可以看出一些相关性。</p><p id="f5c8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在来看时间戳特性，我分析了购买时间戳和交付时间戳。在这些时间戳中没有如此显著的趋势。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="65a2" class="mk jz hi mg b fi ml mm l mn mo">df[df[“purchased_year”]==2018].groupby(“purchased_hour”[“review_score”].value_counts(normalize=True).unstack().plot(<br/> kind=’bar’,figsize=(17,9))</span><span id="ce19" class="mk jz hi mg b fi mp mm l mn mo">plt.show()</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es nc"><img src="../Images/a838d0a0777d83b43983aa4d2a3cdc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfZ2t6cnWQHAIgW8pH3wkw.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">2018年一天中每个小时的复习分数分布</figcaption></figure><p id="00d6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这种类型的观察是使用时间戳发现的，但是没有这样有用的观察来帮助清楚地分类复习分数。</p><ul class=""><li id="6cae" class="kw kx hi il b im in iq ir la mx lc my le mz jg me lh li lj bi translated">从EDA部分来看，可以肯定的是数据集中存在高度的类不平衡。此外，评论分数1、2、3非常重要，因为它们的错误分类会导致卖家的客户流失。所以假阳性应该是这里的关注点。</li><li id="1a1e" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">在这里，每个类的精确度和召回率是很重要的。4，5类的精度更重要，1，2，3类的召回非常重要。因此，我们可以使用F1分数，这是精确度和召回率的组合，因为每一个对我们都很重要，我们可以考虑宏观F1分数..</li><li id="0fdc" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">基于这种观察和商业问题，我选择宏观F1分数作为衡量标准。我还想检查多类混淆矩阵，这样我们可以很容易地观察到错误分类。</li></ul><p id="a7c2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">度量选择，<br/> *宏F1分数<br/> *多级混淆矩阵</em> </strong></p><p id="1524" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从详细的EDA中，我了解到，没有任何现有的特征对分类复习分数有很大的帮助。所以我们必须创建一些非常有用的特性来构建一个好的模型。<strong class="il hj"> <em class="ik">让我们转到特色工程。</em>T9】</strong></p><h1 id="19b1" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">8.特征工程:</h1><p id="6277" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">特别是在这种情况下，特征工程起着非常关键的作用，因为给定的特征对实现目标没有多大用处。在这里，我根据可能影响客户对产品和服务满意度的因素，创建了一些基本功能和高级功能。</p><p id="a1e4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj">基于时间的特性:<br/> </strong>电商最重要的是配送时间。如果产品没有在承诺的时间内交付，那么客户很可能不满意。此外，如果承诺的时间太长，客户也会不高兴。如果顾客比预计时间提前拿到产品，那么给予评价的顾客就有可能获得高分。<br/>因此，基于这项研究，我正在创建一些基于数据帧中给出的时间戳的特征。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="12ec" class="mk jz hi mg b fi ml mm l mn mo"># let us define time based features<br/>1. estimated_time <br/>       = order_estimated_delivery_date - order_purchase_timestamp</span><span id="4ff3" class="mk jz hi mg b fi mp mm l mn mo">2. actual_time<br/>      = order_delivered_customer_date - order_purchase_timestamp</span><span id="d639" class="mk jz hi mg b fi mp mm l mn mo">3. diff_actual_estimated<br/>     = order_delivered_customer_date - order_estimated_delivery_date</span><span id="3df7" class="mk jz hi mg b fi mp mm l mn mo">4. diff_purchased_approved <br/>     = order_approved_at - order_purchase_timestamp</span><span id="77f7" class="mk jz hi mg b fi mp mm l mn mo">5. diff_purchased_courrier<br/>     = order_delivered_carrier_date - order_purchase_timestamp<br/></span><span id="f57c" class="mk jz hi mg b fi mp mm l mn mo"># codes of some of the time based features</span><span id="e7e1" class="mk jz hi mg b fi mp mm l mn mo">#Time of estimated delivery<br/>data[“estimated_time”] = (data[“order_estimated_delivery_date”]-data[“order_purchase_timestamp”]).apply(lambda x: x.total_seconds()/3600)</span><span id="010d" class="mk jz hi mg b fi mp mm l mn mo">data[“delivery_day”] = data[“order_delivered_customer_date”].apply(lambda x: x.weekday())<br/>data[“delivery_date”] = data[“order_delivered_customer_date”].apply(lambda x: x.day)<br/>data[“delivery_month”] = data[“order_delivered_customer_date”].apply(lambda x: x.month)<br/>data[“delivery_hour”] = data[“order_delivered_customer_date”].apply(lambda x: x.hour)</span><span id="89a8" class="mk jz hi mg b fi mp mm l mn mo">data[“purchased_day”] = data[“order_purchase_timestamp”].apply(lambda x: x.weekday())<br/>data[“purchased_date”] = data[“order_purchase_timestamp”].apply(lambda x: x.day)<br/>data[“purchased_month”] = data[“order_purchase_timestamp”].apply(lambda x: x.month)<br/>data[“purchased_hour”] = data[“order_purchase_timestamp”].apply(lambda x: x.hour)</span></pre><p id="514f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在让我们分析一下这些创造出来的特征。</p><div class="ji jj jk jl fd ab cb"><figure class="nd jm ne nf ng nh ni paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><img src="../Images/a7e22f375c4c477c1ead2a169fa29733.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*PBEyMwhoRfdsxZ8XyfjlVw.png"/></div></figure><figure class="nd jm nj nf ng nh ni paragraph-image"><img src="../Images/bd5141d8b522aae91511b3c8798c7c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*PFiw5O5zwAqYvJYa7YPhYw.png"/><figcaption class="jt ju et er es jv jw bd b be z dx nk di nl nm translated">实际时间</figcaption></figure></div><p id="4f7f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们可以看到，随着实际交付时间的增加，获得低评审分的机会也就越多。<br/> *这里我们可以看到，对于更高的实际次数，评审分数1的pdf处于更高的高度。其中，审核分数低于1分，3低于2分，4低于3分，5低于4分。<br/> *这实际上是一个好现象，因为在实际时间特征情况下，评论分数没有高度重叠。<br/> *对于较低的实际时间值，评审分数为5的pdf为高峰值。其次是4，3，2，1。<br/> *与审核分数1的pdf相比，审核分数5的pdf在右侧急剧下降。</p><p id="1d53" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">类似地，对于特征diff_actual_estimated，</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es nn"><img src="../Images/275d4c32b3eb861a79172ca482b71118.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*bezdDf8u7xgHCthd-e7CuA.png"/></div></figure><p id="682a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们可以看到，如果产品交付较晚，那么很有可能获得较低的评论分数，如果产品在预计时间之前交付，那么客户可能会给出较高的评级。这意味着评级取决于预计交货时间和实际交货时间的差异。</p><p id="15d2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，我们可以说，新创建的特征在对评论分数进行分类方面有些帮助。</p><p id="9350" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj">基于距离的特征:<br/> </strong>我们观察到，大部分客户来自国有SP，大部分卖家来自SP。SP用户销售的大多数产品都获得了5级评价。<br/>所以，我认为，销售者和顾客之间的距离可能是影响顾客满意度的一个方面。也就是说，如果距离更大，那么客户可能会不满意，并给出更低的评价分数。<br/>基于这一假设，我正在创建新功能“距离”,这是卖家位置和客户位置之间的距离，以公里为单位。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="57ec" class="mk jz hi mg b fi ml mm l mn mo">#<a class="ae jx" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html" rel="noopener ugc nofollow" target="_blank">https://scikitlearn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html</a><br/>X = [] # list to store customer latitude and longitude<br/>Y = [] # list to store seller latitude and longitude</span><span id="ee21" class="mk jz hi mg b fi mp mm l mn mo">for i in range(len(data)):<br/>    X.append([radians(data.lat_customer[i]),radians(data.lng_customer[i])])<br/>Y.append([radians(data.lat_seller[i]),radians(data.lng_seller[i])])<br/> <br/>#converting to numpy array <br/>cust_loc = np.array(X)<br/>seller_loc = np.array(Y)</span><span id="687b" class="mk jz hi mg b fi mp mm l mn mo">distance=[]<br/>for i in range(len(data)):<br/> #calculating distance and multiplying by radius of earth(6371) to get distance in km<br/> dist = haversine_distances([cust_loc[i], seller_loc[i]])*6371<br/> distance.append(dist[0,1])<br/> <br/>data[“distance”] = distance</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es nn"><img src="../Images/b3d3b75f13f09610be7f59b0a810a309.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*CHzEWnyuNRiwQp6A4IitWQ.png"/></div></figure><p id="36e4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，从距离特征，我们可以看到，对于非常小的距离，评论分数5是非常尖峰的，而对于大的距离，评论分数5的密度小于其他分数。</p><p id="446e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">类似地，我创建了一些更基本的特征，如，<br/>速度=(距离/实际时间)<br/>大小=(长度*宽度*高度)<br/>一些二进制特征，如延迟发货、同一州、同一城市。</p><p id="a604" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这些工程特征似乎有助于我们的目标。</p><p id="ea12" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">在高级功能工程中，我创建了卖家共享、客户共享、项目卖家共享、项目客户共享。利用这4个共享特征，我计算了卖家和客户之间的相似度。这些功能的代码如下所示。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="bed2" class="mk jz hi mg b fi ml mm l mn mo">#groupby order item_id<br/>order_seller = data.groupby(“order_item_id”)[“seller_id”].value_counts().unstack()<br/>order_seller.fillna(0,inplace=True)</span><span id="2ba7" class="mk jz hi mg b fi mp mm l mn mo">total_order_id = np.sum(order_seller,axis=1).to_dict()<br/>total_seller_id = np.sum(order_seller,axis=0).to_dict()</span><span id="88a8" class="mk jz hi mg b fi mp mm l mn mo">#creating feature<br/>seller_share = []<br/>bs_share = []<br/>for i in range(len(data)):<br/>    <br/>     seller_share.append((order_seller.loc[(data["order_item_id"][i],data["seller_id"][i])]/total_order_id[data["order_item_id"][i]]))<br/>    <br/>     bs_share.append((order_seller.loc[(data["order_item_id"][i],data["seller_id"][i])]/total_seller_id[data["seller_id"][i]]))</span><span id="c1c8" class="mk jz hi mg b fi mp mm l mn mo">data["seller_share"] = seller_share<br/>data["bs_share"] = bs_share<br/>**********************************************************</span><span id="c9ad" class="mk jz hi mg b fi mp mm l mn mo">user_order = data.groupby("order_item_id")["customer_unique_id"].value_counts().unstack()<br/>user_order.fillna(0,inplace=True)</span><span id="46f6" class="mk jz hi mg b fi mp mm l mn mo">user_total = np.sum(user_order,axis=0).to_dict()<br/>order_total = np.sum(user_order,axis=1).to_dict()</span><span id="aa7a" class="mk jz hi mg b fi mp mm l mn mo">cust_share = []<br/>bu_share = []<br/>for i in range(len(data)):<br/>    <br/>    cust_share.append((user_order.loc[(data["order_item_id"][i],data["customer_unique_id"][i])]/order_total[data["order_item_id"][i]]))<br/>    <br/>    bu_share.append((user_order.loc[(data["order_item_id"][i],data["customer_unique_id"][i])]/user_total[data["customer_unique_id"][i]]))<br/>    <br/>    <br/>data["cust_share"] = cust_share<br/>data["bu_share"] = bu_share<br/>******************************************************</span><span id="ecfa" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">#calculating similarity<br/>similarity = []<br/>for i in range(len(data)):<br/>     similarity.append((np.dot([data["seller_share"][i],data["bs_share"][i]] , [data["cust_share"][i],data["bu_share"][i]])))<br/>        <br/>data["similarity"] = similarity</strong></span></pre><p id="ac80" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这种相似性特征似乎非常有用，</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es no"><img src="../Images/b1006e62e86759d68fd4bd3d82cc3c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*22y9ROHwq8N4k0mbnDPHiQ.png"/></div></figure><p id="c4f3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我们可以看到，对于低相似性得分，得分1密度较高，而对于高相似性得分，得分5的密度较高。这个特性肯定会增加解决我们问题的价值。<br/>同样，我也使用产品类别创建了相似性特征。<br/>还有一个特性是每个卖家的客户总数，以及客户购买的卖家总数。</p><p id="6c0b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，我们已经使用现有功能创建了许多新功能。让我们继续前进。</p><h1 id="cb11" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">9.ML型号:</h1><p id="fe21" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">在应用分类模型之前，我们必须将数据分为训练和测试，并且我们必须处理分类特征、数字特征。</p><p id="9cf7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj">训练测试分割:<br/> </strong>我用分层分割进行训练测试分割，75%用于训练，25%用于测试。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="bcd9" class="mk jz hi mg b fi ml mm l mn mo">#train test split with test size 25% and 75% of data as train<br/>Y = data["review_score"]<br/>X = data</span><span id="9803" class="mk jz hi mg b fi mp mm l mn mo">x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.25,stratify=Y,random_state=10)</span><span id="d2c0" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Dimensions of the splitted data :<br/>Train:  (84828, 45) (84828,)<br/>Test:  (28277, 45) (28277,)</strong></span><span id="dfd2" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">% Distribution of class labels in the total data :<br/>5    57.15<br/>4    19.21<br/>1    11.71<br/>3     8.46<br/>2     3.47<br/>Name: review_score, dtype: float64<br/>**************************************************<br/>% Distribution of class labels in the train data :<br/>5    57.15<br/>4    19.21<br/>1    11.71<br/>3     8.46<br/>2     3.47<br/>Name: review_score, dtype: float64<br/>**************************************************<br/>% Distribution of class labels in the test data :<br/>5    57.15<br/>4    19.21<br/>1    11.71<br/>3     8.46<br/>2     3.47<br/>Name: review_score, dtype: float64<br/>**************************************************</strong></span></pre><p id="6253" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">培训、测试中的复习分数分布与原始数据中的相同。这看起来不错。</p><p id="f5ab" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在我使用CountVectorizer()将分类特征转换成向量。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="dceb" class="mk jz hi mg b fi ml mm l mn mo">#payment_type <br/>vec = CountVectorizer()</span><span id="1e79" class="mk jz hi mg b fi mp mm l mn mo">vec.fit(x_train[“payment_type”].values)</span><span id="ee4c" class="mk jz hi mg b fi mp mm l mn mo">x_tr_pay_type = vec.transform(x_train.payment_type.values)<br/>x_te_pay_type = vec.transform(x_test.payment_type.values)</span><span id="2921" class="mk jz hi mg b fi mp mm l mn mo">print(x_tr_pay_type.shape)<br/>print(x_te_pay_type.shape)</span><span id="d2b3" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">(84828, 4)<br/>(28277, 4)</strong></span></pre><p id="8d94" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">如上所示，我使用CountVectorizer()处理了所有的分类特征。现在我将数字特征标准化如下。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="cd6d" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">def scaling</strong>(train_data,test_data):<br/> “””This function will standardize the numerical data”””<br/> norm = StandardScaler()</span><span id="2f50" class="mk jz hi mg b fi mp mm l mn mo">norm.fit(train_data.values)</span><span id="f1c4" class="mk jz hi mg b fi mp mm l mn mo">x_tr_num = norm.transform(train_data.values)<br/> x_te_num = norm.transform(test_data.values)</span><span id="1568" class="mk jz hi mg b fi mp mm l mn mo">return x_tr_num,x_te_num</span></pre><p id="2575" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，我堆叠了所有的矢量化特征，现在我们可以使用这一训练和测试数据来尝试ML模型。</p><h2 id="4350" class="mk jz hi bd ka np nq nr ke ns nt nu ki la nv nw km lc nx ny kq le nz oa ku ob bi translated">基本型号:</h2><p id="dba8" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">在第一步中，我尝试了一些简单的基本ML模型，以检查模型如何处理这种不平衡的数据。在第一步中，我尝试用一个vs rest，KNN，决策树进行逻辑回归。我用这些模型做了五重交叉验证。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="7ccf" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">def kfold</strong>(k,model):<br/> “””This function will do stratified k-fold cross_validation”””<br/> kf = StratifiedKFold(n_splits=k)<br/> <br/> cv_f1_score = []<br/> for tr_ind,cv_ind in kf.split(train,y_train):<br/> <br/> x_tr,x_cv,y_tr,y_cv = train[tr_ind],train[cv_ind],y_train[tr_ind],y_train[cv_ind]<br/> <br/> model.fit(x_tr,y_tr)<br/> pred_cv = model.predict(x_cv) <br/> cv_f1_score.append((f1_score(y_cv,pred_cv,average=”macro”,labels=[1,2,3,4,5])))<br/> <br/> return np.mean(cv_f1_score)</span></pre><p id="23f0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">但基本款的表现不佳。宏f1分数较少。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="d72c" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Logistic Regression</strong><br/>Train F1 score at 0.01 is :0.2861577232898543<br/>**************************************************<br/>test F1 score at 0.01 is :0.28496554797465007</span><span id="3139" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">KNN</strong><br/>Train F1 score at 5 is :0.5327880988341782<br/>**************************************************<br/>test F1 score at 5 is :0.33440577518222214</span><span id="2c41" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">SVM</strong><br/>Train F1 score at 1e-05 is :0.1455032757226727<br/>**************************************************<br/>test F1 score at 1e-05 is :0.14546436528118462</span><span id="82e3" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Decision Tree</strong><br/>Train F1 score at 20 is :0.6045559359203161<br/>**************************************************<br/>test F1 score at 20 is :0.34712098753895826</span></pre><p id="d414" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，从结果中我们可以看到，KNN，决策树模型过度拟合，性能也不好。逻辑回归没有过度拟合，但是分数很少。SVM是所有基本模型中最差的模型。</p><p id="ffa4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在尝试了一些高级的模型像Random forest，LGBM，XGBoost。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="9719" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">RandomForest</strong><br/>Train F1 score at 200 is :0.996856561806245<br/>**************************************************<br/>test F1 score at 200 is :0.47516460218276235</span><span id="f0c0" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LightGBM<br/></strong>Train F1 score at 2000 is  :0.9864296931649594 <br/>**************************************************<br/>test F1 score at 2000 is :0.5028071813038997</span><span id="da36" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">XGboost<br/></strong>Train F1 score is  :0.5387918992086534 <br/>**************************************************<br/>test F1 score is :0.35880636075112976</span><span id="6cd6" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">RUSBoost<br/></strong>Train F1 score is  :0.29295160471254406 <br/>**************************************************<br/>test F1 score is :0.2951101278199316</span></pre><p id="2244" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从这些模型中我们可以看到，尽管测试宏f1分数增加了，但是模型过度拟合得非常厉害。RUSBoost是一种针对不平衡数据的欠采样算法级方法。但是这样也不好。</p><p id="9e85" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这个糟糕的结果可能是由于数据中的高等级不平衡。因此，让我们尝试随机过采样来处理不平衡数据。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="2e84" class="mk jz hi mg b fi ml mm l mn mo">from imblearn.over_sampling import RandomOverSampler<br/>om = RandomOverSampler(random_state=10) <br/>x_res , y_res = om.fit_resample(train,y_train)</span><span id="c836" class="mk jz hi mg b fi mp mm l mn mo">print("class distribution BEFORE SMOTE in train data: \n",y_train.value_counts())<br/>print("class distribution AFTER SMOTE in train data: \n",y_res.value_counts())</span><span id="3047" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">class distribution BEFORE SMOTE in train data: <br/> 5    48477<br/>4    16293<br/>1     9931<br/>3     7180<br/>2     2947<br/>Name: review_score, dtype: int64<br/>class distribution AFTER SMOTE in train data: <br/> 4    48477<br/>3    48477<br/>5    48477<br/>2    48477<br/>1    48477<br/>Name: review_score, dtype: int64</strong></span></pre><p id="a23c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">在随机过采样之后，我尝试了之前尝试过的相同模型。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="8dc4" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Logistic regression</strong><br/>Train F1 score at 10 is :0.3030978235390651<br/>**************************************************<br/>test F1 score at 10 is :0.28286350316755565</span><span id="02ca" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Decision Tree</strong><br/>Train F1 score at 20 is :0.7016532041986847<br/>**************************************************<br/>test F1 score at 20 is :0.34301458062753587</span><span id="612f" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Random Forest<br/></strong>Train F1 score at 500 is :0.9985973924070967<br/>**************************************************<br/>test F1 score at 500 is :0.5136173216792821</span><span id="e368" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">XGBoostRF<br/></strong>Train F1 score at 0.001 is  :0.35404401698400156 <br/>**************************************************<br/>test F1 score at 0.001 is :0.30375644020951065</span><span id="840b" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LightGBM</strong><br/>Train F1 score is  :0.7637536506482032 <br/>**************************************************<br/>test F1 score is :0.39361553077802675</span></pre><p id="65dc" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在我们可以看到，随机过采样后，模型性能并没有得到改善。所以随机过采样在不平衡数据中不起作用。</p><p id="823c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这种直截了当的方法没有奏效。所以我尝试了另一种方法。方法如下。</p><p id="f064" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">模型1:首先我们把分数5看作一个类(1)，其他所有分数都看作其他类(0)。我们对此进行二元分类。如果我们得到输出1，那么类标签直接是5。另外，我们在类别1、2、3、4之间建立另一个多类别分类算法模型。由于不平衡在这种情况下并不多，我们可以期待更好的结果。</em> </strong></p><p id="3921" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，首先使用这种方法，我在第5类和其余类(1，2，3，4)上尝试了二元分类模型。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="2381" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Logistic Regression</strong><br/>Train F1 score at 0.01 is :0.6143489348445506<br/>**************************************************<br/>test F1 score at 0.01 is :0.6085867692979023</span><span id="d06b" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">SVM</strong><br/>Train F1 score at 0.01 is :0.363654776640036<br/>**************************************************<br/>test F1 score at 0.01 is :0.36375161899674946</span><span id="1aa9" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">KNN</strong><br/>Train F1 score at 3 is :0.8161479646108369<br/>**************************************************<br/>test F1 score at 3 is :0.6114315717337961</span><span id="303a" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Decision Tree</strong><br/>Train F1 score at 15 is :0.7252478785857026<br/>**************************************************<br/>test F1 score at 15 is :0.6208240044481035</span><span id="cec6" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">RandomForest</strong><br/>Train F1 score at 500 is :0.9989050920209032<br/>**************************************************<br/>test F1 score at 500 is :0.6790110979361804</span><span id="2b64" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LightGBM</strong><br/>Train F1 score at 2000 is  :0.9254666480999973 <br/>**************************************************<br/>test F1 score at 2000 is :0.6443430798206108</span><span id="cfcc" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">XGBoost</strong><br/>Train F1 score at 1 is  :0.8070625906785363 <br/>**************************************************<br/>test F1 score at 1 is :0.6287153755871924</span></pre><p id="2fd0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，在这里，模型与二元分类配合得非常好，这意味着模型能够预测第5类，并获得不错的分数。但是LightGBM，RF，KNN，DT模型都过拟合。逻辑回归没有过度拟合，得分几乎与其他模型相同。</p><p id="bc34" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在我试着选择特征来避免过度拟合，但这也不起作用。</p><p id="d1ab" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">为了提高分数，我尝试了随机抽样。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="205f" class="mk jz hi mg b fi ml mm l mn mo">om = RandomOverSampler(random_state=10) <br/>x_res , y_res = om.fit_resample(train_features,y_train)</span><span id="f32a" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">class distribution BEFORE SMOTE in train data: <br/> 1    48477<br/>0    36351<br/>Name: binary_target, dtype: int64<br/>class distribution AFTER SMOTE in train data: <br/> 1    48477<br/>0    48477<br/>Name: binary_target, dtype: int64<br/></strong></span><span id="948d" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Logistic Regression</strong><br/>Train F1 score at 10 is :0.6097127688974593<br/>**************************************************<br/>test F1 score at 10 is :0.6048836027921374</span><span id="0d47" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Decision Tree</strong><br/>Train F1 score at 15 is :0.7207902073616186<br/>**************************************************<br/>test F1 score at 15 is :0.6245482973145802</span><span id="4fe3" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">RandomForest</strong><br/>Train F1 score at 500 is :0.9990614105433693<br/>**************************************************<br/>test F1 score at 500 is :0.6866765711400296</span><span id="96fb" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LightGBM</strong><br/>Train F1 score is  :0.7112466091857768 <br/>**************************************************<br/>test F1 score is :0.6320387076110848</span></pre><p id="65a3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">从结果可以看出，随机过采样并没有提高模型性能。</p><p id="d0fa" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">但是从这种方法来看，模型对于类别5和作为二元分类的其余类别表现良好。而Logistic回归是这一步的最佳模型，没有过拟合，得分与其他不相上下。所以我选择逻辑回归作为这个方法的模型1。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="efac" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Logistic Regression</strong><br/>C=[0.00001,0.0001,0.001,0.01,0.1,1,10]</span><span id="0757" class="mk jz hi mg b fi mp mm l mn mo">f1_scores = []<br/>for i in C:<br/> model = None<br/> model = LogisticRegression(C=i,class_weight=”balanced”)<br/> k_fold_score = kfold(5,model,train,y_train)<br/> f1_scores.append(k_fold_score)<br/> print(“Macro F1 score at C={} is {} “.format(i,k_fold_score))</span><span id="c00c" class="mk jz hi mg b fi mp mm l mn mo">print(“*”*50) <br/>plt.plot(C,f1_scores,color=”darkblue”)<br/>plt.xscale(“log”)<br/>plt.grid()<br/>plt.title(“Cross Validation F1 score for each C”)<br/>plt.xlabel(“hyper parameter ©”)<br/>plt.ylabel(“F1 score”)<br/>plt.show()</span><span id="6332" class="mk jz hi mg b fi mp mm l mn mo">best_param = C[np.argmax(f1_scores)]</span><span id="0bee" class="mk jz hi mg b fi mp mm l mn mo">model = None<br/>model = LogisticRegression(C=i,class_weight=”balanced”)<br/>model.fit(train,y_train)</span><span id="845b" class="mk jz hi mg b fi mp mm l mn mo">print(“*”*50)<br/>print(“Train F1 score at {} is :{}”.format(best_param,<br/>f1_score(y_train,model.predict(train),labels=model.classes_,average=”macro”)))<br/>print(“*”*50)<br/>print(“test F1 score at {} is :{}”.format(best_param, f1_score(y_test,model.predict(test),labels=model.classes_,average=”macro”)))</span><span id="e3fe" class="mk jz hi mg b fi mp mm l mn mo">#plotting confusion matrix<br/>predicted = model.predict(test)<br/>plot_confusion_matrix(y_test,predicted)</span><span id="e8a4" class="mk jz hi mg b fi mp mm l mn mo">Macro F1 score at C=1e-05 is 0.6063750815874365 <br/>Macro F1 score at C=0.0001 is 0.6095742704086244 <br/>Macro F1 score at C=0.001 is 0.610961119057039 <br/>Macro F1 score at C=0.01 is 0.6129262895423754 <br/>Macro F1 score at C=0.1 is 0.6128481022485971 <br/>Macro F1 score at C=1 is 0.6128756224346488 <br/>Macro F1 score at C=10 is 0.6126459838606673 <br/>**************************************************</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es oc"><img src="../Images/8390ffbac71d947a88e960fd774eea10.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*dpWfYlhaiCBwSwsLAaka6w.png"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">交叉验证曲线</figcaption></figure><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="14d6" class="mk jz hi mg b fi ml mm l mn mo">**************************************************<br/>Train F1 score at 0.01 is :0.6143489348445506<br/>**************************************************<br/>test F1 score at 0.01 is :0.6085867692979023</span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es od"><img src="../Images/2c048cf5589785423012458dcf5d487c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YFL9UqOzrkUPsVD63HTAgg.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">混淆矩阵</figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es oe"><img src="../Images/9454adf51c319fef7e6d92cdba9c02d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BW1ci0vrQ7nyVPnqZQH6Ug.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">精度矩阵</figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es oe"><img src="../Images/adaddf639e30a3586ea3f41c699d347a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gpAafzM0FhZbY2iRyRhh6w.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">回忆矩阵</figcaption></figure><p id="a8de" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，我们必须在分数1、2、3、4之间进行多类分类。</p><p id="1886" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，我尝试了不同的模型，但分数并不太好，而且模型高度过度拟合。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="5c4f" class="mk jz hi mg b fi ml mm l mn mo">% Distribution of class labels in the total data :<br/>4    44.82<br/>1    27.32<br/>3    19.75<br/>2     8.11<br/>Name: review_score, dtype: float64<br/>**************************************************<br/>% Distribution of class labels in the train data :<br/>4    44.82<br/>1    27.32<br/>3    19.75<br/>2     8.10<br/>Name: review_score, dtype: float64<br/>**************************************************<br/>% Distribution of class labels in the test data :<br/>4    44.82<br/>1    27.32<br/>3    19.75<br/>2     8.11<br/>Name: review_score, dtype: float64<br/>**************************************************</span></pre><p id="f312" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">这是复习分数1，2，3，4的分布。</p><p id="0647" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">简单模型在这种多类分类中不起作用。所以我创建了一个定制的整体模型。</p><p id="e4c7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">训练数据将被分成50-50个d1和d2集合。从d1集合中随机取样替换的点，并取k个样本。用k个样本训练k个模型。并通过将d2传递给k个模型中的每一个来预测d2集合。现在我们得到了k个预测。</em>T3】</strong></p><p id="efe2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">现在使用k个预测作为输入建立元分类器，这意味着使用k个预测训练元分类器。在训练时，目标变量应该是d2集中的复习分数。元分类器的输出将被认为是预测的评论分数。<br/> </em> </strong>这就是我如何创建定制的合奏模型。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="79e6" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">def custom_ensemble</strong>(x_tr,y_tr,x_te,n_estimators,estimator,meta_clf):<br/> “””This function creates the custom ensemble model and returns predicted target variable of test set”””<br/> <br/> ########### SPlitting train data into 50–50 as d1 and d2 <br/> kf = StratifiedKFold(n_splits=2)<br/> <br/> d1 = x_tr[list(kf.split(x_tr,y_tr))[1][0]]<br/> d1_y = y_tr[list(kf.split(x_tr,y_tr))[1][0]]</span><span id="9e96" class="mk jz hi mg b fi mp mm l mn mo"> d2 = x_tr[list(kf.split(x_tr,y_tr))[1][1]]<br/> d2_y = y_tr[list(kf.split(x_tr,y_tr))[1][1]]<br/> ####################################################################<br/> d1_y = np.array(d1_y)<br/> d2_y = np.array(d2_y)<br/> ####################################################################<br/> ## Creating base learners and training them using samples of d1 ##<br/> <br/> models=[]<br/> <br/> for i in range(n_estimators):<br/> ind = np.random.choice(19387,size=(20000),replace=True)<br/> sample = d1[ind]<br/> sample_y = d1_y[ind] <br/> <br/> estimator.fit(sample,sample_y)<br/> models.append(estimator)<br/> <br/> ########### Predictions from base learners for d2 set ######<br/> predictions = []<br/> for model in models: <br/> <br/> pred = model.predict(d2)<br/> predictions.append(pred)<br/> <br/> predictions = np.array(predictions).reshape(-1,n_estimators)<br/> <br/> ########## meta classifier on predictions of base learners ####<br/> <br/> meta_clf.fit(predictions,d2_y)<br/> train_pred = meta_clf.predict(predictions)<br/> <br/> ####################################################################<br/> ######################## TEST SET ########################<br/> <br/> pred_test = []<br/> for model in models:<br/> pred_test.append(model.predict(test))<br/> <br/> pred_test = np.array(pred_test).reshape(-1,n_estimators)<br/> test_y_predicted = meta_clf.predict(pred_test)<br/> <br/>#### Return train predictions on d2, test predictions and actual labels of d2 ####</span><span id="bccd" class="mk jz hi mg b fi mp mm l mn mo">return train_pred,test_y_predicted,d2_y</span></pre><p id="9398" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">现在，我可以在这个函数中调用任意数量的任意模型，以获得该基本模型的集合。</p><p id="dac5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">我用不同数量的基础学习者尝试了逻辑回归、决策树、随机森林、XGboost、LGBM，因此基础模型的数量被视为超参数。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="891e" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Logistic Regression</strong><br/>Train Macro F1 score for n_estimator=150 is : 0.27057451737250016<br/>Test Macro F1 score for n_estimator=150 is : 0.23298332333913324<br/>************************************************************</span><span id="fa0f" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Decision Tree</strong><br/>Train Macro F1 score for n_estimator=100 is : 0.2554723104438191<br/>Test Macro F1 score for n_estimator=100 is : 0.22523027867967155<br/>************************************************************</span><span id="ef9f" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Random Forest</strong><br/>Train Macro F1 score for n_estimator=200 is : 0.27199880277608407<br/>Test Macro F1 score for n_estimator=200 is : 0.2287252929706321<br/>*************************************************************</span><span id="9258" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LGBM<br/></strong>Train Macro F1 score for n_estimator=50 is : 0.24091801912897187<br/>Test Macro F1 score for n_estimator=50 is : 0.22058180580346975<br/>************************************************************</span><span id="2651" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">LGBM with GOSS</strong><br/>Train Macro F1 score for n_estimator=25 is : 0.23258597383182883<br/>Test Macro F1 score for n_estimator=25 is : 0.20645592800527962<br/>************************************************************</span><span id="e0b6" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">XGBoost</strong><br/>Train Macro F1 score for n_estimator=50 is : 0.24604171363035154<br/>Test Macro F1 score for n_estimator=50 is : 0.23023241796944321</span></pre><p id="b7c6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">因此，我选择了逻辑回归定制系综。<br/>虽然性能得分不好，但过拟合问题减少。为了提高分数，我们必须进一步努力，在1，2，3，4这一课上创造更多的特色。现在我选择了LR定制套装。</p><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="1299" class="mk jz hi mg b fi ml mm l mn mo">n = [10,15,25,50,75,100,120,150,175,200]<br/>test_f1 =[]<br/>train_f1 = []</span><span id="4ce2" class="mk jz hi mg b fi mp mm l mn mo">for i in n:<br/> <br/> train_pred,test_pred,d2_y = custom_ensemble(train,y_train,test,i,LogisticRegression(class_weight=”balanced”),<br/> LogisticRegression(class_weight=”balanced”))<br/> <br/> train_score = f1_score(d2_y,train_pred,average=”macro”,labels=[1,2,3,4])<br/> test_score = f1_score(y_test,test_pred,average=”macro”,labels=[1,2,3,4])<br/> <br/> train_f1.append(train_score)<br/> test_f1.append(test_score)<br/> <br/> print(“*”*60)<br/> print(“Train Macro F1 score for n_estimator={} is : {}”.format(i,train_score))<br/> print(“Test Macro F1 score for n_estimator={} is : {}”.format(i,test_score))<br/> print(“*”*60)<br/> <br/>plt.plot(n,test_f1,label=”test”)<br/>plt.plot(n,train_f1,label=”train”)<br/>plt.legend()<br/>plt.xlabel(“Number of base learners(n)”)<br/>plt.ylabel(“Macro F1 score”)<br/>plt.title(“no. of Base learners v/s Macro F1 score”)<br/>plt.show()</span><span id="6e16" class="mk jz hi mg b fi mp mm l mn mo">best_n = n[np.argmax(test_f1)]</span><span id="feb1" class="mk jz hi mg b fi mp mm l mn mo">train_pred,test_pred,d2_y = custom_ensemble(train,y_train,test,best_n,LogisticRegression(class_weight=”balanced”),<br/> LogisticRegression(class_weight=”balanced”))<br/> <br/>train_score = f1_score(d2_y,train_pred,average=”macro”,labels=[1,2,3,4])<br/>test_score = f1_score(y_test,test_pred,average=”macro”,labels=[1,2,3,4])<br/> <br/>print(“*”*60)<br/>print(“Train Macro F1 score for n_estimator={} is : {}”.format(best_n,train_score))<br/>print(“Test Macro F1 score for n_estimator={} is : {}”.format(best_n,test_score))<br/>print(“*”*60)</span><span id="9401" class="mk jz hi mg b fi mp mm l mn mo">plot_confusion_matrix(y_test,test_pred)</span><span id="2b37" class="mk jz hi mg b fi mp mm l mn mo"><em class="ik">************************************************************<br/>Train Macro F1 score for n_estimator=10 is : 0.2275975085298737<br/>Test Macro F1 score for n_estimator=10 is : 0.22768654176316655<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=15 is : 0.23294871450254453<br/>Test Macro F1 score for n_estimator=15 is : 0.2202721123645503<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=25 is : 0.22863676451490095<br/>Test Macro F1 score for n_estimator=25 is : 0.21830870779971911<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=50 is : 0.2392766892756102<br/>Test Macro F1 score for n_estimator=50 is : 0.2192628608297082<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=75 is : 0.2605528481876316<br/>Test Macro F1 score for n_estimator=75 is : 0.21871970743696173<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=100 is : 0.25442330900194493<br/>Test Macro F1 score for n_estimator=100 is : 0.2106638150334702<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=120 is : 0.25863560405190616<br/>Test Macro F1 score for n_estimator=120 is : 0.21821822503158228<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=150 is : 0.2701955250061928<br/>Test Macro F1 score for n_estimator=150 is : 0.23056390517919373<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=175 is : 0.26995816705602926<br/>Test Macro F1 score for n_estimator=175 is : 0.22545213261796726<br/>************************************************************<br/>************************************************************<br/>Train Macro F1 score for n_estimator=200 is : 0.2725679232221619<br/>Test Macro F1 score for n_estimator=200 is : 0.21870631179230154<br/>************************************************************</em></span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es of"><img src="../Images/1275ee347d2e77150dc59ce0645401dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*p2WMxgS1tVXqftljTbMB4A.png"/></div></figure><pre class="ji jj jk jl fd mf mg mh mi aw mj bi"><span id="bbba" class="mk jz hi mg b fi ml mm l mn mo"><strong class="mg hj">Train Macro F1 score for n_estimator=150 is : <em class="ik">0.27057451737250016</em></strong></span><span id="c411" class="mk jz hi mg b fi mp mm l mn mo"><strong class="mg hj">Test Macro F1 score for n_estimator=150 is : <em class="ik">0.23298332333913324</em></strong></span></pre><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es og"><img src="../Images/c1d16618fadd7cc8e707fda26d36fb10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vAD1E6OA_HGeMHpSSC45fA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">混淆矩阵</figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es oh"><img src="../Images/fdb3549055aa74fb1dd1630979ca5a1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h98maV3BvVsj7_RjPFfGoA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">精度矩阵</figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es oh"><img src="../Images/739e3ce3a01683d2887d14db5914aafa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0EA2L7T1s-d2Zpffli29w.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">回忆矩阵</figcaption></figure><p id="bd15" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">分数不是很好。但是为了增加分数，我们必须在功能工程上多下功夫。</p><h1 id="cb55" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">10.未来的改进:</h1><p id="441a" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">现在，我考虑这个宏观F1分数，但在未来的工作中，我将通过更多的功能工程来增加分数。我尝试了大部分处理职业不平衡的技术，但是都没有达到预期的效果。但是在第二种方法(二进制+多类)中，如果我们做更多的特征工程，我们可以提高分数。此外，如果我们获得更多数据，如客户的人口统计细节(年龄、性别、财务状况等。)那就更好了。</p><h1 id="722a" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak"> 11。部署:</strong></h1><p id="d16f" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it la mb iw ix lc mc ja jb le md je jf jg hb bi translated">我已经使用Flask部署了模型。这里 可以看到<a class="ae jx" href="https://youtu.be/4KlVL-yA_Js" rel="noopener ugc nofollow" target="_blank"> <strong class="il hj">部署的演示</strong></a></p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="oi oj l"/></div></figure><p id="36be" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated">整个项目，摘要，代码在我的<a class="ae jx" href="https://github.com/praveen-hegde/E-commerce-customer-satisfaction-predicton" rel="noopener ugc nofollow" target="_blank"><strong class="il hj">github</strong>T3】中给出</a></p><p id="8e36" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it la iv iw ix lc iz ja jb le jd je jf jg hb bi translated"><em class="ik">随时欢迎对成绩的改进提出建议。</em></p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><blockquote class="if ig ih"><p id="431d" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><em class="hi">你可以在</em><a class="ae jx" href="https://www.linkedin.com/in/praveen-hegde-5bb6121b7/" rel="noopener ugc nofollow" target="_blank"><strong class="il hj"><em class="hi">LinkedIn</em></strong></a><em class="hi"><br/></em><a class="ae jx" href="https://www.linkedin.com/in/praveen-hegde-5bb6121b7/" rel="noopener ugc nofollow" target="_blank"><strong class="il hj"><em class="hi">Praveen Hegde</em></strong></a><em class="hi"><br/>MSc Statistics<br/></em><a class="ae jx" href="http://pgh3337@gmail.com" rel="noopener ugc nofollow" target="_blank"><em class="hi">pgh3337@gmail.com</em></a></p></blockquote></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="86be" class="jy jz hi bd ka kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv bi translated">12.参考资料:</h1><ul class=""><li id="0cbf" class="kw kx hi il b im ky iq kz la lb lc ld le lf jg me lh li lj bi translated">现有解决方案:<a class="ae jx" href="https://www.kaggle.com/andresionek/predicting-customer-satisfaction" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/andresionek/predicting-customer-satisfactio</a>n</li><li id="e4e1" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">重复电子商务买家预测<a class="ae jx" href="https://www.kdd.org/kdd2016/papers/files/adf0160-liuA.pdf" rel="noopener ugc nofollow" target="_blank">https://www.kdd.org/kdd2016/papers/files/adf0160-liuA.pdf</a></li><li id="a7d7" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">LightGBM分类器:<a class="ae jx" href="https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/2017/file/6449 f 44 a 102 FDE 848669 BDD 9 EB 6b 76 fa-paper . pdf</a></li><li id="f508" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">重击技术:<a class="ae jx" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1106.1813.pdf</a></li><li id="4312" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">关于欠采样、过采样、SMOTE、集成模型的博客:<a class="ae jx" href="https://xang1234.github.io/louvain/" rel="noopener ugc nofollow" target="_blank">https://xang1234.github.io/louvain/</a></li><li id="af7b" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated">RUSBoost算法:<a class="ae jx" href="https://www.researchgate.net/publication/224608502_RUSBoost_A_Hybrid_Approach_to_Alleviating_Class_Imbalance" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/224608502 _ RUSBoost _ A _ Hybrid _ Approach _ to _ submitting _ Class _ unbalanced</a></li><li id="f7ea" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated"><a class="ae jx" href="https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/针对不平衡分类的随机过采样和欠采样/ </a></li><li id="d6a3" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated"><a class="ae jx" href="https://www.researchgate.net/publication/323111412_The_effects_of_customer_satisfaction_with_e-commerce_system" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/323111412 _ The _ effects _ of _ customer _ satisfaction _ with _ e-commerce _ system</a></li><li id="22de" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated"><a class="ae jx" href="https://towardsdatascience.com/using-data-science-to-predict-negative-customer-reviews-2abbdfbf3d82" rel="noopener" target="_blank">https://towards data science . com/using-data-science-to-predict-negative-customer-reviews-2 abbdfb 3d 82</a></li><li id="3761" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated"><a class="ae jx" href="https://www.kaggle.com/goldendime/data-cleaning-viz-and-stat-analysis-on-e-com" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/golden dime/data-cleaning-viz-and-stat-analysis-on-e-com</a></li><li id="13d4" class="kw kx hi il b im lk iq ll la lm lc ln le lo jg me lh li lj bi translated"><a class="ae jx" href="https://www.kaggle.com/jsaguiar/e-commerce-exploratory-analysis" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/jsa guiar/e-commerce-explorative-analysis</a></li></ul></div></div>    
</body>
</html>