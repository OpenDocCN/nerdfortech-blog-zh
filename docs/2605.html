<html>
<head>
<title>Vision Transformers Use Case: Satellite Image Classification without CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">视觉变形器用例:没有CNN的卫星图像分类</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/vision-transformers-use-case-satellite-image-classification-without-cnns-2c4dbeb06f87?source=collection_archive---------2-----------------------#2021-05-13">https://medium.com/nerd-for-tech/vision-transformers-use-case-satellite-image-classification-without-cnns-2c4dbeb06f87?source=collection_archive---------2-----------------------#2021-05-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/bf8dc94b7901a5994dc491ae03aa87ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8PlMNc7X9lJNw-XyG4qF6A.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">视觉转换器架构</figcaption></figure><p id="28e0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">近年来，卷积神经网络作为现有技术已经广泛用于计算机视觉任务。图像的分类、检测和分割使用卷积滤波器从输入图像中提取特征图，为下一层执行其指定任务提供元素。然而，一种不使用卷积的架构称为视觉变压器(ViT ),在图像分类和对象检测等任务中显示出令人鼓舞的结果。CNN的统治要结束了吗？</p><h1 id="3181" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">卷积神经网络</h1><p id="390f" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">要了解更多关于CNN的信息，请访问下面的链接:</p><div class="ld le ez fb lf lg"><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener follow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">卷积神经网络综合指南ELI5方法</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">人工智能见证了人类能力差距的巨大增长…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">towardsdatascience.com</p></div></div><div class="lp l"><div class="lq l lr ls lt lp lu iw lg"/></div></div></a></div><h1 id="f09b" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">变形金刚(电影名)</h1><p id="80a9" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">论文“<a class="ae lv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a>”介绍了一种叫做变压器的新颖架构。正如标题所示，它使用了我们之前看到的注意力机制。像LSTM一样，Transformer是一种借助两个部分(编码器和解码器)将一个序列转换为另一个序列的架构，但它不同于先前描述的/现有的序列到序列模型，因为它不意味着任何递归网络(GRU、LSTM等)。).</p><p id="d817" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">更多:</p><div class="ld le ez fb lf lg"><a rel="noopener follow" target="_blank" href="/inside-machine-learning/what-is-a-transformer-d07dd1fbec04"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">什么是变压器？</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">机器学习中的变压器和序列对序列学习介绍</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">medium.com</p></div></div><div class="lp l"><div class="lw l lr ls lt lp lu iw lg"/></div></div></a></div><h1 id="a406" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">视觉变形金刚</h1><p id="fc1d" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">论文，<a class="ae lv" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">一幅图像相当于16×16个字:用于大规模图像识别的变形金刚</a>介绍了变形金刚在图像分类中的应用。CNN使用像素阵列，而Visual Transformer (ViT)将图像划分为视觉标记。首先，将图像分割成小块。在NLP中，图像补丁被视为单词。我们有输入到变压器块的补丁嵌入层。图像序列将有它自己的向量。因为一张图片是16乘以16个字的区域变换器。</p><p id="0e19" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">“图像被分成小块，比如说9个，每个小块可能包含16×16个像素。输入序列由来自大小为16×16的面片的像素值的展平矢量(2D到1D)组成。每个展平的元素被送入一个线性投影层，这将产生他们所谓的“补丁嵌入”。</p><p id="8a21" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">然后，位置嵌入被线性地添加到图像补片序列中，使得图像可以保留它们的位置信息。它注入了序列中图像碎片的相对或绝对位置信息。</p><p id="27c0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">根据图像补片的位置，将额外的可学习(类)嵌入附加到序列中。这种类别嵌入用于预测输入图像在被自关注更新后的类别。</p><p id="c320" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">分类是通过在变换的顶部，在我们添加到序列中的额外可学习嵌入的位置，堆叠一个MLP头来执行的。"(<a class="ae lv" href="https://www.analyticsvidhya.com/blog/2021/03/an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale-vision-transformers/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2021/03/an-image-is-worth-16x 16-words-transformers-for-image-recognition-at-scale-vision-transformers/</a>)</p><p id="218c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">ViT也被用于物体检测，在论文中:<a class="ae lv" href="https://arxiv.org/pdf/2005.12872.pdf" rel="noopener ugc nofollow" target="_blank">用变压器进行端到端的物体检测</a>。有关更多信息，请访问:</p><div class="ld le ez fb lf lg"><a href="https://towardsdatascience.com/are-you-ready-for-vision-transformer-vit-c9e11862c539" rel="noopener follow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">你准备好接受视觉变形器(ViT)了吗？</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">《一张图像抵得上16x16个字:大规模图像识别的变形金刚》可能会给计算机带来又一次突破…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">towardsdatascience.com</p></div></div><div class="lp l"><div class="lx l lr ls lt lp lu iw lg"/></div></div></a></div><div class="ld le ez fb lf lg"><a href="https://becominghuman.ai/vision-transformers-attention-for-vision-task-d0ef0fafe119" rel="noopener  ugc nofollow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">视觉变形者-视觉任务的注意。</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">最近在open-review上有一篇论文“一幅图像值16x16个字:大规模图像识别的变形金刚”。它…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">becominghuman.ai</p></div></div><div class="lp l"><div class="ly l lr ls lt lp lu iw lg"/></div></div></a></div><div class="ld le ez fb lf lg"><a href="https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833" rel="noopener  ugc nofollow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">变形金刚会取代计算机视觉中的CNN吗？</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">几分钟后，您将了解如何通过一种新的方式将transformer架构应用于计算机视觉</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">pub.towardsai.net</p></div></div><div class="lp l"><div class="lz l lr ls lt lp lu iw lg"/></div></div></a></div><h1 id="cedc" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">遥感图像分析中的变压器</h1><p id="b77f" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">在遥感图像的分析中，开始探索ViT的使用，例如，Bazi等人(2021)使用航空图像数据集(AID)和Merced数据集进行图像分类的任务。</p><p id="dda4" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">【https://www.mdpi.com/2072-4292/13/3/516/htm T4】</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es ma"><img src="../Images/597a809a7bcdbbcbc698cb257233f8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*imyltwkLqnkdR_B-ZL6EVQ.png"/></div></figure><p id="02cb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这项工作的结果表明，这种架构是非常有前途的，比使用卷积的统一架构获得更高的价值。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mb"><img src="../Images/4292e0141f7fa6a0eca1f018f15c321f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWvDX4vl1gVGWcAb1HpSBw.png"/></div></div></figure><h1 id="b67d" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">研究案例:欧洲卫星数据库</h1><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mc"><img src="../Images/ccf23b44e90fdb5298c7364cb3ce289f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNtwvndjnTOkWQqS2eCwSg.jpeg"/></div></div></figure><p id="094c" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们将使用Eurosat数据集来评估ViT在图像分类中的使用。该数据集包含27000幅13个光谱带的图像，分为10个不同的土地利用和土地覆盖类别。</p><p id="ab92" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><a class="ae lv" href="https://arxiv.org/abs/1709.00029" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1709.00029</a></p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es md"><img src="../Images/e49c7ab66a22fb98976737ab8d6bfca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzzhOfqmPv5kSk4dIgwaIA.png"/></div></div></figure><p id="4867" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们将使用Google Colab来构建和训练我们的ViT。利用Colab与Google Drive的集成，我们将数据集存储在Drive中，以便于访问。首先，让我们绘制一个条形图，显示每类图像的数量:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es me"><img src="../Images/e6c6d5d213d6188b6a026e99db2e53f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l7th09bkYmnHzA76c471Wg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">分类样本</figcaption></figure><p id="6111" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们注意到这些类包含了2000到3000张图片，部分是平衡的。因此，我们可以执行预处理步骤并构建我们将在此比较中使用的模型。</p><p id="c333" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">神经网络模型:</p><ul class=""><li id="c812" class="mf mg hi je b jf jg jj jk jn mh jr mi jv mj jz mk ml mm mn bi translated">自定义CNN</li><li id="8cbd" class="mf mg hi je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn bi translated">VGG16</li><li id="7746" class="mf mg hi je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn bi translated">ResNet-50</li><li id="e9ac" class="mf mg hi je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn bi translated">维生素t</li></ul><h2 id="64b7" class="mt kb hi bd kc mu mv mw kg mx my mz kk jn na nb ko jr nc nd ks jv ne nf kw ng bi translated">自定义CNN</h2><p id="8326" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">用于欧洲卫星数据集分类的第一个模型将是一个定制的有线电视新闻网，有些层和参数由用户配置。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es nh"><img src="../Images/020bc823fa99e149149b0380474c10b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXDSTFS2PnoYkoB7vs3u6A.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">自定义CNN</figcaption></figure><p id="17b5" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在300个训练时期之后，测试数据集具有0.93的准确度。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/d20a3f908dc477f7af9673671ce8e765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLm4vu6d1bYsknwCYV-u0w.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型精确度图表</figcaption></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/30801f855352a2f778ce2787f13645bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8uxzMNLFMbk3qHcvlzULYQ.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型损失图</figcaption></figure><p id="ff81" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">所以我们可以按类绘制混淆矩阵，表示模型预测的数量:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es nj"><img src="../Images/6953f98aa529f57c2463ba0fed52ff77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFJqCH78a71Dugbyda0MNA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">混淆矩阵</figcaption></figure><h2 id="0f6f" class="mt kb hi bd kc mu mv mw kg mx my mz kk jn na nb ko jr nc nd ks jv ne nf kw ng bi translated">VGG16</h2><p id="c46e" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">现在，我们将数据输入VGG16，并对其进行训练以验证结果:</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es nk"><img src="../Images/6f13f484888c05647b8826052748ed65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*S1Hscivc54HspvtSGHegGQ.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">VGG16</figcaption></figure><p id="79f9" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我们还将对这个模型进行300个纪元的训练。在测试数据集中获得的准确度为0.95，略好于定制的CNN。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/751cf61e09f73d135c70a2c5377070ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESkbuhtjbL3VZ7c2DSD6sg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">型号Acuraccy VGG16</figcaption></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/ad1ab11593a981789921e268872b2272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhDAJYwdS3w-XLY5dxEuDg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型损耗VGG16</figcaption></figure><p id="1678" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">混淆矩阵:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es nj"><img src="../Images/61e9fc02c692c250b71796a0aa8a9ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CS7JtqOUu-59md-z_B2Xag.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">混淆矩阵</figcaption></figure><h2 id="3baa" class="mt kb hi bd kc mu mv mw kg mx my mz kk jn na nb ko jr nc nd ks jv ne nf kw ng bi translated">ResNet-50</h2><p id="cabb" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">我们将使用ResNet50，这是一种非常著名的架构，广泛用于计算机视觉任务。与VGG16一样，ResNet-50也由Keras提供。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es nl"><img src="../Images/2c129e0f22ba1a7953881e2a6b256682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*zv-ZU7PaxDhlpxdi-_vl2A.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">ResNet-50</figcaption></figure><p id="3b06" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">经过300个训练时期后，该模型在测试数据集中显示了0.83的准确性，远低于以前模型获得的值。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/9849a1e4bc140b05a02c5bdbe31d7a08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SUgcDkT8o7lu0BPMZ2Ga8g.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">精度ResNet-50型</figcaption></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/0d1d2f522eb6498d87b5553da3d64b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZ7bV6cc8nWX9S3YCXi8OA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型损失ResNet-50</figcaption></figure><p id="61bd" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">混淆矩阵:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es nj"><img src="../Images/fe1bf46ba579ba1e66260829e1700f30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTw-cpHsgxpd_fzOCNKWMA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">混淆矩阵</figcaption></figure><h2 id="2cfd" class="mt kb hi bd kc mu mv mw kg mx my mz kk jn na nb ko jr nc nd ks jv ne nf kw ng bi translated">视觉变形金刚</h2><p id="f4d6" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">为了构建此模型，我们将使用下面链接的示例，其中ViT体系结构是在cifar10数据集中创建和训练的:</p><div class="ld le ez fb lf lg"><a href="https://keras.io/examples/vision/image_classification_with_vision_transformer/" rel="noopener  ugc nofollow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">Keras文档:使用视觉转换器进行图像分类</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">作者:Khalid Salama创建日期:2021/01/18最近修改时间:2021/01/18描述:实现愿景…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">keras.io</p></div></div><div class="lp l"><div class="nm l lr ls lt lp lu iw lg"/></div></div></a></div><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es nn"><img src="../Images/7ce5798783620d8b2e4da39823f1c18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*ouBexvXuAaL4TkMAtQO9kw.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">补丁创建</figcaption></figure><p id="e128" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">因此，在使用100个时期进行训练后，该模型在测试数据集中获得了0.92的准确度。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/4f292f4eed034bbdadb0cc494b0a1da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QAg9P49KDNpRm8u4d3SdYA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型精度ViT</figcaption></figure><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ni"><img src="../Images/9ff10a3e7a8ff808a99d747c9cfc9ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0UuWyZWg40sgsSjfO_87qQ.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">模型损耗ViT</figcaption></figure><p id="3852" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">混淆矩阵:</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es nj"><img src="../Images/967dd976956dda3cddced768f5ce5916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYfg6fGliKdd4NrCjPv-ag.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">混淆矩阵</figcaption></figure><h1 id="8433" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结论</h1><p id="6174" class="pw-post-body-paragraph jc jd hi je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz hb bi translated">正如在上述工作中，我们的案例研究表明，视觉变压器的图像分类结果是非常令人兴奋的。还有其他作品将卷积和ViT结合起来用于计算机视觉任务，但正如我们在许多文章中看到的那样，卷积网络的统治可能即将结束…</p><p id="1d69" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在LinkedIn上关注我:<a class="ae lv" href="https://www.linkedin.com/in/jo%C3%A3o-otavio-firigato-4876b3aa/" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/in/jo % C3 % A3o-OTA VIO-firigato-4876 B3 aa/</a></p><p id="22fc" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">谢谢！</p></div></div>    
</body>
</html>