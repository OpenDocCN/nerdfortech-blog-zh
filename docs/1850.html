<html>
<head>
<title>Review — UNIT: Unsupervised Image-to-Image Translation Networks (GAN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">审查-单位:无监督的图像到图像的翻译网络(甘)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/review-unit-unsupervised-image-to-image-translation-networks-gan-4a25ced6d078?source=collection_archive---------7-----------------------#2021-04-10">https://medium.com/nerd-for-tech/review-unit-unsupervised-image-to-image-translation-networks-gan-4a25ced6d078?source=collection_archive---------7-----------------------#2021-04-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a6e9" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><strong class="ak">在共享潜在空间假设下，</strong>扩展<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener">科根</a>，在领域适应性上优于<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener">科根</a></h2></div><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es iy"><img src="../Images/bda2c8ac767d6f64a442fd283080af5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_maMdlKFRDyI7AyidGdxiA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">共享潜在空间Z </strong></figcaption></figure><p id="afee" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di">在</span>这个故事中，回顾了NVIDIA的<strong class="jr hj">无监督图像到图像翻译网络</strong>(单元)。在本文中:</p><ul class=""><li id="3c16" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj">作出共享潜在空间假设</strong>，其假设不同域中的一对对应图像可以被映射到共享潜在空间中的同一潜在表示。</li><li id="7223" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">通过共享潜在空间进行图像到图像的转换。</strong>(此时，没有成对的例子显示如何将一个图像翻译成另一个域中的相应图像。)</li></ul><p id="fd35" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">这是一篇发表在<strong class="jr hj"> 2017 NIPS </strong>的论文，引用超过<strong class="jr hj"> 1500次</strong>。(<a class="li lj ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----4a25ced6d078--------------------------------" rel="noopener" target="_blank">曾植和</a> @中)</p></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="54de" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated">概述</h1><ol class=""><li id="93fc" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk mn la lb lc bi translated"><strong class="jr hj">共享潜在空间假设</strong></li><li id="221e" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk mn la lb lc bi translated"><strong class="jr hj">单位:框架</strong></li><li id="874f" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk mn la lb lc bi translated"><strong class="jr hj">培训损失</strong></li><li id="a772" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk mn la lb lc bi translated"><strong class="jr hj">图像到图像的翻译结果</strong></li><li id="3041" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk mn la lb lc bi translated"><strong class="jr hj">域适配结果</strong></li></ol></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="ffe0" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated"><strong class="ak"> 1。共享潜在空间假设</strong></h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mo"><img src="../Images/03c901ad1cf0111c77a62646c1e32fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*29bZv4VEszv2eRF9TwryfA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">共享潜在空间假设</strong></figcaption></figure><blockquote class="mp mq mr"><p id="975d" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">假设，<strong class="jr hj">对于分别来自两个不同域<em class="hi"> X </em> 1和<em class="hi"> X </em> 2的任意给定图像对<em class="hi"> x </em> 1和<em class="hi"> x </em> 2，在共享潜在空间<em class="hi"> Z </em>中存在一个共享潜在代码<em class="hi"> z </em>。</strong></p></blockquote><ul class=""><li id="df51" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj"> <em class="ms"> E </em> 1 </strong>和<strong class="jr hj"> <em class="ms"> E </em> 2 </strong>是2个<strong class="jr hj">编码函数，将图像映射为潜码。</strong></li><li id="8ddf" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj"> <em class="ms"> G </em> 1 </strong>和<strong class="jr hj"> <em class="ms"> G </em> 2 </strong>为2 <strong class="jr hj">生成函数，将潜码映射到图像。</strong></li></ul></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="a148" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated"><strong class="ak"> 2。单位:框架</strong></h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es mw"><img src="../Images/598280b55a174dc8ae53c20a7f06ca7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*uC49YE8pZ72eXGw4tMxd1A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">单位:框架</strong></figcaption></figure><h2 id="6709" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">2.1.变分自动编码器(VAE)</h2><ul class=""><li id="ba7e" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated">编码器-发电机对<strong class="jr hj"> { <em class="ms"> E </em> 1，<em class="ms"> G </em> 1} </strong>构成了<em class="ms"> X </em> 1域的VAE，称为<strong class="jr hj"> VAE1 </strong>。</li></ul><blockquote class="mp mq mr"><p id="0943" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated"><strong class="jr hj"> VAE1首先通过编码器<em class="hi"> E </em> 1 </strong>将输入图像<em class="hi"> x </em> 1映射到潜在空间<em class="hi"> Z </em>中的代码，然后<strong class="jr hj">通过生成器<em class="hi"> G </em> 1对代码的随机扰动版本进行解码以重构输入图像。</strong></p></blockquote><ul class=""><li id="cdf8" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">假设<strong class="jr hj">潜在空间<em class="ms"> Z </em> </strong> <em class="ms"> </em>中的分量是<strong class="jr hj">条件独立的且具有单位方差的高斯型。</strong></li><li id="d6d6" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">同样，<strong class="jr hj"> { <em class="ms"> E2 </em>，<em class="ms"> G2 </em> } </strong>构成了<em class="ms"> X </em> 2: <strong class="jr hj"> VAE2 </strong>的VAE。</li><li id="519e" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">对于自重建，即<em class="ms"> X </em> 1 → <em class="ms"> X </em> 1和<em class="ms"> X </em> 2 → <em class="ms"> X </em> 2到<em class="ms"> Z </em>，称为图像重建流。</li><li id="92f7" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">该图像重建流可以被监督训练</strong>，因为存在地面真相。</li></ul><h2 id="c8f7" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">2.2.重量共享约束</h2><blockquote class="mp mq mr"><p id="f0d8" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated"><em class="hi"> E </em> 1、<em class="hi"> E </em> 2、<em class="hi"> G </em> 1和<em class="hi"> G </em> 2使用CNNs并使用<strong class="jr hj">权重共享约束(虚线)</strong>实现共享潜在空间假设，其中<strong class="jr hj">最后几层(高级层)的连接权重在<em class="hi"> E </em> 1和<em class="hi"> E </em> 2 </strong>中被捆绑(用虚线表示)并连接</p></blockquote><ul class=""><li id="7b9f" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">重量共享约束最初来自<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener"> CoGAN </a>。因此，作者实际上是在扩展<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener"> CoGAN </a>用于图像到图像的翻译。</li><li id="fb36" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">共享潜在空间约束隐含了来自CycleGAN的循环一致性约束。</li><li id="a959" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">通过对抗训练，可以使用上述方法进行图像到图像的翻译。</li></ul><h2 id="cec4" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">2.3.<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a></h2><ul class=""><li id="2977" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated">生成对抗网络有两个:<strong class="jr hj"> GAN1 = { <em class="ms"> D </em> 1、<em class="ms"> G </em> 1} </strong>和<strong class="jr hj"> GAN2 = { <em class="ms"> D </em> 2、<em class="ms"> G </em> 2} </strong>。</li><li id="749d" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">对于从第一个域采样的真实图像，<em class="ms"> D </em> 1应该输出true，而对于<em class="ms"> G </em> 1产生的图像，应该输出false。</li><li id="a55f" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><em class="ms"> G </em> 1生成的图像可以有两个来源，一个是重建()，一个是翻译(<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a>)。</li><li id="16e9" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">对于图像到图像的转换，即<em class="ms"> X </em> 1 → <em class="ms"> X </em> 2和<em class="ms"> X </em> 2 → <em class="ms"> X </em> 1到<em class="ms"> Z </em>，称为图像转换流。</li><li id="1953" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">与自我重建相反，<strong class="jr hj">该图像翻译流是对手训练的</strong>。</li></ul><h2 id="054a" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">2.4.循环一致性</h2><ul class=""><li id="a76b" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated"><strong class="jr hj">可以在所提出的框架中实施</strong>循环一致性约束，以<strong class="jr hj">进一步正则化</strong>不适定的无监督图像到图像的翻译问题。</li><li id="a7a8" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">产生的信息处理流被称为<strong class="jr hj">循环重构流。</strong></li></ul><blockquote class="mp mq mr"><p id="2f98" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">(由于有和<a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a>，文中使用了更多的数学表达式，例如如何基于输入图像绘制潜在向量。如果感兴趣，请阅读该文件。)</p></blockquote></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="bbff" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated">3.<strong class="ak">培训损失</strong></h1><ul class=""><li id="f813" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated">VAE1、VAE2、GAN1和GAN2的图像重建流、图像平移流和循环重建流被<strong class="jr hj">联合训练</strong>:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nl"><img src="../Images/2ae663ba23a2b5fe6fdecc5b20b4bd32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8OgjILMLIEXkt0hZyQK1Sg.png"/></div></div></figure><h2 id="7acb" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">3.1.图像重建流</h2><ul class=""><li id="9e1e" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated"><strong class="jr hj"> VAE </strong>的损失函数是带有正则项的<strong class="jr hj">负对数似然:</strong></li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es et"><img src="../Images/6d623b085e3fc2e7d53a4253339f9b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kcQb93wwuJLGBd0g_xIMYQ.png"/></div></div></figure><ul class=""><li id="fbac" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj">KL散度项惩罚潜在代码的分布与先前分布的偏差。</strong></li><li id="92fb" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">这是VAE相当大的损失。(请随意阅读<a class="ae ix" href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/" rel="noopener ugc nofollow" target="_blank">教程——什么是变分自动编码器？</a>)</li></ul><h2 id="5874" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">3.2.图像翻译流</h2><ul class=""><li id="30d2" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated"><a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75"> <strong class="jr hj"> GAN </strong> </a> <strong class="jr hj">损耗</strong>是有条件的GAN ( <a class="ae ix" rel="noopener" href="/@sh.tsang/review-cgan-conditional-gan-gan-78dd42eee41"> CGAN </a>)损耗，因为<em class="ms"> z </em>是基于输入图像<em class="ms"> x </em>:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nm"><img src="../Images/4adffa6737b5a09614de8a54eb30c96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkSEoyXt5rXDXXmQqgm1Xg.png"/></div></div></figure><ul class=""><li id="7c3f" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">它们分别用于<strong class="jr hj">确保翻译后的图像类似于目标域中的图像</strong>。</li></ul><h2 id="aa67" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated"><strong class="ak"> 3.3。循环重建流</strong></h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es nn"><img src="../Images/4e2a5c764905fcbe0c1eb20fe6fd419e.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*YhZZfbaO7cwhP29CPBi0IA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图来自CycleGAN(我们这里可以把X当X1，Y当X2，或者把X当X2，Y当X1。)</strong></figcaption></figure><ul class=""><li id="9274" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">一个<strong class="jr hj">类似VAE的目标函数</strong>用于<strong class="jr hj">模拟循环一致性约束</strong>:</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es no"><img src="../Images/6cd23a243b7bfe9529385607dc9ea414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ruOC_RAxE3PjRhN8Qlt49Q.png"/></div></div></figure><ul class=""><li id="130e" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">其中<strong class="jr hj">负对数似然客观项确保两次翻译的图像与输入图像相似。</strong></li><li id="d78d" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj"> KL项惩罚在循环重构流</strong>中偏离先前分布的潜在码(因此，有两个KL项)。</li><li id="3307" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><em class="ms"> λ </em> 0 = 10，<em class="ms"> λ </em> 3 = <em class="ms"> λ </em> 1 = 0.1，<em class="ms"> λ </em> 4 = <em class="ms"> λ </em> 2 = 100。</li></ul><h2 id="15c8" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">3.4.交替梯度更新方案</h2><ul class=""><li id="c166" class="ku kv hi jr b js mi jv mj jy mk kc ml kg mm kk kz la lb lc bi translated">第一个玩家是由编码器和生成器组成的团队。第二个玩家是由敌对的歧视者组成的团队。</li><li id="8737" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">除了击败第二个玩家之外，第一个玩家必须最小化VAE损失和周期一致性损失。</li><li id="93fb" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">使用了<strong class="jr hj">交替梯度更新方案</strong>。</li></ul><blockquote class="mp mq mr"><p id="49d6" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">具体来说，<strong class="jr hj">首先应用一个梯度上升步骤</strong>更新<strong class="jr hj">D1和<em class="hi">D</em>2<em class="hi">E</em>1、<em class="hi"> E </em> 2、<em class="hi"> G </em> 1、<em class="hi"> G </em> 2固定。然后<strong class="jr hj">采用梯度下降步骤</strong>更新<strong class="jr hj">E1、<em class="hi"> E </em> 2、<em class="hi"> G </em> 1、<em class="hi"> G </em> 2 </strong>，固定<em class="hi"> D </em> 1和<em class="hi"> D </em> 2。</strong></p></blockquote></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="cc07" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated">4.图像到图像的翻译结果</h1><figure class="iz ja jb jc fd jd er es paragraph-image"><div class="er es np"><img src="../Images/051d72bb62ec3bd8b174df769505fda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*GjTfbgGhcBSCrmMgvzx2nw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图像到图像翻译的网络架构</strong></figcaption></figure><ul class=""><li id="25c6" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">每个小批量由来自第一域的一个图像和来自第二域的一个图像组成。</li><li id="8a6f" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">对于网络架构，<strong class="jr hj">编码器</strong>由作为前端的<strong class="jr hj"> 3个卷积层</strong>和作为后端的<strong class="jr hj"> 4个基本残差块</strong>组成。</li><li id="e9e9" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">生成器</strong>由作为前端的<strong class="jr hj"> 4个基本残差块</strong>和作为后端的<strong class="jr hj"> 3个转置卷积层</strong>组成。</li><li id="1a60" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">鉴别器</strong>由<strong class="jr hj">叠卷积层</strong>组成。</li><li id="2531" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj"> LeakyReLU </strong>用于非线性。</li></ul><h2 id="863e" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">4.1.消融研究的地图数据集</h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nq"><img src="../Images/397e995a4de5da0940f2222e4cbf77c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhQY_C_3VYxZ1m2mIdUMgw.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">地图数据集结果</strong></figcaption></figure><ul class=""><li id="6092" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj">(a)</strong>:<strong class="jr hj">地图数据集</strong>的图示。左图:卫星图像。右图:地图。</li><li id="5954" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">如果色差在地面真实颜色值的16°以内，则像素转换被认为是正确的。</li></ul><blockquote class="mp mq mr"><p id="2ddf" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">测量<strong class="jr hj">平均像素精度</strong>。</p></blockquote><ul class=""><li id="5c09" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj"> (b) </strong>:重量分担层数从1层变更为4层。鉴别器使用不同的层数。</li><li id="f3c6" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">最浅的鉴别器</strong>架构导致了<strong class="jr hj">最差的性能</strong>。</li><li id="a74d" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">发现<strong class="jr hj">重量分担层数影响不大。</strong>这是由于使用了残余块。</li></ul><blockquote class="mp mq mr"><p id="0332" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">基于这个结果，在剩余的实验中，使用具有1个共享层的<strong class="jr hj">VAEs</strong>和5个层的<strong class="jr hj">鉴别器</strong>。</p></blockquote><ul class=""><li id="530a" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj"> (c) </strong>:翻译准确度与不同超参数值的关系。</li><li id="eb70" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">一般来说，<strong class="jr hj">负对数似然项</strong>的较大权重值产生了<strong class="jr hj">更好的翻译准确性</strong>。</li><li id="fd03" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">还发现将KL项的权重设置为0.1会导致持续良好的性能。</li></ul><blockquote class="mp mq mr"><p id="ea0f" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">因此设定<em class="hi"> λ </em> 1 = <em class="hi"> λ </em> 3 = 0.1，<em class="hi"> λ </em> 2 = <em class="hi"> λ </em> 4 = 100。</p></blockquote><ul class=""><li id="f4a5" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jr hj"> (d) </strong>:权重分配和周期一致性约束对翻译准确性的影响。</li><li id="4781" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">当移除权重共享约束</strong>(因此，框架中的重建流被移除)<strong class="jr hj">框架被简化为CycleGAN架构</strong>。该模型实现了0.569的平均像素精度。</li><li id="2510" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">(希望未来可以回顾一下CycleGAN。)</li><li id="4a80" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">当<strong class="jr hj">去除循环一致性约束</strong>并且仅使用权重共享约束时，它实现了<strong class="jr hj"> 0.568平均像素精度</strong>。</li><li id="5a2b" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">但是当使用<strong class="jr hj">全型号</strong>时，单元达到了<strong class="jr hj"> 0.600平均像素精度</strong>的最佳性能。</li></ul><blockquote class="mp mq mr"><p id="90a6" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">对于不适定的联合分布恢复问题，<strong class="jr hj">更多的约束是有益的。</strong></p></blockquote><h2 id="a0a9" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">4.2.定性结果</h2><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nr"><img src="../Images/354f1052ecf4432cf494a351a093db3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jalrO7Ac_p1JbEXrX5WTJw.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">街景图像翻译结果。对于每一对，左边是输入，右边是翻译的图像。</strong></figcaption></figure><ul class=""><li id="67d9" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">UNIT应用于几个无人监管的街景图像翻译任务，包括<strong class="jr hj">晴天到雨天，白天到夜晚，夏天到下雪</strong>，反之亦然。</li><li id="649e" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">为了把<strong class="jr hj">真实转化为合成</strong>翻译，单位把城市景观图像做成卡通状。对于<strong class="jr hj">合成到真实</strong>的转换，UNIT在建筑、天空、道路和汽车区域取得了比人类区域更好的效果。</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es ns"><img src="../Images/7d90cc5ad092bbe90844fb4de0007b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Jpx4vMdcGbmdsXt4RF6eA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">狗狗品种翻译结果。</strong></figcaption></figure><ul class=""><li id="f4a2" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">ImageNet中的狗狗图片用于学习<strong class="jr hj">在不同品种</strong>之间翻译狗狗图片。</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nt"><img src="../Images/6f31f95998a899296407ea7f6addfb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LeMP9siDVg7X3mlC-G6OIA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">猫种翻译结果</strong></figcaption></figure><ul class=""><li id="d58a" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">同样，ImageNet数据集中的猫图像被用来学习<strong class="jr hj">在不同物种之间翻译猫图像</strong>。</li></ul><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nu"><img src="../Images/9b5b1ae5ee1de72d8ca18b25d71c5582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tK2C2VyrsfPdPPCFoiKrhg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">基于属性的人脸翻译结果</strong></figcaption></figure><ul class=""><li id="ce6b" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">CelebA数据集用于<strong class="jr hj">基于属性的人脸图像翻译</strong>。</li><li id="1d62" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">这些属性包括金发、微笑、山羊胡子和眼镜。</li><li id="4a9e" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">翻译后的人脸图像是真实的。</li></ul></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h1 id="cd80" class="lr ls hi bd jo lt lu lv lw lx ly lz ma io mb ip mc ir md is me iu mf iv mg mh bi translated">5.领域适应结果</h1><blockquote class="mp mq mr"><p id="e4d7" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">单元应用于<strong class="jr hj">的问题，调整使用一个域(源域)中的标记样本训练的分类器，以分类新域(目标域)中的样本，其中新域中的标记样本在训练期间不可用。</strong></p></blockquote><ul class=""><li id="74f5" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">该框架被训练成在源域和目标域之间翻译图像，并使用由源域中的鉴别器提取的特征对源域中的样本进行分类。</li></ul><blockquote class="mp mq mr"><p id="4dda" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated"><strong class="jr hj">高级层<em class="hi"> D </em> 1和<em class="hi"> D </em> 2的权重并列。</strong>这允许在源域中训练的分类器适应目标域。</p><p id="f4b6" class="jp jq ms jr b js jt ij ju jv jw im jx mt jz ka kb mu kd ke kf mv kh ki kj kk hb bi translated">同样，对于不同域中生成的一对图像，<strong class="jr hj">由最高层鉴别器提取的特征之间的L1距离被最小化</strong>，这进一步<strong class="jr hj">鼓励<em class="hi"> D </em> 1和<em class="hi"> D </em> 2以相同的方式解释一对对应的图像。</strong></p></blockquote><figure class="iz ja jb jc fd jd er es paragraph-image"><div role="button" tabindex="0" class="je jf di jg bf jh"><div class="er es nv"><img src="../Images/b9168b9141f885a6e2efe68568774f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3JQ-eil00py4bwoU3th8nQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">无监督域自适应性能</strong></figcaption></figure><ul class=""><li id="8bdf" class="ku kv hi jr b js jt jv jw jy kw kc kx kg ky kk kz la lb lc bi translated">该单元适用于多项任务，包括<strong class="jr hj">从街景门牌号码(SVHN)数据集到MNIST数据集</strong>的适配，以及<strong class="jr hj">在MNIST和美国邮政数据集</strong>之间的适配。</li><li id="c227" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jr hj">该装置在SVHN→MNIST任务</strong>中实现了0.9053的精度，这比之前最先进的方法【26】实现的0.8488的精度要好得多。</li><li id="3302" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">对于MNIST→SVHN任务，单元<strong class="jr hj">也比最先进的</strong> <a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener"> <strong class="jr hj"> CoGAN </strong> </a>取得了更好的性能</li><li id="97f9" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">数字图像的分辨率很低。因此，<strong class="jr hj">使用了小型网络</strong>。</li><li id="0c0b" class="ku kv hi jr b js ld jv le jy lf kc lg kg lh kk kz la lb lc bi translated">还发现<strong class="jr hj">周期一致性约束对于该任务不是必需的</strong>。</li></ul></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><h2 id="1b91" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">参考</h2><p id="eb48" class="pw-post-body-paragraph jp jq hi jr b js mi ij ju jv mj im jx jy nw ka kb kc nx ke kf kg ny ki kj kk hb bi translated">[2017 NIPS] [UNIT] <br/> <a class="ae ix" href="https://papers.nips.cc/paper/6672-unsupervised-image-to-image-translation-networks.pdf" rel="noopener ugc nofollow" target="_blank">无监督的图像到图像翻译网络</a></p><h2 id="25e1" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated">生成对抗网络</h2><p id="a697" class="pw-post-body-paragraph jp jq hi jr b js mi ij ju jv mj im jx jy nw ka kb kc nx ke kf kg ny ki kj kk hb bi translated"><strong class="jr hj">图像合成</strong> [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-gan-generative-adversarial-nets-gan-e12793e1fb75">甘</a> ] [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-cgan-conditional-gan-gan-78dd42eee41"> CGAN </a> ] [ <a class="ae ix" rel="noopener" href="/@sh.tsang/review-lapgan-laplacian-generative-adversarial-network-gan-e87200bbd827">拉普甘</a>[<a class="ae ix" rel="noopener" href="/@sh.tsang/review-dcgan-deep-convolutional-generative-adversarial-network-gan-ec390cded63c">DCGAN</a>][<a class="ae ix" href="https://sh-tsang.medium.com/review-cogan-coupled-generative-adversarial-networks-gan-273f70b340af" rel="noopener">CoGAN</a>]<br/><strong class="jr hj">图像到图像平移</strong> [ <a class="ae ix" href="https://sh-tsang.medium.com/review-pix2pix-image-to-image-translation-with-conditional-adversarial-networks-gan-ac85d8ecead2" rel="noopener"> Pix2Pix </a> ] [ <a class="ae ix" href="https://sh-tsang.medium.com/review-unit-unsupervised-image-to-image-translation-networks-gan-4a25ced6d078" rel="noopener">单元</a><br/><strong class="jr hj">超分辨率</strong>[<a class="ae ix" rel="noopener" href="/@sh.tsang/review-srgan-srresnet-photo-realistic-super-resolution-gan-super-resolution-96a6fa19490">SRGAN&amp;SRG <br/> <strong class="jr hj">摄像头篡改检测</strong></a><a class="ae ix" href="https://sh-tsang.medium.com/review-mantinis-visapp-19-generative-reference-model-and-deep-learned-features-camera-f608371c9854" rel="noopener">曼蒂尼的VISAPP’19</a><strong class="jr hj"><br/>视频编码</strong><a class="ae ix" rel="noopener" href="/@sh.tsang/reading-vc-lapgan-video-coding-oriented-laplacian-pyramid-of-generative-adversarial-networks-74daa2d23d3c">VC-lap gan</a><a class="ae ix" href="https://sh-tsang.medium.com/review-zhu-tmm20-generative-adversarial-network-based-intra-prediction-for-video-coding-c8a217c564ea" rel="noopener">朱TMM’20</a><a class="ae ix" href="https://sh-tsang.medium.com/review-zhong-elecgj21-a-gan-based-video-intra-coding-hevc-intra-9e3486dbca78" rel="noopener">钟elec gj’21</a></p><h2 id="50d4" class="mx ls hi bd jo my mz na lw nb nc nd ma jy ne nf mc kc ng nh me kg ni nj mg nk bi translated"><a class="ae ix" href="https://sh-tsang.medium.com/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e" rel="noopener">我以前的其他论文阅读材料</a></h2></div></div>    
</body>
</html>