<html>
<head>
<title>Insight into a few basic deep learning algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">洞察一些基本的深度学习算法</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/insight-into-a-few-basic-deep-learning-algorithms-7779a539f926?source=collection_archive---------9-----------------------#2021-03-11">https://medium.com/nerd-for-tech/insight-into-a-few-basic-deep-learning-algorithms-7779a539f926?source=collection_archive---------9-----------------------#2021-03-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="bf81" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="81a2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">学习可以定义为通过经验、学习或被教导获得知识或技能。因此，<strong class="jf hj">机器学习</strong>可以被定义为一种<strong class="jf hj"> </strong>现象，在这种现象中，机器可以被教会或自己学习，而无需显式编程。</p><figure class="kc kd ke kf fd kg er es paragraph-image"><div role="button" tabindex="0" class="kh ki di kj bf kk"><div class="er es kb"><img src="../Images/698614d9e47d963bb174bf6727df1aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*svdXFf5fzrgAcIdv"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">照片由<a class="ae kr" href="https://unsplash.com/@lucabravo?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卢卡·布拉沃</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><h2 id="f5ee" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">定义</h2><p id="8232" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">维基百科将<strong class="jf hj">深度学习</strong>定义为:</p><blockquote class="lg lh li"><p id="0cca" class="jd je lj jf b jg lk ji jj jk ll jm jn lm ln jq jr lo lp ju jv lq lr jy jz ka hb bi translated">深度学习是一类机器学习算法，它使用多层从原始输入中逐步提取更高级别的特征。例如，在图像处理中，较低层可以识别边缘，而较高层可以识别与人相关的概念，例如数字、字母或脸。</p></blockquote><p id="d595" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">在本文中，我们将讨论一些深度学习算法，如深度信念网络、生成对抗网络、变压器和图形神经网络。</p><h1 id="57a1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">深度信念网络</h1><p id="73dc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在深入到深层信念网络之前，让我们先讨论一下<strong class="jf hj">受限玻尔兹曼机器</strong>。</p><h2 id="2996" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">受限玻尔兹曼机器</h2><p id="b1c2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">受限玻尔兹曼机器可以被认为是因子分析的二进制版本，即我们可以将输出作为二进制变量(以 0 或 1 的形式)。</p><p id="ffe3" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">维基百科对 RBM 的定义是:</p><pre class="kc kd ke kf fd ls lt lu lv aw lw bi"><span id="fb6c" class="ks ig hi lt b fi lx ly l lz ma">A <strong class="lt hj">restricted Boltzmann machine</strong> (<strong class="lt hj">RBM</strong>) is a generative stochastic artificial neural network that can learn a probability distribution over its set of inputs. They can be trained in either supervised or unsupervised ways, depending on the task.</span></pre><p id="4c91" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated"><em class="lj">例如:如果你去过一家餐馆，然后用两个标准来判断这家餐馆:要么你喜欢这家餐馆，要么你不喜欢这家餐馆。对于这种情况，我们可以使用 RBMs。</em></p><p id="6049" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">成果管理制有三个主要组成部分</p><ol class=""><li id="92f4" class="mb mc hi jf b jg lk jk ll jo md js me jw mf ka mg mh mi mj bi translated">输入层</li><li id="2058" class="mb mc hi jf b jg mk jk ml jo mm js mn jw mo ka mg mh mi mj bi translated">隐蔽层</li><li id="2a83" class="mb mc hi jf b jg mk jk ml jo mm js mn jw mo ka mg mh mi mj bi translated">偏见</li></ol><p id="b614" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">在上面的例子中，可见的单位是你是否喜欢这家餐馆。隐藏单元有助于发现是什么让你喜欢那家特定的餐厅。偏见是一个额外的组成部分，它是为了融合不同餐馆的不同属性而添加的。</p><p id="6cc7" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">在这种网络中，每个可见单元连接到所有隐藏单元，偏置单元连接到所有可见单元和所有隐藏单元。</p><p id="1059" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">让我们看看决策过程中的步骤</p><ol class=""><li id="5cdf" class="mb mc hi jf b jg lk jk ll jo md js me jw mf ka mg mh mi mj bi translated">活化能计算</li><li id="ff70" class="mb mc hi jf b jg mk jk ml jo mm js mn jw mo ka mg mh mi mj bi translated">计算活化能的活化函数 sigmoid。这会给我们一个概率。</li><li id="940a" class="mb mc hi jf b jg mk jk ml jo mm js mn jw mo ka mg mh mi mj bi translated">使用上面计算的概率，隐藏单元可以<strong class="jf hj">打开或关闭</strong>可见单元中的任何节点。</li></ol><h2 id="10c9" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">深度信念网络</h2><p id="3298" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">深度信念网络是由多个隐藏层组成的生成图形模型。它们包含有向层和无向层。深度信念网络中的每一层都学习整个输入。在卷积神经网络中，前几层只过滤基本特征的输入，后几层重新组合前几层发现的所有简单模式。它们有两个阶段:-预训练阶段和微调阶段。它包含多层 RBM，而微调阶段是一个前馈神经网络。每个子网络的隐藏层作为下一个网络的可见层。训练是以贪婪的逐层方式进行的，通过权重微调从原始输入数据中提取分层特征。</p><p id="70c3" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">它们广泛应用于图像和视频识别。除此之外，它们还用于跟踪物体或人的运动。</p><h1 id="2f8e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">生成对抗网络</h1><p id="911e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">总结输入变量分布的无监督模型可用于创建或生成输入分布中的新示例。这些类型的模型被称为生成模型。</p><p id="40e8" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">生成敌对网络正变得流行，因为它们能够以惊人的准确度理解和重建视觉数据。它们可用于从轮廓填充图像、从文本生成逼真的图像、制作产品原型的照片般逼真的描述或将黑白图像转换为彩色图像。GANs 有两部分:生成器和鉴别器</p><h2 id="4a79" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated"><strong class="ak">发电机</strong></h2><p id="b11d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">生成器学习生成数据。生成的实例成为鉴别器的负训练样本。生成器模型将固定长度的随机向量作为输入，并在域中生成样本。该向量随机取自高斯分布，并且该向量用于生成过程的种子。在训练之后，这个多维向量空间中的点将对应于问题域中的点，形成数据分布的压缩表示。</p><h2 id="e095" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated"><strong class="ak">鉴别器</strong></h2><p id="6913" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">鉴别器学习区分生成器的假数据和真实数据，并作为基本分类模型工作。鉴别器的主要作用是惩罚产生错误或伪造数据的生成器。</p><p id="2045" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">需要首先识别期望的输出，然后基于识别的参数收集训练数据集。然后，该数据被随机化，并作为输入被馈送到发生器，直到它被训练成具有产生实际输出的合理精度。</p><p id="0e82" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">此后，产生的输出与实际数据一起被馈入鉴频器。鉴别器然后过滤信息，并返回范围从 0 到 1 的概率，以表示每个图像的真实性。然后手动验证这些概率值是否成功，并重复该过程，直到达到期望的输出。</p><h1 id="d23a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">变形金刚(电影名)</h1><p id="4cea" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Transformer 是一种广为人知的深度学习模型，主要用于自然语言处理(NLP)。它旨在处理顺序数据，但不要求数据按顺序处理。因此，与递归神经网络相比，该模型允许更多的并行化，从而减少了训练时间。它允许在比引入 transformer 之前更大的数据集上进行训练。</p><h2 id="69ef" class="ks ig hi bd ih kt ku kv il kw kx ky ip jo kz la it js lb lc ix jw ld le jb lf bi translated">体系结构</h2><p id="a08c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这是一种编码器-解码器架构。</p><p id="2bd0" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated"><strong class="jf hj">编码器</strong>由一组编码层组成，通过每一层迭代处理输入，包含输入的哪些部分彼此相关的信息。</p><p id="5462" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated"><strong class="jf hj">解码器</strong>由一组解码层组成，解码层利用编码器输出中包含的上下文信息对其进行处理，以生成输出序列。</p><p id="aeab" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">对于每一个输入，每一层都衡量每一个输入的相关性，并相应地从中提取信息以产生输出。每一层还具有前馈神经网络，用于输出的附加处理。</p><p id="8b04" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">BERT ad XLNets 是最著名的经过预先培训的自然语言系统，用于各种自然语言处理任务，并且基于变形金刚。</p><h1 id="6767" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">图神经网络</h1><p id="f2ab" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">图形神经网络是另一种基于非结构化数据结构的神经网络，称为图形神经网络。图中的每个节点都被分配了一个标签，然后我们想要预测没有基础事实的节点的标签。它们广泛应用于现实世界中可以用图形表示的问题，如社会网络、化学化合物、地图和交通系统。</p><p id="fe74" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">GNN 识别图中所有节点之间的关系，并产生一种特殊的表示方式，以便以后可以在任何其他 ML 模型中使用，如聚类、分类等。</p><p id="8849" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated">相邻节点通过边缘神经网络将其信息传递到参考节点上的递归单元中。通过对当前嵌入应用递归函数以及对相邻节点嵌入的边缘神经网络输出求和来更新参考递归单元的新嵌入。</p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="4ecb" class="pw-post-body-paragraph jd je hi jf b jg lk ji jj jk ll jm jn jo ln jq jr js lp ju jv jw lr jy jz ka hb bi translated"><strong class="jf hj"> <em class="lj">感谢您阅读本文！请随时留下您的反馈。</em> </strong></p></div></div>    
</body>
</html>