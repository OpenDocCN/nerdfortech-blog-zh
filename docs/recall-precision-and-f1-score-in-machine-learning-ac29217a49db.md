# 机器学习中的召回率、精确度和 F1 分数

> 原文：<https://medium.com/nerd-for-tech/recall-precision-and-f1-score-in-machine-learning-ac29217a49db?source=collection_archive---------17----------------------->

一位店主最近注意到商店行窃率高得惊人。他开发了一个机器学习模型，可以预测顾客是否在商店行窃，准确率高达 95%。他部署了模型，但是一个月后没有抓到小偷…为什么？

在我们研究这个问题之前，理解什么是精确度是很重要的。准确度是你预测正确的次数除以你实际预测的次数。

如果您仔细观察数据集，您会注意到，在进入商店的 10，000 名顾客中，只有 500 人是当月的扒手。一些简单的数学计算会告诉你 95%的顾客不是商店扒手，另外 5%是。

这个问题发生在数据严重倾斜的“不平衡”数据集中。你要么是一个商店扒手，要么不是，前者在数据集中出现得更多。我们的模型找到了提高精确度的捷径。

用正式的术语来说，“回忆”是用这个公式来定义的

这个指标的基本作用是告诉我们，我们的模型在识别相关样本方面有多好。或者我们的模型在抓住真正的商店扒手方面有多好？TP:正确识别商店扒手 FN:遗漏商店扒手

现在，如果模型将每个人都归类为商店扒手，那么召回率将为 0。这意味着，如果我们为了尽可能高的召回率而进行优化，那就“一点也不好”。另一方面，如果我们把每个人都贴上商店扒手的标签会怎么样？

我们会进行 100%的召回，毕竟，召回只关心不遗漏商店扒手，而不是对顾客的错误指控(假阳性)。但是有一个度量标准确实关心对客户的错误指控，即精确度。

我们基本上是在分母中用假阳性代替假阴性。在我们正确预测的所有积极类中，有多少实际上是积极的。或者我们的模型在不做虚假指控方面有多好？

至此，您可能已经猜到，如果我们只针对模型中的高精度进行优化，我们会遇到什么问题。该模型可以把所有人都称为非扒手，精度高。

查全率和查准率是相关的，高查准率导致低查全率，低查准率导致高查全率。我们显然希望两者都尽可能的高，有没有什么指标可以同时兼顾查准率和查全率呢？向 F₁配乐问好

F₁分数是精确度和召回率的调和平均值。调和平均值是一种特殊类型的平均值(平均值),可以用这个公式来解释。

我们用这个平均值代替正态平均值，因为正态会惩罚极端值。

现在，如果我们优化我们的模型，使其具有 F₁分数，我们就可以获得高精度和高召回率。这意味着我们的模型能够抓住商店扒手，同时不会错误地指控无辜的顾客。

当模型抓到一个商店扒手时，它将确定它实际上是一个商店扒手，从而结束这个故事。在接下来的几个月里，我将解释更多的评估指标，比如 F₁分数。