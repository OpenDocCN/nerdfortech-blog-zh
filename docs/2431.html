<html>
<head>
<title>Predicting a Failure in the APS of a Scania Truck using Machine Learning — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测斯堪尼亚卡车APS的故障—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/predicting-a-failure-in-the-aps-of-a-scania-truck-using-machine-learning-part-1-fefb407040db?source=collection_archive---------5-----------------------#2021-05-06">https://medium.com/nerd-for-tech/predicting-a-failure-in-the-aps-of-a-scania-truck-using-machine-learning-part-1-fefb407040db?source=collection_archive---------5-----------------------#2021-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3b2ba269d9de39a4e4d7117f8722a380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-DKgiEmcRoPu_qWG"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">里卡多·戈麦斯·安吉尔在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="5389" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">一辆</span>卡车有许多子系统。一个这样的子系统被称为APS或<em class="kc">气压系统(APS)。</em>APS负责为卡车内部提供必要的空气压力。现代重型卡车使用空气制动器，而不是其他轻型车辆中使用的传统液压制动器。这些制动器需要持续供应压缩空气来保持分离，这样车辆才能继续行驶。如果由于任何情况，这种压缩空气的供应受到损害，制动器将不再分离，卡车将停止。当这种情况发生时，车主必须派出维修车辆来诊断和修理故障。然而，APS广泛分布在卡车和拖车上，由大量的管道组成，这些管道实际上提供空气。这使得很难诊断问题是否与接入点有关。这花费了车队所有者大量可以节省的时间和金钱。</p><p id="53fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，拥有能够预测卡车中的故障是否是由APS引起的机器学习算法/系统将对相关人员非常有帮助，因为它可以在一定程度上减少停机时间和在故障中花费的总金钱。</p><p id="9394" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个问题的端到端解决方案将由两部分组成。在第一部分，我们将讨论问题的基础，如问题陈述、约束、性能指标等，并执行EDA和数据集的数据预处理。 <em class="kc">在第二部分中，我们将在处理后的数据上训练实际的机器学习模型，然后选择最佳模型，以webapp的形式部署在AWS EC2实例上，使用</em><a class="ae iu" href="https://docs.streamlit.io/en/stable/" rel="noopener ugc nofollow" target="_blank"><em class="kc">Streamlit</em></a><em class="kc">制作。读完第二部</em> <a class="ae iu" href="https://amansavaria.medium.com/predicting-a-failure-in-the-aps-of-a-scania-truck-using-machine-learning-part-2-271814dfebdd" rel="noopener"> <em class="kc">这里</em> </a> <em class="kc">。</em></p></div><div class="ab cl kd ke gp kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="hb hc hd he hf"><h1 id="0dc5" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">内容:</h1><ol class=""><li id="a473" class="li lj hi ix b iy lk jc ll jg lm jk ln jo lo js lp lq lr ls bi translated">机器学习的问题公式化</li><li id="6bbb" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">业务限制</li><li id="767f" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">数据集描述和获取数据</li><li id="9e6d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">性能指标</li><li id="52db" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">入门指南</li><li id="ba87" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">探索性数据分析</li><li id="7a8f" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">缺失值插补</li><li id="a39d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">数据标准化</li></ol></div><div class="ab cl kd ke gp kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="hb hc hd he hf"><h1 id="4a56" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">ML的问题公式化</h1><p id="2948" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">这个问题可以被视为一个简单的二进制分类模型，其中<em class="kc">正类意味着卡车中的问题是由于APS </em>中的故障造成的，而<em class="kc">负类则意味着其他原因。</em>因此，给定一个涉及特定故障的新数据点，我们需要对故障是否是APS故障的结果进行分类。</p><h1 id="769b" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">业务限制</h1><ul class=""><li id="d12a" class="li lj hi ix b iy lk jc ll jg lm jk ln jo lo js mg lq lr ls bi translated"><strong class="ix hj">延迟:</strong>在获得数据后进行预测所需的时间必须相当短，以避免任何不必要的维护时间和成本的增加。</li><li id="a0e5" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js mg lq lr ls bi translated"><strong class="ix hj">错误分类的成本:</strong>错误分类的成本非常高，尤其是错误地将一个正类数据点分类，因为这可能导致卡车完全损坏，并导致一些严重的成本。在这里进行错误的分类只会浪费修理工的时间，因为他们会因为相信模型的分类而在错误的地方寻找问题。</li></ul><h1 id="6922" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">数据集描述</h1><p id="2f0a" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">该数据集是作为<strong class="ix hj"> IDA-2016工业挑战</strong>的一部分提供的，包含从日常使用的斯堪尼亚卡车上获取的读数，由斯堪尼亚自己收集和提供。由于专有原因，所有功能的名称都是匿名的。</p><p id="d709" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此案例研究的数据集可在此处找到:</p><p id="c977" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/datasets/APS+Failure+at+Scania+Trucks</a></p><p id="7628" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集分为两部分，一个<strong class="ix hj">训练集</strong> <em class="kc"> </em>和一个<strong class="ix hj">测试集</strong>。列车组包含<strong class="ix hj">60000行</strong>，而测试组包含<strong class="ix hj">16000行。</strong>数据集中有171列，其中一列是数据点的类标签，导致每个数据点有170个特征。这些特征是数字特征和从直方图箱构建的特征的组合。所有的特征本质上都是数字的。仅通过查看数据集，就可以看出这是一个高度不平衡的数据集<strong class="ix hj"/><em class="kc"/>，其中有<strong class="ix hj">59000个</strong>属于<strong class="ix hj">负类</strong>，只有<strong class="ix hj">1000个</strong>属于<strong class="ix hj">正类</strong>。另一件要注意的事情是，数据点包含许多缺失值。有些特性甚至有<strong class="ix hj">超过一半</strong>的值在其中缺失。训练和测试数据集中的许多数据点至少包含一个缺失值。</p><h1 id="af97" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">性能指标</h1><p id="a9dd" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">使用以下性能指标:</p><ul class=""><li id="bbec" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated"><strong class="ix hj">错误分类成本:</strong>该指标是竞赛的一部分。它由下式给出:</li></ul><blockquote class="mk"><p id="d44d" class="ml mm hi bd mn mo mp mq mr ms mt js dx translated"><strong class="ak">误分类成本:(cost_2 x FN) + (cost_1 x FP) </strong></p><p id="81f0" class="ml mm hi bd mn mo mu mv mw mx my js dx translated"><strong class="ak">其中，成本_1 = 10，成本_2 = 500 </strong></p></blockquote><p id="9582" class="pw-post-body-paragraph iv iw hi ix b iy mz ja jb jc na je jf jg nb ji jj jk nc jm jn jo nd jq jr js hb bi translated">此指标表示由于模型的错误分类，车队所有者将承担的成本。在这种情况下，成本_1指的是需要在车间由机械师进行不必要的检查的成本，而成本_2指的是错过故障卡车的成本，这可能是未来发生故障的成本。</p><ul class=""><li id="e089" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated"><strong class="ix hj">混淆、精确和召回矩阵:</strong>混淆、精确和召回度量将告诉我们基于每个类的模型的性能，这是非常重要的，因为数据集如此偏向于负类。</li><li id="4a35" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js mg lq lr ls bi translated"><strong class="ix hj"> F-1分数:</strong>单个指标中的F-1分数可以根据模型的精确度和召回率告诉我们模型的整体性能，使用单个数字比矩阵更容易解释。我们将使用<strong class="ix hj">宏观平均F-1分数</strong>，因为它考虑了两个级别的f1分数，因此可以告诉我们模型在两个级别的整体性能。</li></ul><h1 id="0050" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">入门指南</h1><p id="d1ef" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">首先，让我们从导入库和加载数据开始。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">导入库和加载数据</figcaption></figure><h1 id="0f79" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">探索性数据分析</h1><p id="3b63" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">首先，我们将分析关于完整数据集的非常基本的东西，例如数据的类别分布等。然后再讨论特性本身的实际EDA。</p><h2 id="9892" class="nk kl hi bd km nl nm nn kq no np nq ku jg nr ns ky jk nt nu lc jo nv nw lg nx bi translated"><strong class="ak">首先来看看数据的阶级分布:</strong></h2><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据的分类分布。</figcaption></figure><p id="0afe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，在数据集中的<strong class="ix hj">60000个</strong>数据点中，<strong class="ix hj">59000个(~98.3%) </strong>属于<strong class="ix hj">负类</strong>，只有<strong class="ix hj">1000个(~1.7%) </strong>属于<strong class="ix hj">正类。</strong>因此，数据集非常不平衡，因此我们将需要使用技术来抵消这种不平衡，否则我们将在正类上获得非常糟糕的性能。</p><p id="136e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">现在，让我们看看有多少特征是数值特征，有多少是基于直方图的特征:</strong></p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据集中的要素分布。</figcaption></figure><p id="857a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，有7个直方图，从这些直方图中已经构建了不同的直方图特征，并且对于每个直方图特征，我们有10个箱，因此在170个特征中总共有70个特征是直方图特征，而剩余的100个特征是数值特征。</p><h2 id="0f5a" class="nk kl hi bd km nl nm nn kq no np nq ku jg nr ns ky jk nt nu lc jo nv nw lg nx bi translated"><strong class="ak">现在，我们来分析一下数据集中缺失的值:</strong></h2><p id="cd53" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">在查看数据时，我们意识到数据集中有相当多的缺失值。现在，让我们实际分析这些缺失的数据，看看数据集中到底有多少缺失值。因为我们知道要素中有很多缺失值，所以我们将分析每个数据点和每个要素的缺失值。</p><p id="bc6d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.<strong class="ix hj">每个特性的缺失值分析:</strong></p><p id="2899" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，让我们看看有多少特性没有缺失值及其名称。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">没有缺失值的要素。</figcaption></figure><p id="7014" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，只有一个特征没有缺失值，即<em class="kc"> aa_000。</em></p><p id="bb38" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们通过获得任何特征中缺失值的最小和最大数量以及特征中缺失值数量的分布来做一些进一步的分析。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="9815" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于要素bt_000，我们可以找到的最少缺失值数是167，而对于要素br_000，最大缺失值数是49264，这是数据集的大部分。由于该值较大，每个特征的平均值约有5000个缺失值，几乎是中值688的9倍。这可能表明有些要素缺少大量的值。<br/>进一步的分析证实了这一假设，我们发现只有28个特征的缺失值大于平均值，其中大多数特征在60000个训练数据点中至少有9550个缺失值，这是一个很大的百分比。</p><p id="b598" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们通过绘制图表来查看每个特性的缺失值的实际数量。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">每个要素中缺失值的数量。</figcaption></figure><p id="e023" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大多数要素的缺失值不到5%,其他一些要素的缺失值在5-25%之间，少数在25-50%之间。但是，有些要素有超过70%的缺失值。基于这个缺失值的百分比，我们将制定我们的插补策略。</p><h2 id="3e13" class="nk kl hi bd km nl nm nn kq no np nq ku jg nr ns ky jk nt nu lc jo nv nw lg nx bi translated">3.EDA上的特性</h2><p id="cb75" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">现在，让我们对实际功能进行EDA。由于有两种类型的特征，即数字和直方图特征，我们将对这两种特征分别执行EDA。然而，我们有100个数字特征和70个直方图特征。因此，在所有这些方面进行EDA是不可能的。因此，我们将从这两种类型中选择前15个特性，然后对它们执行EDA。我们将使用RandomForestClassifier 给出的<em class="kc">特征重要性来获取重要特征。</em></p><p id="8c14" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kc">功能选择</em> <strong class="ix hj"> : </strong></p><pre class="ne nf ng nh fd ny nz oa ob aw oc bi"><span id="d8fb" class="nk kl hi nz b fi od oe l of og">def top_important_features(data, labels, top_x=15, verbose=10):<br/>    '''<br/>        This function uses random forests to get feature importances of the features and returns top_x important features<br/>        and their feature importances.<br/>        Returns:<br/>            tuple of (features, importances).<br/>    '''<br/>    # training a random forest<br/>    rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=verbose, random_state=42)<br/>    rf.fit(data, labels)<br/>    <br/>    # get the feature importances<br/>    feat_imp = rf.feature_importances_<br/>    imp_ind = np.argsort(feat_imp)[::-1] # getting the indices in decreasing order of importance<br/>    top15_ft = data.columns[imp_ind][:15]<br/>    top15_imp = feat_imp[imp_ind][:15]<br/>    <br/>    return(top15_ft, top15_imp)</span></pre><p id="7e6b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kc">对给定特征进行单变量分析的功能:</em></p><pre class="ne nf ng nh fd ny nz oa ob aw oc bi"><span id="37e5" class="nk kl hi nz b fi od oe l of og">def univariate_analysis(features):<br/>    """<br/>        This function takes a list of features and performs univariate analysis on them by plotting CDF, PDF, Boxplots and <br/>        printing mean, standard deviation and median for that feature.<br/>    """<br/>    for ft in features:<br/>        print('---UNIVARIATE ANALYSIS OF', ft, '---')<br/>        values = train_eda[ft]<br/>        values0 = train_eda[train['class']=='neg'][ft]<br/>        values1 = train_eda[train['class']=='pos'][ft]<br/>        desc_neg = values0.describe() # for printing the mean and standard deviation values of the feature for individual classes<br/>        desc_pos = values1.describe()</span><span id="cd01" class="nk kl hi nz b fi oh oe l of og">print("FOR NEGATIVE CLASS:- 1. Mean:", round(desc_neg['mean'], 3), '2. Standard Deviation:', round(desc_neg['std'], 3), '3. Median:', round(desc_neg['50%'], 3))<br/>        print("FOR POSITIVE CLASS:- 1. Mean:", round(desc_pos['mean'], 3), '2. Standard Deviation:', round(desc_pos['std'], 3), '3. Median:', round(desc_pos['50%'], 3))</span><span id="3fce" class="nk kl hi nz b fi oh oe l of og"># plots<br/>        fig, ax = plt.subplots(ncols=3, figsize=(18,6))<br/>        sns.kdeplot(values0, ax=ax[0], shade=True, label='Neg')<br/>        sns.kdeplot(values1, ax=ax[0], shade=True, label='Pos')<br/>        sns.kdeplot(values0, ax=ax[1], cumulative=True, label='Neg')<br/>        sns.kdeplot(values1, ax=ax[1], cumulative=True, label='Pos')<br/>        sns.boxplot(data=train, x=Y, y=ft, ax=ax[2])</span><span id="4701" class="nk kl hi nz b fi oh oe l of og">ax[0].set_title('PDF of '+ft+' for Class 0')<br/>        ax[1].set_title('CDF of '+ft)<br/>        ax[2].set_title('Boxplot of '+ft)<br/>        ax[0].legend()<br/>        ax[1].legend()<br/>        plt.show()<br/>        print('-'*100)</span></pre><ul class=""><li id="c06a" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated"><strong class="ix hj"> EDA上的数字特性:</strong></li></ul><p id="fcbb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，让我们选出前15个数字特征。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="a35e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经得到了前15个特征，让我们对它们进行单变量分析。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><blockquote class="oi oj ok"><p id="16aa" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">15个特征中的大部分都有一个总的趋势。与负类相比，正类值的分布更广。负类具有相对较小的分布，如大多数要素的密集PDF和非常陡峭的CDF所示</p><p id="b917" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">平均值、标准偏差和中值都遵循上述趋势，所有这些特征的所有三个值都非常大，大约是正类的负类的10或100或有时甚至1000或更多倍。</p><p id="7bb1" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">特征<strong class="ix hj"> ci_000、aq_000、bj_000、ck_000、aa_000、dn_000、cq_000、ap_000、by_000、bx_000、bt_000、bb_000 </strong>具有正类和负类的独立iqr，如方框图所示。与负类相比，正类的CDF和pdf也更加分散。</p><p id="a58a" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">对于特征，<strong class="ix hj"> ai_000、al_000和am_0 </strong>，超过95%的数据点具有等于或非常接近0的负类值。</p></blockquote><p id="eba2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们看看所选特性与类别标签的相关性。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">重要特征与类别标签的相关性分析。</figcaption></figure><blockquote class="oi oj ok"><p id="d7c8" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">特征<strong class="ix hj"> ci_000、aq_000、bj_000、ck_000、aa_000、dn_000、cq_000、ap_000、by_000、bx_000、bt_000、bb_000 </strong>在+0.5附近具有更高的相关性，这解释了为什么正类数据点比负类数据点具有更高的正值。</p><p id="afc8" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">从它们的单变量分析来看，具有大约0的大部分值的特征<strong class="ix hj"> am_0、al_000和ai_000 </strong>具有小于0.4的较小相关值。特征<strong class="ix hj"> ai_000 </strong>在0.11–0.13附近的所有特征中相关性最小。</p></blockquote><p id="12cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过对特性<strong class="ix hj"> ai_000 </strong>和其他顶级特性进行二元分析，来获得更多关于特性<strong class="ix hj">的信息。</strong></p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">特征的二元分析<em class="oo"> ai_000 </em></figcaption></figure><blockquote class="oi oj ok"><p id="1f73" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">对于大多数数据点，特征<strong class="ix hj"> ai_000 </strong>的值等于0。有一些数据点对于两个类都有非零值。</p><p id="6e18" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">该特征可以与其他重要特征一起用于预测。其他特征试图在其自身的轴上将两个类别分开，因为可以看出，对于大多数图来说，与负类别点相比，正类别点(橙色)在x轴上具有更高的值。</p></blockquote><ul class=""><li id="a7f0" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated"><strong class="ix hj">直方图上的EDA特征</strong></li></ul><p id="a82a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，让我们选择直方图特征的前15个特征。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">直方图特征中的特征选择</figcaption></figure><p id="8aaa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经得到了前15个特征，让我们对它们进行单变量分析。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">直方图特征的单变量分析</figcaption></figure><blockquote class="oi oj ok"><p id="df76" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">直方图特征也遵循同样的趋势。一般来说，与负类数据点相比，正类数据点具有更大的平均值、中间值和标准偏差，并且具有更高的分布。</p><p id="d68a" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">对于特征<strong class="ix hj">，ag_002、ag_001、cn_000、cn_001、az_000和ay_005 </strong>有超过95%的特征具有非常小的值(相对而言)为负类。</p><p id="12e3" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">此外，特征<strong class="ix hj"> ag_002、ag_003、ag_001、cn_000、cn_001和ay_005 </strong>的中值为0，表明对于负类，至少50%的值等于0。</p><p id="2a6e" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">从重要度图中可以看出，最重要的特征小于或等于0.03，只有两个特征，即<strong class="ix hj"> ag_002和ee_005 </strong>的值分别大于0.06和0.05。</p></blockquote><p id="b4ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们看看所选特性与类别标签的相关性。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">直方图特征与类别标签的相关性分析。</figcaption></figure><blockquote class="oi oj ok"><p id="d648" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">特征<strong class="ix hj"> ee_005，ag_003，ba_000，cn_001，ee_000，ba_003，cs_004，ba_004 </strong>相关性大于等于0.4。</p><p id="2e9f" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated"><strong class="ix hj"> ee_005 </strong>相关系数值最高，在0.49左右。</p><p id="61d0" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated"><strong class="ix hj"> ag_001和az_000 </strong>相关系数最低，分别为0.18和0.2左右。</p></blockquote><p id="5687" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于<em class="kc"> ag_001和az_000 </em>相关性最小，让我们使用散点图对这两个特征进行双变量分析，看看使用两个特征是否能改善什么。首先，让我们做一下<em class="kc"> ag_001 </em>的二元分析。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><blockquote class="oi oj ok"><p id="79e7" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">对于所有数据点来说，<strong class="ix hj"> ag_001 </strong>的大多数值都相对较小。</p><p id="88ef" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">这个特性的较大值都是针对正类的。</p></blockquote><p id="3876" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，是时候为特性<em class="kc"> az_000做同样的事情了。</em></p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">特征az_000的二元分析</figcaption></figure><blockquote class="oi oj ok"><p id="d166" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">特性<strong class="ix hj"> az_000 </strong>对于这两个类来说有很多交集。</p><p id="76fe" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">对于此功能，大多数值都很小。</p></blockquote><ul class=""><li id="7ac2" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated"><strong class="ix hj">所有特征的多元分析。</strong></li></ul><p id="319d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了进行<em class="kc">多变量分析，</em>我们将执行<strong class="ix hj"> <em class="kc"> t_SNE </em> </strong>并绘制结果。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">所有特征的t-SNE图</figcaption></figure><blockquote class="oi oj ok"><p id="d842" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">从t_SNE图中，我们可以看到负类点到处都是。然而，它们是在定义明确的集群中。</p><p id="c5a5" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">然而，正如我们在图中看到的，正类数据点也在聚类中，但是这些聚类与负类聚类相交很多。</p><p id="df03" class="iv iw kc ix b iy iz ja jb jc jd je jf ol jh ji jj om jl jm jn on jp jq jr js hb bi translated">在2D，有很多的混合，但是考虑到这些点存在于清晰可见的集群中，在更高的维度中，很有可能在两个类的集群之间得到分离。</p></blockquote><h1 id="c82b" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">缺失数据插补</h1><p id="988e" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">对于输入缺失数据，我们将使用以下策略:</p><ul class=""><li id="fdcc" class="li lj hi ix b iy iz jc jd jg mh jk mi jo mj js mg lq lr ls bi translated">或者缺失值少于5%的特征，我们将进行均值插补。</li><li id="697e" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js mg lq lr ls bi translated">对于缺失值在5%和15%之间的特征，我们将使用中位数插补，因为它对异常值具有鲁棒性。</li><li id="be78" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js mg lq lr ls bi translated">对于缺失值在15-70%之间的特征，我们将使用基于模型的插补。为此，我们将使用两种不同的技术</li></ul><blockquote class="mk"><p id="22a9" class="ml mm hi bd mn mo mp mq mr ms mt js dx translated"><strong class="ak"> MICE </strong> -通过链式方程进行多重插补是一种处理数据集中缺失数据的可靠、信息丰富的方法。该过程通过一系列迭代预测模型来估算数据集中的缺失数据。要了解更多关于老鼠的知识，请参考<a class="ae iu" href="https://www.youtube.com/watch?v=WPiYOS3qK70&amp;ab_channel=RachitToshniwal" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><p id="082e" class="ml mm hi bd mn mo mu mv mw mx my js dx translated">基于KNN的插补</p></blockquote><ul class=""><li id="4ed8" class="li lj hi ix b iy mz jc na jg op jk oq jo or js mg lq lr ls bi translated">对于缺失值超过70%的要素，我们会将其从数据集中完全删除。</li></ul><p id="445b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们执行缺失值插补。首先，我们将丢弃缺失值超过70%的特征，执行均值插补和中值插补。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="958c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注意:</strong> <em class="kc"> strategy_list </em>只是一个嵌套列表，包含4个不同的列表，包含基于上面定义的策略的特性名称。</p><p id="2824" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们对具有15-70%缺失值的特征执行MICE <em class="kc">插补</em>和基于KNN <em class="kc">的插补</em>，插补所有数据，然后保存由此形成的数据帧和对象。</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div></figure><p id="2376" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们从磁盘中加载这些对象，对测试数据集进行插补并保存它们。</p><h1 id="6a31" class="kk kl hi bd km kn mb kp kq kr mc kt ku kv md kx ky kz me lb lc ld mf lf lg lh bi translated">数据标准化</h1><p id="efc9" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg ly ji jj jk lz jm jn jo ma jq jr js hb bi translated">既然我们已经成功地估算了所有的数据并构建了所有的要素，那么是时候执行要素缩放了。对于特征缩放，我们将执行归一化。我们将对两个数据集进行归一化处理</p><figure class="ne nf ng nh fd ij"><div class="bz dy l di"><div class="ni nj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">标准化数据集</figcaption></figure><p id="8eae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇由两部分组成的博客的第一部分<em class="kc">到此结束。在第二篇博客中，我们将讨论建模部分和AWS EC2实例中最佳模型的部署。最后，总结这个解决方案。在此阅读第2部分<a class="ae iu" href="https://amansavaria.medium.com/predicting-a-failure-in-the-aps-of-a-scania-truck-using-machine-learning-part-2-271814dfebdd" rel="noopener"/>。</em></p></div></div>    
</body>
</html>