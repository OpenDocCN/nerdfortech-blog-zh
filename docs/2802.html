<html>
<head>
<title>Paper Explained — A Full-Image Full-Resolution End-to-End-Trainable CNN Framework for Image Forgery Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释——用于图像伪造检测的全图像全分辨率端到端可训练 CNN 框架</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/paper-explained-a-full-image-full-resolution-end-to-end-trainable-cnn-framework-for-image-f33771c97c60?source=collection_archive---------15-----------------------#2021-05-20">https://medium.com/nerd-for-tech/paper-explained-a-full-image-full-resolution-end-to-end-trainable-cnn-framework-for-image-f33771c97c60?source=collection_archive---------15-----------------------#2021-05-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9bb9" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">调整图像大小会导致对图像伪造检测至关重要的信息丢失；全分辨率网络更适合这项任务</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/3a5e129d27bfa6f712c8ee78d6c19505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SdtivoMmm783f8NKZjgeQA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">Noiseprint (Noiseprint:一款基于 CNN 的相机型号指纹<a class="ae jn" href="https://arxiv.org/abs/1808.08396" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1808.08396</a></figcaption></figure><h2 id="8e14" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">在本文中</h2><ul class=""><li id="9a82" class="km kn hi ko b kp kq kr ks jz kt kd ku kh kv kw kx ky kz la bi translated">Xception 用于从完整图像的小块中提取特征，而不需要任何大小调整。</li><li id="5124" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">使用各种池技术来执行特征聚合。</li><li id="dec9" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">完全连接的层用于图像级的伪造检测。</li><li id="ab7d" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">Noiseprint 是作为 RGB 波段的附加功能进行实验的。</li><li id="b5d4" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">梯度检查点用于网络的内存管理。</li><li id="5fbd" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">该网络是端到端可训练的(E2E)。</li></ul><p id="cd7c" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated"><a class="ae jn" href="https://scholar.google.com/citations?user=oIewU-0AAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">弗朗西斯科·马拉</a>是论文的第一作者。多媒体取证是他的研究领域之一。全文可在 https://arxiv.org/abs/1909.06751 的<a class="ae jn" href="https://arxiv.org/abs/1909.06751" rel="noopener ugc nofollow" target="_blank">找到。</a></p><h2 id="123f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">概述</h2><ul class=""><li id="0c37" class="km kn hi ko b kp kq kr ks jz kt kd ku kh kv kw kx ky kz la bi translated">介绍</li><li id="8de3" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">数据</li><li id="8d5a" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">提议的模型</li><li id="d9ab" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">损失函数</li><li id="98a5" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">性能指标</li><li id="cae8" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">结果</li><li id="a3bc" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">伪造本地化</li><li id="9eef" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">履行</li></ul><h1 id="79f8" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">介绍</h1><p id="64bf" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">典型的计算机视觉模型依赖于图像中的宏观模式。但是在图像取证的情况下，微图案非常重要。大多数 CNN 分类器都需要调整图像大小，这可能会破坏这些信息。因此，对于取证任务，需要避免调整图像大小。</p><div class="iy iz ja jb fd ab cb"><figure class="mj jc mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/2f65bd5c23537edd1c971470d57ebb1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*HoJqGJZ0voAnGtfgP4rJvQ.png"/></div></figure><figure class="mj jc mp ml mm mn mo paragraph-image"><img src="../Images/da1f457c5fe8fe75d80a2d975253ce49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*G4JpK5ikelODFHWhKSbr4w.png"/><figcaption class="jj jk et er es jl jm bd b be z dx mq di mr ms translated">调整大小前后的纹理差异。由于调整大小，信息丢失。</figcaption></figure></div><p id="adb7" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">然而，在不调整大小的情况下处理全尺寸图像在计算上是不可行的，这导致了 CNN 的流行。</p><p id="385a" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">可行的解决方案是，</p><ul class=""><li id="583d" class="km kn hi ko b kp li kr lk jz mt kd mu kh mv kw kx ky kz la bi translated">逐块查看完整图像</li><li id="7bc3" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">从面片中获取特征，面片数量因图像而异</li><li id="fb56" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">聚集这些特征以获得一致的特征维度，这成为特征描述符</li><li id="6265" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">最后，在聚合要素的基础上训练用于分类的完全连接的图层</li></ul><p id="70c2" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">在高层次上，这是本文遵循的方法。</p><h1 id="3a6f" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">数据</h1><p id="f0b5" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">本文使用合成数据以及取证研究社区中可用的数据进行培训和实验。下面分享一下列表，详情参考论文。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mw"><img src="../Images/7ef7bf53ed3fd92ee99e7b6cdd46ae53.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*UqZNEA9YTS7OTsD30MRjlA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用的数据集</figcaption></figure><h1 id="6bb2" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">提议的模型</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/97b6191cb467d7101797f117e76101b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JteWzyoZyPaiy8kmVhkgOQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">E2E:拟议的示范框架</figcaption></figure><p id="d091" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">重要的是要注意，这个模型不是设计来预测像素级的伪造，而是在图像标签。因此，该类表示图像(或图像的某个部分)是否是伪造的。在图像分类文献中，对于定位也是期望输出的情况，这也被称为弱监督。</p><p id="5dc3" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">但是，由于模型会查看补丁，因此它会了解哪些补丁与其他补丁相比更有区别，以便进行正确的预测。后来，这被证明是解释结果的有用信息。</p><h2 id="6ab6" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">特征抽出</h2><p id="ab6e" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">从输入图像</p><ul class=""><li id="8825" class="km kn hi ko b kp li kr lk jz mt kd mu kh mv kw kx ky kz la bi translated">使用异常从重叠面片中提取特征</li><li id="f2d3" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">此外，Noiseprint 与 RGB 波段一起作为功能添加。<em class="my">“噪声印迹是高通图像残留，通过专用网络提取”</em></li></ul><h2 id="23db" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">特征聚合</h2><p id="eaf9" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">要素聚合是通过一种或多种池化技术完成的，即最小值、最大值、平均值、平方平均值。注意，这些都是基于元素的操作。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/e67760b5d5eb7e5fd5503168d556a4f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*oNrle4jsIrMCtWI6PWSqYA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">汇集技术</figcaption></figure><p id="153e" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">本文中关于池化的有趣讨论描述了何时使用何种池化。引用下面的文章:</p><blockquote class="na nb nc"><p id="fb8f" class="lg lh my ko b kp li ij lj kr lk im ll nd lm ln lo ne lp lq lr nf ls lt lu kw hb bi translated"><em class="hi">“最合适的统筹方式取决于利益问题。当信息分布在整个图像上时，平均汇集是合理的，而当区别信息集中在局部区域时，最小或最大汇集更合适"</em></p></blockquote><h2 id="4698" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">决定</h2><p id="c211" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">最后，使用全连接层来解决分类问题。</p><h2 id="b654" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">内存管理</h2><p id="4103" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">模型实现使用梯度检查点来节省内存。你可以在由<a class="ng nh ge" href="https://medium.com/u/5511064b4364?source=post_page-----f33771c97c60--------------------------------" rel="noopener" target="_blank">雅罗斯拉夫·布拉托夫</a>撰写的名为<a class="ae jn" rel="noopener" href="/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9">让更大的网络适应内存</a>的优秀博客中读到它。</p><h2 id="e79d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">模型的设计选择</h2><ul class=""><li id="a2bf" class="km kn hi ko b kp kq kr ks jz kt kd ku kh kv kw kx ky kz la bi translated">用相应的噪声印迹波段增强的输入 RGB 波段</li><li id="03c5" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">作为特征提取器的例外</li><li id="0beb" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">通过包含所有类型的池进行聚合</li><li id="ba7b" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw kx ky kz la bi translated">两个完全连接的层，大小 FC1=512，FC2=256，用于执行最终分类。</li></ul><p id="58be" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">通过在验证集中展示性能，这些设计选择是合理的。结果如下表所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/dd3416a5efbb6051662b87bb9be99067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*0Z7RvlSVaXBM-cx6O__HWA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">第一行是选择的模型。随后的每一行都表示一个变更，您可以将其解读为“变更-&gt;原始”。</figcaption></figure><h2 id="7bc8" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">融合模型</h2><p id="208c" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">作者还创建了仅具有 RGB(E2E-RGB)、仅具有噪声印迹(E2E-NP)以及两者都作为输入(E2E-RGB+NP)的 e2e 模型的集合。他们使用三次预测的平均值作为最终结果。这被称为 E2E 聚变。</p><h1 id="dae4" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">损失函数</h1><p id="b42e" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">没有明确提及，因此可以假设标准二进制交叉熵损失用于训练网络。</p><h1 id="c696" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">性能指标</h1><p id="7b24" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">AUC 用作所有模型比较的性能指标。</p><h1 id="db78" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">结果</h1><p id="04b6" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">通过许多基准测试方法，作者表明，在许多情况下，使用不同输入(仅 RGB、仅 noiseprint 或两者结合)的端到端训练表现更好。E2E 融合在相对更多的情况下给出更强的性能。这些结果列在下表中，</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/8f571539d2b02e526ed6373b93adfbd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYo1TkL4x_gFcGs4wXr7Og.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">E2E 比较结果</figcaption></figure><h1 id="4d27" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">伪造本地化</h1><h2 id="3f50" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">激活图</h2><p id="ecd4" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">Grad-CAM(引导梯度加权类激活图)用于可视化使用激活图的结果。</p><p id="d99a" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">引用论文中的话，<em class="my">“没有操纵的时候，显著区域分散在整个图像上。相反，当拼接发生时，他们往往会专注于拼接对象的边界，这证明系统已经学会了查看这些补丁来做出决定。因此，当检测到伪造的图像时，这种激活提供了关于可能的操纵位置的提示。”</em></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/fb6d3885b6d020dcd6f0dc8e874af1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Td6mSpCuPIWEh63dPdsCZw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">示例图像(顶部)和激活图(底部)。原始图像在奇数列，伪造图像在偶数列。活动补丁以青色叠加到图像的灰度/红色版本上。</figcaption></figure><h2 id="85df" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">基于 ROI 的分析</h2><p id="c5f4" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">作者表明，当可疑活动区域被选择并再次通过网络时，它预测在伪造的情况下伪造的概率高，而在原始情况下得分低。</p><p id="3ea7" class="pw-post-body-paragraph lg lh hi ko b kp li ij lj kr lk im ll jz lm ln lo kd lp lq lr kh ls lt lu kw hb bi translated">考虑到网络是用弱标签(即图像级标签)进行本地化训练的，在本地化上的结果相当惊人！</p><h1 id="a5d6" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">履行</h1><p id="8bb8" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">你可以在 https://github.com/FrancescoMarra/E2E-ForgeryDetection 的<a class="ae jn" href="https://github.com/FrancescoMarra/E2E-ForgeryDetection" rel="noopener ugc nofollow" target="_blank">找到作者的实现</a></p><h1 id="6099" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">结束语</h1><p id="fa9b" class="pw-post-body-paragraph lg lh hi ko b kp kq ij lj kr ks im ll jz mg ln lo kd mh lq lr kh mi lt lu kw hb bi translated">这是一篇有很多细节的有趣论文。它解决了图像级标签的伪造检测问题，但最终的网络也显示出能够学习定位。更多细节请参考这篇论文，我强烈推荐阅读它。</p><h1 id="3fd5" class="lv jp hi bd jq lw lx ly ju lz ma mb jy io mc ip kc ir md is kg iu me iv kk mf bi translated">参考</h1><ol class=""><li id="db11" class="km kn hi ko b kp kq kr ks jz kt kd ku kh kv kw nl ky kz la bi translated">用于图像伪造检测的全图像全分辨率端到端可训练 CNN 框架(【https://arxiv.org/abs/1909.06751】T4)。</li><li id="5822" class="km kn hi ko b kp lb kr lc jz ld kd le kh lf kw nl ky kz la bi translated">Noiseprint:基于 CNN 的相机模型指纹(<a class="ae jn" href="https://arxiv.org/abs/1808.08396" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1808.08396</a>)</li></ol></div></div>    
</body>
</html>