# 自然语言处理中的文本预处理技术

> 原文：<https://medium.com/nerd-for-tech/text-preprocessing-techniques-in-nlp-9431de089582?source=collection_archive---------11----------------------->

![](img/f3d701efafed18734f069c88eb165377.png)

来源:[https://laptrinhx . com/NLP-text-预处理-步骤-工具-实例-3097989363/](https://laptrinhx.com/nlp-text-preprocessing-steps-tools-and-examples-3097989363/)

作为数据科学家，我们将文本数据用于各种任务，如情感分析、主题建模、机器翻译、对话生成等等。所有这些任务都需要大量数据，这些数据是用于训练模型的连续文本数据，我们通过由真人在各种平台上编写的 web 报废来获得这些数据。为了模型的最佳性能，我们的数据应该倾向于模型将要工作的任务。例如，如果我们对电影评论进行情感分析，我们最好的数据是用户在 IMDB 和其他来源上给出的电影评论。如果我们要对任何产品(比如说炊具)的评论进行情感分析，我们希望我们的数据是各种在线商店(比如 Flipkart 和亚马逊)的评论。

**为什么文本预处理很重要！！**

我们获得的真实世界的数据通常不适合直接训练模型。它太吵了，我们需要适当地清洁它，以便使它有用。众所周知，我们的计算机不太擅长处理文字，它处理的是数字。现在，不需要的字符或没有重要值的单词的存在将使系统关注那些单词，因为它们的数量可能比重要的单词多。例如，在情感分析或主题建模中，像“我”、“我们”、“是”、“是”等词。并不重要，但是如果我们看看我们的数据，这些是出现频率最高的词。因此，适当的文本预处理将在很大程度上提高我们的模型性能。

现在让我们从文本预处理的各个步骤开始。

1.  **处理表情符号**

我们要做的第一步是处理表情符号。现在，人们喜欢用表情符号来表达他们的感情。我们肯定希望在我们的数据中保留这一点。但是我们的系统无法处理表情符号。所以，我们需要将表情符号转换成文本。

**2。从数据中去除噪声**

为了消除噪声，我们将执行以下两个操作:

*   删除任何多余的空白。
*   删除所有存在的 HTML 标签。

**3。将重音字符转换成英文字符**

我们的数据可能包含许多重音字符，如 café中的“é”。这里，我们将把任何重音字符转换成英语字符。

**4。扩张收缩**

在我们的数据中，可能会有像“不能”、“不会”和“喜欢”这样的词。我们可以把这些转换成不能也不会使用下面的代码。我们将在本文中进一步了解为什么这一步很重要。

**5。移除数字**

这一步删除数字可能对一些应用有用，如情感分析，但对一些应用可能是致命的，如问答。假设我们的问题是“这个冰淇淋的价格是多少？”。所以我们的系统应该有这个数。无论如何，让我们看看如果需要，如何删除这些数字。

如果我们想保留这个数字，我们可以用这个把它从文本形式转换成数字形式。

**6。去掉标点符号**

标点符号在我们的数据中并不重要。我们将借助以下代码删除标点符号。

**7。规范化(小写)**

这是我们在 NLP 的几乎所有应用中遵循的基本步骤。这使得文本中的所有单词处于同一水平。

**8。符号化**

我们将把我们的文本转换成一个令牌列表。我们的模型通常使用这些令牌。

**9。移除停用词**

正如我们在本文前面讨论的，文本中使用了许多单词，但它们对我们的模型并不重要。我们称之为停用词。我们将从 nltk 库中导入这些停用词的列表。同样，我们可能希望根据我们的要求添加一些单词或从列表中删除一些单词。例如，“not”包含在停用词中。但是什么都不能改变整个句子的意思。“电影不好”会改成“电影好”。所以，我一般不喜欢删除一些停用词。把“不能”扩展成“不可以”的用法来了，因为我们想去掉“可以”，但又想保留“不”。我将在这里从 nltk 导入停用词，然后我们将制作我们自己的自定义停用词列表。如果第一次使用 nltk.download('停用字词')，您可能需要下载停用字词

**10。词汇化和词干化**

词汇化和词干化都是用来获得单词的基本形式，并删除任何不必要的前缀和后缀。词汇化倾向于获取实际的英语单词，但是词干化对单词来说太苛刻了，会删除任何常见的前缀或后缀，如“ing”或“es”。我个人不喜欢词干，因为很多时候我们找不到真正的英语单词。在大多数情况下，单独使用词汇化似乎可以很好地工作。但是在这里，我们将同时寻找词干化和词干化。让我们使用两个著名的库 nltk 和 spacy 来比较哪一个性能更好。

您可能需要运行`nltk.download('wordnet')`

让我们看看使用 nltk 的词干。Spacy 其实对词干没有任何作用。惊讶！我也是。但是 Lemmatizer 似乎非常适合 spacy，它实际上不需要词干。

这就是文本预处理的全部内容。我试图涵盖所有可以完成的处理。不过，我可能漏掉了一些。现在，它取决于我们的应用程序和数据集，我们希望保留有用的信息，不想丢失任何东西。

来源:

 [## Lemmatizer spaCy API 文档

### 词汇化组件的管道组件，使用基于词性的规则将基本形式分配给标记…

空间. io](https://spacy.io/api/lemmatizer) [](https://towardsdatascience.com/text-preprocessing-with-nltk-9de5de891658) [## 用 NLTK 进行文本预处理

### 使用词干化和词汇化用 NLTK 库预处理样本语料库的详细演练。

towardsdatascience.com](https://towardsdatascience.com/text-preprocessing-with-nltk-9de5de891658) [](https://www.geeksforgeeks.org/text-preprocessing-in-python-set-1/) [## Python | Set - 1 - GeeksforGeeks 中的文本预处理

### 先决条件:自然语言处理简介每当我们有文本数据，我们需要应用几个预处理步骤，以…

www.geeksforgeeks.org](https://www.geeksforgeeks.org/text-preprocessing-in-python-set-1/) [](https://laptrinhx.com/nlp-text-preprocessing-steps-tools-and-examples-3097989363/) [## 自然语言处理文本预处理:步骤、工具和例子

### 为自然语言处理任务预处理文本的标准逐步方法。文本数据无处不在，从你的日常…

laptrinhx.com](https://laptrinhx.com/nlp-text-preprocessing-steps-tools-and-examples-3097989363/)