<html>
<head>
<title>Stroke Prediction &amp; Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">中风预测和不平衡数据</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/stroke-prediction-imbalanced-data-b6c406a81b8a?source=collection_archive---------1-----------------------#2021-03-19">https://medium.com/nerd-for-tech/stroke-prediction-imbalanced-data-b6c406a81b8a?source=collection_archive---------1-----------------------#2021-03-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/65128afcf15470df00b010ece1af9198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XklfbFzk7iMFEhLTk6QTpg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">所有图片均由PixaBay.com提供</figcaption></figure><p id="8838" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们都曾经历过——在我们开始改变之前，我们都曾感受过那种恐惧。value_counts()。</p><p id="ff38" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们很少能满足于找到一个50/50的二元目标。很少，我们可能会看到60%的0和40%的1。但当我们有一百万个0，只有少数1时，会发生什么呢？好吧，不要放弃希望，当然也不要相信你的第一个模型有98%的准确性！</p><p id="840b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于这个演练，我们将使用<a class="ae js" href="https://www.kaggle.com/fedesoriano/stroke-prediction-dataset" rel="noopener ugc nofollow" target="_blank">中风预测数据集，它可以在Kaggle </a>上找到。现在，也将标准库导入到您的笔记本中。我们将快速完成EDA和准备工作。如果你感到迷茫，看看这本<a class="ae js" rel="noopener" href="/nerd-for-tech/a-beginners-guide-to-your-first-classification-f8547d679411">分类初学者指南</a>。</p><p id="f35b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们要做的第一件事是读入数据并做一些EDA:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="fa30" class="kc kd hi jy b fi ke kf l kg kh">df = pd.read_csv('./data/healthcare-dataset-stroke-data.csv')</span><span id="a554" class="kc kd hi jy b fi ki kf l kg kh">df.info()</span><span id="6abe" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 5110 entries, 0 to 5109<br/>Data columns (total 12 columns):<br/> #   Column             Non-Null Count  Dtype  <br/>---  ------             --------------  -----  <br/> 0   id                 5110 non-null   int64  <br/> 1   gender             5110 non-null   object <br/> 2   age                5110 non-null   float64<br/> 3   hypertension       5110 non-null   int64  <br/> 4   heart_disease      5110 non-null   int64  <br/> 5   ever_married       5110 non-null   object <br/> 6   work_type          5110 non-null   object <br/> 7   Residence_type     5110 non-null   object <br/> 8   avg_glucose_level  5110 non-null   float64<br/> 9   bmi                4909 non-null   float64<br/> 10  smoking_status     5110 non-null   object <br/> 11  stroke             5110 non-null   int64  <br/>dtypes: float64(3), int64(4), object(5)<br/>memory usage: 479.2+ KB</span></pre><p id="746c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们在这里看到的第一件事是身体质量指数的缺失值。我没有医学背景，无法诚实地评价这些价值，所以现在，我们将放弃它们。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="6f1f" class="kc kd hi jy b fi ke kf l kg kh">df.dropna(subset = ['bmi'], inplace = True)</span></pre><p id="a611" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，让我们仔细看看我们的对象列，并想出一个转换它们的策略。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3a05" class="kc kd hi jy b fi ke kf l kg kh">text_cols = ['gender', 'ever_married', 'work_type',<br/>             'Residence_type', 'smoking_status']</span><span id="edfa" class="kc kd hi jy b fi ki kf l kg kh">[print(df[i].unique()) for i in df[text_cols]]</span><span id="4e00" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>['Male' 'Female' 'Other']<br/>['Yes' 'No']<br/>['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']<br/>['Urban' 'Rural']<br/>['formerly smoked' 'never smoked' 'smokes' 'Unknown']</span></pre><p id="5f1c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在让我们采取阻力最小的方法，对这些对象进行一些简单的二进制转换。为了使事情变得更简单，我们将把smoking_status变量组合成吸烟者与非吸烟者。我们稍后将保存的唯一类别是work_type。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="6575" class="kc kd hi jy b fi ke kf l kg kh">df['gender'] = np.where(df['gender'] == 'Male', 1, 0)</span><span id="73fc" class="kc kd hi jy b fi ki kf l kg kh">df['ever_married'] = np.where(df['ever_married'] == 'Yes', 1, 0)</span><span id="0988" class="kc kd hi jy b fi ki kf l kg kh">df['Residence_type'] = np.where(df['Residence_type'] == 'Urban', 1, 0)</span><span id="5263" class="kc kd hi jy b fi ki kf l kg kh">df['smoking_status'] = np.where(((df['smoking_status'] == 'smokes') | (df['smoking_status'] == 'formerly smoked')), 1, 0)</span></pre><p id="0738" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你和我一样，你会迫不及待地向量化work_type。对于这个任务，我推荐SKLearn的LabelEncoder。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="359b" class="kc kd hi jy b fi ke kf l kg kh">from sklearn.preprocessing import LabelEncoder</span><span id="881a" class="kc kd hi jy b fi ki kf l kg kh">le = LabelEncoder()</span><span id="abcc" class="kc kd hi jy b fi ki kf l kg kh">df['work_type'] = le.fit_transform(df['work_type'])</span></pre><p id="157f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从上面看我们的工作:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5cf1" class="kc kd hi jy b fi ke kf l kg kh">[print(df[i].unique()) for i in df[text_cols]]</span><span id="81d9" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>[1 0]<br/>[1 0]<br/>[2 3 0 4 1]<br/>[1 0]<br/>[1 0]</span></pre><p id="70f5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在是关键时刻了。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="b655" class="kc kd hi jy b fi ke kf l kg kh">df.stroke.value_counts()</span><span id="a8f1" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>0    4700<br/>1     209<br/>Name: stroke, dtype: int64</span></pre><p id="15b9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">相当不平衡！但这就是我们在这里的原因。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="dc4e" class="kc kd hi jy b fi ke kf l kg kh">sns.displot(df.stroke);</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kj"><img src="../Images/0ea3a2d8e96d6c55fa5a0b9d52b649a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*6h6X-nbU4vSlZ1aRNcnpIQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">这并没有让我们感觉好多少，是吗？</figcaption></figure><p id="3e6a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在平衡我们的目标之前，我们还有几个预处理步骤。接下来，让我们使用来自SKLearn的隔离森林来移除连续变量身体质量指数和血糖水平的一些异常值。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="d828" class="kc kd hi jy b fi ke kf l kg kh">from sklearn.ensemble import IsolationForest</span><span id="13db" class="kc kd hi jy b fi ki kf l kg kh">iso = IsolationForest(n_estimators = 1000, contamination = 0.03)<br/>  # the contamination value determines the outlier cut-off value<br/>  # we can adjust this value to ensure we do not further <br/>  # imbalance our target</span><span id="5178" class="kc kd hi jy b fi ki kf l kg kh">outs = pd.Series(iso.fit_predict(df[['bmi', 'avg_glucose_level']]),<br/>                 name = 'outliers')</span><span id="5501" class="kc kd hi jy b fi ki kf l kg kh">outs.value_counts()</span><span id="3f50" class="kc kd hi jy b fi ki kf l kg kh">output:<br/> 1    4761<br/>-1     148<br/>Name: outliers, dtype: int64</span></pre><p id="a640" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们为异常值标识符创建一个新的列，删除异常值，并看看它是如何影响我们的目标的。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="dc85" class="kc kd hi jy b fi ke kf l kg kh">df = pd.concat([outs.reset_index(), df.reset_index()], axis = 1,<br/>               ignore_index = False).drop(columns = 'index')</span><span id="761e" class="kc kd hi jy b fi ki kf l kg kh">df = df[df['outliers'] == 1]</span><span id="7d6e" class="kc kd hi jy b fi ki kf l kg kh">df['stroke'].value_counts()</span><span id="1e03" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>0    4564<br/>1     197<br/>Name: stroke, dtype: int6</span></pre><p id="8941" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这实际上平衡了一些类！但是我们必须小心不要删除重要的或有意义的数据点，所以我们将在运行几个模型后重新评估我们的污染值。</p><p id="f539" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，让我们通过标准化数值和定义变量来完成预处理。(注意:我们可以使用make-column-selector和transformer在一个管道中实现所有这些。)</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="6f60" class="kc kd hi jy b fi ke kf l kg kh">from sklearn.preprocessing import StandardScaler</span><span id="baad" class="kc kd hi jy b fi ki kf l kg kh">ss = StandardScaler()</span><span id="9b6b" class="kc kd hi jy b fi ki kf l kg kh">num_cols = ['age', 'avg_glucose_level', 'bmi']</span><span id="b2e8" class="kc kd hi jy b fi ki kf l kg kh">df[num_cols] = ss.fit_transform(df[num_cols])</span><span id="98c3" class="kc kd hi jy b fi ki kf l kg kh">X = df.drop(columns = ['stroke', 'id', 'outliers'])<br/>y = df.stroke</span><span id="949f" class="kc kd hi jy b fi ki kf l kg kh">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                              stratify =y)</span></pre><p id="6838" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">有趣的是:建模。</p><p id="55f6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将需要一个基线模型来比较我们以后的平衡行为。为此，我通常会建议从逻辑回归开始，但是已经浪费了一天时间来尝试和调整该数据集的不同模型，我将建议使用随机森林分类器。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="a39b" class="kc kd hi jy b fi ke kf l kg kh">rf = RandomForestClassifier()</span><span id="0897" class="kc kd hi jy b fi ki kf l kg kh">rf.fit(X_train, y_train)</span><span id="f9bb" class="kc kd hi jy b fi ki kf l kg kh">y_pred = rf.predict(X_test)</span><span id="65e6" class="kc kd hi jy b fi ki kf l kg kh">def classification_eval(y_test, y_pred):<br/>    print(f'accuracy  = {np.round(accuracy_score(y_test,<br/>                                           y_pred), 3)}')<br/>    print(f'precision = {np.round(precision_score(y_test,<br/>                                           y_pred), 3)}')<br/>    print(f'recall    = {np.round(recall_score(y_test, <br/>                                           y_pred), 3)}')<br/>    print(f'f1-score  = {np.round(f1_score(y_test, y_pred), 3)}')<br/>    print(f'roc auc   = {np.round(roc_auc_score(y_test, <br/>                                           y_pred), 3)}')<br/>    print(f'null accuracy = {round(max(y_test.mean(), <br/>                             1 - y_test.mean()), 2)}')</span><span id="d07c" class="kc kd hi jy b fi ki kf l kg kh">classification_eval(y_test, y_pred)</span><span id="2a1d" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>accuracy  = 0.96<br/>precision = 0.0<br/>recall    = 0.0<br/>f1-score  = 0.0<br/>roc auc   = 0.5<br/>null accuracy = 0.96</span></pre><p id="90d2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">96%的准确率！相比之下……零模型的准确率为96%。准确性在这里不是一个很好的衡量标准，因此，Kaggle使用f-1对该数据集的模型进行评分。我们的f1分数为0.0，我不认为这会让我们登上排行榜。</p><p id="d378" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们现在有一个0.0的f-1基线分数要打破。我认为这是可以实现的。为此，我们将利用来自<a class="ae js" href="https://pypi.org/project/imbalanced-learn/" rel="noopener ugc nofollow" target="_blank"> imblearn库</a>的工具。</p><p id="c3d0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从imblearn库文档:</p><p id="30ff" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">重采样技术分为两类:</p><ol class=""><li id="8a5a" class="kk kl hi iw b ix iy jb jc jf km jj kn jn ko jr kp kq kr ks bi translated">对多数类欠采样。</li><li id="86b2" class="kk kl hi iw b ix kt jb ku jf kv jj kw jn kx jr kp kq kr ks bi translated">对少数民族阶层进行过度采样。</li><li id="c25a" class="kk kl hi iw b ix kt jb ku jf kv jj kw jn kx jr kp kq kr ks bi translated">结合过采样和欠采样。</li><li id="4137" class="kk kl hi iw b ix kt jb ku jf kv jj kw jn kx jr kp kq kr ks bi translated">创建整体平衡集。</li></ol><p id="4a08" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们的第一次尝试中，我们将利用带有默认参数的随机过采样器，这是最简单的策略。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="7755" class="kc kd hi jy b fi ke kf l kg kh">from imblearn.over_sampling import RandomOverSampler</span><span id="2382" class="kc kd hi jy b fi ki kf l kg kh">rs = RandomOverSampler()</span><span id="33f6" class="kc kd hi jy b fi ki kf l kg kh">X, y = rs.fit_resample(X, y)</span><span id="91cd" class="kc kd hi jy b fi ki kf l kg kh">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                             stratify = y)</span><span id="75e2" class="kc kd hi jy b fi ki kf l kg kh">rf = RandomForestClassifier()<br/>rf.fit(X_train, y_train)</span><span id="45cd" class="kc kd hi jy b fi ki kf l kg kh">y_pred = rf.predict(X_test)</span><span id="a5e0" class="kc kd hi jy b fi ki kf l kg kh">classification_eval(y_test, y_pred)</span><span id="5094" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>accuracy  = 0.994<br/>precision = 0.988<br/>recall    = 1.0<br/>f1-score  = 0.994<br/>roc auc   = 0.994<br/>null accuracy = 0.5</span></pre><p id="9147" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">RandomOverSampler工作得非常好，以至于我花了大约4个小时试图解决我的工作问题，确信测试数据已经泄露了。让我们尝试更多的技巧，但是f-1的0.994分将很难被打破。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="52ce" class="kc kd hi jy b fi ke kf l kg kh">from imblearn.over_sampling import SMOTE</span><span id="13f9" class="kc kd hi jy b fi ki kf l kg kh">smote = SMOTE()</span><span id="feaa" class="kc kd hi jy b fi ki kf l kg kh">X, y = smote.fit_resample(X, y)</span><span id="febb" class="kc kd hi jy b fi ki kf l kg kh">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                             stratify = y)</span><span id="d2e3" class="kc kd hi jy b fi ki kf l kg kh">rf = RandomForestClassifier()<br/>rf.fit(X_train, y_train)</span><span id="be9b" class="kc kd hi jy b fi ki kf l kg kh">y_pred = rf.predict(X_test)</span><span id="9772" class="kc kd hi jy b fi ki kf l kg kh">classification_eval(y_test, y_pred)</span><span id="23e2" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>accuracy  = 0.948<br/>precision = 0.925<br/>recall    = 0.975<br/>f1-score  = 0.949<br/>roc auc   = 0.948<br/>null accuracy = 0.5</span></pre><p id="b609" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">与我们的基线模型相比，有了相当可观的改进，但性能不如RandomOverSampler。</p><p id="d3e8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">注意:如果每次拟合都得到相同的指标，那是因为我们需要通过重新运行上面的单元格来重新定义变量。</p><p id="b134" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">另一项技术:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="e499" class="kc kd hi jy b fi ke kf l kg kh">from imblearn.over_sampling import ADASYN</span><span id="408c" class="kc kd hi jy b fi ki kf l kg kh">ada = ADASYN()</span><span id="718f" class="kc kd hi jy b fi ki kf l kg kh">X, y = ada.fit_resample(X, y)</span><span id="bc70" class="kc kd hi jy b fi ki kf l kg kh">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                             stratify = y)</span><span id="71f4" class="kc kd hi jy b fi ki kf l kg kh">rf = RandomForestClassifier()<br/>rf.fit(X_train, y_train)</span><span id="82aa" class="kc kd hi jy b fi ki kf l kg kh">y_pred = rf.predict(X_test)</span><span id="d736" class="kc kd hi jy b fi ki kf l kg kh">classification_eval(y_test, y_pred)</span><span id="ce9b" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>accuracy  = 0.933<br/>precision = 0.907<br/>recall    = 0.964<br/>f1-score  = 0.935<br/>roc auc   = 0.933<br/>null accuracy = 0.5</span></pre><p id="4401" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后一次尝试:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="a65f" class="kc kd hi jy b fi ke kf l kg kh">from imblearn.over_sampling import SMOTENC</span><span id="d897" class="kc kd hi jy b fi ki kf l kg kh">sm = SMOTENC(categorical_features = [0, 2])<br/>     #here we have to define our categorical columns</span><span id="6b8c" class="kc kd hi jy b fi ki kf l kg kh">X, y = sm.fit_resample(X, y)</span><span id="e850" class="kc kd hi jy b fi ki kf l kg kh">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                             stratify = y)</span><span id="8e86" class="kc kd hi jy b fi ki kf l kg kh">rf = RandomForestClassifier()<br/>rf.fit(X_train, y_train)</span><span id="9b60" class="kc kd hi jy b fi ki kf l kg kh">y_pred = rf.predict(X_test)</span><span id="fdb4" class="kc kd hi jy b fi ki kf l kg kh">classification_eval(y_test, y_pred)</span><span id="3834" class="kc kd hi jy b fi ki kf l kg kh">output:<br/>accuracy  = 0.94<br/>precision = 0.917<br/>recall    = 0.968<br/>f1-score  = 0.942<br/>roc auc   = 0.94<br/>null accuracy = 0.5</span></pre><p id="550a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">与基线相比又一个巨大的进步，但仍然比不上我们的第一次尝试。我们可以尝试调整采样技术，并调整我们的分类器的超参数(这是我已经尝试过的，你可以在我的<a class="ae js" href="https://github.com/csinnott0219" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中看到)，但我仍然不认为我们会打破我们最初的f-1分数0.994。</p><p id="a8dd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们通过可视化我们的一些结果来结束。我建议在您的笔记本中创建一个新的部分，或者从一个新的笔记本开始，只包含最佳性能的模型，以便在我们评估时保持简单。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="22f3" class="kc kd hi jy b fi ke kf l kg kh">plot_confusion_matrix(rf, X_test, y_test);</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/341bba7ea67333c5ddcd0215d3d7acdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*P_vYA6BvBch7_Eg-PsYLbw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">假阴性比假阳性多——对健康预测不理想，这是我们想要调整的。</figcaption></figure><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5de1" class="kc kd hi jy b fi ke kf l kg kh">y_pred_prob = model.predict_proba(X_test)</span><span id="813b" class="kc kd hi jy b fi ki kf l kg kh">sns.displot(y_pred_prob[:, 1]);<br/>plt.title('Histogram of predicted probabilities');</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/006b3b37a3ac53835a957d93e4e7539a.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*CyRtHP5oAuc1qAT654Gbcg.png"/></div></figure><p id="aee6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，特征提取:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="aee0" class="kc kd hi jy b fi ke kf l kg kh">feat_names = [i for i in X_train]<br/>classed = [i for i in y_train]<br/>feat_import_df = pd.DataFrame({'importances': model.feature_importances_, <br/>      'name': feat_names}).sort_values('importances')</span><span id="d5ec" class="kc kd hi jy b fi ki kf l kg kh">x = feat_import_df['importances'].tail(9)<br/>y = feat_import_df['name'].tail(9)<br/>sns.barplot(x = x, y = y).set_title('Top ranking features by importance');</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es la"><img src="../Images/a0d55507494351156686454579d23e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*muLoXwsw-FlPYdzAfL2NtA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">看到特性的重要性，谁不兴奋呢？</figcaption></figure><p id="c4c4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">上面我们可以看到年龄、平均血糖水平和身体质量指数是预测中风的最重要因素，f-1值为0.994，我们对这些发现相当有信心。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f888fff75e27adf759214d1a2993dc2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z75HdU7YfEq2Qjbge6v08Q.jpeg"/></div></div></figure><p id="bf69" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">感谢阅读！我希望下一次你要检查你的值计数时，你会感到自信，你甚至可以对最不平衡的数据进行分类。</p></div></div>    
</body>
</html>