<html>
<head>
<title>A Self Case Study on Road Damage Detection &amp; Classification using State-of-the-art AI Solutions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用最先进的人工智能解决方案进行道路损坏检测和分类的自我案例研究</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/a-self-case-study-on-road-damage-detection-classification-using-state-of-the-art-ai-solutions-a3daed88e6f9?source=collection_archive---------2-----------------------#2021-05-14">https://medium.com/nerd-for-tech/a-self-case-study-on-road-damage-detection-classification-using-state-of-the-art-ai-solutions-a3daed88e6f9?source=collection_archive---------2-----------------------#2021-05-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ffc5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">一个阳光明媚的星期天，长长的假期，清新的空气掠过，我们还错过了什么？是啊！！长驱动</em>🚗<em class="jd">。但是这个甜蜜的梦会让你想到什么呢？我有你，交通，俚语，当然还有坑坑洼洼。对于所有生活在印度的人来说，坑坑洼洼完全不需要介绍。尺寸可能会因地点而异，但我们无法避免坑洞，尤其是在这个国家。责怪制度或个人不会有任何好处，也不会避免我们面临的</em> <a class="ae je" href="https://gomechanic.in/blog/road-hazards-in-india-reasons/" rel="noopener ugc nofollow" target="_blank"> <em class="jd">危险</em> </a> <em class="jd">！请继续阅读，找出可以提出的解决方案，以便在适当的时候采取适当的措施。</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/474ec735d0dd1601c96a9df4b7399211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hPqGKjQT8SJ0Iy3RT6LY8Q.jpeg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">坑洞可能看起来很小，但可能造成大灾难。参考号:<a class="ae je" href="https://unsplash.com/photos/-TQUERQGUZ8" rel="noopener ugc nofollow" target="_blank"> unsplash </a></figcaption></figure><h1 id="0bb1" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">目录</h1><ol class=""><li id="8561" class="kt ku hi ih b ii kv im kw iq kx iu ky iy kz jc la lb lc ld bi translated"><em class="jd">问题陈述</em></li><li id="c9c9" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">目标</em></li><li id="12f8" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">映射成深度学习任务</em></li><li id="e388" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">数据来源&amp;动机</em></li><li id="ed68" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">数据概述</em></li><li id="beb3" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">指标</em></li><li id="5bbf" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">第一次切割模型</em></li><li id="7f9d" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">探索性数据分析</em></li><li id="eeaf" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">移动互联网</em></li><li id="9cee" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd"> YOLO </em></li><li id="b7e7" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">最终管线</em></li><li id="2ca9" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">演示</em></li><li id="0c16" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">未来工作</em></li><li id="c07d" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">和我联系</em></li><li id="d815" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><em class="jd">参考文献</em></li></ol><h1 id="942d" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">1.问题陈述</h1><p id="1550" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">路面检查主要基于人工视觉观察和使用昂贵机器的定量分析。其中，目视检查方法不仅需要有经验的道路管理者，而且<strong class="ih hj">耗时且昂贵</strong>。此外，目视检查往往<strong class="ih hj">不一致且不可持续</strong>，这增加了风险。另一方面，缺乏必要资源的城市没有适当和经常地进行基础设施检查，增加了结构恶化带来的风险。相比之下，基于大规模检查的定量测定，如使用移动测量系统(MMS) (KOKUSAI KOGYO CO .，2016年)或激光扫描方法(Yu和Salari，2011年)被广泛采用。虽然定量检查非常准确，但进行这种全面检查的费用太高，特别是对缺乏必要财政资源的小城市而言。</p><h1 id="fe4c" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">2.目标</h1><p id="7066" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">2.1本案例研究是深度学习在对不同类型的道路损坏进行分类和检测方面的实际应用。</p><p id="e108" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.2这将有助于政府/市政当局提供一种高效且经济的维护方式，以保持道路的良好和安全状况。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lm"><img src="../Images/4a4e5909de5f8155a2c613e4cf897f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2vh3Frp1zViHKgw-GWgHnQ.jpeg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">礼貌:<a class="ae je" href="https://www.picfair.com/pics/04615076-a-road-damage-ahead-sign-full-of-bullet-holes-along-lonely-road-in-wyoming" rel="noopener ugc nofollow" target="_blank"> Picfair </a></figcaption></figure><h1 id="9756" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">3.映射到深度学习任务</h1><p id="fccd" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">将基于深度学习的端到端目标检测方法应用于路面破损检测问题，并验证其检测精度。特别是，我们检查我们是否可以通过应用最先进的物体检测方法来检测八类道路损坏。</p><h1 id="4bc8" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">4.数据来源和动机</h1><p id="872d" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated"><em class="jd">4.1</em><a class="ae je" href="https://arxiv.org/pdf/2008.13101.pdf" rel="noopener ugc nofollow" target="_blank">T5】研究论文 </a></p><p id="4ab3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者使用MobileNet作为他们的基本模型。他们从多个国家收集了数据，并根据该数据集创建了组合，并试图提出一个通用模型，该模型可用于检测任何其他国家的故障/问题。在这里，他们将问题分成8个不同的部分/ 8个不同的对象。他们利用了来自其他数据集的已训练模型(迁移学习),作者使用F1分数作为IoU阈值= 0.5的评估指标。</p><p id="14ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.2本案例研究的<a class="ae je" href="https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/IEEE_bigdata_RDD2020/train.tar.gz" rel="noopener ugc nofollow" target="_blank">数据源</a>由上述研究论文的作者共享。</p><p id="df8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.3 <a class="ae je" href="https://www.youtube.com/watch?v=T7o3xvJLuHk&amp;ab_channel=CodeEmporium" rel="noopener ugc nofollow" target="_blank">深度方向可分离卷积——更快的卷积！</a>，<a class="ae je" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">可分卷积的基本介绍</a></p><p id="b832" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的博客和视频中，我们了解了深度方向可分离卷积，它是如何工作的，深度方向和点方向卷积如何显著减少计算时间。这是Mobilenet背后的核心思想。</p><p id="b2b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.4 <a class="ae je" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank"> MobileNets:用于移动视觉应用的高效卷积神经网络</a></p><p id="78fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.5 <a class="ae je" href="https://towardsdatascience.com/custom-object-detection-using-tensorflow-from-scratch-e61da2e10087" rel="noopener" target="_blank">从头开始使用TensorFlow进行自定义对象检测</a></p><p id="4e4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.6 <a class="ae je" href="https://learnopencv.com/selective-search-for-object-detection-cpp-python/" rel="noopener ugc nofollow" target="_blank">对象检测的选择性搜索(C++ / Python) </a></p><p id="479b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.7 <a class="ae je" href="https://towardsdatascience.com/exploring-mobilenets-from-paper-to-keras-f01308ada818" rel="noopener" target="_blank">探索移动互联网:从纸张到Keras </a></p><p id="1851" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.8 <a class="ae je" rel="noopener" href="/@selfouly/r-cnn-3a9beddfd55a"> R-CNN(目标探测)。《最……|的初学者指南》作者:Sharif Elfouly </a></p><p id="9762" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.9 <a class="ae je" href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e" rel="noopener" target="_blank"> R-CNN，快速R-CNN，更快R-CNN，YOLO——目标检测算法</a></p><p id="259f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.10<a class="ae je" href="https://www.ccoderun.ca/programming/darknet_faq/" rel="noopener ugc nofollow" target="_blank">https://www.ccoderun.ca/programming/darknet_faq/</a></p><h1 id="34eb" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">5.数据概述</h1><p id="17ec" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">数据包括从印度、捷克、日本收集的图像。该数据集仅考虑了四种损坏类别，主要包括裂缝和坑洞，即D00、D10、D20和D40。请注意，与道路标记退化(如人行横道或白线模糊)评估相关的标准在几个国家之间存在显著差异。因此，这些类别被排除在研究之外，以便通用模型可以被训练成适用于监测一个以上国家的道路状况。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ln"><img src="../Images/f2e1d7dfb6f84f612b896dac69638593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XodLtlh7jlnWKk_dn2Zo8Q.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">Ref : <a class="ae je" href="https://nbviewer.jupyter.org/github/sekilab/RoadDamageDetector/blob/master/images/RoadDamageTypeDef.png" rel="noopener ugc nofollow" target="_blank">塞基拉布</a></figcaption></figure><h1 id="f42e" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">6.韵律学</h1><ul class=""><li id="961b" class="kt ku hi ih b ii kv im kw iq kx iu ky iy kz jc lo lb lc ld bi translated"><a class="ae je" href="https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173#:~:text=for%20Object%20Detection-,Jonathan%20Hui,value%20over%200%20to%201." rel="noopener"> <strong class="ih hj"> IoU(交集超过并集)</strong> </a> <strong class="ih hj"> : </strong> IoU测量两个边界之间的重叠。我们用它来衡量我们预测的边界与地面事实(真实物体的边界)有多少重叠。在一些数据集中，我们预定义了一个IoU阈值(比如0.5)来区分预测是真阳性还是假阳性。</li><li id="53e5" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated"><a class="ae je" href="https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a>【平均精度(mAP)】:为了在对象检测的背景下计算mAP，我们首先计算每个类的平均精度(AP)，然后计算所有类的平均值。给定真正值IoU检测次数&gt; 0.5</li></ul><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lp"><img src="../Images/38a8cca50bf8fe62d89b3cf19fe4e5a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1eFTrnNIS0umPKy9.jpg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">参考号:<a class="ae je" href="https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge" rel="noopener ugc nofollow" target="_blank">堆叠交换</a></figcaption></figure><p id="1d31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong> <code class="du lq lr ls lt b">mAP@[.5:.95]</code>表示不同IoU阈值上的平均mAP，从0.5到0.95，步长0.05 (0.5，0.55，0.6，0.65，0.7，0.75，0.8，0.85，0.9，0.95)。<code class="du lq lr ls lt b">mAP@[.5]</code>表示IoU = 0.5时的平均mAP</p><div class="lu lv ez fb lw lx"><a href="https://datascience.stackexchange.com/questions/25119/how-to-calculate-map-for-detection-task-for-the-pascal-voc-challenge" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">如何计算PASCAL VOC挑战赛检测任务的mAP？</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">回答你的问题:是的，你的方法对A，B和C是正确的。正确答案是B。解释…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">datascience.stackexchange.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://datascience.stackexchange.com/questions/16797/what-does-the-notation-map-5-95-mean/16813#16813" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">符号mAP@[.5:.95]是什么意思？</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">对于检测，确定一个对象提议是否正确的一个常用方法是交集对并集(IoU…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">datascience.stackexchange.com</p></div></div><div class="mg l"><div class="mm l mi mj mk mg ml jp lx"/></div></div></a></div><h1 id="22ae" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">7.首次切割模型</h1><p id="e89c" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">在这里，我们提出了第一个切割模型，它是基于我们想如何处理这个问题，以及我们脑海中首先出现的关于这个问题的最初实验想法。</p><p id="90fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.1.我们将与MobileNet报纸合作。</p><p id="cbdd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.2.将执行EDA，如果有任何垃圾数据，将进行数据清理</p><p id="89d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.3.将做预处理，以及像结构的文件位置适当，标签的图像等。</p><p id="b13a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.4.我将进行EDA，并尝试寻找任何重要的变量，以便我们可以改善IoU</p><p id="f034" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.5.将逐一探索DL模型，并评估结果。</p><h1 id="0caf" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">8.探索性数据分析</h1><p id="80ad" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">EDA是一种彻底的检查，旨在揭示数据集的底层结构，它对公司非常重要，因为它揭示了不容易显现的趋势、模式和关系。</p><p id="6196" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们不能仅仅通过搜集大量的数据来得出可靠的结论——相反，我们必须通过分析的镜头仔细地、有条不紊地看待它。</p><p id="5119" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对这些关键信息的“感觉”可以帮助你发现错误，揭穿假设，并理解不同关键变量之间的关系。这种认识可能最终导致选择合适的预测模型</p><p id="640d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> 8.1概述</em>T3】</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es mn"><img src="../Images/bf72f774583ffd17508fb26156e41cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*66WHJg6ouXNQRNcTbbN7Hw.png"/></div></figure><p id="4c57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">从数据中获得高层次的理解</em></p><ul class=""><li id="1f83" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc lo lb lc ld bi translated">数据集不平衡。</li><li id="39a6" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">与其他伤害等级相比，我们拥有D00、D20、D40等等级的更多数据。</li><li id="13a2" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">来自日本的损害类别D20比任何其他损害类别都多。</li></ul><p id="f2c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 8.2数据可视化</strong></p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="mr ms l"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">Ref : <a class="ae je" href="https://github.com/sekilab/RoadDamageDetector/blob/master/RoadDamageDatasetTutorial.ipynb" rel="noopener ugc nofollow" target="_blank">路面破损教程</a></figcaption></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mt"><img src="../Images/816fd5347c18666db57a031138e25fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nWg-K23fzNIyv2gXjrW6w.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">不同类型的道路损坏</figcaption></figure><p id="36dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 8.3关于数据的其他信息</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mu"><img src="../Images/fd856000d82a71ac33d72c680aede30c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3y121s0SmZFd7IMn-fzMgw.png"/></div></div></figure><p id="ea80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">观察结果</em></p><ul class=""><li id="9ece" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc lo lb lc ld bi translated">这些图像具有不同的大小。我们需要调整图像的大小，以加快处理速度</li></ul><p id="3cc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 8.4数据预处理</strong></p><ul class=""><li id="bba5" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc lo lb lc ld bi translated">调整图像及其相应边界框的大小。</li><li id="bcc6" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">增强数据平衡/上采样。</li><li id="97e8" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">相应的对象边界框应该相应地调整大小和增加。</li></ul><blockquote class="mv mw mx"><p id="6a80" class="if ig jd ih b ii ij ik il im in io ip my ir is it mz iv iw ix na iz ja jb jc hb bi translated"><strong class="ih hj">增强</strong>:图像数据增强是一种技术，可用于通过创建数据集中存在的图像的修改版本来人为扩展训练数据集的大小。增强技术可以创建图像的变体，这些变体可以提高fit模型将他们所学到的概括到新图像的能力</p></blockquote><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="mr ms l"/></div></figure><p id="4644" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">少量增强图像</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es nb"><img src="../Images/a8d5a8eb7dc77f1837ccddc7edf709e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Osw0PbEkN-dko02Cd_NnZQ.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">增强是创建同一图像的不同版本，这使得模型更加通用</figcaption></figure><h1 id="01e2" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">9.移动网络</h1><p id="e42b" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">MobileNets基于一种流线型架构，使用深度方向可分离卷积来构建轻量级深度神经网络。有两个简单的全局超级参数(宽度乘数和分辨率乘数)可以有效地在延迟和准确性之间进行权衡。这些超参数允许我们根据问题的约束条件为其应用选择合适的模型。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es nc"><img src="../Images/aff9e1da7e70ef378eea4d86ed96a14f.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*YogdrKSZr5anEt4imUluMQ.png"/></div></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es nd"><img src="../Images/8bf3501643fb16f8b92cee24176dd0eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*FsREer2ZERmTI7OGxUJ0gA.png"/></div></figure><p id="f85e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">张量板图追踪这个问题中的损耗和其他参数</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ne"><img src="../Images/5955cf6960c5e971b799444d964b6ef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJ635VEheyDvLqcVSaus4Q.png"/></div></div></figure><p id="eb03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">来自MobileNets的最终结果</em></p><ul class=""><li id="7d96" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc lo lb lc ld bi translated">mAP[IoU=0.50:0.95] : 0.054</li><li id="59cb" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">映射[IoU=0.50] : 0.118</li></ul><h1 id="d42b" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">10.YOLO</h1><p id="dd6d" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">在使用了第一个切割模型之后，我们继续尝试最先进的对象检测模型，即YOLOv3、YOLOv4和YOLOv5。由于YOLOv5比其他版本工作得更好，因此我们将只讨论v5。为了深入了解YOLOs的历史，我们推荐阅读YOLOv4的详细分析。简而言之，YOLO模型是一种快速紧凑的对象检测模型，相对于其大小而言，它的性能非常好，并且一直在稳步改进。</p><p id="ea00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1约洛夫5 </strong></p><p id="3653" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Darknet框架中，YOLOv4的最新版本有一些改进，为了避免版本冲突，它被重命名为YOLOv5。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es nf"><img src="../Images/9a365086083d946e13206119ed5b487b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*_nzpRagS5QbHjJnDsGkAew.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated"><em class="ng">另一幅物体检测过程(</em> <a class="ae je" href="https://arxiv.org/pdf/2004.10934.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ng">引文</em> </a> <em class="ng">出自YOLOv4) </em></figcaption></figure><p id="8217" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">YOLO网络由三个主要部分组成。</strong></p><p id="c709" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.1 </strong> <a class="ae je" href="https://blog.roboflow.com/glossary/#:~:text=backbone" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">主干</strong> </a> —在不同粒度下聚合并形成图像特征的卷积神经网络。在YOLO v5中，<a class="ae je" href="https://arxiv.org/abs/1911.11929" rel="noopener ugc nofollow" target="_blank">CSP——跨级局部网络</a>被用作主干，以从输入图像中提取丰富的信息特征。</p><p id="58fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.2 </strong> <a class="ae je" href="https://blog.roboflow.com/glossary/#:~:text=neck%20-" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">颈部</strong> </a> <strong class="ih hj"> — </strong>一系列层混合和组合图像特征，以将它们向前传递给预测。在YOLO v5 <a class="ae je" href="https://arxiv.org/abs/1803.01534" rel="noopener ugc nofollow" target="_blank">中，PANet </a>用于作为颈部以获得特征金字塔。有关要素金字塔的详细信息，请参考以下链接。欲了解更多信息，请访问<a class="ae je" rel="noopener" href="/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c">了解用于目标检测的特征金字塔网络(FPN) </a></p><p id="1391" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.3 </strong> <a class="ae je" href="https://blog.roboflow.com/glossary/#:~:text=head%20-" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">头部</strong> </a> <strong class="ih hj"> — </strong>从颈部消耗特征，采取盒和类预测步骤。在YOLO，v5模型的头部与之前的YOLO V3和V4版本相同。</p><p id="2afc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.4激活功能</strong>——YOLO V5作者决定采用泄漏ReLU和<a class="ae je" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> Sigmoid </a>激活功能。</p><p id="7880" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.5优化功能</strong> —对于YOLO v5中的优化功能，我们有两种选择:</p><ol class=""><li id="b7b3" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc la lb lc ld bi translated">新币</li><li id="d82b" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc la lb lc ld bi translated"><a class="ae je" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank">亚当</a></li></ol><p id="12b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在YOLO v5中，用于训练的默认优化函数是SGD。</p><p id="cf21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.6成本函数或损失函数</strong> —在YOLO家族中，有一种复合损失是基于目标得分、类别概率得分和边界框回归得分计算的。</p><p id="52c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Ultralytics使用PyTorch的<a class="ae je" href="https://pytorch.org/docs/master/generated/torch.nn.BCEWithLogitsLoss.html" rel="noopener ugc nofollow" target="_blank">二进制交叉熵和Logits Loss </a>函数来计算类别概率和对象分数的损失。</p><p id="f9f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.7结构</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es nh"><img src="../Images/a0f42a476d091f62c6968d8fd823f62f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJO1iLk3WVZ1Y8oLUkWruA.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">参考号:<a class="ae je" href="https://www.researchgate.net/figure/The-network-architecture-of-Yolov5-It-consists-of-three-parts-1-Backbone-CSPDarknet_fig1_349299852" rel="noopener ugc nofollow" target="_blank">研究之门</a></figcaption></figure><p id="e70e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 10.1.8一些预测图像</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ni"><img src="../Images/1fd3386018cdaeb9e2cccbfc1b2a673a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yeAMQCnV1O0bbxL9ZhrzOQ.jpeg"/></div></div></figure><p id="3d16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">10.1.9结果<strong class="ih hj"/></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es nj"><img src="../Images/0d35b0574db95a5f2f6d8d09e8421cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3sR2LUtqzewq3dbiooY3vg.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">我们数据的yolov5结果</figcaption></figure><p id="3364" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">yolov 5的最终结果:</em></p><ul class=""><li id="833d" class="kt ku hi ih b ii ij im in iq mo iu mp iy mq jc lo lb lc ld bi translated">mAP[IoU=0.50:0.95] : 0.175</li><li id="5082" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">映射[IoU=0.50] : 0.279</li></ul><h1 id="45d2" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">11.最终管道</h1><p id="b031" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">我们发现Yolov5在测试数据上表现更好。因此，我们将该模型的权重保存为最终模型。我们创建了一个数据管道，它将消费来自最终用户的有关道路损坏的图像或录制的视频，代码将通过类和概率的边界框展示图像/视频。</p><h1 id="89fa" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">12.演示</h1><p id="3262" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">在我们为模型创建最终管道后，我们在AWS中使用flask创建了一个web应用程序，用户必须传递道路损坏的图像或视频。</p><p id="6d42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:由于我们使用的是带CPU的云服务器(来自AWS的免费轮胎资源)，视频的干扰时间比图像多</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es nk"><img src="../Images/419cd6b53f811e94732845b6e1d34aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*gW5CK5RD_end_YtSs0afbw.gif"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">用于演示的已部署应用程序</figcaption></figure><h1 id="0629" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">13.未来的工作</h1><ul class=""><li id="ff36" class="kt ku hi ih b ii kv im kw iq kx iu ky iy kz jc lo lb lc ld bi translated">我们必须找到一种方法，将标签D00、D01替换为相应的损伤类型，如线性裂纹，并将其实时显示为标签，因为它对所有人都是可解释的。</li><li id="ce64" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">我们必须升级应用程序，以便它可以与直播流。</li><li id="b29f" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">其他增强技术可能也很有效。</li><li id="faf5" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">如果我们用更多的数据来训练模型，那将是有益的。</li><li id="6c98" class="kt ku hi ih b ii le im lf iq lg iu lh iy li jc lo lb lc ld bi translated">其他深度学习模型需要尝试。</li></ul><h1 id="87c6" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">14.与我联系</h1><p id="9a98" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq lj is it iu lk iw ix iy ll ja jb jc hb bi translated">以上代码可以在我的<a class="ae je" href="https://github.com/gokulhaldar/Road-Damage-Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GitHub </strong> </a>上找到。如有任何疑问、改进，可以通过<a class="ae je" href="https://www.linkedin.com/in/gokul-sakha-haldar/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> LinkedIn </strong> </a>联系我。</p><h1 id="ef68" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">15.参考</h1><div class="lu lv ez fb lw lx"><a href="https://www.appliedaicourse.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">应用课程</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">我们知道转行是多么具有挑战性。我们的应用人工智能/机器学习课程被设计为整体学习…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">www.appliedaicourse.com</p></div></div><div class="mg l"><div class="nl l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://github.com/sekilab/RoadDamageDetector" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">Seki lab/道路损坏检测器</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">2021-03-23]: IEEE大数据杯-gr DDC 2020:2020 IEEE大数据国际会议论文集…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">github.com</p></div></div><div class="mg l"><div class="nm l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://towardsdatascience.com/implementing-single-shot-detector-ssd-in-keras-part-ii-loss-functions-4f43c292ad2a" rel="noopener follow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">在Keras中实现单触发探测器(SSD ):第二部分——损失函数</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">在Keras中实现SSD丢失功能</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="nn l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://github.com/asetkn/Tutorial-Image-and-Multiple-Bounding-Boxes-Augmentation-for-Deep-Learning-in-4-Steps" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">asetkn/Tutorial-图像和多边界框-增强深度学习-4步</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">假设我们有图像来训练我们的深度神经网络。我们也有单独的PASCAL VOC格式的XML文件…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">github.com</p></div></div><div class="mg l"><div class="no l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a rel="noopener follow" target="_blank" href="/@quangnhatnguyenle/how-to-train-yolov3-on-google-colab-to-detect-custom-objects-e-g-gun-detection-d3a1ee43eda1"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">如何在Google Colab上训练YOLOv3检测自定义对象(例如:枪支检测)</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">一.导言</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">medium.com</p></div></div><div class="mg l"><div class="np l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a rel="noopener follow" target="_blank" href="/@thamqianyu96/quick-object-detection-yolo-7f2bbdaf6a6d"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">快速脏物检测(YOLO)</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">YOLOv3和YOLOv4代码实现</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">medium.com</p></div></div><div class="mg l"><div class="nq l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://blog.roboflow.com/yolov5-improvements-and-evaluation/#:~:text=The%20YOLOv5%20repository%20is%20a,then%20move%20forward%20to%20production" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">YOLOv5新版本-改进和评估</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">6月25日，Ultralytics发布了YOLOv5的首个正式版本。在本帖中，我们将讨论小说…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">blog.roboflow.com</p></div></div><div class="mg l"><div class="nr l mi mj mk mg ml jp lx"/></div></div></a></div><div class="lu lv ez fb lw lx"><a href="https://towardsai.net/p/computer-vision/yolo-v5%E2%80%8A-%E2%80%8Aexplained-and-demystified" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">YOLO V5 -解释和去神秘化</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">YOLO V5 -模型架构和技术细节解释从我上一篇关于YOLO V5的文章开始，我收到了多个…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">towardsai.net</p></div></div><div class="mg l"><div class="ns l mi mj mk mg ml jp lx"/></div></div></a></div><h2 id="96e6" class="nt jw hi bd jx nu nv nw kb nx ny nz kf iq oa ob kj iu oc od kn iy oe of kr og bi translated">今天到此为止。感谢阅读。欢迎在评论区分享你的反馈。</h2></div></div>    
</body>
</html>