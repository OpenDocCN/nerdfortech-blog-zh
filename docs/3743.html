<html>
<head>
<title>K-Nearest Neighbors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/k-nearest-neighbors-aac72032aaea?source=collection_archive---------6-----------------------#2021-06-22">https://medium.com/nerd-for-tech/k-nearest-neighbors-aac72032aaea?source=collection_archive---------6-----------------------#2021-06-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f37a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">k-最近邻是一种有监督的机器学习算法。它用于分类和回归。它根据k个最近的数据点预测输出。在该算法中，我们不从训练集学习，而是使用整个训练集来预测新数据点的输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/f1ea3bac78517b6ff34059584aeeb810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*Xs2TsUIbdycaMkw6Dp889w.png"/></div></figure><p id="5bf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们举一个分类的例子，其中我们有两个类A和b。为了预测一个新点(用红色显示)的类，我们考虑它的k-最近邻。如果k = 3，在最近的三个数据点中，有2个点属于B类，1个点属于a类，所以，我们可以说新的数据点属于B类。</p><p id="bc0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于回归，我们通过计算k个最近数据点的平均值或中值来预测连续输出值。</p><p id="f2a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两点之间的距离可以使用欧几里德距离、曼哈顿距离、汉明距离或闵可夫斯基距离来计算。</p><p id="d58f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">KNN数据准备</strong></p><ol class=""><li id="46bd" class="jl jm hi ih b ii ij im in iq jn iu jo iy jp jc jq jr js jt bi translated"><strong class="ih hj">特征缩放</strong>是必要的，因为这里我们找出了距离。因此，不同尺度的特征对输出的影响是不同的。</li><li id="73c8" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">应该没有<strong class="ih hj">丢失值</strong>，因为我们无法定位丢失特征的数据点。</li><li id="169f" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">如果有许多功能，KNN就不能很好地工作。因此，应该使用<strong class="ih hj">降维</strong>技术。</li></ol><p id="ef89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从头开始看看python实现。在这里，我们不会使用任何像sklearn这样的库。</p><p id="9787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入必要的库</strong></p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="c3f2" class="ke kf hi ka b fi kg kh l ki kj">import pandas as pd</span><span id="37d7" class="ke kf hi ka b fi kk kh l ki kj">import numpy as np</span><span id="8fd8" class="ke kf hi ka b fi kk kh l ki kj">import matplotlib.pyplot as plt</span><span id="fe20" class="ke kf hi ka b fi kk kh l ki kj">import seaborn as sns</span></pre><p id="22de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">加载数据集</strong></p><p id="5171" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用seaborn图书馆的iris数据集:</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="1245" class="ke kf hi ka b fi kg kh l ki kj">data = sns.load_dataset('iris')</span><span id="34b0" class="ke kf hi ka b fi kk kh l ki kj">data.head()</span></pre><p id="5be6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">编码目标变量</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kl"><img src="../Images/c007abeaadf1e07150ef326e1e46472d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*C_Bzjd3ZfEwHb3I8J_jvag.png"/></div></figure><h2 id="067c" class="ke kf hi bd km kn ko kp kq kr ks kt ku iq kv kw kx iu ky kz la iy lb lc ld le bi translated">特征缩放</h2><p id="f74b" class="pw-post-body-paragraph if ig hi ih b ii lf ik il im lg io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">应用规范化:</p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="d5d1" class="ke kf hi ka b fi kg kh l ki kj">for column in data.columns[:-1]:</span><span id="0643" class="ke kf hi ka b fi kk kh l ki kj">data[column] = ( data[column]-min(data[column]) ) / ( max(data[column])-min(data[column]) )</span></pre><h2 id="d075" class="ke kf hi bd km kn ko kp kq kr ks kt ku iq kv kw kx iu ky kz la iy lb lc ld le bi translated">分割独立和从属特征</h2><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="62b1" class="ke kf hi ka b fi kg kh l ki kj">X = data.iloc[:, :-1].values</span><span id="ee68" class="ke kf hi ka b fi kk kh l ki kj">Y = data.iloc[:, -1].values</span></pre><h2 id="09d7" class="ke kf hi bd km kn ko kp kq kr ks kt ku iq kv kw kx iu ky kz la iy lb lc ld le bi translated">Knn分类模型</h2><p id="0151" class="pw-post-body-paragraph if ig hi ih b ii lf ik il im lg io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated"><strong class="ih hj">使用成本图找到k的最佳值:</strong></p><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="0f79" class="ke kf hi ka b fi kg kh l ki kj">def knn_classification_model(dataidx, X, k):</span><span id="4842" class="ke kf hi ka b fi kk kh l ki kj"> temp = X[dataidx] - X</span><span id="9d54" class="ke kf hi ka b fi kk kh l ki kj"> temp = temp**2</span><span id="8eca" class="ke kf hi ka b fi kk kh l ki kj"> temp = np.sum(temp, axis=1)**(1/2)</span><span id="aa90" class="ke kf hi ka b fi kk kh l ki kj"> idx = np.argpartition(temp, k)</span><span id="b364" class="ke kf hi ka b fi kk kh l ki kj"> k_min_idx = Y[idx[1:k+1]]</span><span id="6d10" class="ke kf hi ka b fi kk kh l ki kj"> k_min_idx = pd.Series(k_min_idx)</span><span id="3464" class="ke kf hi ka b fi kk kh l ki kj"> res = k_min_idx.value_counts().index[0]</span><span id="dcba" class="ke kf hi ka b fi kk kh l ki kj"> return res</span><span id="212c" class="ke kf hi ka b fi kk kh l ki kj"># Find cost</span><span id="9efb" class="ke kf hi ka b fi kk kh l ki kj">def find_cost(y_pred, Y):<br/>  t = np.sum((y_pred - Y)**2)/len(Y)<br/>  return t</span><span id="7af4" class="ke kf hi ka b fi kk kh l ki kj"># <br/>cost = np.zeros(20)<br/>for k in range(1, 20):</span><span id="c070" class="ke kf hi ka b fi kk kh l ki kj">  y_pred = []</span><span id="859c" class="ke kf hi ka b fi kk kh l ki kj">  for i in range(len(data)):</span><span id="20bb" class="ke kf hi ka b fi kk kh l ki kj">  y_pred.append(knn_classification_model(i, X, k))</span><span id="0e91" class="ke kf hi ka b fi kk kh l ki kj">  cost[k] = find_cost(y_pred, Y)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lk"><img src="../Images/29bb06a48cd6954b1802f5b9ec7f7d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*9P-Zf5iulmjyCMPAe_unoA.png"/></div></figure><p id="5d37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">k = 8具有最小成本，即它是最佳值，因此在模型中使用该值:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/e1fafb07ce15258e9c08377fdc7aadbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*xrhq7pwnmqSqoxoXZ0GRBQ.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/1e7850a07eccc41f2218de39493e021f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*-rOtltsdFEHjq83_XT2x_Q.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/cd6cdc8bdb5589f7f91a2421192c2a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8AFFmQILI1NZFdCLiT0b4A.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/d9d0bdea47938e13abd981cd7f9355d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*HX0SW9B6tqBv2ikLfIiZeQ.png"/></div></figure><h2 id="c6b4" class="ke kf hi bd km kn ko kp kq kr ks kt ku iq kv kw kx iu ky kz la iy lb lc ld le bi translated">寻找准确性</h2><pre class="je jf jg jh fd jz ka kb kc aw kd bi"><span id="22d4" class="ke kf hi ka b fi kg kh l ki kj">accuracy = len(data.loc[y_pred==Y_label])/len(data)*100</span><span id="f864" class="ke kf hi ka b fi kk kh l ki kj">accuracy</span></pre><p id="cf39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们模型的准确率达到了98%。类似地，对于回归，我们将k个最近的数据点的平均值/中值。</p><p id="700d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这样，我们完成了我们的KNN算法。希望你觉得有用。如果你喜欢我的博客，那么看看我以前的一些博客:</p><ol class=""><li id="abaf" class="jl jm hi ih b ii ij im in iq jn iu jo iy jp jc jq jr js jt bi translated"><a class="ae lt" href="https://khushijain2810.medium.com/linear-regression-9fd219098405" rel="noopener">线性回归</a></li><li id="07e0" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated"><a class="ae lt" href="https://khushijain2810.medium.com/introduction-to-opencv-586e38d536fd" rel="noopener"> OpenCV </a></li><li id="17fb" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated">Seaborn </li><li id="68be" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated"><a class="ae lt" href="https://khushijain2810.medium.com/pandas-python-data-analysis-library-1d061c982fc8" rel="noopener">熊猫</a></li><li id="f3b3" class="jl jm hi ih b ii ju im jv iq jw iu jx iy jy jc jq jr js jt bi translated"><a class="ae lt" href="https://khushijain2810.medium.com/numpy-day-3-at-internity-foundation-efcef826e549" rel="noopener"> Numpy </a></li></ol><p id="77db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐学习！</p></div></div>    
</body>
</html>