<html>
<head>
<title>Dropping Constant Features using VarianceThreshold: Feature Selection -1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 VarianceThreshold 删除常量要素:要素选择-1</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/removing-constant-variables-feature-selection-463e2d6a30d9?source=collection_archive---------0-----------------------#2021-06-15">https://medium.com/nerd-for-tech/removing-constant-variables-feature-selection-463e2d6a30d9?source=collection_archive---------0-----------------------#2021-06-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="8212" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用 Python 变量阈值移除常量/准常量预测值的最直接指南</h2></div><p id="c5f8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">在本指南中，您将准确阅读在进行特征选择时移除恒定特征所需的内容。</strong></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/58d7ffb39c217b16d2f16dcfadb74cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dd-I5QQXspAmm7-I.jpg"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated"><a class="ae kj" href="https://www.walpaperlist.com/2020/01/beautiful-wallpaper-rainbow-rose.html" rel="noopener ugc nofollow" target="_blank">图像参考</a></figcaption></figure><p id="0e62" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kk">常量要素在数据集中的所有观测值中显示相似/单一值。这些特征不提供允许 ML 模型预测目标的信息。</em></p><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es kl"><img src="../Images/0b8523167410e0798240d9ad67b9b89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*xSKlEFsbIV3pgBgoK9GpdA.png"/></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">这里的 c、D 列是常量特征</figcaption></figure><p id="66da" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">预测因子的高方差:良好的指示</strong></p><p id="99aa" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">低方差预测值:对模型不利</strong></p><p id="7d6d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用 Sklearn 的方差阈值来丢弃常量特征。</p><p id="a6b3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">参考官方文件</strong>:<a class="ae kj" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . feature _ selection。VarianceThreshold.html</a></p><p id="981f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在我的 GitHub 上找到完整的代码文件和数据集:<a class="ae kj" href="https://github.com/shelvi31/Feature-Selection" rel="noopener ugc nofollow" target="_blank">https://github.com/shelvi31/Feature-Selection</a></p><h2 id="c186" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">差异阈值:</h2><p id="9b7d" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">方差阈值是一个要素选择器，用于从数据集中移除所有在建模中没有太大用处的低方差要素。</p><p id="f5be" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它只关注特征(x)，而不是期望的输出(y)，因此可以用于无监督学习。</p><p id="d029" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">阈值的默认值为 0</p><ul class=""><li id="bde5" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated">如果方差阈值= 0(移除恒定特征)</li><li id="78f9" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">如果方差阈值&gt; 0(移除准常数特征)</li></ul><h2 id="53c6" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">Python 实现:</h2><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="a27f" class="km kn hi mb b fi mf mg l mh mi">import pandas as pd<br/>import numpy as np</span><span id="baf9" class="km kn hi mb b fi mj mg l mh mi"># Loading data from train.csv file<br/>train_df = pd.read_csv("train data credit card.csv")<br/>train_df.head(5)</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl mk"><img src="../Images/766a5a6bb0497cbf06d98ab3aafcf528.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Vm9fYtaD6h8Vzm4jKSCSwQ.png"/></div></figure><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="a907" class="km kn hi mb b fi mf mg l mh mi">train_df.shape</span><span id="ccf6" class="km kn hi mb b fi mj mg l mh mi">(245725, 11)</span></pre><h2 id="1354" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">缩短庞大的数据集</h2><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="574b" class="km kn hi mb b fi mf mg l mh mi">train = train_df.loc[1:40000,:]<br/>train.shape</span><span id="504b" class="km kn hi mb b fi mj mg l mh mi">(40000, 11)</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl mk"><img src="../Images/9e68601206d21c81f92f939d53c7921a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jPhAP8abHJVWB3nw3MV60Q.png"/></div></figure><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="2518" class="km kn hi mb b fi mf mg l mh mi">#Filling Null values if any</span><span id="f8bc" class="km kn hi mb b fi mj mg l mh mi">train = train.fillna("None")</span></pre><h2 id="cdf3" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">删除 ID 列，定义目标</h2><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="86c6" class="km kn hi mb b fi mf mg l mh mi">train1 = train.drop(["ID","Is_Lead"],axis=1)<br/>y = train["Is_Lead"]</span></pre><p id="1af9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为方差阈值只能对数字数据起作用。我们需要首先转换另一个非整数/非浮点列的数据类型。为此，我们将使用一个顺序编码器。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ml"><img src="../Images/5f7afb7d984d4833788afc80877a0290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s02VooP4f-wZawKs.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated"><a class="ae kj" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fmedium.com%2Fanalytics-vidhya%2Ftypes-of-categorical-data-encoding-schemes-a5bbeb4ba02b&amp;psig=AOvVaw0ARUG45y3UZ9_hSZuzrEVJ&amp;ust=1623853386354000&amp;source=images&amp;cd=vfe&amp;ved=0CA0QjhxqFwoTCKDQvfbrmfECFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">图像参考:中等</a></figcaption></figure><h2 id="7dde" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">要查看每列中唯一值的数量:</h2><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="f534" class="km kn hi mb b fi mf mg l mh mi">train1.nunique(axis=0)</span><span id="90f9" class="km kn hi mb b fi mj mg l mh mi">Gender                     2<br/>Age                       62<br/>Region_Code               35<br/>Occupation                 4<br/>Channel_Code               4<br/>Vintage                   66<br/>Credit_Product             3<br/>Avg_Account_Balance    35278<br/>Is_Active                  2<br/>dtype: int64</span></pre><h2 id="b5e8" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">使用顺序编码器:阈值处理前需要</h2><p id="0eb7" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">在顺序编码中，每个唯一的类别值都被赋予一个整数值。比如“红”是 1，“绿”是 2，“蓝”是 3。这称为序数编码或整数编码，很容易逆转。通常，使用从零开始的整数值。</p><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="4407" class="km kn hi mb b fi mf mg l mh mi"># import ordinal encoder from sklearn<br/>from sklearn.preprocessing import OrdinalEncoder<br/>ord_enc = OrdinalEncoder()<br/>  <br/># Transform the data<br/>train1[["Gender","Region_Code","Occupation","Channel_Code","Credit_Product","Is_Active"]] = ord_enc.fit_transform(train1[["Gender","Region_Code","Occupation","Channel_Code","Credit_Product","Is_Active"]])</span></pre><h2 id="06d7" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">主要代码:</h2><h2 id="fc38" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">定义和拟合阈值</h2><p id="6726" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">对于一个非常大的子集具有相同值的准常数要素，使用阈值 0.01 将意味着删除 99%的值相似的列。</p><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="b091" class="km kn hi mb b fi mf mg l mh mi">from sklearn.feature_selection import VarianceThreshold<br/><br/>var_thr = VarianceThreshold(threshold = 0.25) #Removing both constant and quasi-constant<br/>var_thr.fit(train1)<br/><br/>var_thr.get_support()</span><span id="0392" class="km kn hi mb b fi mj mg l mh mi">array([False,  True,  True,  True,  True,  True,  True,  True, False])</span></pre><p id="e24c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><ul class=""><li id="9a34" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated">真:高方差</li><li id="15a6" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">错误:低方差</li></ul><h2 id="6061" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">选取低差异列:</h2><p id="2bbf" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">按照我上面的代码，我删除了 75%或更多相似的列(您可以保留您喜欢的任何值)</p><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="fb0a" class="km kn hi mb b fi mf mg l mh mi">concol = [column for column in train1.columns <br/>          if column not in train1.columns[var_thr.get_support()]]<br/><br/>for features in concol:<br/>    print(features)</span><span id="3d6b" class="km kn hi mb b fi mj mg l mh mi">Gender<br/>Is_Active</span></pre><h2 id="161e" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">删除低差异列:</h2><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="6425" class="km kn hi mb b fi mf mg l mh mi">train1.drop(concol,axis=1)</span></pre><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="ab fe cl mk"><img src="../Images/bb2f9398193f28a3f1135387907e451a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*woIDV7TSomeuxIFWBqFN9Q.png"/></div></figure><pre class="ju jv jw jx fd ma mb mc md aw me bi"><span id="71cb" class="km kn hi mb b fi mf mg l mh mi">train1.columns</span><span id="606b" class="km kn hi mb b fi mj mg l mh mi">Index(['Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code', 'Vintage',<br/>       'Credit_Product', 'Avg_Account_Balance', 'Is_Active'],<br/>      dtype='object')</span></pre><p id="1cff" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是我们如何看到哪些列具有高方差，从而有助于更好的模型。在应用阈值之前，不要忘记将列 dtype 转换为 integer 或 flow。</p><p id="e25b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦确定了低方差列，就可以随时反转编码，用原始数据继续您的旅程。另外，在预测结果之前，不要忘记从测试数据中删除相同的列！:)</p><p id="8691" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">干杯！</p><p id="9953" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢尔维·❤</p><p id="61ee" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">参考文献:</strong></p><ul class=""><li id="895a" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated"><a class="ae kj" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . feature _ selection。VarianceThreshold.html</a></li></ul></div></div>    
</body>
</html>