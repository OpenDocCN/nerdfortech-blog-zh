<html>
<head>
<title>Traditional ML- Linear Regression(Maths and Code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">传统的最大似然线性回归(数学和代码)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/traditional-ml-linear-regression-maths-and-code-ec67e25ea500?source=collection_archive---------22-----------------------#2021-06-05">https://medium.com/nerd-for-tech/traditional-ml-linear-regression-maths-and-code-ec67e25ea500?source=collection_archive---------22-----------------------#2021-06-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1123" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我关于传统机器学习算法的第一篇文章，我将从线性回归开始。T3】</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/803d3a95b9417d43e9d2fad4af6ff9b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MN9QQtVgKR0H_t-N"/></div></div></figure><p id="3b44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归是一种统计工具或程序，用于根据其他变量的值来预测某个变量值。一个更技术性的定义是，从自变量计算或预测因变量的统计工具或程序。在深入这个话题之前，让我们先定义因变量和自变量。</p><ol class=""><li id="41a3" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">自变量:这些变量独立于所提供数据中的其他变量，并且基本上是原因。</li><li id="62cc" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">因变量:这些变量的值依赖于自变量，并且是那些原因的结果</li></ol><p id="968f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">从这些定义中，我们可以清楚地得到一种因果关系的感觉，我们可以很容易地从散点图或任何其他图表中得到这种类型的关系的想法。</em></p><p id="c4d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看一些问题陈述的例子</p><ol class=""><li id="6580" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">学生在期末考试/测验中的得分有多高。</li><li id="b793" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">给定里程数和车龄，预测汽车价格(2 个独立变量)。</li></ol><p id="3180" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归使用数学方程 y = b*x + a，该方程描述了<em class="jd"> y </em>(因变量)和<em class="jd"> x </em>(自变量)之间关系的最佳拟合线<strong class="ih hj">。<strong class="ih hj">回归系数</strong>，即<em class="jd"> r^ </em> 2，暗示了<em class="jd"> y </em>由于<em class="jd"> x 的变化程度，b 是直线的斜率，a 代表截距。</em></strong></p><blockquote class="ke kf kg"><p id="b22b" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated"><strong class="ih hj">假设</strong></p></blockquote><p id="e2e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设是检查特定数据集是否可以使用线性回归进行分析的好方法。</p><ol class=""><li id="f9fc" class="jq jr hi ih b ii ij im in iq js iu jt iy ju jc jv jw jx jy bi translated">因变量和自变量都必须是连续的。</li><li id="2a43" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">绘制时，我们应该注意到两个变量之间的某种线性关系。</li><li id="d825" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">数据必须显示同方差，即当您沿着最佳拟合线移动时，沿着该线的方差保持相似。</li><li id="180e" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">绘制时，如果您注意到一些异常值，请确保将其删除</li><li id="2054" class="jq jr hi ih b ii jz im ka iq kb iu kc iy kd jc jv jw jx jy bi translated">“y”的所有值都是相互独立的，尽管依赖于“x”</li></ol><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kk"><img src="../Images/1be56d7eba10d48dfa22a52c5cd3acdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*RfvYAI_WWX_l6rjmQl7vDQ.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">线性散点图</figcaption></figure><p id="2218" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们处理第一个问题陈述，看看我们的数据是什么样的</p><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="49a6" class="ku kv hi kq b fi kw kx l ky kz">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression</span><span id="c150" class="ku kv hi kq b fi la kx l ky kz">data = pd.read_csv('./data_set/scores')<br/>data.head()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/a1b90bfd43fe31caf1bf1e8edc01ad43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hu7-M4qMj_kRoi5X1S_ZZQ.png"/></div></div></figure><p id="e65c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们也看看情节是怎样的</p><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="a3fd" class="ku kv hi kq b fi kw kx l ky kz">plt.scatter(x = data.Hours ,y = data.Scores ,color="green")<br/>plt.xlabel("No. of study Hours")<br/>plt.ylabel("Scores")<br/>plt.title("Hours V/S Scores")<br/>plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lc"><img src="../Images/3bb5b76d091d94782598b50b1e50e0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*8PyGv9rJ6MWZPXQqp2DOqg.png"/></div></figure><p id="09da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在继续之前，我们必须跳进去做一些数学计算。我们如何得到 a 和 b 的值，即我们要画的回归线的截距和斜率？这里有一些公式，让你明白是怎么做到的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kk"><img src="../Images/24446bde8029c4d8630dfe6956caaff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*_u4kR2dSWkE-hHypMpeGCA.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ld"><img src="../Images/e1fa6f8021f97169c94b739260daeaee.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*juDbnwTDlWdYPUbNL4VwNw.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">皮尔逊系数</figcaption></figure><p id="c108" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的 x 和 Y 代表各自的意思。</p><p id="6868" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">r 是 Y 在 x 上的线性回归可以解释的 Y 的总方差的比例。1-r 是回归不能解释的比例。因此 1-r = s xY / s Y。</p><p id="5a63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">决定系数</strong>是因变量总变化的一部分，可以用自变量的变化来解释。r 给出一个从 1 到 0 的值，如果它是+1，则因变量和自变量之间存在完美的关系，当它接近 0 时，这种关系就很弱。</p><blockquote class="ke kf kg"><p id="4ebd" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated"><strong class="ih hj">将数据集拆分成训练</strong></p></blockquote><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="e041" class="ku kv hi kq b fi kw kx l ky kz">x = data.drop("Scores" ,axis ="columns")<br/>y = data.drop("Hours" ,axis ="columns")</span><span id="ae6e" class="ku kv hi kq b fi la kx l ky kz">X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size = 0.2 ,random_state = 40)</span><span id="b53e" class="ku kv hi kq b fi la kx l ky kz">## you can always print and check how x,y,X_train,Y_train etc looks like or what their shape is(just to confirm)</span></pre><blockquote class="ke kf kg"><p id="dc70" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated"><strong class="ih hj">实现线性回归</strong></p></blockquote><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="a547" class="ku kv hi kq b fi kw kx l ky kz">lin = LinearRegression()<br/>lin.fit(x,y)<br/>line = lin.coef_*x + lin.intercept_</span><span id="91df" class="ku kv hi kq b fi la kx l ky kz">plt.scatter(x,y ,color = "green")<br/>plt.plot(x,line,color = "orange")<br/>plt.show()</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/3f7a34a95623404edd41d556568c79a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*UHmYImXNBUmXjKfB54BWOw.png"/></div></figure><blockquote class="ke kf kg"><p id="8853" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc hb bi translated"><strong class="ih hj">做预测</strong></p></blockquote><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="873f" class="ku kv hi kq b fi kw kx l ky kz">Y_predicted = lin.predict(X_test)<br/>pd.DataFrame(np.c_[X_test,Y_test,Y_predicted] ,columns = ["Study hours" ,"original marks" ,"predicted Marks"])</span></pre><p id="ad76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将给出一个包含所有预测值和实际值的表格。现在为了检查我们模型的准确性，</p><pre class="jf jg jh ji fd kp kq kr ks aw kt bi"><span id="3e6a" class="ku kv hi kq b fi kw kx l ky kz">lin.score(X_test,Y_test)</span></pre><p id="5c36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我的模型有 0.95 的精确度</p></div><div class="ab cl lf lg gp lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hb hc hd he hf"><p id="08bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过使用相同的概念，我们可以用多个独立变量进行多元线性回归和多项式回归。</p><p id="3237" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢你抽出时间</p></div></div>    
</body>
</html>