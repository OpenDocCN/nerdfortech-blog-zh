<html>
<head>
<title>Linear Regression and it’s not so weird Assumptions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归并不是什么奇怪的假设</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/linear-regression-and-its-not-so-weird-assumptions-9ae419b7ccf6?source=collection_archive---------20-----------------------#2021-07-03">https://medium.com/nerd-for-tech/linear-regression-and-its-not-so-weird-assumptions-9ae419b7ccf6?source=collection_archive---------20-----------------------#2021-07-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h1 id="f1f5" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">什么是线性回归？</strong></h1><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/cd6bf766653e30720b01da4f2181c466.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*0zC7P44-0ntEsEtG.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">不想让背景看起来全是白色:P</figcaption></figure><p id="ce7f" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">它是一种统计模型，试图找到输入变量和给定输出变量之间的线性关系，如果这种关系存在的话。</p><h1 id="6f06" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">线性回归的类型</strong></h1><p id="8135" class="pw-post-body-paragraph jw jx hi jy b jz kz kb kc kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt hb bi translated">大体上我们可以说有两类，简单和多元线性回归。</p><p id="8b23" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">简单线性回归涉及使用单个输入变量来预测输出变量。例如:-给定身高预测体重(但这可能不是完美的方法)</p><p id="1435" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">多元线性回归涉及使用多个输入变量来预测输出变量。例如:- <a class="ae le" href="https://www.kaggle.com/kmldas/loan-default-prediction" rel="noopener ugc nofollow" target="_blank">预测贷款违约</a>，<a class="ae le" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">预测房价</a></p><h1 id="484b" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">型号</strong></h1><p id="9550" class="pw-post-body-paragraph jw jx hi jy b jz kz kb kc kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt hb bi translated">线性回归的一般方程包括</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es lf"><img src="../Images/82d4bf950888bed5855ac46337961d52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*zn6f5MSzZH8_eBQvQuygww.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">线性回归方程</figcaption></figure><p id="1a33" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">其中I表示数据点的实例，1，…，p表示我们用来预测y的p个不同的值。</p><p id="123a" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">当我们使用基本矩阵标量乘法的矩阵表示时，我们可以把它写成x ^ T *B</p><h1 id="8b0d" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">解决方案</strong></h1><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="lg lh l"/></div></figure><p id="436c" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">现在我们已经有了模型，我们需要找出betas(权重)的值。</p><p id="1520" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们用于线性回归的成本函数通常是SSE(误差平方和)。其他选择是RMSE，湄(成本函数的使用主要取决于我们的目标是什么)。</p><p id="30d9" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们知道，我们最终想要的是能够降低成本函数的betas值。</p><blockquote class="li lj lk"><p id="a04a" class="jw jx ll jy b jz ka kb kc kd ke kf kg lm ki kj kk ln km kn ko lo kq kr ks kt hb bi translated">最小化就是求梯度，等于0</p></blockquote><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es lp"><img src="../Images/bb86e4f66a59017879d9a58c1b10fd16.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*IHowhqgU_OgTyERVo1W_XA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">成本函数</figcaption></figure><p id="e323" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">如前所述，我们可以将它表示为线性方程和矩阵乘积的形式，因此，我们可以根据我们决定如何描述模型，以多种方式求解它。</p><ol class=""><li id="2291" class="lq lr hi jy b jz ka kd ke kh ls kl lt kp lu kt lv lw lx ly bi translated"><strong class="jy hj">法线方程</strong></li></ol><p id="efaa" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">当我们在模型的矩阵形式中求导并使其等于零时，我们最终得到β为(x^T*x)^-1(x^T*y).</p><p id="bf3d" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我知道这看起来有点模糊，不要担心，我会在最后给你一些好的资源。</p><p id="3d9f" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">2.<strong class="jy hj">梯度下降</strong></p><p id="3021" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">梯度下降的基本思想包括在每一步中寻找梯度，并向与之相反的方向移动，以便找到最小值点。</p><p id="1b08" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">梯度下降有不同的变体，如随机梯度下降和批量梯度下降。</p><h1 id="2c8e" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">指标</strong></h1><p id="32d3" class="pw-post-body-paragraph jw jx hi jy b jz kz kb kc kd la kf kg kh lb kj kk kl lc kn ko kp ld kr ks kt hb bi translated">我们如何知道我们的模型表现得有多好？</p><p id="09f6" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">我们可以使用原始RMSE值本身，但问题是它是没有界限的。所以我们利用R值。</p><p id="40ce" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">够好吗？</p><p id="295c" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">这可能不是最好的，假设您有一个问题，其中您有大约100个输入特征，因此如果我们决定进行增量特征添加来改进我们的模型，R值将继续增加，尽管添加的特征对预测输出变量没有贡献。</p><p id="81ab" class="pw-post-body-paragraph jw jx hi jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt hb bi translated">Tadaa，我们有调整过的R值来处理它。</p><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="lz lh l"/></div></figure><h2 id="2321" class="ma in hi bd io mb mc md is me mf mg iw kh mh mi ja kl mj mk je kp ml mm ji mn bi translated">等等！什么时候可以用线性回归？</h2><h2 id="4342" class="ma in hi bd io mb mc md is me mf mg iw kh mh mi ja kl mj mk je kp ml mm ji mn bi translated">当然，需要满足一系列条件。但那将是另一个帖子！</h2><h1 id="dcc9" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">睡觉用的东西</strong></h1><ol class=""><li id="a958" class="lq lr hi jy b jz kz kd la kh mo kl mp kp mq kt lv lw lx ly bi translated">线性回归中偏倚的重要性是什么？</li><li id="69d0" class="lq lr hi jy b jz mr kd ms kh mt kl mu kp mv kt lv lw lx ly bi translated">我们什么时候才能找到解决方案？</li><li id="dd91" class="lq lr hi jy b jz mr kd ms kh mt kl mu kp mv kt lv lw lx ly bi translated">得到的解会一直是最优的吗？</li></ol><h1 id="58bb" class="im in hi bd io ip ku ir is it kv iv iw ix kw iz ja jb kx jd je jf ky jh ji jj bi translated"><strong class="ak">资源(你可能觉得超出你能力范围的东西)</strong></h1><div class="mw mx ez fb my mz"><a href="https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/" rel="noopener  ugc nofollow" target="_blank"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hj fi z dy ne ea eb nf ed ef hh bi translated">线性回归中的正规方程</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">正规方程是一种使用最小二乘成本函数进行线性回归的分析方法。我们可以直接找到…</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">www.geeksforgeeks.org</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn jq mz"/></div></div></a></div><div class="mw mx ez fb my mz"><a href="https://builtin.com/data-science/gradient-descent" rel="noopener  ugc nofollow" target="_blank"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hj fi z dy ne ea eb nf ed ef hh bi translated">梯度下降:机器学习最流行的算法之一介绍</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">梯度下降是迄今为止在机器学习和深度学习中使用的最流行的优化策略</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">builtin.com</p></div></div><div class="ni l"><div class="no l nk nl nm ni nn jq mz"/></div></div></a></div></div></div>    
</body>
</html>