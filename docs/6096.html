<html>
<head>
<title>Hey, Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">嘿，阿帕奇火花</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/hello-world-apache-spark-458a03ced9c4?source=collection_archive---------2-----------------------#2021-12-29">https://medium.com/nerd-for-tech/hello-world-apache-spark-458a03ced9c4?source=collection_archive---------2-----------------------#2021-12-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="549a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你熟悉大数据，那么你可能听说过Apache Spark。Spark是一个强大的开源数据处理引擎，可以轻松分析大型数据集。在本帖中，我们将看看为什么Spark如此受欢迎的一些原因，并探索它的一些关键特性</p><p id="9079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache Spark是一个计算引擎，Apache Spark是一个计算引擎和一系列大数据工具。它具有流式传输、查询数据集、机器学习(Spark MLlib)和图形处理(GraphX)等功能。在本帖中，我们将回顾什么是Apache spark及其用例。Spark是用Scala开发的，但是也有Python、Java、SQL和R的绑定。Spark完全依赖于内存处理，这使得它比相应的Hadoop功能的性能快几倍。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6126682b2c46ed9d0a377643a551aef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CDMMB511oDu5O2NG"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@davealmine?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">达维德·扎维亚</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="ea87" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">概观</h1><p id="e2cd" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">Spark的核心是一个弹性分布式数据集(RDD)，这是一个分布在一个机器集群上的只读多数据项集，跨操作维护在内存中。这种基本的抽象使Spark能够支持批处理式计算，例如map-reduce作业，以及交互式查询。rdd是从HDFS或任何Hadoop支持的文件系统中的一个或多个外部数据集开始构建的，并使用并行操作(如map、reduce、join和cogroup)来转换这些数据。</p><p id="2159" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为一个独立的集群管理器，Spark支持自动化常见的集群资源管理任务(例如，监控、调度)，利用内置的原语，这些原语可以很容易地组合到更高级别的应用程序逻辑中。该库可以在标准Hadoop发行版上获得，也可以单独下载。</p><p id="d99b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark是一款多用途发动机。它可用于批处理，对存储在HDFS或其他文件系统中的数据集进行交互式查询。为了处理来自不同来源的流数据，Apache Spark通过Spark Streaming提供了实时流处理功能，可以分析和处理内存中或通过磁盘持久性的数据。在Apache Spark的未来版本中，它将支持新的前端语言，如R和Python，以提供针对大型数据集的交互式分析，而无需我们编写任何代码。</p><h1 id="e55a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">MapReduce和Spark比较</h1><p id="dc20" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">随着Spark的出现，MapReduce框架退居二线，原因如下:</p><ul class=""><li id="30f6" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj">迭代作业:</strong>某些机器学习算法对数据集进行多次遍历以计算结果。每一次传递都可以表示为一个不同的MapReduce作业。但是，每个作业从磁盘读取其输入数据，然后将其输出转储到磁盘，供下一个作业读取。当涉及磁盘I/O时，与从主存储器访问相同的数据相比，作业执行时间增加了许多倍。</li><li id="3fd4" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">交互分析:</strong>用户可以使用Hive或Pig等工具对大型数据集运行特定的SQL查询。如果用户发出针对同一个数据集的多个查询，每个查询可以转换为一个MapReduce作业，从磁盘读取同一个数据集，并对其进行操作。让多个MapReduce作业从磁盘读取同一个数据集是低效的，并且增加了查询执行延迟。</li><li id="c893" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">丰富的API:</strong>Spark通过提供各种丰富的API，可以简洁地表达一个操作，否则在MapReduce中表达时会包含许多行代码。与MapReduce相比，使用Spark时，用户和开发人员的体验相对简单。</li></ul><h1 id="d3f8" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">弹性分布式数据集</h1><ul class=""><li id="def1" class="kx ky hi ih b ii ks im kt iq ll iu lm iy ln jc lc ld le lf bi translated"><strong class="ih hj">弹性:</strong>这意味着RDD是容错的，能够重新计算由于节点故障而丢失或损坏的分区。这种自我修复是通过使用RDD谱系图实现的，我们将在后面介绍。RDD记得它是如何达到当前状态的，并且可以追溯到重新计算任何丢失分区的步骤。<strong class="ih hj">分布式:</strong>当组成RDD的数据分布在一个机器集群上时。数据集:这是指我们处理的数据记录的表示。可以通过JDBC使用各种来源加载外部数据，如JSON文件、CSV文件、文本文件或数据库。</li></ul><h1 id="0ea6" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">RDD的属性</h1><ul class=""><li id="044b" class="kx ky hi ih b ii ks im kt iq ll iu lm iy ln jc lc ld le lf bi translated"><strong class="ih hj">弹性:</strong>这意味着RDD是容错的，能够重新计算由于节点故障而丢失或损坏的分区。这种自我修复是通过使用RDD谱系图实现的，我们将在后面介绍。RDD记得它是如何达到当前状态的，并且可以追溯到重新计算任何丢失分区的步骤。</li><li id="b9ed" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">分布式:</strong>当组成RDD的数据分布在一群机器上时。</li><li id="80cb" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">数据集:</strong>这是指我们处理的数据记录的表示。可以通过JDBC使用各种来源加载外部数据，如JSON文件、CSV文件、文本文件或数据库。</li></ul><h1 id="9993" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">为什么要从Hadoop转型</h1><p id="becb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">如果您正在使用Hadoop，并希望提升您的数据处理水平，迁移到Spark可能是一个不错的选择。</p><p id="f57e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，所有的迁移都需要花费工时。以下是一些迁移的好理由:</p><ul class=""><li id="37d3" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">Spark在内存中进行处理，比Hadoop MapReduce快很多倍。</li></ul><p id="0dd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark声称比Hadoop MapReduce快100倍。</p><p id="05f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">项目的采用带来了高质量的文档、课程和书籍，可以帮助您正确地完成它。相反，在专门处理文本流的MapReduce上，Spark中有各种高级抽象，最常见的是RDD。</p><ul class=""><li id="144e" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">几乎所有我们需要处理的数据都可以通过Spark来完成。如上所述，Spark可以执行流式活动、机器学习、查询数据和图形处理。当然，我们可以用RDD级别做任何数据操作。</li><li id="1f82" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">用于交互式数据争论的Spark shell。就像我们在Python shell中构建Python代码的原型一样，我们也可以在spark-shell中用我们的spark作业做同样的事情。</li></ul><h1 id="d42a" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">MLlib与Tensorflow/Pytorch</h1><p id="61de" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">围绕机器学习有许多超级流行和有据可查的框架，如Tensorflow和Pytorch。所以用MLlib出现？</p><p id="5735" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Spark生态系统中任何工具的一个重要原因是它的分布式性质。除了执行内存计算，Spark还可以在分布式文件系统上执行。</p><p id="7e53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这有助于扩展流程，并且您不必学习可能与Spark不兼容的第二种技术。</p><p id="fe48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还记得上节课的网球例子吗？我们可以写一个模型来预测下一个球的颜色。由于我们已经在HDFS有了数据，我们可以利用与HDFS的Spark集成，并在那里运行我们的机器学习模型。</p><h1 id="fe21" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">Spark和Hadoop MapReduce</h1><p id="1275" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">Hadoop问世时是大数据处理的突破。虽然它仍然是一个受欢迎的工具，但Spark在许多方面都优于它，比如性能和实时需求。</p><p id="8120" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark依靠内存运行，仅此一点就能改变游戏规则。</p><h1 id="0719" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">火花的应用</h1><ul class=""><li id="79e4" class="kx ky hi ih b ii ks im kt iq ll iu lm iy ln jc lc ld le lf bi translated">趋势计算。</li><li id="e545" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">商业智能。</li><li id="ffac" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">使用GraphX的TextRank等图形算法对语料库进行汇总。</li><li id="8bd1" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">使用Spark流和MLlib实时检测欺诈性支付。</li><li id="a76e" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">用Spark流实现ETL管道。</li></ul><p id="4742" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要了解Spark如何工作的更多信息，请访问:<a class="ae jt" href="https://spark.apache.org/docs/latest/index.html#how-it-works" rel="noopener ugc nofollow" target="_blank">https://Spark . Apache . org/docs/latest/index . html # how-it-works</a></p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><p id="c683" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache Spark是一个开源集群计算系统，可用于对大型数据集进行分析。你对它的工作原理了解得越多，你就能更好地分析大数据，并通过机器学习技术利用它的优势，下次再见</p></div></div>    
</body>
</html>