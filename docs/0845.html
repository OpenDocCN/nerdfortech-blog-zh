<html>
<head>
<title>Schedule Tweets with Python for a Job Search Website</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 为求职网站安排推文</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/schedule-tweets-with-python-for-a-job-search-website-75589b0a1229?source=collection_archive---------6-----------------------#2021-02-18">https://medium.com/nerd-for-tech/schedule-tweets-with-python-for-a-job-search-website-75589b0a1229?source=collection_archive---------6-----------------------#2021-02-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="28ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将使用 Python 为我们的求职网站编写代码，我们已经使用 Python 和 Django 编写了代码。我们已经发布了一系列文章，涵盖了使用 Python 和 Django 从头构建一个全功能 Web 应用程序的各个阶段。</p><p id="62e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在前两篇文章中，我们讨论了:</p><ul class=""><li id="e117" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><a class="ae jm" href="https://skolo-online.medium.com/scrap-data-from-website-and-pdf-document-for-django-app-fa8f37010085" rel="noopener">从网站和 PDF 文档中删除数据</a></li><li id="3eb8" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated"><a class="ae jm" href="https://skolo-online.medium.com/step-by-step-guide-to-python-twitter-bot-with-tweepy-in-15min-f3c8b50a5429" rel="noopener">带 Tweepy 的 Python 推特机器人分步指南</a></li></ul><p id="08c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将结合前两篇文章的内容，构建一个 twitter 机器人，它将发布我们从网络报废活动中收集的数据。</p><h1 id="d58b" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">本教程的原因</h1><p id="278d" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">像 twitter 和 facebook 这样的社交媒体网站在世界访问量最大的网站中排名前五。社交媒体很受消费者欢迎，因此是接触潜在受众的好地方。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/b877439600812bb7439ae9faaa34151f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DmOi6Vb0VCRJYRjjg6W2Ig.jpeg"/></div></div></figure><p id="85b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">社交媒体也是根据兴趣、群体和标签来组织的。这使得它成为一个营销的好地方，因为你可以将你的信息瞄准一个特定的标签或受众，而不是一个寻找任何可能遇到它的人的广告牌。</p><p id="e67c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，当我们开始推出我们的求职平台时，我们也要关注如何利用社交媒体接触更广泛的受众，这一点很重要。理想情况下，我们希望在社交媒体上接触到人们，这样我们就可以开发我们的 web 应用程序。</p><h2 id="bd99" class="lh jt hi bd ju li lj lk jy ll lm ln kc iq lo lp kg iu lq lr kk iy ls lt ko lu bi translated">重新确定 Web 报废代码的用途</h2><p id="74c7" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们已经编写了代码来删除我们需要获取工作数据的网站，但我们现在需要重新利用这些代码来删除我们需要的推文。使用同一个网站，创建一个新文件，再次为推文废弃数据:</p><pre class="kw kx ky kz fd lv lw lx ly aw lz bi"><span id="9ff2" class="lh jt hi lw b fi ma mb l mc md">from bs4 import BeautifulSoup<br/>from datetime import date<br/>import requests<br/>import json<br/>import config</span><span id="b7b7" class="lh jt hi lw b fi me mb l mc md">headers =  {'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'}<br/>baseUrl = '<a class="ae jm" href="https://careers.vodafone.com'" rel="noopener ugc nofollow" target="_blank">https://careers.vodafone.com'</a><br/>url = "<a class="ae jm" href="https://careers.vodafone.com/key/vodacom-vacancies.html?q=vodacom+vacancies" rel="noopener ugc nofollow" target="_blank">https://careers.vodafone.com/key/vodacom-vacancies.html?q=vodacom+vacancies</a>"</span><span id="5f99" class="lh jt hi lw b fi me mb l mc md">#Read a JSON File<br/>def readJson(filename):<br/>        with open(filename, 'r') as fp:<br/>            return json.load(fp)</span><span id="67fe" class="lh jt hi lw b fi me mb l mc md">#Write a JSON file<br/>def writeJson(filepath, data):<br/>    with open(filepath, 'w') as fp:<br/>        json.dump(data, fp)</span><span id="b765" class="lh jt hi lw b fi me mb l mc md">def shortenUrl(linkUrl):<br/>    linkRequest = {<br/>      "destination": linkUrl,<br/>      "domain": { "fullName": "messages.careers-portal.co.za" },<br/>      #"slashtag": "",<br/>    }</span><span id="88f3" class="lh jt hi lw b fi me mb l mc md">requestHeaders = {<br/>      "Content-type": "application/json",<br/>      "apikey": config.rebrand_api_key,<br/>    }</span><span id="3547" class="lh jt hi lw b fi me mb l mc md">r = requests.post("<a class="ae jm" href="https://api.rebrandly.com/v1/links" rel="noopener ugc nofollow" target="_blank">https://api.rebrandly.com/v1/links</a>",<br/>        data = json.dumps(linkRequest),<br/>        headers=requestHeaders)</span><span id="b4a4" class="lh jt hi lw b fi me mb l mc md">if (r.status_code == requests.codes.ok):<br/>        link = r.json()<br/>        return link["shortUrl"]<br/>    else:<br/>        return ''</span><span id="4eee" class="lh jt hi lw b fi me mb l mc md">#Scan the website<br/>def jobScan(link):<br/>    the_job = {}</span><span id="195e" class="lh jt hi lw b fi me mb l mc md">jobUrl = '{}{}'.format(baseUrl, link['href'])<br/>    the_job['urlLink'] = shortenUrl(jobUrl)</span><span id="d86a" class="lh jt hi lw b fi me mb l mc md">job=requests.get(jobUrl, headers=headers)<br/>    jobC=job.content<br/>    jobSoup=BeautifulSoup(jobC, "html.parser")</span><span id="e507" class="lh jt hi lw b fi me mb l mc md">to_test = jobSoup.find_all("div", {"class": "joblayouttoken displayDTM"})</span><span id="28fb" class="lh jt hi lw b fi me mb l mc md">if to_test == []:<br/>        return None<br/>    else:</span><span id="4546" class="lh jt hi lw b fi me mb l mc md">title = jobSoup.find_all("h1")[0].text<br/>        the_job['title'] = title</span><span id="f01c" class="lh jt hi lw b fi me mb l mc md">the_divs = jobSoup.find_all("div", {"class": "joblayouttoken displayDTM"})</span><span id="932a" class="lh jt hi lw b fi me mb l mc md">country = the_divs[1].find_all("span")[1].text<br/>        the_job['location'] = country</span><span id="d734" class="lh jt hi lw b fi me mb l mc md">date_posted = the_divs[2].find_all("span")[1].text<br/>        the_job['date_posted'] = date_posted</span><span id="1128" class="lh jt hi lw b fi me mb l mc md">full_part_time = the_divs[3].find_all("span")[1].text<br/>        the_job['type'] = 'Full Time'</span><span id="8c48" class="lh jt hi lw b fi me mb l mc md">contract_type = the_divs[4].find_all("span")[1].text<br/>        the_job['contract_type'] = contract_type</span><span id="2e1e" class="lh jt hi lw b fi me mb l mc md">return the_job</span><span id="0c18" class="lh jt hi lw b fi me mb l mc md">r = requests.get(url, headers=headers)<br/>c = r.content<br/>soup = BeautifulSoup(c, "html.parser")</span><span id="9e20" class="lh jt hi lw b fi me mb l mc md">#Modified these lines here . . . .<br/>table=[]<br/>results = soup.find_all("a", {"class": "jobTitle-link"})<br/>[table.append(x) for x in results if x not in table]</span><span id="861f" class="lh jt hi lw b fi me mb l mc md">#run the scanner and get all the jobs . . . .<br/>final_jobs = []<br/>for x in table:<br/>    job = jobScan(x)<br/>    if job:<br/>        final_jobs.append(job)</span><span id="a383" class="lh jt hi lw b fi me mb l mc md">#Save the data in a Json<br/>filepath = '/absolute-path-to-folder/vodacom.json'<br/>writeJson(filepath, final_jobs)</span></pre><p id="0d7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">U <strong class="ih hj"> RL 缩短</strong></p><p id="bc72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将工作页面添加到 dict 对象之前，我们添加了用于缩短工作页面 URL 的特定代码，该代码保存在我们的 JSON 中。由于字符限制，URL 缩短对 twitter 至关重要——一条推文只能有 160 个字符。</p><p id="d787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用了一个名为 Rebrandly(<a class="ae jm" href="https://www.rebrandly.com/" rel="noopener ugc nofollow" target="_blank">https://www . rebrandy . com)/</a>的服务—您可以在这里创建一个新帐户，并在代码中使用它来缩短 URL。</p><p id="03b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">保存数据</strong></p><p id="f355" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在页面底部，我们对这段代码所做的是:将数据保存在一个 json 文件中。这样，我们就可以定期运行这段代码，总是检查最新的可用作业，并刷新保存在文件中的数据。tweeting 代码只需要访问保存的文件，就可以获得最新的数据。</p><h2 id="4c60" class="lh jt hi bd ju li lj lk jy ll lm ln kc iq lo lp kg iu lq lr kk iy ls lt ko lu bi translated">从 JSON 数据创建 Tweet</h2><p id="dde1" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">我们将分两个阶段创建推文:</p><ul class=""><li id="2935" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">清理网站上的数据，并将其串在一起，以创建推文消息</li><li id="7e41" class="jd je hi ih b ii jn im jo iq jp iu jq iy jr jc ji jj jk jl bi translated">将 tweep 消息与适当的 hashtags 连接起来，并创建 Tweepy API 对象来发送 tweep</li></ul><p id="8586" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据处理，创建推文</strong></p><pre class="kw kx ky kz fd lv lw lx ly aw lz bi"><span id="7d13" class="lh jt hi lw b fi ma mb l mc md">import json</span><span id="3829" class="lh jt hi lw b fi me mb l mc md">def readJson(filename):<br/>        with open(filename, 'r') as fp:<br/>            return json.load(fp)</span><span id="4982" class="lh jt hi lw b fi me mb l mc md">def grabVodacomJobs():<br/>    statuses = []<br/>    filepath = 'absolute-path-to-folder/vodacom.json'<br/>    jobs = readJson(filepath)</span><span id="886a" class="lh jt hi lw b fi me mb l mc md">for job in jobs:<br/>        status = 'Vodacom-{}{} Apply {}'.format(job['title'], job['contract_type'], job['urlLink']).replace('\n', '').replace('  ',' ')<br/>        statuses.append(status)</span><span id="94af" class="lh jt hi lw b fi me mb l mc md">return statuses</span></pre><p id="5e48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">用标签建立推文信息</strong></p><p id="0767" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不要忘记将上面的文件导入到 tweeting 文件中，我们需要访问从数据库中获取数据的函数。</p><pre class="kw kx ky kz fd lv lw lx ly aw lz bi"><span id="0084" class="lh jt hi lw b fi ma mb l mc md"># -*- coding: utf-8 -*-</span><span id="b4a7" class="lh jt hi lw b fi me mb l mc md">import tweepy<br/>import config<br/>import random<br/>import tweet_data</span><span id="3c75" class="lh jt hi lw b fi me mb l mc md">import schedule<br/>import time</span><span id="5f39" class="lh jt hi lw b fi me mb l mc md"><br/>def createTheAPI():<br/>    auth = tweepy.OAuthHandler(config.api_key, config.api_secret)<br/>    auth.set_access_token(config.access_token, config.access_token_secret)<br/>    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)<br/>    return api</span><span id="b17a" class="lh jt hi lw b fi me mb l mc md">vodaJobs = tweet_data.grabVodacomJobs()<br/>hashtags = ["#hashtag1", "hashtag2", "hashtag3", "hashtag4", "hashtag5"]</span><span id="bbe2" class="lh jt hi lw b fi me mb l mc md">def createVodacomTweet():<br/>    while True:<br/>        msg = random.choice(vodaJobs)</span><span id="f65a" class="lh jt hi lw b fi me mb l mc md">hashtags = getTags()<br/>        tags = random.sample(hashtags, 2)</span><span id="72d6" class="lh jt hi lw b fi me mb l mc md">if len(msg) &lt; 110:<br/>            msg += ' '+tags[0]<br/>            msg += ' '+tags[1]</span><span id="cc4a" class="lh jt hi lw b fi me mb l mc md">if len(msg) &lt; 160:<br/>            return msg<br/>            break</span><span id="2f05" class="lh jt hi lw b fi me mb l mc md"><br/>def sendVodacomTweet():<br/>    api = createTheAPI()<br/>    tweet = createVodacomTweet()<br/>    api.update_status(tweet)<br/>    print('Just tweeted: {}'.format(tweet))<br/></span><span id="70b3" class="lh jt hi lw b fi me mb l mc md">#The Scheduling is happening below: schedule.every().day.at("10:30").do(sendVodacomTweet)<br/>while True:<br/>    schedule.run_pending()<br/>    time.sleep(1)</span></pre><p id="6476" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用在文件顶部导入的随机函数来(1)从数据库发送的列表中选择一条随机 tweet ,( 2)从 hashtags 列表中选择 2 个随机样本。只要你需要，你可以列出这个列表，随机选择的标签也可以防止你连续发送两条相同的推文。</p><p id="394a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还使用 python 时间表库来创建任务的每日时间表——有多种方法可以使用，直接从时间表网站——https://pypi.org/project/schedule/<a class="ae jm" href="https://pypi.org/project/schedule/" rel="noopener ugc nofollow" target="_blank"/></p><p id="a48a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文档中的代码:</p><pre class="kw kx ky kz fd lv lw lx ly aw lz bi"><span id="c63d" class="lh jt hi lw b fi ma mb l mc md">import schedule<br/>import time<br/><br/>def job():<br/>    print("I'm working...")<br/><br/>schedule.every(10).seconds.do(job)<br/>schedule.every(10).minutes.do(job)<br/>schedule.every().hour.do(job)<br/>schedule.every().day.at("10:30").do(job)<br/>schedule.every(5).to(10).minutes.do(job)<br/>schedule.every().monday.do(job)<br/>schedule.every().wednesday.at("13:15").do(job)<br/>schedule.every().minute.at(":17").do(job)<br/><br/>while True:<br/>    schedule.run_pending()<br/>    time.sleep(1)</span></pre><p id="dc95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整视频教程:</p><figure class="kw kx ky kz fd la"><div class="bz dy l di"><div class="mf mg l"/></div></figure></div></div>    
</body>
</html>