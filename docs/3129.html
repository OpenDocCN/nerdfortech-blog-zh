<html>
<head>
<title>Review — A Blur Classification Approach Using Deep Convolution Neural Network (Blur Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述—使用深度卷积神经网络的模糊分类方法(模糊分类)</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/review-a-blur-classification-approach-using-deep-convolution-neural-network-blur-classification-93edf4552fd7?source=collection_archive---------6-----------------------#2021-05-30">https://medium.com/nerd-for-tech/review-a-blur-classification-approach-using-deep-convolution-neural-network-blur-classification-93edf4552fd7?source=collection_archive---------6-----------------------#2021-05-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1a0a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">基于CNN的手势图像模糊分类</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/44edc14e471dbe4e0623c6ef36f727eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tiO9hMiClLREFoNukWTHqw.png"/></div></div></figure><p id="aa58" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi kf translated"><span class="l kg kh ki bm kj kk kl km kn di">在</span>这篇报道中，对石油和能源研究大学的<strong class="jl hj">使用深度卷积神经网络的模糊分类方法</strong>(tiwa ri iji SMD ' 20)进行了回顾。在本文中:</p><ul class=""><li id="d549" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated"><strong class="jl hj">使用CNN对<strong class="jl hj">手势图像</strong>进行四种模糊分类:运动、散焦、高斯和框模糊</strong>。</li><li id="408a" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">确定准确的模糊类型对于盲图像恢复至关重要。</li></ul><p id="dafc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这是<strong class="jl hj"> 2020 IJISMD </strong>上的一篇论文。(<a class="lc ld ge" href="https://medium.com/u/aff72a0c1243?source=post_page-----93edf4552fd7--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h1 id="a767" class="ll lm hi bd ln lo lp lq lr ls lt lu lv io lw ip lx ir ly is lz iu ma iv mb mc bi translated">概述</h1><ol class=""><li id="f88d" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke mi ku kv kw bi translated"><strong class="jl hj">模糊模型</strong></li><li id="5f83" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke mi ku kv kw bi translated"><strong class="jl hj">模糊分类框架</strong></li><li id="d0ca" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke mi ku kv kw bi translated"><strong class="jl hj">实验结果</strong></li></ol></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h1 id="f80b" class="ll lm hi bd ln lo lp lq lr ls lt lu lv io lw ip lx ir ly is lz iu ma iv mb mc bi translated"><strong class="ak"> 1。模糊模型</strong></h1><h2 id="f917" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">1.1.运动模糊</h2><ul class=""><li id="0543" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke kt ku kv kw bi translated">当<strong class="jl hj">被摄物体相对于成像设备</strong>运动时，出现运动模糊；</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mx"><img src="../Images/719ecc5a73fae6c7b2ffdbb9a04524d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*_y9kcRy6qV4hn_VMMt9PBQ.png"/></div></figure><ul class=""><li id="e6d2" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">其中<em class="my"> L </em>为匀速运动模糊的模糊长度。</li></ul><h2 id="4717" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">1.2.散焦模糊</h2><ul class=""><li id="8ce2" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke kt ku kv kw bi translated">由于<strong class="jl hj">来自传感器平面</strong>上的物体的光会聚不足而捕获的图像导致散焦模糊(或失焦):</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/fbb06192c84630df6745ae1665dbdb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*ut-uhC02KnEmstSAMlwE7Q.png"/></div></figure><ul class=""><li id="3344" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">其中<em class="my"> R </em>为圆盘的半径。</li></ul><h2 id="1e8f" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">1.3.高斯模糊</h2><ul class=""><li id="a320" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke kt ku kv kw bi translated">对于大范围的设备，如光学图像照相机、显微镜、望远镜等，模糊函数通常近似为高斯函数；</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/7627fb70eef2eab0c7fecc36c6d46b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*07auyr77xu13bY_eML2WEQ.png"/></div></figure><ul class=""><li id="cfb9" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">其中<em class="my"> σ </em>是具有标准偏差的高斯模糊函数。</li><li id="e678" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">有时，这种模糊也被用来模拟<strong class="jl hj">散焦模糊</strong>。</li></ul><h2 id="3af8" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">1.4.框模糊</h2><ul class=""><li id="d030" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke kt ku kv kw bi translated">框模糊是一种均值滤波器，其中输出图像中的每个像素都具有在输入图像的某个特定区域中定义的其相邻像素的均值。</li><li id="9837" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">大多数现有方法将模糊建模为由<strong class="jl hj">恒速运动</strong>引起的盒状模糊:</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nb"><img src="../Images/de9e6b74d8929884a8cb285793e1bdd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*oqGaoch7hDI3_u6UkLnM5g.png"/></div></figure><ul class=""><li id="7242" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">其中<em class="my"> Suv </em>是矩形模糊内核中的点集<em class="my"> m </em> * <em class="my"> n </em>是内核大小。</li></ul></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h1 id="743e" class="ll lm hi bd ln lo lp lq lr ls lt lu lv io lw ip lx ir ly is lz iu ma iv mb mc bi translated">2.模糊分类<strong class="ak">框架</strong></h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/bfca92133b1ee11c0d495ebc257f181d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8iWer6dwSDJW7iq_2XZtQ.png"/></div></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">模糊分类框架</strong></figcaption></figure><h2 id="64e7" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">2.1.预处理&amp;傅立叶变换&amp;裁剪</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/8709f4df213e00476a57f75d5ac034f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*hyy9LBa5PvRfyBNw4GloUA.png"/></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln"> (a)原始图像，(b)(a)的傅立叶频谱，(c)一维汉恩窗，(D)二维汉恩窗(e)汉恩窗图像，(f)(e)的傅立叶频谱</strong></figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/ac2d216cbdc87cf895728882043d6d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*C3ojVGhyph7qIDInaEPzyw.png"/></div></figure><ul class=""><li id="f26a" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">周期性的边界条件和图像边界之间的尖锐不连续性在频谱中形成交叉图案。</li><li id="0a98" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">Haan窗口用于避免这个问题。</li><li id="0e82" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">然后，应用傅立叶变换。</li><li id="7f91" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">图像被裁剪为32×32。</li></ul><h2 id="63c7" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">2.2.多层感知器模型</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/880ebe6474c5450717aacb02bca73c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*gnrfOfbfpbyMw7VXObjo4Q.png"/></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">多层感知器神经网络模型</strong></figcaption></figure><ul class=""><li id="ef12" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">一个MLP用的只是<strong class="jl hj">三层</strong>即输入、隐藏和输出。</li><li id="9623" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">第一层即<strong class="jl hj">输入层中的神经元是1024个</strong>，输出层是4个，因为输入是32 × 32的图像，<strong class="jl hj">输出是4 × 1的向量</strong>，指示<strong class="jl hj">四个模糊等级</strong>。</li><li id="7049" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">考虑隐藏层中的<strong class="jl hj"> 500个神经元。</strong></li></ul><h2 id="6567" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">2.3.卷积神经网络</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/5bf329416f431128806effa44b8f1569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SNU64VDGPa8Q4Wc_Cc6UFA.png"/></div></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">卷积神经网络模型</strong></figcaption></figure><ul class=""><li id="9ede" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">在通道里。作者提到用于模糊分类的CNN模型具有三个卷积滤波器层:64–3×3、128–3×3、512–3×3卷积滤波器。(但是在图中，只有2个卷积。)</li><li id="88a4" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">使用2×2最大池。</li><li id="5b26" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">最后一层是致密层，具有4个单元的softmax激活功能。</li><li id="b280" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated"><a class="ae nl" href="https://sh-tsang.medium.com/paper-dropout-a-simple-way-to-prevent-neural-networks-from-overfitting-image-classification-a74b369b4b8e" rel="noopener">下降</a>用于减少过拟合。</li></ul></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h1 id="11fb" class="ll lm hi bd ln lo lp lq lr ls lt lu lv io lw ip lx ir ly is lz iu ma iv mb mc bi translated">3.实验结果</h1><h2 id="5a5b" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">3.1.数据集</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/fd18572b62e684d0ddaefaae9f8de594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZkvzoUvVyE_nkeutCoYqjA.png"/></div></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">模糊的手势图像</strong></figcaption></figure><ul class=""><li id="318c" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated"><strong class="jl hj"> Triesch手势数据库</strong>由<strong class="jl hj"> 720幅图像</strong>组成，这些图像由24个不同的人在3个不同的背景中拍摄，每个背景包括10个手势。</li><li id="0bba" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">使用每一类模糊分别模糊所有图像，即<strong class="jl hj">运动、散焦、方框和高斯模糊</strong>。因此，模糊图像数据库的大小为<strong class="jl hj"> 2880幅图像</strong>。</li></ul><h2 id="3318" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">3.2.MLP结果</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/6711892072acda1daa715b636b26a154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jzJ3_EB9B-IComIP_S4RHA.png"/></div></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">基于多层感知器的分类模型的性能</strong></figcaption></figure><ul class=""><li id="efdc" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">模糊图像数据集被分成训练集和验证集。</li><li id="9600" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">分别利用70%和30%模糊图像进行训练和验证。</li><li id="f87a" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">整个图像数据集被用作训练模型的测试集。</li><li id="4756" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">(与训练集重叠的整个数据集很奇怪。)</li><li id="da27" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">模型的总体检验损失和检验精度分别为0.22和0.93。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/fb24367d3e8e7e9f65066cc0e2a38273.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*hGEk4QpVNWNbO8fWTrbeMA.png"/></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">精度曲线和损失曲线分别用于训练和验证数据。</strong></figcaption></figure><h2 id="a8eb" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">3.3.CNN结果</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/a5a5498c27f51bbbf17a84e7c029603c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aoXnNRbwqybCMrwfJKQE-g.png"/></div></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">基于卷积神经网络的分类模型的性能</strong></figcaption></figure><ul class=""><li id="4319" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">数据集分割与MLP数据集分割相同。</li><li id="d589" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">模型的总体检验损失和检验精度分别为0.10和0.97。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es np"><img src="../Images/f8442359f972022f42e655337ce41c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*_U7O_QqDHLIkQQmOm1KyBw.png"/></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">精度曲线和损失曲线分别用于训练和验证数据。</strong></figcaption></figure><h2 id="9009" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">3.4.ROC结果</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nq"><img src="../Images/f5ad234c222ab31083092118b8b949fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*SF8bcW_G5A98dmO6c9KQJQ.png"/></div><figcaption class="nd ne et er es nf ng bd b be z dx translated"><strong class="bd ln">(a)MLP模型的ROC图，(CNN模型的ROC图</strong></figcaption></figure><ul class=""><li id="5aa7" class="ko kp hi jl b jm jn jp jq js kq jw kr ka ks ke kt ku kv kw bi translated">以上是中华民国的地图。</li></ul><h2 id="6c41" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">3.5.精确度和SOTA比较</h2><ul class=""><li id="4ba7" class="ko kp hi jl b jm md jp me js mf jw mg ka mh ke kt ku kv kw bi translated">通过<strong class="jl hj"> MLP </strong>和<strong class="jl hj"> CNN </strong>模型达到的平均准确率分别为<strong class="jl hj"> 93.0 </strong>和<strong class="jl hj"> 97.0 </strong>。</li><li id="5552" class="ko kp hi jl b jm kx jp ky js kz jw la ka lb ke kt ku kv kw bi translated">合成数据库也用基于<strong class="jl hj">曲波变换的能量特征和基于前馈神经网络的分类模型</strong>进行测试(Tiwari，2017)。使用该模型的平均精度为<strong class="jl hj"> 95.7 </strong>。</li></ul></div><div class="ab cl le lf gp lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="hb hc hd he hf"><h2 id="7297" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">参考</h2><p id="f738" class="pw-post-body-paragraph jj jk hi jl b jm md ij jo jp me im jr js nr ju jv jw ns jy jz ka nt kc kd ke hb bi translated">【2020 iji SMD】【tiwa ri iji SMD’20】<br/><a class="ae nl" href="https://ideas.repec.org/a/igg/jismd0/v11y2020i1p93-111.html" rel="noopener ugc nofollow" target="_blank">一种使用深度卷积神经网络的模糊分类方法</a></p><h2 id="7c79" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated">模糊分类</h2><p id="1190" class="pw-post-body-paragraph jj jk hi jl b jm md ij jo jp me im jr js nr ju jv jw ns jy jz ka nt kc kd ke hb bi translated"><strong class="jl hj">2017</strong><a class="ae nl" href="https://sh-tsang.medium.com/review-sfa-simplified-fast-alexnet-blur-classification-4121e6d813f9" rel="noopener">SFA</a>】<strong class="jl hj">2019</strong><a class="ae nl" href="https://sh-tsang.medium.com/review-sfa-sfgn-simplified-fast-googlenet-blur-classification-e99a8c1f5d25" rel="noopener">SFA&amp;SFGN</a><strong class="jl hj">2020</strong><a class="ae nl" href="https://sh-tsang.medium.com/review-convolutional-neural-network-for-blur-images-detection-as-an-alternative-for-laplacian-7b97b6729fed" rel="noopener">桑达萨·SSCI ' 20</a><strong class="jl hj"/><a class="ae nl" href="https://sh-tsang.medium.com/review-a-blur-classification-approach-using-deep-convolution-neural-network-blur-classification-93edf4552fd7" rel="noopener">提瓦里·伊吉斯姆德' 20 </a> ]</p><h2 id="5437" class="mj lm hi bd ln mk ml mm lr mn mo mp lv js mq mr lx jw ms mt lz ka mu mv mb mw bi translated"><a class="ae nl" rel="noopener" href="/@sh.tsang/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e">我之前的其他阅读</a></h2></div></div>    
</body>
</html>