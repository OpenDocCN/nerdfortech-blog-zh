<html>
<head>
<title>Creating a Facial Emotion Recognizer Line by Line</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逐行创建面部情感识别器</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/creating-a-facial-emotion-recognizer-line-by-line-169d8a2c3986?source=collection_archive---------12-----------------------#2021-02-18">https://medium.com/nerd-for-tech/creating-a-facial-emotion-recognizer-line-by-line-169d8a2c3986?source=collection_archive---------12-----------------------#2021-02-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d9cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近我有了一个想法，用机器学习来识别人们脸上的微表情。在我自己学习如何制作算法的过程中，我想我应该从基础开始，制作一个可以检测普通<strong class="ih hj">宏表达式</strong>的算法。</p><p id="a3d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用CK+48数据集发现<a class="ae jd" href="https://www.kaggle.com/gauravsharma99/ck48-5-emotions" rel="noopener ugc nofollow" target="_blank">在这里</a>，我能够复制一个模型，达到66%的最高精度水平。由于数据集的规模较小，这种准确性不是最大的，我计划在未来尝试改进这一点，但就目前而言，创建该模型是一次很好的学习体验。</p><p id="6b69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们开始，如何使用PyTorch一行一行地检测面部表情。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/a7f97089afc7a229e7e3b86efe7e7898.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*AcxsHKATmpOVEBv8ouO4JQ.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">鸣谢:Getty Images/iStockphoto</figcaption></figure><h2 id="1933" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">导入所需的模块</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="11a6" class="jq jr hi km b fi kq kr l ks kt">import numpy as np<br/>import torch<br/>from torch import nn<br/>from torch import optim<br/>import torch.nn.functional as F<br/>from torchvision import datasets, transforms, models</span></pre><p id="0069" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们正在导入制作模型所需的必要模块。<strong class="ih hj">导入numpy作为np </strong>导入NumPy库来创建和操作矩阵。<strong class="ih hj">导入torch </strong>导入pytorch库，它有几个函数可以用更少的代码创建网络。<strong class="ih hj">从torch导入nn </strong>从torch库中导入nn函数，这使得我们可以轻松地为网络创建层。<strong class="ih hj">从torch导入optim </strong>导入optim功能，使我们可以轻松访问减少误差的功能。<strong class="ih hj">导入torch.nn.functional as F </strong>导入torch.nn.functional函数，可从torchvision导入数据集、转换、模型<strong class="ih hj">用命令“F”调用该函数</strong>从torchvision模块导入必要的库。<strong class="ih hj">数据集</strong>帮助我们将图像转换成可以操作的数据集，<strong class="ih hj">变换</strong>为我们提供可以对图像进行的不同变换，<strong class="ih hj">模型</strong>让我们从torchvision网站访问预先训练好的卷积网络。</p><p id="18ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">将数据集上传到google collab </strong></p><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="9578" class="jq jr hi km b fi kq kr l ks kt">from google.colab import files<br/>uploaded = files.upload()<br/>for fn in uploaded.keys():<br/>   print('User uploaded file "{name}" with length {length}      <br/>   bytes'.format(name=fn, length=len(uploaded[fn])))</span></pre><p id="4331" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">从google.colab导入文件</strong>导入google colab上的文件库。<strong class="ih hj">uploaded = files . upload()</strong>为上传文件的字典创建一个变量。<strong class="ih hj">对于uploaded.keys()中的fn:print('长度为{length}字节的用户上传文件" {name} ")。format(name=fn，length=len(uploaded[fn]))) </strong>显示上传文件的名称和大小。运行此代码后，将弹出一个“上传”按钮，允许您访问您的zip文件。</p><h2 id="7976" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated"><strong class="ak">提取压缩数据文件</strong></h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="2651" class="jq jr hi km b fi kq kr l ks kt">from zipfile import ZipFile<br/>file_name = "Emotions.zip"<br/>with ZipFile(file_name, 'r') as zip:<br/>   zip.extractall()<br/>   print("Done")</span></pre><p id="452a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">从zipfile导入ZipFile </strong>导入模块ZipFile。<strong class="ih hj"> file_name = "Emotions.zip" </strong>创建一个名为“file_name”的变量，其值为“emotions . zip”<strong class="ih hj">zip file(file_name，' r ')为zip: </strong>找到file _ name的路径，并将该文件作为zip引用。<strong class="ih hj"> zip.extractall() </strong>提取zip中的所有文件。<strong class="ih hj"> print("Done) </strong>用于告诉我们提取完成的时间。</p><h2 id="2b54" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">转换数据</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="9065" class="jq jr hi km b fi kq kr l ks kt">test_dir = '/content/Emotions/CK+48/test'<br/>train_dir = '/content/Emotions/CK+48/train'</span><span id="d006" class="jq jr hi km b fi ku kr l ks kt">train_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(100),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])</span><span id="2da2" class="jq jr hi km b fi ku kr l ks kt">test_transforms = transforms.Compose([transforms.Resize(255), transforms.CenterCrop(224),transforms.ToTensor()])</span></pre><p id="33a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面两行将路径分配给测试数据文件夹和训练数据文件夹，以及它们对应的测试和训练目录。第二行创建一个变量，该变量包含将应用于训练集中照片的所有变换。<strong class="ih hj"> RandomRotation(30) </strong>以30*的间隔随机旋转每张照片。<strong class="ih hj"> RandomResizedCrop(100) </strong>将照片裁剪为100个单位的边长。<strong class="ih hj"> RandomHorizontalFlip() </strong>会沿着其横轴随机翻转部分照片。<strong class="ih hj"> ToTensor() </strong>将照片转换成张量，以便稍后模型可以对其进行计算。<strong class="ih hj"> Normalize([0.5，0.5，0.5]，[0.5，0.5])]) </strong>有助于将每个像素的颜色值转换为-1到1之间的值，因此它们更容易被模型处理。最后一行创建一个变量，该变量包含将应用于测试集中照片的所有转换。<strong class="ih hj"> Resize(255) </strong>调整所有边长为255个单位的照片的大小。<strong class="ih hj"> CenterCrop(224) </strong>裁剪照片，并使其上下左右居中16个像素。</p><h2 id="2692" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">创建可计算的数据集</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="a88f" class="jq jr hi km b fi kq kr l ks kt">train_data = datasets.ImageFolder(train_dir, transform=train_transforms)<br/>trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)</span><span id="8b55" class="jq jr hi km b fi ku kr l ks kt">test_data = datasets.ImageFolder(test_dir, transform=test_transforms)<br/>testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)</span></pre><p id="782d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一行为由train文件夹中的图像组成的训练数据创建一个变量，并对它们应用前面提到的转换。第二行将这个新转换的训练数据分成每批32个图像的批，并且每批中的照片被送入模型的顺序在每次迭代中被打乱。最后两行与前两行做同样的事情，但是使用的是测试数据。</p><h2 id="110d" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">载入我们预先训练的模型</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="16f7" class="jq jr hi km b fi kq kr l ks kt">model = models.alexnet(pretrained=True)</span><span id="3335" class="jq jr hi km b fi ku kr l ks kt">for param in model.parameters():<br/>   param.requires_grad = False</span></pre><p id="d532" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一行是使用开头导入的“模型”库，将预先训练好的卷积网络“alexnet”上传到代码中。<strong class="ih hj"> pretrained=True </strong>只是表示网络是预先训练好的。这个网络来自torchvision，一个你可以找到预先训练好的网络的网站。它们已经在数千张照片上进行了训练，非常适合通用图像识别。</p><p id="3757" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后两行遍历网络中的每个参数(或层)，并使用<strong class="ih hj">param . requires _ grad = False</strong>命令关闭每个参数的反向传播功能。由于这些参数已经过预先训练，我们不希望我们添加的数据影响它们。</p><h2 id="7147" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">创建分类器并将其添加到模型中</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="ff26" class="jq jr hi km b fi kq kr l ks kt">classifier = nn.Sequential(nn.Linear(9216, 1000), nn.ReLU(), nn.Dropout(0.2), nn.Linear(1000, 5), nn.LogSoftmax(dim=1))</span><span id="186f" class="jq jr hi km b fi ku kr l ks kt">model.classifier = classifier</span></pre><p id="f33c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一行定义了一个有五层的分类器。<strong class="ih hj"> nn。Linear(9216，1000) </strong>是一个普通层，它接受9216个输入，输出1000个值。<strong class="ih hj"> nn。ReLU() </strong>是一个用于将1000个输出值转换为1或0的函数。<strong class="ih hj"> nn。Dropout(0.2) </strong>是一个关闭层中节点的函数，每个节点有20%的机会被关闭。这有助于防止过度拟合，强制模型进行更多的概括。<strong class="ih hj"> nn。Linear(1000，5) </strong>是另一个正常层，它接受1000个输入，并吐出5个输出，每个输出对应于我们试图分类的每一类情绪。<strong class="ih hj"> nn。LogSoftmax(dim=1) </strong>通过Softmax函数发送五个输出中的每一个，softmax函数将输入转换为0到1之间的某个值，每个值代表该图像出现在每类情绪中的概率。</p><p id="ea20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一行只是用我们刚刚创建的分类器替换了alexnet模型的原始分类器。</p><h2 id="2752" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated"><strong class="ak">创建损失和反向传播功能</strong></h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="5889" class="jq jr hi km b fi kq kr l ks kt">criterion = nn.NLLLoss()</span><span id="8ca3" class="jq jr hi km b fi ku kr l ks kt">optimizer = optim.SGD(model.classifier.parameters(), lr=0.003)</span></pre><p id="d832" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">判据= nn。NLLLoss() </strong>将创建一个名为criterion的变量，当被命令时，将计算给定参数的负对数似然损失。这有助于通过将每个类别中的预测值与实际图像值进行比较来确定模型预测的错误程度。</p><p id="4183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优化器= optim。Adam(model . classifier . parameters()，lr=0.003) </strong>为反向传播函数创建一个变量，在本例中是Adam函数。该函数应用于我们之前创建的分类器变量中的所有参数或层。学习率<strong class="ih hj"> lr=0.003 </strong>被设置为0.003，这决定了函数改变节点的权重和偏差的幅度。</p><h2 id="0e0d" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">为培训创建变量</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="d981" class="jq jr hi km b fi kq kr l ks kt">epochs = 8<br/>steps = 0<br/>running_loss = 0<br/>print_every = 5</span></pre><p id="aae4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">时期</strong>是所有数据通过模型向前和向后反馈一次的次数。<strong class="ih hj">步数</strong>是训练模型运行的批次数。这被设置为零，因为还没有批次被前馈。<strong class="ih hj"> running_loss </strong>是在训练阶段早期建立的损失函数或标准的输出的累加值。<strong class="ih hj"> print_every </strong>是一个设定值，用于确定在多少个步骤后对模型进行测试运行。</p><h2 id="d0d2" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">创建训练循环</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="3e30" class="jq jr hi km b fi kq kr l ks kt">for epoch in range(epochs):<br/>   for inputs, labels in trainloader:<br/>      steps += 1<br/>      optimizer.zero_grad() <br/>      logps = model.forward(inputs) <br/>      loss = criterion(logps, labels) <br/>      loss.backward()<br/>      optimizer.step()<br/>      running_loss += loss.item()</span></pre><p id="1eb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对于范围内的时期(epochs): </strong>按照epochs的值运行训练循环，在本例中为8次。<strong class="ih hj">对于输入，trainloader中的标签:</strong>遍历我们的训练数据集trainloader中的每个输入和相应的标签。<strong class="ih hj"> steps += 1 </strong>每通过训练循环发送一批，我们的“steps”变量增加1点。</p><p id="bd3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于优化器的自然趋势是累积每个输入的梯度，而不是静止它们，<strong class="ih hj"> optimizer.zero_grad() </strong>用于在反向传播步骤中重置每个节点的梯度值。<strong class="ih hj">logps = model . forward(inputs)</strong>通过我们的模型将来自我们的训练批次的输入向前馈送，并创建一个称为“logps”的输出变量。<strong class="ih hj"> loss = criterion(logps，labels) </strong>使用我们之前创建的标准函数计算批次中每个图像的损失。<strong class="ih hj"> loss.backward() </strong>计算损失函数的输出相对于通过分类器发送的原始输入的导数。<strong class="ih hj"> optimizer.step() </strong>根据loss.backward()函数给每个节点的导数，更新和改变每个节点的权重和偏差。<strong class="ih hj">running_loss+= loss . item()</strong>将每个输入的损失值添加到我们的“running _ loss”变量中，以便我们可以确定该批的总训练损失。随着时间的推移，这应该会变小。</p><h2 id="d973" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">创建测试循环条件和变量</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="91fb" class="jq jr hi km b fi kq kr l ks kt">if steps % print_every == 0:<br/>   test_loss = 0<br/>   accuracy = 0 <br/>   model.eval()</span></pre><p id="3d6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一行是这样的，当“steps”除以“print_every”的余数为0时，执行后续代码。基本上每五步就要进行一次测试。</p><p id="2e39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> test_loss = 0 </strong>与running_loss相同，但专门针对测试数据。<strong class="ih hj">精度= 0 </strong>只是为模型的精度创建一个变量，从0开始。<strong class="ih hj"> model.eval() </strong>将模型置于评估模式。</p><h2 id="97af" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">创建测试循环</h2><p id="7375" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated"><em class="la">注意:下面的代码属于上面的if语句。</em></p><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="972a" class="jq jr hi km b fi kq kr l ks kt">with torch.no_grad():<br/>   for inputs, labels in testloader:<br/>      logps = model.forward(inputs)<br/>      batch_loss = criterion(logps, labels)<br/>      test_loss += batch_loss.item()</span></pre><p id="a66a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> torch.no_grad() </strong>停止测试数据的反向传播。这一点很重要，因为我们在这里不是试图训练模型，而是测试模型在当前状态下的准确性。<strong class="ih hj">对于输入，testloader中的标签:</strong>遍历testloader(我们的测试数据集)中的输入和相应的标签。<strong class="ih hj">logps = model . forward(inputs)</strong>通过当前模型向前馈送测试数据输入。<strong class="ih hj">batch _ loss = criteria(logps，labels) </strong>计算测试批次的损失。<strong class="ih hj">test_loss+= batch _ loss . item()</strong>将批处理中每个输入的损失添加到我们的“test _ loss”变量中。</p><h2 id="be9b" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">检查我们模型的准确性</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="c443" class="jq jr hi km b fi kq kr l ks kt">ps = torch.exp(logps)<br/>top_p, top_class = ps.topk(1, dim=1)<br/>equals = top_class == labels.view(*top_class.shape)<br/>accuracy += torch.mean(equals.type(torch.FloatTensor)).item()</span></pre><p id="2c40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> ps = torch.exp(logps) </strong>计算图像在五个情感类别中的概率。<strong class="ih hj"> top_p，top_class = ps.topk(1，dim=1) </strong>根据前面的<strong class="ih hj"> </strong>行，将变量“top_class”赋给概率最高的类。<strong class="ih hj">equals = top _ class = = labels . view(* top _ class . shape)</strong>检查概率最高的类别是否等于图像实际所属的类别。<strong class="ih hj">准确度+=火炬.平均值(等于.类型(火炬。FloatTensor)。item() </strong>将“equals”变量转换为浮点张量(因为之前它是一个字节张量)，然后对所有预测取正确预测的平均值，并将该值添加到我们的准确度中。</p><h2 id="62d2" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">打印结果并将模型设置回训练模式</h2><pre class="jf jg jh ji fd kl km kn ko aw kp bi"><span id="69c2" class="jq jr hi km b fi kq kr l ks kt">print(f"Epoch {epoch+1}/{epochs}.. "<br/>      f"Train loss: {running_loss/print_every:.3f}.. "<br/>      f"Test loss: {test_loss/len(testloader):.3f}.. "<br/>      f"Test accuracy: {accuracy/len(testloader):.3f}")</span><span id="9029" class="jq jr hi km b fi ku kr l ks kt">running_loss = 0<br/>model.train()</span></pre><p id="e616" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一个语句仅使用模型中的变量来打印当前时期、该时期的列车损失、该时期的测试损失以及最重要的测试准确度。<strong class="ih hj"> running_loss = 0 </strong>将running_loss设置回0，以便模型可以在下一批上训练。<strong class="ih hj"> model.train() </strong>使模型退出评估模式，并返回测试模式。</p><h2 id="6d23" class="jq jr hi bd js jt ju jv jw jx jy jz ka iq kb kc kd iu ke kf kg iy kh ki kj kk bi translated">你完了！</h2><p id="d37c" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">你有它！我们刚刚逐行创建了一个面部情绪识别模型。你应该能得到60%以上的准确率。</p><p id="9dd8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想在GitHub上查看代码，点击<a class="ae jd" href="https://gist.github.com/Strady123/949f3d3ac8257c1e8e168a08460d1b54#file-emotion-recognition-ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。感谢你的阅读，祝你在发现这些情绪时愉快！:)</p></div></div>    
</body>
</html>