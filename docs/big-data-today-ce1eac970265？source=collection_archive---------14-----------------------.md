# 当今的大数据。

> 原文：<https://medium.com/nerd-for-tech/big-data-today-ce1eac970265?source=collection_archive---------14----------------------->

## 数据已经成为本世纪的一个突出话题。许多人意识到了这一点，但对其造成的破坏性影响缺乏了解。

![](img/63c57a7ab3f9b58d0ba89aae770b5be6.png)

Unsplash [@matthewhenry](https://unsplash.com/@matthewhenry)

凯茜·奥尼尔的**数学毁灭武器(WMD)** 是描述我们当前科技世界以及有多少科技公司依靠我们的数据蓬勃发展的完美书籍。

数据被用来创建一个数据驱动的模型，该模型理应在各个方面提高效率、生产力和透明度。这些模型成为量化重要特征的一种方式:教师的素质、累犯风险和工作适应性。它成为我们生活中的一个决定性因素，因为我们经常强加我们的价值观和思想，因为它影响我们的决定。

反过来，这导致不平等，威胁我们的民主。现在，我将在本书中浓缩一些值得注意的要点:

**冲击**

**IMPACT** 是一款教师评估工具，帮助评估教育工作者的教学效率和熟练程度。当一名教师收到的分数没有达到通过率，他们将被解雇。

然而，可以看出，这个工具并不是对教师的准确评估，因为有些教师得到了学生的好评，但仍然得到很低的分数。

该评估考虑了学生在学校的表现，并根据教师的教学能力来计算学生的进步程度。然而，它没有考虑到学生们正处于人生关键时刻的情况。也就是说，如果学生表现不佳，评估会认为老师没有能力。

> 他们定义自己的现实，并用它来证明他们的结果。这种模式是自我延续的，极具破坏性的——而且非常普遍。

**累犯**

![](img/8f25eaddfef30cc27aa7e79bc95e4b51.png)

unsplash from[@ tingeyinjurrylawfirm](https://unsplash.com/@tingeyinjurylawfirm)

累犯模型用于评估罪犯重新犯罪的可能性。该模式的目标是在量刑时创造透明度并减少人为偏见。

使用的一个流行模型是**服务库存水平修订版(LSI-R)** 。囚犯们必须填写一份调查他们个人生活的问卷，这将决定他们的“风险等级”。然而，LSI-R 模型不能提供不同人群之间的公正比较。

> 纽约公民自由联盟(New York Civil Liberties Union)2013 年的一项研究发现，尽管年龄在 14 岁至 24 岁之间的黑人和拉丁裔男性仅占该市人口的 4.7%，但他们却占了警察拦截搜身检查的 40.6%。超过 90%的被拦截者是无辜的。
> 
> —凯西·奥尼尔

这个例子表明，这种模式对于穷人和非白人来说是一个巨大的障碍。考虑到数据输入，法官认为这些人更有可能根据环境和他们接触的人的类型重新犯罪。然后，他们又被扔进了监狱。

这造成了一个恶性循环，因为一旦被贴上高危标签的罪犯被释放到社会中，他们将更难找到工作。他们中的一些人可能会因为他们的环境而再次犯罪，并剥夺他们的机会，因为社会以不同的眼光看待他们。

**工作申请**

![](img/56fda74f5cb7b22edbae5fcca1c8f5b3.png)

来自[的取消邀请@madebyvadim](https://unsplash.com/@madebyvadim)

72%的简历从未被看过，因为大多数公司使用求职者系统来优化他们的工作效率。这样的系统有助于以尽可能低的成本筛选出尽可能多的申请者。

人类已经把他们的思想和意识形态嵌入了这个系统。现在，该系统学习如何歧视种族、性别和精神疾病患者，剥夺他们的工作机会。

简化流程确实给公司带来了很多好处，但是，这对我们社会中的少数人来说公平吗？

**结论**

这本书没有为大数据时代的发展提供具体而清晰的方向。它确实强调了模型的创建不仅仅是基于数据，而是基于我们做出的关于使用和不使用哪些数据的选择。

技术将会发展，如果数据仍然被公司滥用，少数民族将会受害。民主认为每个人都应该有平等的地位和机会，然而，今天的技术确实与这种说法相矛盾。

我相信技术应该被用于公共利益，在那里我们创造积极地有益于用户的产品。我们永远无法根除人类的偏见，但政府和技术公司可以采取这些措施来确保正确使用大数据，例如

*   调节数据
*   向公众展示透明度

数学毁灭武器确实给出了许多滥用数据的好例子，以及它如何影响我们的生活。在大数据时代，我们提供的数据经常在我们不知情的情况下被使用。