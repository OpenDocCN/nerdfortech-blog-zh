<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/machine-learning-classifiers-for-different-garments-using-fashion-mnist-dataset-7c7aa524c197?source=collection_archive---------7-----------------------#2021-03-04">https://medium.com/nerd-for-tech/machine-learning-classifiers-for-different-garments-using-fashion-mnist-dataset-7c7aa524c197?source=collection_archive---------7-----------------------#2021-03-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><p id="a76f" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">使用fashion-mnist数据集的不同服装的机器学习分类器。</p><figure class="ig ih ii ij fd ik er es paragraph-image"><div role="button" tabindex="0" class="il im di in bf io"><div class="er es if"><img src="../Images/6475b29b9b3e0809f71894983581b3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrcIRZGvdroq0vCaDvJxXw.png"/></div></div><figcaption class="ir is et er es it iu bd b be z dx translated">F-mnist数据集样本图像</figcaption></figure><p id="6a97" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv"> <em class="iw">算法选择:</em> </strong></p><p id="b75f" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">这里，一般来说，使用不同方法的三种算法被选择用于使用fashion-mnist数据集的服装预测:</p><p id="0eac" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">基于概率:逻辑回归</p><p id="6dff" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">基于特征的:支持向量机。</p><p id="7bb0" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">基于平均基础模型:随机福里斯特</p><p id="f3b1" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv">逻辑回归</strong></p><p id="5bc6" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">这是一种概率方法，它将数据分类到最匹配的类别。它是一个简单且易于训练的分类器，不需要太多的数据集，计算复杂度也较低。这里调整的超参数是正则化方法(L2)，这是“sag”中的内置函数，有助于在更短的时间内解决更高的数据集，常数(C)有助于避免数据过拟合和欠拟合。</p><p id="0766" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv">随机森林</strong></p><p id="8372" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">它是一种集成形式，由m基模型组成，具有所有决策树，但具有不同的输入属性，以避免基模型之间的相关性。开发该算法的原因是最小化方差，而不影响决策树的缺点偏差项。因此，这里调整的超参数是决策树的数量(n-estimators)、树的深度(max-depth)以避免数据集上模型的过拟合或欠拟合，以及输入属性的数量(max-features)以减少方差而不影响性能。</p><p id="9670" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv">支持向量机</strong></p><p id="6cc1" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">SVM是一种受监督的机器学习，它通过将数据点投影到N维特征空间(N =特征数量)来对数据进行分类，从而最大化边缘，但有时数据会在边缘的另一侧结束，这被称为训练误差，这里产生的边缘是软边缘。SVM的边缘仅取决于支持向量(最接近边缘的数据点),因此我们可以说这是一种内存高效的算法。在支持向量机中，为了提高效率，实现了内核技巧，以将其从线性分类器转换为非线性分类器，非线性分类器又将数据投影到更高维度中，以找到多个类之间的最佳间隔。此处调整的超参数是正则化常数(C)，用于选择软边界和内核的严格性(' poly '，' radial '，' sigmoid <strong class="hj iv">'，'</strong> rbf <strong class="hj iv"> ' </strong>)</p><p id="9e49" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv"> <em class="iw">方法论:</em> </strong></p><p id="c21b" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">图像中的每个像素被认为是算法的一个特征，因此为了改进处理时间，所有像素在范围(0，1)中被重新缩放(1/255)</p><p id="7372" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在优化分类算法之前，需要对数据进行加载和整形。为了克服欠拟合和欠拟合，除了训练精度之外，还对验证精度进行监控，因此数据按照75:15:10的比例进行分离，用于训练、验证和测试。主成分分析(PCA = 0.99):这有助于减少我的处理时间，而对模型性能没有任何显著影响，因为只有高度相关的样本被删除，459个特征在应用后被保留。</p><p id="b310" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">用于调整具有低处理时间的超参数，具有5倍的随机化CV。这里，部分数据用于验证，以防止模型欠拟合和过拟合。性能:性能是基于准确度、精确度和F1分数来考虑的，通过检查混淆矩阵，我们可以观察到哪个类被错误分类得最多。</p><p id="d681" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv"> <em class="iw">结果:</em> </strong></p><p id="d891" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在测试超参数c= [0.1，10]和最大迭代次数= [100，150]之后，逻辑回归在c =0.1时达到最大准确度85，但是对于(100，110)，数据没有收敛。</p><p id="7b9b" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在对估计量(300，500)、最大深度=[25，35]、最大特征=[40，50]进行测试后，随机森林对于估计量= 400、最大深度= 32和最大特征= 50获得了88.026的最大准确度。</p><p id="0e5d" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在对超参数c = (40，55)，kernel=('poly '，' radial '，' sigmoid <strong class="hj iv">'，'</strong> RBF ')，degree = [3，4，5]进行测试后，SVM对C = 40，kernel = 'poly '和degree 4达到了89的准确度。</p><figure class="ig ih ii ij fd ik er es paragraph-image"><div class="er es ix"><img src="../Images/59f1c308f38f69e5cbfc3d9166f46465.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/0*vrZcYggjYiDDDeAz"/></div><figcaption class="ir is et er es it iu bd b be z dx translated">图1.1逻辑回归</figcaption></figure><figure class="ig ih ii ij fd ik er es paragraph-image"><div class="er es iy"><img src="../Images/0a78cf6532b5855a58fba878d7beea35.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/0*5esnaTNnREvFMlrL"/></div><figcaption class="ir is et er es it iu bd b be z dx translated">图1.2随机森林</figcaption></figure><figure class="ig ih ii ij fd ik er es paragraph-image"><div class="er es iy"><img src="../Images/b46fa9699c1daf44b0d227fc49f95a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/0*qMhIdiV2_Zl4pThK"/></div><figcaption class="ir is et er es it iu bd b be z dx translated">图1.3支持向量机</figcaption></figure><p id="64ec" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">从混淆矩阵中可以推断出，衬衫总是被错误分类为最多的t恤或套头衫，甚至大衣也被错误分类为衬衫，而不管使用什么算法。</p><p id="465b" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">逻辑回归、随机森林和支持向量机的F1值在测试集上分别为0.85、0.88和0.89。</p><p id="08b9" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated"><strong class="hj iv"> <em class="iw">结论:</em> </strong></p><p id="30b6" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在逻辑回归中，正则化常数C在范围[0.1，1]之后显著增加或降低模型性能，因为模型在该范围之外是欠拟合或过拟合的，并且在这些值之外也不能获得收敛。而且，由于存在时间效率问题，与非PCA实现相比，应用PCA使得预测最差。</p><p id="e879" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在随机森林中，所有三个超参数对每个参数设计的特定范围之外的任何变化都很敏感。最大深度可以在(25，35)之间调整，低于该值时，它会使模型欠拟合，而高于该值时，它会使模型过拟合，类似地，n估计值在范围(300，500)内。这里的PCA降低了模型的性能，这意味着所有特征在预测中都是突出的。</p><p id="4b5c" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">在SVM，核在精度中起着重要的作用，因为不同的核在精度上变化太大。由于我们的数据不是线性可分的,“poly”内核提高了它们之间的相关性，与其他机器学习算法相比，它的预测精度更高。PCA有助于在不影响模型性能的情况下减少处理时间。</p><p id="ac33" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">没有一个分类器能以90%以上的准确度预测服装，这有许多原因。主要原因是，一件特定服装的独特风格图像较少，不仅如此，少数服装之间的相似性也导致了这一问题。这个问题可以通过图像增强来解决，我还没有尝试过，也可以通过移除高度相关的图像来解决。</p><p id="97ed" class="pw-post-body-paragraph hg hh hi hj b hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie hb bi translated">最后，在所有算法中，SVM预测数据集的准确率为89%，但与其他模型相比，处理时间非常长，尽管存在这一缺点，但这是可以高精度预测任何服装的最佳算法。</p></div></div>    
</body>
</html>