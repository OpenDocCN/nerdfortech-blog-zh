<html>
<head>
<title>Digit Recognition using ML Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于最大似然算法的数字识别</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/digit-recognition-using-ml-algorithm-b8171caff87f?source=collection_archive---------8-----------------------#2021-06-30">https://medium.com/nerd-for-tech/digit-recognition-using-ml-algorithm-b8171caff87f?source=collection_archive---------8-----------------------#2021-06-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/8f70baa59e6e534426aab095c048491b.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*e7riTnPuEHfd_xvGzPhmLQ.png"/></div></figure><p id="f62e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我将使用最大似然算法预测数字。我将使用三种流行的算法。</p><h1 id="3a41" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">随机森林算法</strong></h1><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/433631aca2c604042ae2ba285ff44a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*cgye5oUgLr4-R8VwwZZapA.png"/></div></figure><p id="4090" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">随机森林是一种流行的机器学习算法，属于监督学习技术。它可用于 ML 中的分类和回归问题。它基于<strong class="io hj">集成学习的概念，</strong>集成学习是<em class="kn">组合多个分类器来解决复杂问题并提高模型性能的过程。</em></p><p id="eb69" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">顾名思义，<strong class="io hj"> <em class="kn">“随机森林是一种分类器，它包含给定数据集的各个子集上的许多决策树，并取平均值以提高该数据集的预测准确性。”</em> </strong>随机森林不是依赖一棵决策树，而是从每棵树中提取预测，并基于预测的多数票，预测最终输出。</p><p id="b048" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">森林中的树木数量越多，精确度越高，并可防止过度拟合的问题。</strong></p><p id="2cf3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">随机森林分两个阶段工作，首先是通过组合 N 棵决策树来创建随机森林，其次是对第一阶段创建的每棵树进行预测。</p><p id="4fc2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">工作过程可在以下步骤和图表中解释:</p><p id="91bc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">步骤 1: </strong>从训练集中随机选择 K 个数据点。</p><p id="b323" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">步骤 2: </strong>构建与所选数据点(子集)相关的决策树。</p><p id="f786" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">步骤 3: </strong>为您想要构建的决策树选择数量 N。</p><p id="71d0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">步骤 4: </strong>重复步骤 1 &amp; 2。</p><p id="33d9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">第五步:</strong>对于新的数据点，找到每个决策树的预测，将新的数据点分配到赢得多数票的类别。</p><h1 id="6c07" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">让我们编码</strong></h1><p id="cffc" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">我正在使用 jupyter 笔记本，它有助于我将预测可视化。</p><h2 id="0dac" class="kt jl hi bd jm ku kv kw jq kx ky kz ju ix la lb jy jb lc ld kc jf le lf kg lg bi translated">导入数据集和所需的库</h2><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/165741ec53fdce267da0de6e74b2185d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezjC0jkcYrMek6gcveG71Q.png"/></div></div></figure><h2 id="cb7f" class="kt jl hi bd jm ku kv kw jq kx ky kz ju ix la lb jy jb lc ld kc jf le lf kg lg bi translated">让我们看看数据</h2><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/6cacd3478943561d7a6a2520ac2504a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*cFvUIxmNdzBpHqa5CAzU3g.png"/></div></figure><p id="117d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我已经删除了“目标”列，因为它有真值并保存在其他变量中。</p><h2 id="0415" class="kt jl hi bd jm ku kv kw jq kx ky kz ju ix la lb jy jb lc ld kc jf le lf kg lg bi translated">现在我们将训练模型</h2><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es ln"><img src="../Images/baee3a1f53a674c2faabafe460430c8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15bGdLPtfsOZMZqscjd9uw.png"/></div></div></figure><p id="bf31" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在导入随机森林分类器并传递训练好的数据</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/69d6e08d8dd3234ad05cac930d8ce6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*FTRkzndAJrIpnN59NdP4tg.png"/></div></figure><p id="16f9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里，当你保持 n 估计值为 10 或 20 时，你会得到较低的精度分数，这是因为我们之前已经看到更多数量的树更高的精度，但即使你保持 n 估计值大于 40，你也会得到相同的精度分数。让我们看看如何检查分数。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/0fe022c47f3a78753bd8b67a859170fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*BoHpaAZL4kQxkaVzpRWcfA.png"/></div></figure><p id="1ca1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里我们得到了 98%的准确率，这是很好的。</p><p id="2a13" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将会看到热图，在那里我们能够得到预测出错的地方。</p><p id="ecee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为此我们需要得到混淆矩阵。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lq"><img src="../Images/f496efce2265333d6cba8518e7ca1672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqjcIa7Fv7UzK3q7tVynEQ.png"/></div></div></figure><p id="62ba" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，在这个矩阵上，我们将构建热图。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/11f940c1c9c33666e5d8df0d92c00e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*79PJjPRrX_KNqrnCskifKw.png"/></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/183fb823cc869a246b19fb1bff509727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*-n5xJ9fLdBkuIzXJQKtaYA.png"/></div></figure><p id="1f41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以现在你可以看到预测是错误的。</p><h1 id="ce4d" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">K-最近邻算法</strong></h1><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lt"><img src="../Images/ec5794c43417c2c82bb0cc462b94c3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G9jvAQ01FyKh8k94w4AQ0A.png"/></div></div></figure><p id="ebcf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">k 近邻算法是基于监督学习技术的最简单的机器学习算法之一。K-NN 算法假设新案例/数据与可用案例之间的相似性，并将新案例放入与可用类别最相似的类别中。</p><p id="8e80" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">K-NN 算法存储所有可用的数据，并基于相似性对新的数据点进行分类。这意味着当新数据出现时，可以通过使用 K- NN 算法很容易地将其分类到一个很适合的类别中。K-NN 算法既可用于回归，也可用于分类，但主要用于分类问题。K-NN 是一种<strong class="io hj">非参数算法</strong>，也就是说它不对底层数据做任何假设。</p><p id="cd79" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它也被称为<strong class="io hj">懒惰学习算法</strong>，因为它不会立即从训练集中学习，而是存储数据集，并在分类时对数据集执行操作。训练阶段的 KNN 算法只是存储数据集，当它获得新数据时，它会将该数据分类到与新数据非常相似的类别中。</p><p id="a553" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">K-NN 的工作可以基于下面的算法来解释:</p><ul class=""><li id="41e3" class="lu lv hi io b ip iq it iu ix lw jb lx jf ly jj lz ma mb mc bi translated"><strong class="io hj">第一步:</strong>选择邻居的数量 K</li><li id="7650" class="lu lv hi io b ip md it me ix mf jb mg jf mh jj lz ma mb mc bi translated"><strong class="io hj">步骤 2: </strong>计算<strong class="io hj"> K 个邻居</strong>的欧氏距离</li><li id="3f67" class="lu lv hi io b ip md it me ix mf jb mg jf mh jj lz ma mb mc bi translated"><strong class="io hj">第三步:</strong>根据计算出的欧氏距离取 K 个最近邻。</li><li id="e5a2" class="lu lv hi io b ip md it me ix mf jb mg jf mh jj lz ma mb mc bi translated"><strong class="io hj">步骤-4: </strong>在这 k 个邻域中，统计每个类别中的数据点的个数。</li><li id="cfb3" class="lu lv hi io b ip md it me ix mf jb mg jf mh jj lz ma mb mc bi translated"><strong class="io hj">步骤-5: </strong>将新数据点分配到邻居数量最大的类别。</li><li id="ee1a" class="lu lv hi io b ip md it me ix mf jb mg jf mh jj lz ma mb mc bi translated"><strong class="io hj">第六步:</strong>我们的模型做好了。</li></ul><h1 id="9772" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">现在让我们编码</strong></h1><p id="301d" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">导入数据集和库</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mi"><img src="../Images/dac21df9545923430f689bc579c4d153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtfchRvGMG8-ISIwF0UB-A.png"/></div></div></figure><h2 id="2c43" class="kt jl hi bd jm ku kv kw jq kx ky kz ju ix la lb jy jb lc ld kc jf le lf kg lg bi translated">现在我们将训练模型</h2><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mj"><img src="../Images/915526ff1a4bc6db2c5602e9446c58c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pv8GaWvuCFlE5Q3J9_eSbQ.png"/></div></div></figure><p id="46a8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在将使用 knn 分类器和使用欧几里德距离。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/11f9550ccf9ffa919ee14561996fba0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*5KPlMCyVstmyNfca7Fo4RQ.png"/></div></figure><p id="95ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们检查分数</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/26ca6b001b337610f744513a99494936.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*qYDGWQOjyK9qqTFqUvm7Tw.png"/></div></figure><p id="660d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里我们得到了 98%的准确率。</p><p id="851e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将会看到热图，在那里我们能够得到预测出错的地方。</p><p id="d672" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为此我们需要得到混淆矩阵。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/09d115e60f0c198ff2a160106f9424fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*H1DHCEmdWlL7hwU9f4nyOQ.png"/></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/62f8985450aed82db9dd03d579276ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*-UD8Of0kN1Z9AMazcFi0Hw.png"/></div></figure><p id="4034" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以现在你可以看到预测是错误的。</p><h1 id="85cb" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">支持向量机</strong></h1><p id="9824" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">支持向量机或 SVM 是最流行的监督学习算法之一，用于分类和回归问题。然而，它主要用于机器学习中的分类问题。</p><p id="3218" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SVM 算法的目标是创建可以将 n 维空间分成类的最佳线或决策边界，以便我们将来可以轻松地将新数据点放入正确的类别中。这个最佳决策边界称为超平面。</p><p id="a58d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SVM 选择极值点/向量来帮助创建超平面。这些极端情况被称为支持向量，因此算法被称为支持向量机。考虑下图，其中有两个不同的类别，使用决策边界或超平面进行分类:</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/ebe649e157dc1f3f0df085ebe05f4635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Fjj7EblDs2J88GgJmyKL8w.png"/></div></figure><p id="89b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这个算法很难解释，但是当你使用它的时候，你只需要导入算法并使用它。您可以进一步搜索其后端统计数据。</p><h2 id="8241" class="kt jl hi bd jm ku kv kw jq kx ky kz ju ix la lb jy jb lc ld kc jf le lf kg lg bi translated">让我们编码</h2><p id="a8a7" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">导入数据集和所需的库</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/42308abd4b986288d697bb2179dd9863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*f-ohwTlCDeq2qkRQ-uN5pA.png"/></div></figure><p id="61f9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们将训练数据</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mp"><img src="../Images/0257698a2f4ab47ce56c4c007764d790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oamn3c82o1vVppbRg9uaGg.png"/></div></div></figure><p id="09ee" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在我们将使用 svm 分类器</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/b64f43a75f4e770106b5ff6bfd2dcfbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*pCjeIYnu_z5_rPD1_PkaYg.png"/></div></figure><p id="9959" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们检查分数</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/4ca6d6db1e26f20bf4edb2f78f8456e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*BTStfwRbWHteU4U7W-thMw.png"/></div></figure><p id="be0b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里我们得到了 99%的准确率。</p><p id="6d4b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将会看到热图，在那里我们能够得到预测出错的地方。</p><p id="619e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为此我们需要得到混淆矩阵。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/c8c7331f232f07b73bde7704a96ff645.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*1WqNUrHGR3UWNjf3IFuNJw.png"/></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/765f14daca91d9b257ec820a005cbfaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Yv-uWPOy7Z63swGm7_qd1Q.png"/></div></figure><p id="210b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">从这里你可以看到错误的预测值。</p><h1 id="0eb2" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">结论</strong></h1><p id="debc" class="pw-post-body-paragraph im in hi io b ip ko ir is it kp iv iw ix kq iz ja jb kr jd je jf ks jh ji jj hb bi translated">正如我们所看到的，在随机森林算法和 K 最近邻算法中准确率得分是 98%。您还可以看到，在热图中，错误的预测值并不相同。在 SVM，我们获得了最高的 98%的准确率。</p><p id="65e0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">关于代码，你可以访问我的 github 库</p><div class="mu mv ez fb mw mx"><a href="https://github.com/Megha067/Digit-Recognition-using-ML-algorithms" rel="noopener  ugc nofollow" target="_blank"><div class="my ab dw"><div class="mz ab na cl cj nb"><h2 class="bd hj fi z dy nc ea eb nd ed ef hh bi translated">megha 067/使用 ML 算法的数字识别</h2><div class="ne l"><h3 class="bd b fi z dy nc ea eb nd ed ef dx translated">通过在 GitHub 上创建一个帐户，为 Meg ha 067/数字识别-使用-ML-算法的开发做出贡献。</h3></div><div class="nf l"><p class="bd b fp z dy nc ea eb nd ed ef dx translated">github.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ik mx"/></div></div></a></div></div></div>    
</body>
</html>