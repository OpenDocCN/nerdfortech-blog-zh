<html>
<head>
<title>Machine Learning Zuihitsu — III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习 Zuihitsu-III</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/machine-learning-zuihitsu-iii-e36157bc35a?source=collection_archive---------4-----------------------#2021-01-08">https://medium.com/nerd-for-tech/machine-learning-zuihitsu-iii-e36157bc35a?source=collection_archive---------4-----------------------#2021-01-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/3d0164ffea19637b6ebc9320e6899581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HIWckd5wMDiS3LrM"/></div></div></figure><div class=""/><p id="5c5f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> <em class="jo">融合左翼和右翼政客…用自动编码器</em> </strong></p><p id="e905" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">巴黎@Datategy 数据科学家和机器学习工程师埃伦·云吕博士</p><p id="71fb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大家好。今天，我将向您展示自动编码器的一个简单而有趣的应用。对于第一次听到这个术语的人来说，自动编码器(在神经网络的上下文中；类似的策略可以应用于某些其他统计模型)是将输入数据投影到更小的嵌入向量并将其重建到输入维度的神经网络。因此，在他们的监督训练期间，输入和输出数据是相同的。</p><p id="ebd5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它们是最新机器学习的革命性产品，用于去噪、数据压缩、统计分析等等。它们通常有一个<em class="jo">沙漏</em>结构，其中神经元的数量在每一层逐渐减少，直到<em class="jo">瓶颈</em>层，然后对称地扩展回来，直到输出。因此，网络迫使最重要的数据内容集中在瓶颈层。因此，每个数据点的瓶颈层的输出可以用作代表性的压缩向量。由于这种结构，网络还消除了附加噪声或无关紧要的统计推断。自动编码器是一个庞大的主题；有数千种不同的版本，如用于计算机视觉的卷积自动编码器(解卷积层用于重建)、序列处理(可以使用 LSTM 单元)或变分自动编码器(生成应用)等。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jp"><img src="../Images/a30c0d7d62d525d117771ea111ccfe56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rRwpGkxjAEJDtGsG"/></div></div></figure><p id="c801" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">今天，我将演示一个简单的计算机视觉实验，但将使用常规的多层感知器，而不是卷积层。我们的图像尺寸非常小，因此神经元应该能够捕捉所有类型的关于邻居等的信息。</p><p id="f9e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用 scikit-learn 中的“野生标记人脸”数据集，其中包含几位政治家的 50x37 灰度面部图像。</p><p id="d5e8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个实验中，我将只使用两张图片，一张是乔治·w·布什，另一张是雨果·查韦斯。我试图找到这两个家伙最匹配的一对图像，这样他们的姿势和模仿就尽可能地相似和重叠。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ju"><img src="../Images/7e2b683083f6ffeb98ccef41f5b5d082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kL_eGDlvk8cpipPKpe-uvw.png"/></div></div></figure><p id="b9dd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为我们只有两个图像，所以我将尽可能使用最简单的架构。只有一个有 128 个神经元的隐藏层。我们用几十个时期的两幅图像来训练简单的自动编码器模型。让我们看看它如何重塑布什总统的形象。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jv"><img src="../Images/d1cebf78a7f25d0d3946cbb81e703e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6xbJ1xj1Q5zacDM0YmDRA.png"/></div></div></figure><p id="e606" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嗯，它们几乎一样。这暗示我们过度拟合，这对于仅包含 2 个输入数据点的情况是正常的。然而，这并不重要，因为我将要演示的实验并不要求避免过度拟合模型。</p><p id="f5ef" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将纵向和横向剪切和缝合这两位政治家的半幅图像。然后，我们将把它输入到简单的自动编码器中，观察它重建了什么。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jw"><img src="../Images/7c16adb7a6ab11244e45ad55eb9c4090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Q-bLo_6Iq_IL9tDxlrH2A.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">我们将这两个切割和缝合图像作为自动编码器的输入。</figcaption></figure><p id="7fbb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">重建的图像如下:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kb"><img src="../Images/1cfbbc1c6702d7eeb252e8cb56455d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HyArKgLrlzzcy2jfkbjaPA.png"/></div></div></figure><p id="e662" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">很奇怪吧？几乎两个重建是相同的。我们这里确实有一个新人:乔治。查韦斯或雨果·布什。我们观察到 128 个神经元和(重建的突触)能够捕捉面部像素的语义插值。我希望这个简单的实验能帮助你理解和挖掘更多关于自动编码器的知识。</p><p id="44a7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">[1]<a class="ae kc" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . fetch _ lfw _ people . html</a></p></div></div>    
</body>
</html>