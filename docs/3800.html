<html>
<head>
<title>A note on Hard Kumaraswamy Distribution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于硬 Kumaraswamy 分布的一个注记</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/a-note-on-hard-kumaraswamy-distribution-b74278dc6877?source=collection_archive---------13-----------------------#2021-06-24">https://medium.com/nerd-for-tech/a-note-on-hard-kumaraswamy-distribution-b74278dc6877?source=collection_archive---------13-----------------------#2021-06-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="89f1" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">这是摘自我的硕士论文“使用修正随机变量的半监督形态强化”</p></blockquote><p id="18c5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">在这个故事中，我们描述了适用于 Kumaraswamy 分布的拉伸和矫正原理[1]。该技术由 Louizos 等人在 2017 年提出[2]，他们对来自 Gumbel-sigmoid 分布的样本进行了校正。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/2afe2c3ab144330068e8d8ce032681b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3AF2WK1XYTyPyqv-CwQZg.png"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">各种形状参数值的 Kumaraswamy 分布 pdf(左)和 cdf(右)。该插图的原始版本来自 Bastings 等人(2019)。</figcaption></figure><h2 id="28fa" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jh kl km kn ji ko kp kq jj kr ks kt ku bi translated">库马拉斯瓦米分布</h2><p id="4d1b" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jh kx iw ix ji ky ja jb jj kz je jf jg hb bi translated">Kumaraswamy 分布(Kumaraswamy，1980)是定义在区间(0，1)上的双有界连续概率分布。其形状由两个参数<em class="ik"> a∈R &gt; 0 </em>和<em class="ik"> b∈R &gt; 0 </em>控制。如果 a=1 或 b=1 或两者都是，Kumaraswamy 等价于 Beta 分布。对于等效的参数设置，Kumaraswamy 分布非常类似于 Beta 分布(但是具有更高的熵)。其密度函数如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es la"><img src="../Images/6a714248dd5fe70229cb1fdcb5334be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jIVd1W4zvTRP9Fdac9dxFw.png"/></div></div></figure><p id="04d3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">其中<em class="ik"> a </em>和<em class="ik"> b </em>是前面提到的形状参数。其累积分布函数(cdf)可推导如下:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lb"><img src="../Images/59cd9c2459f4f0312f2b64858d8c7dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89WtgyR2o8z9CfOKlA4vZw.png"/></div></div></figure><h2 id="ce12" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jh kl km kn ji ko kp kq jj kr ks kt ku bi translated"><strong class="ak">从库马拉斯瓦米分布中取样</strong></h2><p id="ccc8" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jh kx iw ix ji ky ja jb jj kz je jf jg hb bi translated">我们注意到累积密度函数有[0，1]的支撑。使用上面所示的累积密度函数，我们可以得到它的倒数，如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lc"><img src="../Images/dd7ad8d3d6dd1a4cd911f8d5f72e920b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBOxexa_SyRKup5shbDAEQ.png"/></div></div></figure><p id="4252" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">其中<em class="ik"> z∈[0，1] </em>表示累积密度函数值。因此，为了获得 Kumaraswamy 样本，我们首先从具有 support [0，1]的均匀分布进行采样，并使用逆 cdf 对其进行变换。有了这个公式，我们可以重新参数化预期，如 Nalisnick 和 Smyth，2016 [3]所述。取样程序如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ld"><img src="../Images/d95ee4928c4fc2e55e5181df7adcd7b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hpf0fzb_2HB6X2JLTZRakQ.png"/></div></div></figure><h2 id="bd70" class="ka kb hi bd kc kd ke kf kg kh ki kj kk jh kl km kn ji ko kp kq jj kr ks kt ku bi translated"><strong class="ak">修正后的库马拉斯瓦米分布</strong></h2><p id="e88c" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jh kx iw ix ji ky ja jb jj kz je jf jg hb bi translated">设<em class="ik"> k </em>表示从<em class="ik">库马(a，b) </em>采样的基本随机变量。它的定义域是开区间(0，1)。<em class="ik"> k </em>被拉伸定义在开区间(l，r)内，其中<em class="ik"> l &lt; 0，r &gt; 1 </em>，我们表示拉伸版 ass。其累积密度函数如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es le"><img src="../Images/47289c34892586dd2ff9254a0f385bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JIrWrKg3Y0JlteGjQ3KV9g.png"/></div></div></figure><p id="5c07" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">最后，<em class="ik"> s </em>通过一个硬 sigmoid 函数，即<em class="ik"> min(1，max(0，s)) </em>，被修正为定义在域[0，1]中。我们用<em class="ik"> h </em>表示整流后的变量。根据 Bastings 等人(2019) [1]，我们将拉伸和校正后的分布称为<strong class="il hj">硬 Kumaraswamy 分布</strong>。精确采样的概率<em class="ik"> s= 0 </em>为 0，由于<em class="ik"> s </em>在区间(l，r)内是连续的，精确采样任意值的概率为 0。但是采样<em class="ik"> h= 0 </em>等价于采样任意<em class="ik"> s∈(l，0)</em>。类似地，采样<em class="ik"> h= 1 </em>等价于采样任何<em class="ik"> s∈[1，r) </em>，即</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lf"><img src="../Images/fa40bec425ab9e46c8972d2f74e265fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n3VgyMUC93dUtB_OFsn33A.png"/></div></div></figure><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lg"><img src="../Images/126095976a57252e8f1cf8c5a1e87ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dOCTeqi5EhnQVaAwJfN7pg.png"/></div></div><figcaption class="jw jx et er es jy jz bd b be z dx translated">拉伸和矫正:我们从一个<em class="lh">库马(0.5，0.5) </em>开始，把它的支撑拉伸到区间(-0.1，1.1)，最后我们把 0 以下的质量折叠到{ 0 }，1 以上的质量折叠到{1}。该插图的原始版本来自 Bastings 等人(2019)。</figcaption></figure><p id="b529" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">上图说明了拉伸和矫正的过程。阴影区域显示采样的概率<em class="ik"> h=0 </em>(左)和<em class="ik"> h=1 </em>(右)。经整流的变量<em class="ik"> h </em>具有由 0 和 1 处的点质量组成的分布，以及截断为(0，1)的拉伸分布，</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es li"><img src="../Images/fb211ceb14463e991ebfedb4211116f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsAcZxYhMIejTwzy8kLBCg.png"/></div></div></figure><p id="6289" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">其中 f(h)是 H 的概率密度函数，δ(。)表示狄拉克-德尔塔函数，T 是截断分布，以及</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lj"><img src="../Images/06154da0d6fe3cd1b25945e424fa9a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdzbrJK0Ib0KbnPnYQWvbg.png"/></div></div></figure><p id="5817" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">其中，π₀和π₁分别表示对离散结果进行采样的概率{ 0 }和{1}，π𝒸表示对连续结果进行采样的概率。截断的密度 fₜ(t)被引入，因为 fₛ(s)在(1，r)上被适当地归一化。我们可以看到 fₕ(h)具有以下性质:</p><ol class=""><li id="5650" class="lk ll hi il b im in iq ir jh lm ji ln jj lo jg lp lq lr ls bi translated"><em class="ik">支持一致性</em>:支持[0，1]，包含离散结果{ 0 }和{1}。</li><li id="167e" class="lk ll hi il b im lt iq lu jh lv ji lw jj lx jg lp lq lr ls bi translated"><em class="ik">灵活性</em>:可以控制这个分布的参数，这样我们就可以指定得到结果{ 0 }和{1}的概率。</li><li id="e13a" class="lk ll hi il b im lt iq lu jh lv ji lw jj lx jg lp lq lr ls bi translated"><em class="ik">可微性</em>:为了利用现成的(随机)梯度上升技术，分布在其参数方面几乎处处可微。</li></ol><h1 id="5682" class="ly kb hi bd kc lz ma mb kg mc md me kk mf mg mh kn mi mj mk kq ml mm mn kt mo bi translated">参考</h1><ol class=""><li id="ca37" class="lk ll hi il b im kv iq kw jh mp ji mq jj mr jg lp lq lr ls bi translated">Bastings、w . Aziz 和 I . Titov(2019 年)。具有可微分二元变量的可解释神经预测。arXiv 预印本 arXiv:1905.08160。</li><li id="bd2f" class="lk ll hi il b im lt iq lu jh lv ji lw jj lx jg lp lq lr ls bi translated">Louizos，c .，Welling，m .，和 Kingma，D. P. (2017)。通过 l0 正则化学习稀疏神经网络。</li><li id="ded6" class="lk ll hi il b im lt iq lu jh lv ji lw jj lx jg lp lq lr ls bi translated">Nalisnick，e .和 Smyth，P. (2016 年)。粘连断裂变分自动编码器。</li></ol></div></div>    
</body>
</html>