<html>
<head>
<title>Person Classification using CCTV Surveillance Video</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于闭路电视监控视频的人员分类</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/person-classification-using-cctv-surveillance-video-84aa70a4c296?source=collection_archive---------10-----------------------#2021-07-04">https://medium.com/nerd-for-tech/person-classification-using-cctv-surveillance-video-84aa70a4c296?source=collection_archive---------10-----------------------#2021-07-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="77a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我想分享一下我的Google Bangkit Capstone项目。该项目是关于空屋监测应用程序，可以发送通知，如果有人在房子里。</p><p id="b9cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有时，当我们需要让房子空着去度假时，我们会让房子无人看守。我们使用可以通过应用程序监控的闭路电视摄像机，但我们需要一直监控镜头，因为传统的闭路电视监控应用程序通常无法检测到人的存在。我的团队设计了一个系统，使用机器学习方法来分类现场是否有人，以防止在空房子里发生犯罪。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/45b0d9be554dd18a22dad7c220c6fd61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T-j50-359_h4AXyITnL8kQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">空房子的闭路电视录像</figcaption></figure><h1 id="d331" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">图像分类</h1><p id="fdc3" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我们使用图像分类的方法来实现我们设计的解决方案。图像分类通过定义一组目标类(要在图像中识别对象)并使用标记的示例照片训练模型来识别它们来工作。[1]</p><p id="829d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个项目中只有两个类，person和no person。因此该项目将使用图像进行二值分类。</p><p id="fab0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">进行分类有几个步骤</p><ol class=""><li id="cbca" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lb lc ld le bi translated">准备数据集</li><li id="1fd9" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated">建立神经网络模型</li><li id="89fa" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated">使用收集的数据集训练模型</li><li id="bc17" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated">测试模型。</li></ol><h1 id="2830" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">准备数据集</h1><p id="2ed1" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">基于我们想解决的问题，我们需要一个房子里的监控录像。我从YouTube视频和CCTV录像中收集数据，然后使用这个脚本一帧一帧地分割视频</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">按帧分割视频的脚本</figcaption></figure><p id="40ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我为1帧定制了3秒的切片，以减少多次捕获的相似帧。总共获得2394帧，然后分成80%用于训练，20%用于验证。训练和验证文件的路径结构如下:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h1 id="1cbc" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">建立神经网络模型</h1><p id="2f2d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在这个项目中，我使用迁移学习的方法来实现图像分类算法。InceptionV3用作预训练模型来对图像进行分类。</p><p id="a331" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Inception v3是一种广泛使用的图像识别模型，已被证明在ImageNet数据集上获得了超过78.1%的准确率。该模型是多年来多名研究人员开发的许多想法的结晶。它基于原始论文:<a class="ae lm" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">“重新思考计算机视觉的初始架构”</a>，作者Szegedy等人。艾尔。[2]</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">要导入Inceptionv3的代码段</figcaption></figure><p id="b425" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码将把Inceptionv3模型导入到我们的colab中，然后打印模型摘要以查看层是如何排列的。输入设置为256x256像素，3色通道(RGB)</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="e79d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个项目，我只使用InceptionV3模型，直到“混合7”层，然后展平为1维。扁平化模型进入密集层，具有1024个隐单元和ReLu激活函数。</p><p id="4fcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用了20%的下降层来减少过度拟合，然后输出设置为单个sigmoid层。使用RMSprop编译的模型具有0.0001学习率、二进制交叉熵损失(因为它是二进制分类)和准确性度量。</p><h1 id="5655" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">培养</h1><p id="fca2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在训练模型之前，我们需要将数据集上传到笔记本中。为了使它更容易，我已经将数据集上传到驱动器中，所以它只需要安装到我们的笔记本上</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="6c0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上传图像后，我们需要做图像增强。我使用ImageDataGenerator通过实时数据增强生成批量张量图像数据。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="6f80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一切准备就绪后，我们开始训练吧！</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="2d79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">经过20个纪元的训练，结果如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/535b6c581c69016bc01e99d0e630236a.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*LUKMpa5OdTp-m_932P_dzA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">培训和验证准确性</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/c8ba70d26f4e592709722f82f4cc9995.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*DypRHauVvl334aHyEECPkQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">培训和验证损失</figcaption></figure><p id="5688" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型在某些时候往往有点过拟合，正如在训练精度略大于验证精度时所看到的那样。这是意料之中的，因为缺乏数据集的多样性。为了解决这个问题，我认为增加数据的多样性会有所帮助。</p><h1 id="b00e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试</h1><p id="57bb" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">视频测试通过逐帧分类图像来完成。为此，我们需要运行以下代码</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="bd6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们填充我们的框架之前，我们需要对它进行预处理。我们必须确保格式已经是RGB格式，像素大小调整为256x256像素。然后我们归一化帧值。</p><p id="8769" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果预测值&gt; 0.5，则被分类为包含帧的人。结果如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/857fe837a6a64fd587b7d621abf5fd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-Y7g-qO6YZwntcXJAdivg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">分类结果</figcaption></figure><p id="8056" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型成功地对帧上的人进行了分类。</p><p id="6943" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个项目，我已经创建了一个使用FastAPI在GCP部署模型的API。如果你感兴趣，你可以在这里查看</p><p id="fad9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">链接到<a class="ae lm" href="https://colab.research.google.com/drive/1i0gQkQnIVvdY5a4rlJhT30DmhoFNMGR4?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a></p><p id="0c8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我和我的朋友一起参与了这个项目，欢迎访问<a class="ae lm" href="https://fragitya.medium.com/person-classification-on-cctv-video-21bc0c7fe24e" rel="noopener">https://fragitya . medium . com/person-classification-on-CCTV-video-21 BC 0 c 7 Fe 24 e</a></p><p id="c730" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">来源:</strong></p><p id="ca4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1]<a class="ae lm" href="https://developers.google.com/machine-learning/practica/image-classification" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/practica/image-class ification</a></p><p id="a9ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lm" href="https://cloud.google.com/tpu/docs/inception-v3-advanced" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/tpu/docs/inception-v3-advanced</a></p></div></div>    
</body>
</html>