<html>
<head>
<title>Getting started with Machine Learning and its Algorithms 2021.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习及其算法入门2021。</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/getting-started-with-machine-learning-and-its-algorithms-2020-748811f972f5?source=collection_archive---------2-----------------------#2020-07-18">https://medium.com/nerd-for-tech/getting-started-with-machine-learning-and-its-algorithms-2020-748811f972f5?source=collection_archive---------2-----------------------#2020-07-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="811c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算机技能与消防需求解释容易。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/c890b713d587f7dec1d08dc4ea9f0cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-PN9kY89feweja4K"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">马库斯·温克勒在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="1e3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi ju translated">ola的读者们，从未来的工程师到其他工程师，</p><p id="521a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">机器学习是一个炙手可热的话题</strong>，是在这个<em class="kd">技能和发展</em>的当今时代抢得一份合适工作的<strong class="ih hj">急需技能</strong>。</p><p id="6b3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们说ML很难，不容易，尽管它很难，但它不适合聪明的工作人员和聪明的学习者。开发新的机器学习算法确实涉及大量数学和专业知识。但是大多数时候<strong class="ih hj">做</strong> <strong class="ih hj">机器学习</strong>并不是为了新的算法，而是利用现有的算法和代码库来训练机器学习模型。</p><p id="5de9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在来看什么，为什么，以及其他…</p><blockquote class="ke"><p id="6f73" class="kf kg hi bd kh ki kj kk kl km kn jc dx translated">什么是机器学习？</p></blockquote><p id="302e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在听到术语<strong class="ih hj">机器学习</strong>…这听起来像一个大的<strong class="ih hj">技术术语，</strong>但是当你开始了解它的时候，它对你来说似乎是一个简单的概念，这通常是<em class="kd">现在到处都在使用</em>。这基本上是一种学习，在这种学习中，机器开始自己学习东西<strong class="ih hj">，而不需要显式编程</strong>。它是<strong class="ih hj">人工智能</strong>应用的一个子集或一种类型，为系统提供从过去的经验中自动学习并为未来的处理进行自我改进的能力。</p><p id="58dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习总是致力于计算机程序的开发，因此它可以访问数据，并使用这些数据进行自学。机器学习旨在研究计算机如何在没有任何人工干预或帮助的情况下自动学习，以便机器可以根据需要调整其动作。</p><blockquote class="kt ku kv"><p id="3387" class="if ig kd ih b ii ij ik il im in io ip kw ir is it kx iv iw ix ky iz ja jb jc hb bi translated">“婴儿学会爬、走，然后跑。在应用机器学习方面，我们正处于爬行阶段。”戴夫·沃特斯</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/7a4463a55f5fc28163bd1fe1c331c443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kqKk6KP8xwdczX03"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@maximalfocus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">最大焦点</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">不飞溅</a>上拍摄</figcaption></figure><h1 id="597d" class="la lb hi bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated"><strong class="ak">机器学习的先决条件:</strong></h1><p id="66e8" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated">在学习机器学习之前，先了解以下内容是必要的。</p><p id="84b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.线性代数</p><p id="e5cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.结石</p><p id="7222" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.概率论</p><p id="39ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.编程；编排</p><p id="e8f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.最优化理论</p><p id="7076" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然没有那么必要，但掌握所有这些基础知识将会加快你学习ML的能力。</p></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><h1 id="4f3a" class="la lb hi bd lc ld mk lf lg lh ml lj lk ll mm ln lo lp mn lr ls lt mo lv lw lx bi translated"><strong class="ak">机器学习中流行的算法</strong></h1><h2 id="542c" class="mp lb hi bd lc mq mr ms lg mt mu mv lk iq mw mx lo iu my mz ls iy na nb lw nc bi translated"><strong class="ak"> 1。线性回归:</strong></h2><p id="5ad2" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated"><strong class="ih hj">线性回归</strong>是<strong class="ih hj"> ML </strong>中最常见最通用的算法。基于<strong class="ih hj">监督学习</strong>的线性回归(LR)算法；现在什么是监督学习… <em class="kd">监督学习基本上是利用数据进行学习，或者简单地说，它意味着使用被标记的数据/数据集，即定义的数据集，来训练或教授ML模型。</em></p><p id="20ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，LR基本上是<strong class="ih hj">训练一个模型</strong>，然后是<strong class="ih hj">用一组示例或<strong class="ih hj">测试数据集</strong>测试模型</strong>，这样我们的ML模型分析<strong class="ih hj">训练数据集</strong>并基于其<strong class="ih hj">监督学习算法</strong>产生正确的输出。<br/>它执行<strong class="ih hj">回归任务</strong> …这意味着回归预测建模，即<em class="kd">将从输入变量比如‘x’到连续变量比如‘y’的映射函数进行映射或近似。</em> <br/>根据自变量给出预测值。它主要用于找出变量之间的关系并进行预测。<br/> LR执行任务，根据自变量‘x’预测因变量‘y’。所以基本上给出了‘x’和‘y’的线性关系所谓的<strong class="ih hj">线性变量</strong>。</p><blockquote class="ke"><p id="89d5" class="kf kg hi bd kh ki kj kk kl km kn jc dx translated">LR的假设函数:Y= <strong class="ak"> θ </strong> 1 + <strong class="ak"> θ </strong> 2.x</p></blockquote><p id="6e13" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">这里Y=数据的标签(监督学习)<br/> x =输入训练数据；参数<br/> <strong class="ih hj"> θ </strong> 1 =截距<br/><strong class="ih hj">θ</strong>2 = x的系数<br/> <em class="kd">当训练一个模型时，它拟合最佳线来预测给定的x值的y值。</em> <br/>模型得到最佳回归拟合线，最佳值为<strong class="ih hj"> θ </strong> 1和<strong class="ih hj"> θ </strong> 2。</p><p id="3f00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">LR中的成本函数(J)</strong>…<em class="kd">成本函数用于估计模型的表现有多差</em>。简而言之，成本函数是对模型在估计X和y之间关系的能力方面的错误程度的度量。<em class="kd">这通常表示为预测值和实际值之间的差异或距离。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nd"><img src="../Images/1fb9456dd211fb0e69bcd5c3ed258ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*tGhNGRoAkSEpWgAdNvNmLg.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">LR中的成本函数</figcaption></figure><p id="d096" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在LR中，我们预测‘y’的值，使得预测值和真实值之间的误差最小。<br/> <strong class="ih hj">线性回归的代价函数(J)是预测y值(pred)与真实y值(y)之间的均方根误差(RMSE)。</strong> <br/>它用于<em class="kd">最小化成本</em>和<em class="kd">最大化一个组织的生产率</em>。</p><h2 id="bb31" class="mp lb hi bd lc mq mr ms lg mt mu mv lk iq mw mx lo iu my mz ls iy na nb lw nc bi translated">2.决策树(DT):</h2><p id="45e3" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated"><strong class="ih hj">决策树机器学习算法</strong>是另一种<strong class="ih hj">监督学习</strong>算法。它们可用于解决<strong class="ih hj">回归</strong>和<strong class="ih hj">分类</strong>问题。简单来说，分类算法的<strong class="ih hj">任务是将输入变量‘x’映射为离散输出变量‘y’。<br/> DT在<strong class="ih hj">数据挖掘</strong>和Ml中都有用到……所以我们可以说是一个著名的算法。<br/>决策树基本上使用<strong class="ih hj">树表示</strong>来解决每个<strong class="ih hj">叶节点(最后一个节点没有子节点)</strong>对应一个<strong class="ih hj">类标签</strong>表示“猫】和<strong class="ih hj">属性</strong>在树的内部节点表示为“动物”的问题。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ne"><img src="../Images/f34ead8e68877fba730898ba3b707957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HYnWJ84dVg4WTwLwLNFBIg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.geeksforgeeks.org/decision-tree-introduction-example/" rel="noopener ugc nofollow" target="_blank">https://www.geeksforgeeks.org/</a></figcaption></figure><p id="d368" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们不能忽视这种算法的简单性…它通常被称为从数据中学习决策树。<br/>一般来说<strong class="ih hj"> DT算法</strong>被称为<strong class="ih hj">类和回归树</strong>。<br/> <strong class="ih hj">分类树</strong>是那些总体目标是对可能性进行分类或者更好地说出是/否结果的树。举个例子:他要么吃要么不吃。<br/>而<strong class="ih hj">回归树</strong>是那些预测连续值的回归树。例如:东西的价格。<br/> <strong class="ih hj">生长一棵树涉及到选择哪些特征，使用什么条件进行分裂……以及何时停止的想法。</strong> <br/>因此，<strong class="ih hj">递归二进制分裂</strong>被用作分裂树的技术……在这个过程中，所有的特征都被考虑，并且不同的<strong class="ih hj">分裂点</strong>被<em class="kd">使用成本函数尝试和测试。</em> <br/>我们使用一个成本函数来计算分割的准确度，选择较低的成本。<br/><strong class="ih hj">DT中的成本函数</strong>:<br/>尝试找到最同质的分支，即具有相同响应的相同组。</p><blockquote class="ke"><p id="495a" class="kf kg hi bd kh ki kj kk kl km kn jc dx translated">对于回归:sum(y预测)</p><p id="e3c7" class="kf kg hi bd kh ki kj kk kl km kn jc dx translated">对于分类:总和(pk* (1-pk))</p></blockquote><p id="fdd8" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在决策树中，主要的挑战是识别每一层根节点的属性。这个过程被称为<strong class="ih hj">属性选择</strong>。我们有两个流行的属性选择度量:<br/> <strong class="ih hj">信息增益</strong>和<strong class="ih hj">基尼指数</strong>度量。</p><h2 id="b617" class="mp lb hi bd lc mq mr ms lg mt mu mv lk iq mw mx lo iu my mz ls iy na nb lw nc bi translated">3.k近邻(KNN):</h2><p id="9c9f" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated"><strong class="ih hj">K-最近邻</strong>也是<strong class="ih hj">机器学习</strong>中最基本也是最本质的分类算法之一。<br/>它也是基于前面讨论过的<strong class="ih hj">监督学习算法</strong>。<br/>在<strong class="ih hj">数据挖掘、模式识别</strong>等方面都有应用<br/>在现实生活场景中非常适用。<br/>由于是<strong class="ih hj">非参数</strong>，意思是:<em class="kd">它不对数据的分布做任何潜在的假设。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nf"><img src="../Images/33c1e88ac91549f666a02bb97139e977.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*Re_8ggZZCiQmeggHRQPGjA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.saedsayad.com/k_nearest_neighbors.htm" rel="noopener ugc nofollow" target="_blank">https://www.saedsayad.com/k_nearest_neighbors.htm</a></figcaption></figure><p id="8aa8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图中，箭头表示该点的最近邻。</p><p id="4e71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下两个特性可以很好地定义KNN</p><ul class=""><li id="c6d2" class="ng nh hi ih b ii ij im in iq ni iu nj iy nk jc nl nm nn no bi translated"><strong class="ih hj">懒惰学习算法</strong>——KNN是一种懒惰学习算法，因为它没有专门的训练阶段，在分类时使用所有数据进行训练。</li><li id="97c0" class="ng nh hi ih b ii np im nq iq nr iu ns iy nt jc nl nm nn no bi translated"><strong class="ih hj">非参数学习算法</strong>—KNN也是一种非参数学习算法，因为它没有对底层数据做任何假设。</li></ul><p id="fb93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们获得了一些先验数据(也称为<strong class="ih hj">训练数据</strong>)和另一组数据点(也称为<strong class="ih hj">测试数据</strong>)，如果我们将这些点绘制在图上，我们可能能够定位一些<strong class="ih hj">集群或群组</strong>。现在，给定一个<strong class="ih hj">未分类点</strong>，我们可以通过观察它最近的邻居属于哪个组来将其分配到一个组。这意味着接近被分类为“一类”的点簇的点有更高的概率被分类为完全相同的“一类”。<br/> <strong class="ih hj">随着训练数据集中数据点数量的增加，这种ML模型的准确性也随之增加。</strong></p><h2 id="76ce" class="mp lb hi bd lc mq mr ms lg mt mu mv lk iq mw mx lo iu my mz ls iy na nb lw nc bi translated"><strong class="ak"> 4。随机森林(RF) : </strong></h2><p id="b6ee" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated">它也是一种<strong class="ih hj">监督学习算法</strong>，灵活，易于使用的算法。出错的可能性很小，也不会出现<strong class="ih hj">过拟合问题</strong> ( <strong class="ih hj"> <em class="kd">过拟合</em> </strong> <em class="kd">发生在模型学习训练数据中的细节和噪声，以至于对模型在新数据上的性能产生负面影响</em>)。<br/>生成预测<strong class="ih hj">很慢</strong>因为有很多DT，并且有可能简单的决策<strong class="ih hj">耗时</strong>并且<strong class="ih hj">复杂</strong>但是<strong class="ih hj">偏差</strong>在这里被防止，因为它需要各种投票<strong class="ih hj">的平均值。</strong> <br/>它同时用于<strong class="ih hj">分类</strong>和<strong class="ih hj">回归</strong>技术。<br/>由<strong class="ih hj">树</strong>组成，树越多<strong class="ih hj">健壮的随机森林为</strong>。<br/> RF根据随机选择的<strong class="ih hj">数据样本</strong>创建DT，并根据每棵树给出<strong class="ih hj">预测</strong>，并根据<strong class="ih hj">投票</strong>选择最佳解决方案。<br/> RF的应用范围很广，有些是<strong class="ih hj">图像分类、推荐引擎、疾病预测</strong>等。</p><blockquote class="kt ku kv"><p id="1c43" class="if ig kd ih b ii ij ik il im in io ip kw ir is it kx iv iw ix ky iz ja jb jc hb bi translated">它基本上工作在4个步骤上:-<br/>-从给定的数据集中选择随机样本。<br/> —为每个样本构建一个DT，并预测每个DT的结果。<br/> —对每个预测结果进行投票。<br/> —选择投票最多的预测结果作为最终预测。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nu"><img src="../Images/90429031d042c9a521142a58525f505c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1qOkyyUI2eKfnMskLuxNyg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://blog.quantinsti.com/random-forest-algorithm-in-python/" rel="noopener ugc nofollow" target="_blank">https://blog.quantinsti.com/</a></figcaption></figure><p id="35aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它是<strong class="ih hj">博鲁塔算法</strong>的基础。<em class="kd">这意味着<br/>它选择数据集中的重要特征</em>…围绕Boruta算法总结构建，它试图捕捉所有与结果特征相关的不感兴趣的特征。</p><h2 id="5c9d" class="mp lb hi bd lc mq mr ms lg mt mu mv lk iq mw mx lo iu my mz ls iy na nb lw nc bi translated">5.支持向量机(SVM):</h2><p id="d8b2" class="pw-post-body-paragraph if ig hi ih b ii ly ik il im lz io ip iq ma is it iu mb iw ix iy mc ja jb jc hb bi translated"><strong class="ih hj">支持向量机</strong>也称为<strong class="ih hj">支持向量网络</strong>。<br/>它也是一种<strong class="ih hj">监督ML算法</strong>，既用于<strong class="ih hj">分类</strong>又用于<strong class="ih hj">回归</strong>挑战，但目前大多用于分类。<br/>SVM模型将示例表示为空间中的<strong class="ih hj">点，通过映射，各个类别的示例被尽可能宽的清晰间隙分开，由分离的<strong class="ih hj">超平面</strong> ( <em class="kd">非常好地区分两个类别的直线</em>)…意味着我们将每个数据项绘制为n维空间</strong>中的一个点:<em class="kd"> n是特征的数量，每个特征的值就是值然后，我们通过寻找超平面来执行分类任务。</em></p><blockquote class="kt ku kv"><p id="4f2c" class="if ig kd ih b ii ij ik il im in io ip kw ir is it kx iv iw ix ky iz ja jb jc hb bi translated">现在为了决定<strong class="ih hj">右超平面</strong>，我们得到了一些<strong class="ih hj">规则</strong>，它们是:<br/>——应该选择能更好地分离两个类的超平面。<br/> —计算最近的数据点和超平面之间的距离。具有最大距离的平面将被认为是正确的超平面，以更好地分类。<br/> <strong class="ih hj"> SVM有规则1更占优势。</strong></p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nv"><img src="../Images/ee241a5d1112b274b1452784b3477e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*1Rikws6xFRMRNDU-XXuvyw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">这里的直线是将两个类分开的超线。</figcaption></figure><p id="5d4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们得到一个<strong class="ih hj">外层</strong> ( <em class="kd">一个与其成员位置不同的点/类，即远离其同类</em>)，<br/> SVM取最大<strong class="ih hj">个数据点</strong>并最大化它们。<br/> <strong class="ih hj">我们甚至可以通过添加新的特征或新的轴来进入非线性超平面，为此，SVM具有将低维输入空间带入高维输出空间的内核技巧函数。</strong></p><p id="6f59" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一些最常用的<strong class="ih hj">内核</strong>如下:<br/> 1 .<strong class="ih hj">线性核</strong>为直线超平面。<br/> 2。<strong class="ih hj">曲线和非线性超平面的多项式核</strong>。<br/> 3。<strong class="ih hj">径向基函数核</strong>…常用于SVM机。</p><p id="6c4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，终点将是世界正在走向自动化和人工智能的时代，为了应对这一时代，人们必须充分了解趋势技术和堆栈，而机器学习就是其中之一。</p><blockquote class="kt ku kv"><p id="9f30" class="if ig kd ih b ii ij ik il im in io ip kw ir is it kx iv iw ix ky iz ja jb jc hb bi translated">机器学习只是一个开始...最重要的不是接下来的高级话题，每个人都可以做一些机器学习项目，因为在youtube，medium.com，GitHub，e.t.c上有很多这样的项目，但是理解其中发生了什么，它是如何实现的，以及背后的目的是机器学习和数据科学的新生所关心的事情。</p></blockquote></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nw"><img src="../Images/134a643e4480eca84b86185475f8cb44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N5S8s4WEHfsMRXQt"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jt" href="https://unsplash.com/@heyerlein?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> h heyerlein </a>拍摄</figcaption></figure></div></div>    
</body>
</html>