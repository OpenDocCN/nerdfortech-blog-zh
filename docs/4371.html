<html>
<head>
<title>Never Forget Gradient Descent and Loss Function Ever Again</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">永远不要忘记梯度下降和损失函数</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/never-forget-gradient-descent-and-loss-function-ever-again-e593936a3bf8?source=collection_archive---------1-----------------------#2021-07-18">https://medium.com/nerd-for-tech/never-forget-gradient-descent-and-loss-function-ever-again-e593936a3bf8?source=collection_archive---------1-----------------------#2021-07-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="63f4" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">了解我们为什么使用梯度下降，以及哪种损失函数最适合您的需求</h2></div><p id="6b46" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在之前的<a class="ae jt" rel="noopener" href="/nerd-for-tech/choose-the-best-activation-function-for-your-network-f46154bd9541">文章</a>中，我们了解了各种激活功能，以及哪一个最适合我们的需求。在我们选择了一个激活函数之后，我们就可以把数据输入到我们的神经网络中了。在第一次记录之后，我们得到一个与原始值相差甚远的预测值。</p><p id="2c91" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们如何告诉网络预测值错了x量，重新学习？</p><p id="f324" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="ju">损失和优化器功能。</em> </strong></p><p id="6eb1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将在后面的文章中学习损失函数和优化器。</p><p id="7fed" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是在我们计算损失之前，我们想要决定记录的数量，之后我们将调整权重。发送整个内容，然后更新权重，或者在每一行之后更新权重，或者在中间更新？我们传递数据的方式决定了内存的密集程度以及网络在数据中找到模式的速度。</p><h1 id="9adb" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">梯度下降</h1><p id="b98c" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">梯度下降是任何“学习”发生的基本原理。我们希望减少预测值和原始值之间的差异，也称为损失。如果你花过时间学习机器学习，你一定见过这样一个图，我们想要到达那个图的底部。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ks"><img src="../Images/6f90f3f6988105329839f34e4e3f7100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/0*uk-hExolyh-8TqaJ"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">具有两个输入权重的线性神经元的误差表面|图片来自Wikimedia</figcaption></figure><p id="eb7e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但这意味着什么呢？</p><blockquote class="le lf lg"><p id="a994" class="ix iy ju iz b ja jb ij jc jd je im jf lh jh ji jj li jl jm jn lj jp jq jr js hb bi translated">梯度下降有助于找到权重需要改变的程度，以便模型可以最终到达损失最低的点。换句话说，我们说找到了一个最小值。</p></blockquote><p id="96a8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的陈述可以写成如下等式。</p><p id="7251" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">新重量=旧重量——重量的微小变化</strong></p><p id="c79d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">δW可以代替W 的一个<em class="ju">小变化。所以更新后的等式是，</em></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lk"><img src="../Images/54f5ed752f9277d057e5cd90be2ed039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/0*vjBYemlAuUAy8aQV"/></div></figure><p id="320d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们如何计算δW？这就是梯度下降的由来。为了更好地理解梯度下降，让我们考虑一个例子。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ll"><img src="../Images/14f2c30b80c11843be1d12c8fe125a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*JOery1x3qD05NhFI38pyaA.png"/></div></figure><p id="da39" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我举了一个线性回归的例子，因为它的数学更简单，但是同样的例子也适用于神经网络。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/d2a6181172c9ff4c9a33d92fb934def5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5i66lPTxNr8vXm_5zWeaYw.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图表1:作者图片|图表中绘制的示例数据集</figcaption></figure><p id="5557" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如你在图1中看到的，红色的线最符合数据，但是我们是怎么得到这条线的呢？模型是如何知道这条，也只有这条线，最符合数据的呢？</p><p id="7888" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">答案是<strong class="iz hj"> <em class="ju">渐变下降</em> </strong>。</p><p id="7600" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们首先选择一个随机截距，或者在公式中，<em class="ju"> y = mx + c </em>，c的值。我们可以认为斜率为0.5。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lr"><img src="../Images/f2cdedd0a511b6fee1f58a609b8b63a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ghZWrIkrYWPVlEQv"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图表2:作者图片|截距为0。</figcaption></figure><p id="ca3e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于c = 0和数据中的第一行，我们得到y= 0.5的预测值。检验图表2。</p><p id="52ef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们发现0.5和1.5之间的差异，实际的y值。我们得到1。如果我们将截距移近集群，比如c = 0.5，那么损耗为1。如果我们继续推进截距，我们会得到如第三个图表所示的值。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es ls"><img src="../Images/87890d63cbb09ab02459597c0ecceb76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8omq0ehdSTL0BFw81ZOlDA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图表3:作者图片|损失与截距</figcaption></figure><p id="11a2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于图3，我们知道当截距为1时，损失值最低，也称为最小值。</p><p id="6549" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是，如果您在可能的截距列表中跳过了这个截距值，会怎么样呢？你怎么知道选择哪个截距值呢？</p><p id="5999" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了解决这个问题，我们使用了梯度下降法，它根据上图(图4)的斜率选择梯度值。斜率越陡，截距变化越大，反之亦然。它一直持续到斜率为零。在此之后，我们可以有把握地得出结论，我们已经实现了最小值，并且模型已经实现了最低可能的损失。</p><p id="543f" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">寻找梯度下降的方法是利用微分。如果我们对上面的图表进行微分，就可以得到图表的切线，也就是斜率。想了解更多关于微分的知识，可以通过3b1b查看这个视频:<a class="ae jt" href="https://www.youtube.com/watch?v=IHZwWFHWa-w" rel="noopener ugc nofollow" target="_blank">梯度下降，神经网络如何学习|第二章，深度学习</a>。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lt"><img src="../Images/6c664056ad44f636a85f26ccb48b1fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PNzgIViEwp6z6rMb"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图表4:抛物线和切线的图表</figcaption></figure><p id="19ae" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您还可以设置权重变化量的最大限制，称为学习率。学习率越低，权重变化越小。</p><p id="9da3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们之前看到的等式，δW，可以更新如下。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lu"><img src="../Images/6786ac2b2596146bf85d13dc21947f48.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/0*JXa5A6TPyf7fZSDI"/></div></figure><p id="d20e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将δW的值代入上式，我们就得到梯度下降的方程。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lv"><img src="../Images/97ff32ef5b2a7ca623827e4c0af71d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*35DLPUXPZJCkJtRi"/></div></div></figure><p id="3ebe" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在知道梯度下降是如何计算的了。现在让我们看看传递数据的不同模式。</p><h1 id="c07c" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">梯度下降的类型</h1><p id="5038" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">有三种类型。</p><p id="1893" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">批量梯度下降</strong>:通过整个数据集，计算平均损失。这样可以很好地理解整个数据集，但是速度很慢，而且占用大量内存。</p><p id="237a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一个最好的东西叫做<strong class="iz hj">小批量梯度下降</strong>。我们定义一个批量，比如说n，然后随机选择n个值，计算这些数据点的成本，并相应地更新权重。<em class="ju">如果n =行数，那么就变成批量梯度下降。</em></p><p id="9d0d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为我们可以控制批量大小，所以它占用的内存更少。然而，由于随机选择的记录可能无法给出整个数据集的最佳概括，因此存在较高的波动性。</p><p id="859d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">随机梯度下降</strong>是更新权重的另一种方式；每次记录后都会更新权重。它速度快，占用内存少，但易失性高。可能要花很多时间才能收敛到最小值。</p><p id="f1fd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面提到的传递数据的方法没有一个是错误的；我们可以根据您的需要选择任何方法。</p><h1 id="1a05" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">损失函数</h1><p id="9e7f" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">一旦我们有了Y的预测值，我们想要检查这个值与原始值有多接近。找出答案最简单的方法是减去它们，得到损失。</p><p id="4282" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种方法的问题是，如果我们想要平均所有的损失，我们可能会遇到正损失和负损失相互抵消的问题。为了避免这种情况，我们可以使用绝对值，也称为<strong class="iz hj"> L1损失或平均绝对误差</strong>。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lw"><img src="../Images/c4536c3e9117044f51a361529d9007b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/0*_q5D8CYAmExig5VF"/></div></figure><p id="0cba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们使用的数据可能有这样的异常值，使用损失的绝对值是有意义的。但是，如果我们的数据被压缩得很紧，情况就不那么好了。如果我们想计算损失，突出紧密包装的数据之间的损失，我们可以平方的差异。</p><p id="d140" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> L2损失或均方误差</strong>求损失的平方并求平均值。如果我们的数据有异常值，我们就不能使用这种方法，因为异常值会使数据向一个方向倾斜，从而导致模型拟合不佳。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lx"><img src="../Images/a766cd114a131ede7f7c5ae59d57a512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/0*Sz_aSFW_lO6tD86L"/></div></figure><p id="7fb5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是，如果您的数据既有离群值又有紧密打包的数据，该怎么办呢？你应该使用哪一个？进来的是<strong class="iz hj">胡贝尔的损失。</strong></p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ly"><img src="../Images/85094f3e9797534e38506028f316be18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/0*obeIe4y4gZyG3zyI"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">胡伯损失</figcaption></figure><p id="6591" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它充分利用了L1和L2的损失，完美地拟合了数据。它所做的就是，如果损失比一个值δ更显著，那么它找到绝对损失；否则，它会找到平方损失。</p><p id="bcc0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们讨论的这些损失是针对回归问题的。也就是说，我们的神经网络只有一个输出。如果我们有多个结果，比如在分类问题的情况下，该怎么办？</p><p id="74d8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用的函数之一是交叉熵函数。</p><p id="dd98" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">交叉熵</strong>听起来可能很复杂，但它本质上是所有类的预期值和预测值的对数的乘积之和。</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es lu"><img src="../Images/fb1612714bc610231b57c5026b201d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/0*oCtFjq8RW1O_mne3"/></div></figure><p id="1f7e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，我们有三个类，红色，绿色，蓝色，我们想找到关于实际值的预测值的损失。这种情况下的交叉熵损失为:</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lz"><img src="../Images/60e5e2427585e121374b1a6156d4d180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t_twFza1rvoxZKN8"/></div></div></figure><p id="cb57" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在分类问题中，除了要预测的类别之外的其他类别的期望值为零，因此在这种情况下的交叉熵损失变成</p><figure class="kt ku kv kw fd kx er es paragraph-image"><div class="er es ma"><img src="../Images/7d61187882d19607f85e74453ed5399c.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/0*L-j8iCfs_aFN8Ur2"/></div></figure><p id="129e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为什么我们用圆木代替正方形？简单的答案是，因为对数惩罚的损失更接近于零，这是我们想要的，而不是在平方的情况下，更接近于1，这是我们不想要的。</p><p id="0c71" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还有很多损失函数。你可以在这里阅读更多关于他们的信息<a class="ae jt" href="https://www.analyticsvidhya.com/blog/2019/08/detailed-guide-7-loss-functions-machine-learning-python-code/" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="b330" class="jv jw hi bd jx jy jz ka kb kc kd ke kf io kg ip kh ir ki is kj iu kk iv kl km bi translated">结论</h1><p id="03cd" class="pw-post-body-paragraph ix iy hi iz b ja kn ij jc jd ko im jf jg kp ji jj jk kq jm jn jo kr jq jr js hb bi translated">我们讨论了什么是梯度下降，以及为什么这个方程是这样的。我们还研究了将数据传递给神经网络的各种形式，最后，我们了解了不同的损失函数。我希望这能帮助你理解我们为什么要使用某些方程，以及我们是如何使用它们的。下一篇文章将是关于乐观主义者及其类型的。请保持反馈。让我知道你想让我在接下来的文章中谈论什么。</p></div></div>    
</body>
</html>