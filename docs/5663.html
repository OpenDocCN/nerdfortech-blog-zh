<html>
<head>
<title>Handwriting Recognition: More Than Just MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手写识别:不仅仅是MNIST</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/handwriting-recognition-more-than-just-mnist-36e68832de73?source=collection_archive---------2-----------------------#2021-10-29">https://medium.com/nerd-for-tech/handwriting-recognition-more-than-just-mnist-36e68832de73?source=collection_archive---------2-----------------------#2021-10-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9cc6" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">一种计算高效的整页脱机手写文本识别流水线方法</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/89c909c7a5e084ca9c164a993c6c55b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F4PEJluZ0b1jEvTU"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">诺埃米·马卡韦-卡特茨在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="fdf5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">于是我就在那里，看着苹果正式发布IOS 15。然后，突然之间，他们展示了一个让我印象深刻的功能。IOS现在可以<strong class="jq hj">从图像中复制文本</strong>。这听起来可能不那么令人印象深刻，但这几乎让我大吃一惊。一段时间以来，光学字符识别(OCR)技术已经能够在印刷文本上执行文本识别，甚至基本的手写文本。然而，它总是要么计算量非常大，要么对输入的照片非常敏感。就我所见，IOS的实现没有受到这些缺陷的影响。不用说:我很感兴趣。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/d3e1b1bd3b0edd7d8aba3e3985eb0098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7l2toXt3uD5noDn5"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://www.cnbc.com/2021/09/29/ios-15-live-text-how-to-copy-and-paste-text-from-a-photo.html" rel="noopener ugc nofollow" target="_blank">美国消费者新闻与商业频道</a>拍摄</figcaption></figure><p id="9314" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">经过一番搜索，我看到了Jonathan Chung和Thomas Delteil的一篇论文。本文详细介绍了一个<strong class="jq hj">离线整页笔迹检测流水线</strong>。仔细观察，这条管道有两个特性，可以让它非常类似于苹果的实时文本。首先，离线时，该算法处理手写文本的照片。其次，这种方法适用于整页整页的手写内容，而不仅仅是单个单词或行。这意味着它将能够，比如说，将一张购物清单的照片数字化。</p><p id="c479" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">本文总结了他们论文中使用的技术，以及我打算在实现该算法时使用的一些附加技术。</p><h1 id="5d66" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">概观</h1><p id="3774" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">尽管OCR是新的ML科学家完成的第一个项目，但它在现实环境中仍然是一项具有挑战性的任务。这是因为需要三个相对复杂的步骤才能产生有用的结果。算法需要<strong class="jq hj">在图像中定位文本</strong>，<strong class="jq hj">将其分割成</strong>可管理的块，并执行<strong class="jq hj">手写识别</strong>以确定块中有哪些字符。</p><h2 id="2a17" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">通道识别</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/b6d3d537c5395395e64c9ff6390c97d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wxv3TazQcRaPJkHpwPrR2g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">带段落边框的手写笔记本示例—照片由<a class="ae jn" href="https://unsplash.com/@purejulia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> pure julia </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="6ffb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">段落检测是整页OCR的第一步，包括对图像中包含文本的部分进行分类。这包括在每个文本块周围绘制一个边界框。对于简单的环境，比如本文中使用的环境，可以假设只存在一个文本块。这意味着一个卷积模型，比如<strong class="jq hj"> ResNet </strong>，可以用来定位它。该模型输出对应于边界框的<strong class="jq hj"> x、y、宽度和高度</strong>的四个值。</p><p id="294c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">对于包含多个文本块的更复杂的图像，这是行不通的。诸如<strong class="jq hj"> YOLO </strong>或<strong class="jq hj">固态硬盘</strong>之类的算法可以用来检测图像的哪些部分包含文本。这将允许算法检测单个图像中的多个文本框。</p><h2 id="c842" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">线分割</h2><p id="84cb" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">一旦找到图像中包含文本的部分，下一步就是将段落分割成单独的行。本文选择首先检测单个单词的<strong class="jq hj">包围盒，然后使用聚类算法组合这些包围盒。这样做是为了尽量减少遗漏整行的机会。</strong></p><p id="f5cf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通过使用<strong class="jq hj">单发检测器(SSD) </strong>模型来生成单词边界框。SSD架构可以实时生成多个边界框。他们首先使用像<strong class="jq hj"> ResNet34 </strong>这样的图像处理器提取特征图。固态硬盘然后在提取的特征周围绘制边界框。想了解更多信息，我推荐看看乔纳森·许的这篇文章。</p><p id="c1a5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了提高精度，<strong class="jq hj">后处理</strong>步骤也在边界框上执行。高度大于宽度的单词框将被丢弃。重叠的框也被丢弃。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/54fe90f11150c3c6431d720ded9e5094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NDyvaZYdU0kpxy9qOoYjUg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">带有文字边框的手写笔记示例——照片由<a class="ae jn" href="https://unsplash.com/@purejulia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> pure julia </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="f860" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一旦检测到所有的单词边界框，就可以基于它们的y分量将它们聚类成行。由于文本行通常是从左向右直线书写的，因此边界框的y分量可用于确定两个单词是否在同一行上。如果两个边界框明显重叠，那么它们被聚集到同一条线上。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/e015d804e140c8861c9646e9394df31d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k-LsPciCGJH1gavzjisPZg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">带有线条边框的手写笔记示例——照片由<a class="ae jn" href="https://unsplash.com/@purejulia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> pure julia </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="bc65" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了提高精度，在预测线上执行以下<strong class="jq hj">后处理</strong>步骤。</p><ol class=""><li id="d5b8" class="ly lz hi jq b jr js ju jv jx ma kb mb kf mc kj md me mf mg bi translated">小于某个最小值的行被丢弃</li><li id="50ee" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">超出输入图像边界的行将被丢弃</li><li id="4d41" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">大大短于中线长度的线被丢弃</li><li id="9c37" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">明显高于中间高度的线被分成两条线(占双线)</li><li id="43c1" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">与其他行重叠的行将被丢弃</li></ol><p id="6d08" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">通过这些试探法的所有行都用于手写识别步骤。</p><h2 id="af84" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">手写识别</h2><p id="45f3" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">使用<strong class="jq hj">卷积双向LSTM网络</strong> (CNN-biLSTM)进行手写识别。CNN-bilstm是用于提取与输入空间对齐的特征的模型架构。这意味着输出要素(字母)的顺序应该与输入要素的顺序相同。本文使用<strong class="jq hj"> ResNet34 </strong>从输入图像中提取特征。然后，它使用两个biLSTMs将特征编码转换成一个N x M数组，其中N是最大序列长度，M是唯一字符分类的数量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/696492db2ae9ba599900318e0a4eb2a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vAjgQ0-8Qi9_u4x2QJr9RQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">CNN-biLSTM网络的示例架构</figcaption></figure><h2 id="a772" class="li km hi bd kn lj lk ll kr lm ln lo kv jx lp lq kx kb lr ls kz kf lt lu lb lv bi translated">语言模型denoiser</h2><p id="4aa6" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">语言模型去标器是将手写识别器的N×M结果转换成输出字符串的程序。这个问题最常用的方法叫做<strong class="jq hj">贪婪搜索</strong>。贪婪搜索通过为每N个片段选择具有<strong class="jq hj">最大概率</strong>的字符类来工作。这是一种解决问题的直观方法，但它往往会导致低准确性。为了提高精度，可以使用像<strong class="jq hj">光束搜索</strong>或<strong class="jq hj">这样的系统，预先训练语言模型</strong>。这些方法提高了准确性，因为它们考虑了<strong class="jq hj">字符序列</strong>的概率，而不是单独查看分类的概率。我不能给出一个完整的解释，但是要获得更多的信息，我推荐你看一下<a class="ae jn" href="https://machinelearningmastery.com/author/jasonb/" rel="noopener ugc nofollow" target="_blank">杰森·布朗利</a>写的<a class="ae jn" href="https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/" rel="noopener ugc nofollow" target="_blank">这篇</a>文章。</p><p id="c605" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">本文比较了七种<strong class="jq hj">语言去噪方法</strong>的结果，其中包括一种定制的方法。他们的定制语言模型在一个序列对序列的数据集上进行了预训练，在这个数据集上，输入的字符被随机地<strong class="jq hj">添加、删除或替换为相似的字符</strong>。这样做是为了教会语言模型如何修复与错误分类字符相关的错误。N×M阵列被馈入该降噪器以产生预测输出。</p><h1 id="45e1" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">估价</h1><p id="9af0" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">使用<a class="ae jn" href="https://fki.tic.heia-fr.ch/databases/iam-handwriting-database" rel="noopener ugc nofollow" target="_blank"> <strong class="jq hj"> IAM </strong> </a> <strong class="jq hj">数据集</strong>来评估该系统。该数据集包含约1500页扫描的手写和带标签的文档。数据集被分成一个训练集和一个测试集。根据报告的<strong class="jq hj">损失和准确度</strong>以及通过系统运行验证数据产生的<strong class="jq hj">定性视觉样本</strong>对系统进行评估。</p><h1 id="0d08" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">培训详情</h1><p id="cf90" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">本文选择使用<strong class="jq hj"> Apache的MXNet深度学习框架</strong>来开发其网络。每个网络都是单独训练的，都使用了Adam优化器。以下损失用于每个网络:</p><ul class=""><li id="86d5" class="ly lz hi jq b jr js ju jv jx ma kb mb kf mc kj mn me mf mg bi translated"><strong class="jq hj">通道检测:</strong>均方误差</li><li id="c3ea" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated"><strong class="jq hj">单词检测:</strong>分类交叉熵</li><li id="612c" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated"><strong class="jq hj">手写识别:</strong> CTC丢失</li><li id="6c86" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated"><strong class="jq hj">语言符号:</strong>自定义试探法</li></ul><p id="6254" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">由于数据集的性质，许多常见的数据扩充方法不可用。但是，使用了以下内容:</p><ul class=""><li id="b47d" class="ly lz hi jq b jr js ju jv jx ma kb mb kf mc kj mn me mf mg bi translated">翻译</li><li id="1251" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated">剪羊毛</li><li id="f696" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated">咬合</li><li id="0bd9" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated">随机单词/行的消隐</li></ul><h1 id="7c20" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">结果</h1><p id="c4bd" class="pw-post-body-paragraph jo jp hi jq b jr ld ij jt ju le im jw jx lf jz ka kb lg kd ke kf lh kh ki kj hb bi translated">基于定性的观察，我们可以看到，总的来说，所有的步骤都准确地运行。段落检测在定位每个图像的边界框方面做得很好，除了第三列没有找到最后一行。单词检测再次倾向于为行识别器定位足够的单词来包含整个行。然而，许多较短的单词被遗漏了。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/5e7610394d5ad25e84e00b156ebfbaa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LYqp6PP-uppbkySp5IEi6g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图3 —整页OCR示例。输入图像-&gt;段落检测-&gt;单词检测-&gt;线条包围盒</figcaption></figure><p id="7f19" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一旦检测到，手写识别器和自定义denoiser在将行转换为文本方面表现出色。与argmax [AM]和beam search [BS]方法相比，<strong class="jq hj">自定义降噪器[D]的性能明显优于</strong>。当笔迹变得<strong class="jq hj">不清晰</strong>时，这一点尤为突出，例如在样本(d)中。有趣的是，custom denoiser的语言建模能力使其<strong class="jq hj">遗漏了一些来自奇数单词的字母</strong>，例如sample中“desterted”的第一个“t”。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/78f471555078150aa35ac164dadc3f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xKY8VNqB_vph6W4QuGJNpw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图4</figcaption></figure><p id="a6b5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">分析每种去噪方法的报告字符错误率(CER)清楚地表明，自定义去噪器比任何其他算法都精确得多。然而，它不能比输入图像被裁剪(<em class="mq">)的其他方法更准确，即，与该方法中概述的整页相比，馈入仅包含手写部分的图像。</em>)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/f056925af17507e124231c2abb990eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6YWOcePz0nHwNW6aaUc4rg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">表1 —文本去噪方法与CER的比较</figcaption></figure><p id="9b7a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这种方法的内存和时间需求也明显低于其他方法。本文的方法花费的时间比目前最快的可比方法少约1.5倍，内存比Wigington的方法少约3.5倍。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/1ac1396991135e868b7c900e3733b7f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tAsvnMRLSee50FrayLFqTA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">表2 —文本去噪方法与内存使用和时间的比较</figcaption></figure><p id="03a6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">所以，回到我最初的观点，这项技术是惊人的。我能想到它至少有20种用途。我真的很期待在未来与它更多地合作，实现一个成熟的OCR系统。</p><h1 id="48dc" class="kl km hi bd kn ko kp kq kr ks kt ku kv io kw ip kx ir ky is kz iu la iv lb lc bi translated">参考</h1><ul class=""><li id="b59c" class="ly lz hi jq b jr ld ju le jx mt kb mu kf mv kj mn me mf mg bi translated">原文:【https://arxiv.org/pdf/1910.00663.pdf T2】</li><li id="9fa3" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated">IAM数据集:<a class="ae jn" href="https://fki.tic.heia-fr.ch/databases/iam-handwriting-database" rel="noopener ugc nofollow" target="_blank">https://fki . TIC . heia-fr . ch/databases/IAM-手写-数据库</a></li><li id="832e" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj mn me mf mg bi translated">手写识别的基础知识:<a class="ae jn" href="https://nanonets.com/blog/handwritten-character-recognition/" rel="noopener ugc nofollow" target="_blank">https://nano nets . com/blog/手写字符识别/ </a></li></ul><blockquote class="mw mx my"><p id="c683" class="jo jp mq jq b jr js ij jt ju jv im jw mz jy jz ka na kc kd ke nb kg kh ki kj hb bi translated"><em class="hi">感谢阅读我的文章！请随时查看我的</em> <a class="ae jn" href="https://tks.life/profile/robert.macwha#portfolio" rel="noopener ugc nofollow" target="_blank"> <em class="hi">作品集</em> </a> <em class="hi">，在</em><a class="ae jn" href="https://www.linkedin.com/in/robert-macwha-0555141b6/" rel="noopener ugc nofollow" target="_blank"><em class="hi">LinkedIn</em></a><em class="hi">上给我留言，如果你有什么要说的，或者在Medium上关注我，当我发布另一篇文章时，你会收到通知。</em></p></blockquote></div></div>    
</body>
</html>