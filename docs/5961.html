<html>
<head>
<title>Spark remote job submission to Yarn running on AWS EMR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark远程作业提交到AWS EMR上运行的Yarn</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/spark-remote-job-submission-to-yarn-running-on-aws-emr-5d6ffd8cb373?source=collection_archive---------0-----------------------#2021-12-12">https://medium.com/nerd-for-tech/spark-remote-job-submission-to-yarn-running-on-aws-emr-5d6ffd8cb373?source=collection_archive---------0-----------------------#2021-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="23d3" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Spark远程作业提交允许客户端从任何地方向Yarn集群提交Spark作业，将客户端从Yarn集群中分离出来。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/05f7ddd6275c12888fedf0a7079ac7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xWPZCsDLcmZeRRij"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com/@ffstop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Fotis Fotopoulos </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="dbff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">Spark远程作业提交允许客户从任何地方向Yarn集群提交Spark作业。这也可以用来将Spark作业提交给运行不同版本Hadoop和Spark的不同Yarn集群。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="68fe" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">问题陈述</h1><p id="8b7a" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">我们使用AWS EMR集群和Yarn作为资源管理器来运行我们的Spark作业。我们希望远程向EMR集群提交作业，而不需要对主节点使用ssh，也不需要直接在主节点上运行spark-submit命令。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="a484" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">解决办法</h1><p id="a9b9" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">利用Spark的远程作业提交功能，从远程任何地方向Yarn cluster提交作业。</p><h2 id="0639" class="lo ks hi bd kt lp lq lr kx ls lt lu lb jx lv lw ld kb lx ly lf kf lz ma lh mb bi translated"><strong class="ak">远程实例的基本要求:</strong></h2><p id="9a8e" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated"><strong class="jq hj"> 1。Java和Python运行时</strong></p><p id="4c32" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 2。Hadoop和Spark二进制</strong></p><p id="40b9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">远程主机上应该有二进制文件(不需要安装)。远程计算机和目标EMR群集中的二进制文件版本应该匹配。</p><p id="88fd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">二进制文件可以在<a class="ae jn" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">这里</a>下载，也可以从EMR主节点的以下位置<strong class="jq hj"><em class="mc">/usr/lib/Hadoop</em></strong>&amp;<strong class="jq hj"><em class="mc">/usr/lib/spark</em></strong>复制。如果没有从EMR集群复制二进制文件，请确保从EMR集群复制emrfs-hadoop-assembly jar。</p><p id="fbe0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将二进制文件放在远程实例中，并设置以下环境变量。</p><ul class=""><li id="b67f" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><em class="mc">导出</em> HADOOP_HOME= <em class="mc"> &lt; </em>路径到HADOOP二进制文件夹<em class="mc"> &gt; </em></li><li id="4c59" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated"><em class="mc">导出</em> SPARK_HOME= <em class="mc"> &lt; </em>路径到SPARK二进制文件夹<em class="mc"> &gt; </em></li></ul><p id="d4ad" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 3。EMR集群的Hadoop和Spark配置文件</strong></p><p id="3090" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从/etc/hadoop/conf复制Hadoop配置文件yarn-site.xml、core-site.xml、mapred-site.xml，并从/etc/spark/conf复制spark配置文件hive-site.xml。</p><p id="f61f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些配置文件将向Spark提供关于EMR集群的信息，比如在运行spark-submit时，哪个是主节点、资源管理器和hive metastore要连接到的。将配置文件存储在远程实例的文件夹中，并设置以下环境变量。</p><ul class=""><li id="b4e1" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><em class="mc">导出</em>HADOOP _ CONF _目录= <em class="mc"> &lt; </em>路径到hadoop configs文件夹<em class="mc"> &gt; </em></li><li id="b108" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated"><em class="mc">导出</em>SPARK _ HIVE _ XML _ CONF _ DIR =<em class="mc">&lt;</em>路径到spark configs文件夹<em class="mc"> &gt; </em></li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h2 id="dfc6" class="lo ks hi bd kt lp lq lr kx ls lt lu lb jx lv lw ld kb lx ly lf kf lz ma lh mb bi translated"><strong class="ak">运行火花提交</strong></h2><p id="fad4" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">如下所示运行spark-submit命令，将spark deploy模式设置为集群模式。</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="4a00" class="lo ks hi ms b fi mw mx l my mz"><em class="mc">$</em>SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.dist.files=<em class="mc">${</em>SPARK_HIVE_XML_CONF_DIR<em class="mc">}</em>/hive-site.xml sample-spark-code.py</span></pre><p id="592e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，spark-submit在远程实例上运行，将实际的spark作业提交给EMR集群。</p><h1 id="c2f1" class="kr ks hi bd kt ku na kw kx ky nb la lb io nc ip ld ir nd is lf iu ne iv lh li bi translated">结论</h1><ul class=""><li id="9bdd" class="md me hi jq b jr lj ju lk jx nf kb ng kf nh kj mi mj mk ml bi translated">通过利用spark的远程作业提交特性，我们可以从远程的任何地方向Yarn集群提交Spark作业，而不需要对主节点使用SSH，或者直接在主节点上运行spark-submit。</li><li id="a5cc" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">远程实例可以有不同版本的Hadoop和Spark二进制文件。通过根据运行时的需求为每个会话设置指向特定版本的二进制文件夹的环境变量，我们可以使用多个版本的Spark &amp; Hadoop提交Spark作业。</li><li id="785b" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">我们可以在远程实例中存储不同EMR集群的Spark和Hadoop配置文件，并通过为每个会话设置指向特定集群配置文件夹的环境变量，在运行时选择不同的EMR集群。</li><li id="3efd" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">远程实例可以是Docker容器或Kubernetes pod，其映像中嵌入了Hadoop和Spark二进制文件。</li><li id="ad11" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">这样，我们可以将提交Spark作业的客户机从EMR集群中分离出来。支持客户端使用多个版本的Spark和Hadoop向多个EMR集群提交Spark作业。</li></ul></div></div>    
</body>
</html>