<html>
<head>
<title>Spark remote job submission to Yarn running on AWS EMR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 远程作业提交到 AWS EMR 上运行的 Yarn</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/spark-remote-job-submission-to-yarn-running-on-aws-emr-5d6ffd8cb373?source=collection_archive---------0-----------------------#2021-12-12">https://medium.com/nerd-for-tech/spark-remote-job-submission-to-yarn-running-on-aws-emr-5d6ffd8cb373?source=collection_archive---------0-----------------------#2021-12-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="23d3" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">Spark 远程作业提交允许客户端从任何地方向 Yarn 集群提交 Spark 作业，将客户端从 Yarn 集群中分离出来。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/05f7ddd6275c12888fedf0a7079ac7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xWPZCsDLcmZeRRij"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com/@ffstop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Fotis Fotopoulos </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="dbff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">Spark 远程作业提交允许客户从任何地方向 Yarn 集群提交 Spark 作业。这也可以用来将 Spark 作业提交给运行不同版本 Hadoop 和 Spark 的不同 Yarn 集群。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="68fe" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">问题陈述</h1><p id="8b7a" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">我们使用 AWS EMR 集群和 Yarn 作为资源管理器来运行我们的 Spark 作业。我们希望远程向 EMR 集群提交作业，而不需要对主节点使用 ssh，也不需要直接在主节点上运行 spark-submit 命令。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="a484" class="kr ks hi bd kt ku kv kw kx ky kz la lb io lc ip ld ir le is lf iu lg iv lh li bi translated">解决办法</h1><p id="a9b9" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">利用 Spark 的远程作业提交功能，从远程任何地方向 Yarn cluster 提交作业。</p><h2 id="0639" class="lo ks hi bd kt lp lq lr kx ls lt lu lb jx lv lw ld kb lx ly lf kf lz ma lh mb bi translated"><strong class="ak">远程实例的基本要求:</strong></h2><p id="9a8e" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated"><strong class="jq hj"> 1。Java 和 Python 运行时</strong></p><p id="4c32" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 2。Hadoop 和 Spark 二进制</strong></p><p id="40b9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">远程主机上应该有二进制文件(不需要安装)。远程计算机和目标 EMR 群集中的二进制文件版本应该匹配。</p><p id="88fd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">二进制文件可以在<a class="ae jn" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">这里</a>下载，也可以从 EMR 主节点的以下位置<strong class="jq hj"><em class="mc">/usr/lib/Hadoop</em></strong>&amp;<strong class="jq hj"><em class="mc">/usr/lib/spark</em></strong>复制。如果没有从 EMR 集群复制二进制文件，请确保从 EMR 集群复制 emrfs-hadoop-assembly jar。</p><p id="fbe0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">将二进制文件放在远程实例中，并设置以下环境变量。</p><ul class=""><li id="b67f" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><em class="mc">导出</em> HADOOP_HOME= <em class="mc"> &lt; </em>路径到 HADOOP 二进制文件夹<em class="mc"> &gt; </em></li><li id="4c59" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated"><em class="mc">导出</em> SPARK_HOME= <em class="mc"> &lt; </em>路径到 SPARK 二进制文件夹<em class="mc"> &gt; </em></li></ul><p id="d4ad" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> 3。EMR 集群的 Hadoop 和 Spark 配置文件</strong></p><p id="3090" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">从/etc/hadoop/conf 复制 Hadoop 配置文件 yarn-site.xml、core-site.xml、mapred-site.xml，并从/etc/spark/conf 复制 spark 配置文件 hive-site.xml。</p><p id="f61f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这些配置文件将向 Spark 提供关于 EMR 集群的信息，比如在运行 spark-submit 时，哪个是主节点、资源管理器和 hive metastore 要连接到的。将配置文件存储在远程实例的文件夹中，并设置以下环境变量。</p><ul class=""><li id="b4e1" class="md me hi jq b jr js ju jv jx mf kb mg kf mh kj mi mj mk ml bi translated"><em class="mc">导出</em>HADOOP _ CONF _ 目录= <em class="mc"> &lt; </em>路径到 hadoop configs 文件夹<em class="mc"> &gt; </em></li><li id="b108" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated"><em class="mc">导出</em>SPARK _ HIVE _ XML _ CONF _ DIR =<em class="mc">&lt;</em>路径到 spark configs 文件夹<em class="mc"> &gt; </em></li></ul></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h2 id="dfc6" class="lo ks hi bd kt lp lq lr kx ls lt lu lb jx lv lw ld kb lx ly lf kf lz ma lh mb bi translated"><strong class="ak">运行火花提交</strong></h2><p id="fad4" class="pw-post-body-paragraph jo jp hi jq b jr lj ij jt ju lk im jw jx ll jz ka kb lm kd ke kf ln kh ki kj hb bi translated">如下所示运行 spark-submit 命令，将 spark deploy 模式设置为集群模式。</p><pre class="iy iz ja jb fd mr ms mt mu aw mv bi"><span id="4a00" class="lo ks hi ms b fi mw mx l my mz"><em class="mc">$</em>SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.dist.files=<em class="mc">${</em>SPARK_HIVE_XML_CONF_DIR<em class="mc">}</em>/hive-site.xml sample-spark-code.py</span></pre><p id="592e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，spark-submit 在远程实例上运行，将实际的 spark 作业提交给 EMR 集群。</p><h1 id="c2f1" class="kr ks hi bd kt ku na kw kx ky nb la lb io nc ip ld ir nd is lf iu ne iv lh li bi translated">结论</h1><ul class=""><li id="9bdd" class="md me hi jq b jr lj ju lk jx nf kb ng kf nh kj mi mj mk ml bi translated">通过利用 spark 的远程作业提交特性，我们可以从远程的任何地方向 Yarn 集群提交 Spark 作业，而不需要对主节点使用 SSH，或者直接在主节点上运行 spark-submit。</li><li id="a5cc" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">远程实例可以有不同版本的 Hadoop 和 Spark 二进制文件。通过根据运行时的需求为每个会话设置指向特定版本的二进制文件夹的环境变量，我们可以使用多个版本的 Spark &amp; Hadoop 提交 Spark 作业。</li><li id="785b" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">我们可以在远程实例中存储不同 EMR 集群的 Spark 和 Hadoop 配置文件，并通过为每个会话设置指向特定集群配置文件夹的环境变量，在运行时选择不同的 EMR 集群。</li><li id="3efd" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">远程实例可以是 Docker 容器或 Kubernetes pod，其映像中嵌入了 Hadoop 和 Spark 二进制文件。</li><li id="ad11" class="md me hi jq b jr mm ju mn jx mo kb mp kf mq kj mi mj mk ml bi translated">这样，我们可以将提交 Spark 作业的客户机从 EMR 集群中分离出来。支持客户端使用多个版本的 Spark 和 Hadoop 向多个 EMR 集群提交 Spark 作业。</li></ul></div></div>    
</body>
</html>