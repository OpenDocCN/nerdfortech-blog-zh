<html>
<head>
<title>Apache Spark — Installation &amp; how to use it</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark —安装和如何使用它</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/apache-spark-installation-how-to-use-it-31ab4768634a?source=collection_archive---------4-----------------------#2021-03-10">https://medium.com/nerd-for-tech/apache-spark-installation-how-to-use-it-31ab4768634a?source=collection_archive---------4-----------------------#2021-03-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/59da1f93473bf2a27b4e5ff8d61da0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*SaK2Ygu1rldp95xAyCGS0w.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">DAG可视化</figcaption></figure><p id="e130" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如今，许多社交应用正在被开发，每次都会导致大规模的数据改进，当我们谈论每次连接的数百万用户时，每当用户与社交媒体或其他网站交互时，信息就会被共享，所以问题就出现了，如何处理这些海量数据，以及通过什么媒体或工具来处理和存储数据。这就是大数据展现的地方。</p><p id="5401" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以第一个问题是什么是大数据？</p><p id="567f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">大数据是一个描述大量数据的术语，这些数据包括结构化数据和非结构化数据，每天充斥着企业。但重要的不是数据量。重要的是组织如何处理数据。可以分析大数据以获得洞察力，从而做出更好的决策和战略性业务举措。</em></p><p id="f33c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大数据的概念已经存在多年，现在他们明白，如果他们捕获所有数据，他们就可以实施分析并从中受益匪浅。</p><p id="eff7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着对大数据技术的极大兴趣和投资，数据分析和数据工程等领域具有最宝贵的价值。一些大数据工具基于Python和Java，使得已经在使用这些语言的程序员更容易了解大数据分析和分析工具。借助Power Bi、Qlikview、Tableau等可视化工具。，用户可以轻松地分析数据并提出新的策略。</p><p id="e75c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但在此之前，当然要针对大数据，大量的做好正确的数据处理。因为阿帕奇火花出现了。</p><p id="32fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阿帕奇火花</strong></p><p id="7304" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Apache Spark是用于大规模数据处理的统一分析引擎。</p><p id="3363" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Apache Spark是一个用于大规模数据处理的开源统一分析引擎。Spark提供了一个接口，通过隐式数据并行和容错对整个集群进行编程。Spark代码库最初是由加州大学伯克利分校的AMPLab开发的，后来被捐赠给了Apache Software Foundation，该基金会一直维护着它。</p><p id="bbd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">速度</strong></p><p id="24f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">工作负载运行速度提高100倍。</strong></p><p id="b009" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Apache Spark使用最先进的DAG调度程序、查询优化器和物理执行引擎，为批处理和流数据实现了高性能。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/a60ad83b1d81c98b164597574cb2d966.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*ZZDv9XAglRAbRgd_u-81RA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">速度</figcaption></figure><p id="1d9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 2。易用性</strong></p><p id="bab2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用Java、Scala、Python、R、SQL快速编写应用。</p><p id="92b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark提供了80多个高级操作符，可以轻松构建并行应用。您可以在Scala、Python、R和SQL shells中交互使用它。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es ju"><img src="../Images/1adb372079553f00d8dd879c5376f93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9GPKalK4I0xx5tBzRcgJg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">加载数据</figcaption></figure><p id="9ecb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 3。通用性</strong></p><p id="152a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结合SQL、流和复杂分析。</p><p id="c88b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark支持一系列库，包括SQL和DataFrames、用于机器学习的MLlib、GraphX和Spark Streaming。您可以在同一个应用程序中无缝地组合这些库。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/c4c79da3f6fd1762ee3de1b4354cf215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*eGyqPUF0ql9dRnSmqPaK9A.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">大部分</figcaption></figure><p id="4e1e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> 4。到处跑</strong></p><p id="3651" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark可以运行在Hadoop、Apache Mesos、Kubernetes上，可以独立运行，也可以运行在云中。它可以访问不同的数据源。</p><p id="493a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以在EC2、Hadoop YARN、Mesos或Kubernetes上使用其独立集群模式运行Spark。访问HDFS、Alluxio、Apache Cassandra、Apache HBase、Apache Hive和数百个其他数据源中的数据。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/a53188d442519304832f60286512f6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*GZMlclnj8R05AewwHuxFCg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">到处跑</figcaption></figure><p id="c91f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">安装</strong></p><p id="0f06" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">a)选择火花释放</p><p id="c549" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">b)选择包装类型</p><p id="9c07" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">c)选择下载类型:(直接下载)</p><p id="c139" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">d)下载Spark。请记住，如果您下载一个较新的版本，您将需要为您下载的文件修改其余的命令。</p><p id="c350" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">确保您的计算机上安装了Java 7+。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kb"><img src="../Images/d46691c0e705d2db40130438c2e76477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*paoLoqp4_FGjUqN_vmDfHA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">[计] 下载</figcaption></figure><p id="e297" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">设定环境</strong></p><p id="6961" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">setx SPARK _ HOME ~你的文件夹\spark-3.1.1-bin-hadoop2.7</p><p id="40b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">setx HADOOP _ HOME ~你的文件夹\spark-3.1.1-bin-hadoop2.7</p><p id="0849" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">setx py spark _ DRIVER _ PYTHON ipython</p><p id="46e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">setx PYSPARK_DRIVER_PYTHON_OPTS笔记本</p><p id="ab8b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在你的路径中添加~你的文件夹\spark-3.1.1-bin-hadoop2.7\bin。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kc"><img src="../Images/784155e5acea7c42ea9a1b62101b94bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*diARFW_ELBt6T9r6e1zD9g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">环境</figcaption></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kd"><img src="../Images/c35136110e742764e562473772c3f213.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JLsqcGg2hjWtn67b__VPcg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">环境</figcaption></figure><p id="467d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">运行</strong></p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ke"><img src="../Images/1bc8a2f86fd19098739469a9023abf03.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*FZpyY3VIYE-Gjppdz0_hPA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">奔跑</figcaption></figure><p id="f20e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">— master参数用于设置主节点地址。这里，我们在两个内核上本地启动Spark进行本地测试。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kf"><img src="../Images/8cf06ecac78b36b8b35f962a704ab22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ortdbPPnkky31S8GPAv57w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">火花3.1.1</figcaption></figure><p id="24dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">简单练习</strong></p><p id="c963" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">打开新的Jupyter笔记本。如果你是Spark的新手，需要在window的机器上使用Jupyter notebook设置Spark，那么先完成设置。通过spark会话创建一个访问spark的入口点。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es kg"><img src="../Images/5626cd1a9bfc28f7643de21e42875d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*AQlCIpT3AtpP8LjZPryGQQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">创建访问权限</figcaption></figure><p id="abda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们可以通过读取CSV文件来创建输入数据框。按照下面的代码片段创建spark数据框。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kf"><img src="../Images/48da50e8c5b6487fa1a362e48d205d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNw39-G2_eigkQj7OJfHlg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">数据帧</figcaption></figure><p id="491c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> SPARK UI </strong></p><p id="19de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Apache Spark提供了一套Web UI/用户界面(作业、阶段、任务、存储、环境、执行器和SQL)来监控Spark/PySpark应用程序的状态、Spark集群的资源消耗和Spark配置。</p><p id="1acc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以点击Spark UI</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/698ec5f6bb1dd509bdc0390bf014074f.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*nWbBDl7pb5L1Y4Tp8CHIsQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">Spark UI</figcaption></figure><p id="c830" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">火花作业标签</strong></p><p id="5022" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我希望您了解jobs部分下的详细信息，包括调度模式、spark作业的数量、它拥有的阶段数量以及Spark作业中的描述。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es ki"><img src="../Images/a0476cbcabecf456fafdb25444f0a535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OiCCw04BBP7KeDQ70DDDBw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">作业选项卡</figcaption></figure><p id="d984" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阶段选项卡</strong></p><p id="422d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以通过两种方式导航到阶段选项卡。</p><p id="4cc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.选择相应Spark作业的描述(仅显示所选Spark作业的阶段)</p><p id="8a85" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.在Spark作业选项卡的顶部，选择阶段选项(显示应用程序中的所有阶段)</p><p id="3f55" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的应用程序中，我们总共有7个阶段。</p><p id="2442" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Stage选项卡显示一个摘要页面，该页面显示spark应用程序中所有Spark作业的所有阶段的当前状态</p><p id="c091" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以在每个阶段看到的任务数量是spark将要处理的分区数量，并且一个阶段中的每个任务都是spark将要完成的相同工作，但是是在不同的数据分区上</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kj"><img src="../Images/f320f4e678ca54bdda3538702b4c8443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9okM19WZKtey1dNfcMPooA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">阶段</figcaption></figure><p id="27e1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">舞台细节</strong></p><p id="822e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阶段的详细信息展示了该阶段的有向无环图(DAG ),其中顶点表示rdd或数据帧，边表示要应用的操作。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es if"><img src="../Images/59da1f93473bf2a27b4e5ff8d61da0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*SaK2Ygu1rldp95xAyCGS0w.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">DAG可视化</figcaption></figure><p id="4e83" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结论</p><p id="c103" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大数据分析的重要性导致竞争激烈，对大数据专业人员的需求增加。因此，对于专业人员来说，始终跟上技术的发展并不断增加专业知识变得非常重要。Apache Spark旨在帮助应对这个大数据时代的挑战。</p><p id="ab88" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参考</p><p id="68fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="https://www.sas.com/en_au/insights/big-data/what-is-big-data.html" rel="noopener ugc nofollow" target="_blank">大数据:它是什么，为什么重要| SAS </a></p><p id="5765" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">Apache Spark—大数据统一分析引擎</a></p><p id="e0fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="https://en.wikipedia.org/wiki/Apache_Spark" rel="noopener ugc nofollow" target="_blank">阿帕奇火花—维基百科</a></p><p id="8f05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="https://sparkbyexamples.com/spark/spark-web-ui-understanding/" rel="noopener ugc nofollow" target="_blank"> Spark Web UI —了解Spark执行—Spark by示例</a></p><p id="130b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" rel="noopener" href="/@GalarnykMichael/install-spark-on-windows-pyspark-4498a5d8d66c">在Windows上安装Spark(PySpark)|作者:Michael Galarnyk | Medium </a></p><p id="a262" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="https://www.learntospark.com/2020/01/show-full-content-in-spark-dataframe.html" rel="noopener ugc nofollow" target="_blank">如何在Apache Spark(learntospark.com)中查看数据帧的全部内容</a></p><p id="9a97" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae kk" href="https://pythonexamples.org/pyspark-word-count-example/" rel="noopener ugc nofollow" target="_blank"> PySpark —字数示例— Python示例</a></p></div></div>    
</body>
</html>