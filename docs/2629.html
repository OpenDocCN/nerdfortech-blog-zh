<html>
<head>
<title>Hypothesis Testing On Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的假设检验</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/hypothesis-testing-on-linear-regression-c2a1799ba964?source=collection_archive---------0-----------------------#2021-05-14">https://medium.com/nerd-for-tech/hypothesis-testing-on-linear-regression-c2a1799ba964?source=collection_archive---------0-----------------------#2021-05-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/da03ea59d0adf8b1bcc0974f8d6b7565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qo1yyqHK4b47porjAUMlsA.png"/></div></div></figure><p id="7137" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated">当我们建立多元线性回归模型时，我们可能会有一些潜在的预测因子/独立变量。因此，选择真正显著的、对实验有强烈影响的变量是极其重要的。为了得到最优模型，我们可以尝试所有可能的独立变量组合，看看哪个模型最合适。但这种方法耗时且不可行。因此，我们需要另一种方法来得到一个合适的模型。我们可以通过<strong class="is hj">手动特征消除</strong>或者通过使用任何<strong class="is hj">自动方法</strong> (RFE、正则化等)来做同样的事情。).</p><p id="cf4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在手动特征消除中，我们可以:</p><ul class=""><li id="0d9d" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf bi translated">建立一个具有所有特征的模型，</li><li id="8865" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">丢弃对预测帮助最小的特征(高 p 值)，</li><li id="8227" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">丢弃冗余的特征(使用相关性和 VIF)，</li><li id="153d" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf bi translated">重建模型并重复。</li></ul><p id="5a0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一般建议我们遵循平衡的方法，即使用自动(粗调)+手动(微调)选择的组合，以便获得最佳模式。在这篇博客中，我们将讨论手动特征消除的第二步，即丢弃对预测帮助最小的特征(无关紧要的特征)。</p><p id="9aab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先出现的问题是:'<strong class="is hj"> <em class="kl">我们所说的重要变量是什么意思？</em></strong>’。我们先用简单的线性回归来理解一下。</p><p id="e513" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们通过数据拟合直线时，我们得到两个参数，即截距(β₀)和斜率(β₁).</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es km"><img src="../Images/0a2e804f745bd20a5bd357fd119665bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*bXojvvRx6PMXVMIG88x-RA.png"/></div></figure><p id="1f4b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，β₀现在不是很重要，但β₁周围有几个方面需要检查和核实。假设我们有一个数据集，其散点图如下所示:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/83deeea66625b7aa63ee1d8cdc033fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*KjPusvaXzw-_pW3nuKjOmw.png"/></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">散点图</figcaption></figure><p id="49b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们在 Python 中对此数据集运行线性回归时，Python 将在数据上拟合一条线，如下所示:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/a7a473890d4366fa5b6e4d8c8e8a8b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*SWWWgcLG5ouQ9m3Oh38NTQ.png"/></div></figure><p id="e95b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以清楚地看到，数据是随机分散的，似乎不遵循线性趋势。<strong class="is hj"> <em class="kl"> Python 无论如何都会使用最小二乘法拟合一条穿过数据的直线。</em> </strong>我们可以看到，在这种情况下，拟合线是没有用的。因此，每次进行线性回归时，我们都需要检验拟合的直线是否显著(换句话说，检验β₁是否显著)。同样，我们将对β₁进行假设检验。</p><p id="fe29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">执行假设检验的步骤:</strong></p><ol class=""><li id="5813" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kx kd ke kf bi translated">设定假设</li><li id="7b79" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kx kd ke kf bi translated">设定决策的重要性水平和标准</li><li id="731f" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kx kd ke kf bi translated">计算测试统计数据</li><li id="4930" class="jx jy hi is b it kg ix kh jb ki jf kj jj kk jn kx kd ke kf bi translated">决定</li></ol><p id="83e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤 1: </strong>我们开始说β₁不重要，即 x 和 y 之间没有关系，因此斜率β₁ = 0。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/f1509b1511ff6da417a833379135f1cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*V9SPmr1WiblvLmZk-w_x-Q.png"/></div></figure><p id="5aaa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">步骤 2: </strong>通常，我们将显著性水平设置为 10%、5%或 1%。</p><p id="8eac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第三步:</strong>在制定零备假设后，下一步要遵循的顺序是<strong class="is hj"> </strong>使用<strong class="is hj"> p 值法</strong>做出决策如下:</p><ol class=""><li id="6c68" class="jx jy hi is b it iu ix iy jb jz jf ka jj kb jn kx kd ke kf bi translated">计算分布平均值的值<strong class="is hj"> t-score </strong>。</li></ol><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kz"><img src="../Images/3587ca7d7afba4acbc24869d2b90847d.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*srJikvo4_NVsLmFV1m3YQA.png"/></div></figure><p id="9a7c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其中，μ是总体均值，s 是样本标准差，除以√n 也称为标准差。</p><p id="d94a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.使用 t 表，根据给定 t 分数的累积概率计算<strong class="is hj"> p 值</strong></p><p id="06f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.根据关于显著性水平给定值的 p 值做出决定。</p><p id="40df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">第四步:</strong>做决定</p><p id="e17b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果，</p><p id="914f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">p 值&lt; <strong class="is hj"> 0.05 </strong>，<strong class="is hj"> </strong>我们可以拒绝零假设。</p><p id="b72c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">p 值&gt;<strong class="is hj"> 0.05 </strong>，我们未能拒绝零假设。</p><p id="2326" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们不能拒绝零假设，这将意味着β₁是零(换句话说，β₁是微不足道的)，在模型中没有用。同样，如果我们拒绝零假设，这将意味着β₁不是零，拟合的线是一个重要的。</p><p id="dcdd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong>以上步骤由 Python 自动执行。</p><p id="e98b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似地，在多元线性回归中，我们将执行与线性回归相同的步骤，除了无效假设和替代假设不同。对于多元回归模型:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es la"><img src="../Images/21386b4151c6478bdedaa3647cd7cc7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*s2M3kt2lSNlkneXgIPI21Q.png"/></div></figure><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/f709d94f587e1f07f87dea9371101973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*njbmnQrLMNqI3jhR8fKovQ.png"/></div></figure><h1 id="415d" class="lc ld hi bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">Python 中的例子</strong></h1><p id="7676" class="pw-post-body-paragraph iq ir hi is b it ma iv iw ix mb iz ja jb mc jd je jf md jh ji jj me jl jm jn hb bi translated">让我们以包含德里地区房产价格的房产数据为例。我们希望利用这些数据，根据面积、卧室、停车场等重要因素，优化房产的销售价格。</p><p id="8499" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集的前五行如下所示:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/1c3874ce0c341b5e83bddc052ea920e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2k29irDQBIDMdI1tDd8H3Q.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">住房数据集</figcaption></figure><p id="7539" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在准备、清理和分析数据后，我们将使用所有变量建立一个线性回归模型(使用<strong class="is hj"> <em class="kl"> statsmodels </em> </strong>通过数据拟合一条回归线)</p><pre class="kn ko kp kq fd mh mi mj mk aw ml bi"><span id="458f" class="mm ld hi mi b fi mn mo l mp mq">import statsmodels.api as sm</span><span id="2240" class="mm ld hi mi b fi mr mo l mp mq">y_train = housing_dataset.pop('price');</span><span id="85dc" class="mm ld hi mi b fi mr mo l mp mq">X_train = housing_dataset;</span><span id="d2a5" class="mm ld hi mi b fi mr mo l mp mq">X_train_lm = sm.add_constant(X_train)</span><span id="fc79" class="mm ld hi mi b fi mr mo l mp mq">lm = sm.OLS(y_train, X_train_lm).fit()</span><span id="1eb4" class="mm ld hi mi b fi mr mo l mp mq">print(lm.summary())</span></pre><p id="6571" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们得到以下输出:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/a2e6b1f428da032f8a999fe33382cc3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jQH0SpkwX4TMqMZa8vsPqQ.png"/></div></div></figure><p id="fde6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">观察 P 值(P&gt;|t|)，一些变量如<strong class="is hj">卧室、半装修的</strong>并不显著(p &gt; 0.05)。我们可以简单地去掉 p 值最高、不重要的变量。</p><p id="2308" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong>一般我们用两个主要参数来判断不显著变量，<strong class="is hj"> p 值</strong>和<strong class="is hj"> VIFs </strong>(方差膨胀因子)。</p></div></div>    
</body>
</html>