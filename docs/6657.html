<html>
<head>
<title>Support Vector Machines: Geometrical Interpretation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机:几何解释</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/support-vector-machines-geometrical-interpretation-27adc9a65dd7?source=collection_archive---------2-----------------------#2022-04-13">https://medium.com/nerd-for-tech/support-vector-machines-geometrical-interpretation-27adc9a65dd7?source=collection_archive---------2-----------------------#2022-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9bc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM是最流行的机器学习技术之一，可用于分类和回归任务。SVM在20世纪90年代开始流行。简而言之，SVM可以被认为是一个受监督的机器学习模型，它使用一个超平面来区分两个类别，其目标是最大化+ve和-ve点之间的距离(用于分类问题)。那么让我们来详细了解一下SVM的几何解释</p><h1 id="704f" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">几何解释:</h1><h2 id="8ed4" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">1.介绍</h2><p id="a151" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">假设我们有一些点，为了简单起见，假设数据是线性可分的</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/ecea9c354e7bf2edf24b6bed986946d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7A8lqysbrD9kkrlSYHRNw.jpeg"/></div></div></figure><p id="e4bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们可以看到的，该数据是线性可分的，我们可以有多个超平面来分隔它们，但为了简单起见，这里我们只考虑这两个超平面。</p><p id="d941" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们稍微改变一下数据，以便于理解-</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/95a48229d1a3da77701cc2c720056eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0S65YahXUlxn7rjrccNd0A.jpeg"/></div></div></figure><p id="8c95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在出现的问题是，在两个超平面π1和π2中，我们应该选择哪个超平面？</p><p id="dac4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们选择π1，那么有许多点接近超平面(用圆圈标记)。由于这些点非常接近超平面，如果超平面稍微改变，那么这些点可能会被错误分类，这是我们必须努力避免的。</p><p id="4d55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要理解的另一个事实是，离超平面越近的点属于远离超平面的类的概率越小(不是在相反的方向上)</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/cdae3f5f2e2abb1471ce910f8977cbac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Od3RznZbfjFUga6lqVjqYg.jpeg"/></div></div></figure><p id="eb95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，距离π1较近的+ve点属于某类的概率为0.55，而距离较远的点属于该类的概率为0.9。</p><p id="27e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，SVM的目标是找到一个尽可能把+ve点和-ve点分开的超平面。所以我们会选择超平面π2而不是π1。参考消息:试图将+ve点与-ve点尽可能分开的超平面称为<strong class="ih hj"> <em class="lg">边缘最大化超平面</em> </strong>。所以这里的π2是一个边际最大化超平面。</p><h2 id="ed9e" class="kb je hi bd jf kc kd ke jj kf kg kh jn iq ki kj jr iu kk kl jv iy km kn jz ko bi translated">2.边缘最大化超平面</h2><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lh"><img src="../Images/9ab4c059c42a5dbb11e1f0ddd2b9ee35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqD6CbLC6Q3zgliKc3Q0qQ.jpeg"/></div></div></figure><p id="279d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们继续画平行于超平面π的超平面，那么过一段时间后，我们将得到一个与第一个+ve点相交的平面，我们称之为π+。类似地，我们将得到一个点，它将与第一个点相交，我们称它为π-。π+和π-都是相互平行的。通过π+和π-的点称为支持向量(对于理解数学公式很重要)</p><p id="43a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设π+和π-之间的距离为d，也叫裕度。</p><p id="0c09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们希望最大化d的值，因为d的值越大，意味着+ve点和-ve点彼此远离，差距越大，对我们越有利。因此，SVM基本上试图最大化余量，即dist(π+，π-)。</p><p id="8473" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果裕量增加= &gt;错误分类减少= &gt;概化精度增加(未来未知数据的精度)</p></div></div>    
</body>
</html>