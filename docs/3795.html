<html>
<head>
<title>Scraping Reddit to Create a Word Cloud About Brazil</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">抓取 Reddit 创建一个关于巴西的文字云</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/scrapping-reddit-to-create-a-word-cloud-about-brazil-f5bb445bf6a6?source=collection_archive---------8-----------------------#2021-06-24">https://medium.com/nerd-for-tech/scrapping-reddit-to-create-a-word-cloud-about-brazil-f5bb445bf6a6?source=collection_archive---------8-----------------------#2021-06-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fb645cb02b63889ea4714771f9cfddc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFY3ESK26mCi74bC0JTN1A.jpeg"/></div></div></figure><p id="b437" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最近，我受邀协助一项心理健康研究，在这项研究中，有必要从大量 Reddit 出版物中删除文本。这就是我如何发现 Praw 的，Praw 是“Python Reddit API Wrapper”的缩写，这是一个 Python 库，旨在使从 Reddit 提取内容和向 Reddit 提交内容变得容易。其实我就是这样发现 Reddit 本身的。我已经知道这个平台，但我不知道它有多大。</p><p id="4829" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Reddit 是一个巨大的社交媒体，每月用户超过 400.000 万，活跃社区超过 130.000 个。它是由 subredditss 构成的，subreddit 是由用户自己创建和管理的讨论特定主题的论坛。</p><p id="1019" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于我之前评论的研究，我必须在子编辑 r/depression 中定位特定的单词。这给了我做以下练习的想法:在 Reddit 上搜索单词“Brazil”(英语单词，因为它在葡萄牙语中拼写为“Brasil”)，以查看国外社区对我们的评论。</p><p id="2b21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我将在两篇文章中介绍这个练习。在这里的这篇文章中，我将展示我如何通过搜索子编辑来找出哪个子编辑有更多包含单词“Brazil”的帖子，然后提取帖子、评论和回复，并将它们保存到用于创建图形单词云的列表中。</p><p id="da63" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在第二篇文章中，我将尝试对我从 subreddit 中提取的文本应用机器学习技术进行情感分析。如果你不知道 Reddit，我建议你花些时间去探索它，搜索你可能感兴趣的子主题和话题。这样做可以更容易理解这篇文章的后续步骤。</p><h1 id="a520" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">PRAW</h1><p id="487f" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在开始使用 PRAW 之前，您必须拥有一个 Reddit 帐户，并且需要在以下地址创建一个 bot:</p><div class="kr ks ez fb kt ku"><a href="https://www.reddit.com/prefs/apps" rel="noopener  ugc nofollow" target="_blank"><div class="kv ab dw"><div class="kw ab kx cl cj ky"><h2 class="bd hj fi z dy kz ea eb la ed ef hh bi translated">reddit.com:登录</h2><div class="lb l"><h3 class="bd b fi z dy kz ea eb la ed ef dx translated">别担心，我们不会告诉任何人你的用户名。登录您的 Reddit 帐户。</h3></div><div class="lc l"><p class="bd b fp z dy kz ea eb la ed ef dx translated">www.reddit.com</p></div></div></div></a></div><p id="90d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，你需要点击<strong class="is hj">创建另一个应用</strong>，并确保你标记了<strong class="is hj">脚本</strong>选项。填写空白处，然后你会收到一个<strong class="is hj">客户 id </strong>和一个<strong class="is hj">秘密令牌</strong>，把它们保存在某个地方。</p><h2 id="a39b" class="ld jp hi bd jq le lf lg ju lh li lj jy jb lk ll kc jf lm ln kg jj lo lp kk lq bi translated">搜索最频繁出现的子记录</h2><p id="adc6" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">首先，我们需要导入库:</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><ul class=""><li id="0337" class="lx ly hi is b it iu ix iy jb lz jf ma jj mb jn mc md me mf bi translated"><strong class="is hj"> Praw </strong>:用于提取 Reddit 帖子。</li><li id="2736" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj">熊猫</strong>:用于操纵数据。</li><li id="2e15" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> Numpy </strong>:用于支持多维数组和矩阵。</li><li id="e8df" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> Pil </strong>:影像库。</li><li id="3503" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated">Nltk:一个 NLP 库。这里我们将只使用它来管理停用词。</li><li id="92b6" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> Wordcloud </strong>:创建和定制我们的云所必需的。</li><li id="24bf" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> Gensim </strong>:用于 ML 和统计应用，在这里管理停用词。</li></ul><p id="bb27" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将使用<strong class="is hj"> Praw 连接到 Reddits。</strong>你需要<strong class="is hj">客户端 id </strong>和<strong class="is hj">密钥。</strong></p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><h2 id="2c9b" class="ld jp hi bd jq le lf lg ju lh li lj jy jb lk ll kc jf lm ln kg jj lo lp kk lq bi translated">WHE 打算用 SUBREDDIT 来定义搜索</h2><p id="eefe" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">为了定义我们的目标子编辑，我们将在所有子编辑中搜索我们的关键字“Brazil ”,我们使用出现次数更多且不太臃肿的子编辑进行搜索。</p><p id="e472" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们创建一个表示所有子编辑的变量(<strong class="is hj">all _ subreddit</strong>)，并使用它来搜索我们的关键字，遍历变量元素(子编辑)和<strong class="is hj">，将</strong>的名称添加到一个名为<strong class="is hj"> subreddit_list </strong>的列表中。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="6438" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可能会检索一个列表，如下图所示，但是有超过 200 个子条目。</p><p id="d622" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> ['selfie '，' antimeme '，' transpositive '，' sehnsuchtpics '，' aww '，' BrasilOnReddit '，' GachaClub '，' softwaregore '，' Cringetopia '，' science '，' COVID19 '，' Basil_cult '，' lgbt '，' unexpectedsimpsons '，' worldnews '，' UFObelievers '，' worldnews '，' NoNewNormal '，' Brazil'] </strong></p><p id="0b17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个列表显示了我们找到关键字的子编辑。然而，这是一个很大的列表，包含一些子条目，用来讨论更具体的话题，比如足球和金融话题，这些话题我们不感兴趣。我们需要更普通的东西。</p><p id="3169" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们使用来自<strong class="is hj"> Pandas </strong>库的<strong class="is hj"> groupby </strong>函数和<strong class="is hj"> loc </strong>函数来过滤出现次数较多的子记录。之后，我们将尝试识别最普通的子编辑。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="12ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们用<strong class="is hj"> Seaborn </strong>绘制分组变量:</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/b29c850c003b4b4cce8e369c098beb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5y8-1cOnLWYiLGby2k9zRg.jpeg"/></div></div></figure><p id="fea2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面这三个子主题来看,<strong class="is hj">世界新闻</strong>似乎最适合我们的练习。那是我们正在使用的一个</p><h2 id="1c1e" class="ld jp hi bd jq le lf lg ju lh li lj jy jb lk ll kc jf lm ln kg jj lo lp kk lq bi translated"><strong class="ak">在 R/WORLDNEWS 子编辑中搜索</strong></h2><p id="e5e2" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">现在我们将创建并执行一个函数来提取 PRAW 的文本:</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="0068" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<strong class="is hj">错误列表</strong>上，我在我们有错误的地方添加了帖子来检索文本。在<strong class="is hj">阅读列表</strong>上，我<strong class="is hj"> </strong>附加了文本，指明它是否是标题、帖子、评论或回复的一部分。在<strong class="is hj"> raw_list </strong>上，我添加了没有引用帖子相应部分的文本。</p><p id="a20a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我创建了一系列循环来遍历标题、帖子、评论和回复。，将字符串追加到列表中。</p><p id="7dee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们将<strong class="is hj"> raw_list </strong>和<strong class="is hj"> reading_list </strong>保存在两个不同的文本文件中，我将在本出版物的第二篇文章中使用它们。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="808b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你打开<strong class="is hj"> readinglist </strong>文本文件，你会看到这样的结构:</p><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/8330f4369686e439a56ae7db89f7be86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7sal7wlgrzTV9bN4CLigg.jpeg"/></div></div></figure><p id="88bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种结构是为了便于阅读而组织的。然而，对于我们的 NLP 项目，原始数据更有用。这就是为什么我创建了两个不同的文件。</p><h1 id="249f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">创建我们的词云</h1><p id="9907" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">为了创建单词云，我使用了库 word cloud 和库 Nltk 和 Gensim(后两个是创建我们的停用词表所必需的)。</p><p id="76e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在自然语言处理(<strong class="is hj"> NLP </strong>)中，我们需要去除句子中只用作连接词的无用单词(如“the”、“is”、“本身”、“my”)。它们被称为停用词。</p><p id="40e3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将从两个不同的库中导入两个不同的停用词表，<strong class="is hj"> Nltk </strong>和<strong class="is hj"> Gensim </strong>。将它们结合起来是改善我们结果的好策略。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="1cd4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们创建 wordcloud 之前，我们需要将<strong class="is hj"> raw_list </strong>转换成一个字符串。此外，将所有文本转换为小写也是一个很好的做法。这样做我们肯定会得到更好的结果。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="b847" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们还必须创建停用词集，用 Gensim 和 nltk 中的列表更新它(在这一步中，我还用我在云中找到的一些脏话进行了更新)。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="07cd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们终于可以创建我们的云了。我们可以用<strong class="is hj"> matplotlib </strong>来可视化。</p><figure class="lr ls lt lu fd ij"><div class="bz dy l di"><div class="lv lw l"/></div></figure><figure class="lr ls lt lu fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/0ee4036257816a40efff00f8cd30902e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sDvy4kRzm02NRSd2Mgf7tA.png"/></div></div></figure><p id="cb08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">瞧啊。我们到了那里，这里是云这个词！这是一个包含从 subreddit Worldnews 中提取的超过 1000 页文本的汇编的图形表示。</p><p id="e084" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有许多不同的方法来定制它。您可以通过阅读库文档来检查它们。</p><div class="kr ks ez fb kt ku"><a href="https://amueller.github.io/word_cloud/" rel="noopener  ugc nofollow" target="_blank"><div class="kv ab dw"><div class="kw ab kx cl cj ky"><h2 class="bd hj fi z dy kz ea eb la ed ef hh bi translated">WordCloud for Python 文档- wordcloud 1.8.1 文档</h2><div class="lb l"><h3 class="bd b fi z dy kz ea eb la ed ef dx translated">在这里你可以找到如何用我的 Python wordcloud 项目创建 wordcloud 的说明。与其他词云相比…</h3></div><div class="lc l"><p class="bd b fp z dy kz ea eb la ed ef dx translated">amueller.github.io</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt io ku"/></div></div></a></div><h1 id="2042" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">最终意见:</h1><p id="a956" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">好了，现在我们用 Reddit 数据完成了练习的第一部分。如果你看一下 cloud 这个词，你会发现一些通常在国际媒体上谈论或写巴西时看到的词。</p><p id="8bf6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作为一个巴西人，看看外国普通人写的关于我的国家的东西是很有趣的。我知道这不一定代表巴西的国际形象。但是这个 90 个单词长的图表综合了超过 1000 页的外国人提到巴西的文字，当然也告诉了 Reddit 公众对这个国家的看法。</p><p id="7477" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你也可以通过阅读我们创建的 reading_list 文本文件来欣赏文章。</p><p id="3618" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下一期出版物中，我们将尝试使用相同的数据集进行情感分析。我希望你喜欢它。</p></div></div>    
</body>
</html>