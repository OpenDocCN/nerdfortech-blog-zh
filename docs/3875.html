<html>
<head>
<title>Batch gradient descent algorithm using Numpy’s einsum</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Numpy 的 einsum 的批量梯度下降算法</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/batch-gradient-descent-algorithm-using-numpy-einsum-f442ef798ee2?source=collection_archive---------23-----------------------#2021-06-27">https://medium.com/nerd-for-tech/batch-gradient-descent-algorithm-using-numpy-einsum-f442ef798ee2?source=collection_archive---------23-----------------------#2021-06-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2debedc2146e6db34fb953f29c274b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PU8_zvYoYmKtrfoEYPnkSg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">免费<a class="ae iu" href="https://pixabay.com/photos/albert-einstein-portrait-1933340/" rel="noopener ugc nofollow" target="_blank">股票图片</a>取自<a class="ae iu" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><h2 id="11a4" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">爱因斯坦求和技术的应用。不，他没有发明它，他用它来表达广义相对论的完整论文。这是格雷戈里奥·利玛窦发明的——柯巴斯托因利玛窦微积分或他们现在称之为“张量分析”而闻名！</h2></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><p id="89e7" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">最近我发现了 numpy 的 einsum，并了解了它在速度和内存效率方面的能力。它在表达矩阵和向量的线性代数运算时也很简洁。</p><p id="0f7c" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">所以我决定用它实现批量梯度下降。在我的代码中，我将加州住房数据作为输入。它总共有 20640 条记录。在我的实现中，如果没有给定批量大小，它被设置为 20640，也就是说，所有的东西都是一次取出的。当批大小(n)给定时，记录被分成 n 批，然后在这些批上实施梯度下降。</p><blockquote class="kv kw kx"><p id="9263" class="ka kb ky kc b kd ke kf kg kh ki kj kk kz kl km kn la ko kp kq lb kr ks kt ku hb bi translated">说够了！给我看看代码！！</p></blockquote><p id="19eb" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">这是我的 colab 笔记本的链接。</p><div class="lc ld ez fb le lf"><a href="https://colab.research.google.com/drive/11Bzqk5zQVa2UYqTvr9mxoxK4RZeexEm2?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hj fi z dy lk ea eb ll ed ef hh bi translated">谷歌联合实验室</h2><div class="lm l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">批次 _ 梯度 _ 下降 _ 数量 _ 总和</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls io lf"/></div></div></a></div><p id="4887" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">下面是使用 numpy 的‘einsum’的批量梯度下降算法的图片。在我的实现中，唯一的限制是数据 X 中的记录总数应该是“batch_size”的倍数，即</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/3a163572db47c4185fe591bde76f4f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*KB3jIbqFBOhH0CpvdRgwDg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据记录计数' m '应能被批处理大小整除-图像归作者所有</figcaption></figure><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/1bea69cddd6566fff37d5decdaf9655f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*Tzq6Ec6KrBVp_LZU8aspcQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 numpy 的 einsum 实现批量梯度下降—图像归作者所有</figcaption></figure><figure class="lu lv lw lx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/1809346a402c6ced66347541bde47fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*irALw2oC1iyp1suq2zbFIQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据标准化-图像归作者所有</figcaption></figure><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/7a5ba677de6172237752a7646363e3c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*flAiVW2X8GHIodJGHkxQlw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">批量为 10 的调用和每次迭代的成本衰减—图片归作者所有</figcaption></figure><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/84eae1df7a2444bad92d22c9fea63820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*IGyMDIH8uJuqNI1tBIg27Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">批量为 1 的调用和每次迭代的成本衰减—图片归作者所有</figcaption></figure><p id="767d" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">现在你可能会问，为什么在实现批量梯度下降时应该选择“np.einsum”而不是正常的 numpy 函数。让我们尝试在不使用 einsum 方法的情况下实现批量梯度下降。</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/67a6bd1ce337dbc9316f9cdb1d6f190d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*9PLm9j6osxxoPAgn_hAMiw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">不使用 einsum 的正常批量梯度下降—图像归作者所有</figcaption></figure><p id="11c0" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">只需看看在不使用 einsum 的情况下实现正常批处理梯度下降时使用的巨大代码量和大量 for 循环。尽管机器学习对新手来说看起来很容易，但执行这段代码所需的时间和内存却一飞冲天。我还忽略了一个事实，即不使用 einsum 的正常实现只处理一维数组特征向量，而不是完整的数据帧。</p><p id="f9c8" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">以下是<strong class="kc hj">使用 einsum </strong>方法所用的时间:</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es md"><img src="../Images/28e135f7feca4761c860efd1f29ee42c.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*hSo-6Pi7NUPnk3GsGcc_jw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用 1000 个时期、批次大小为 80 的 einsum 进行批次梯度下降所用的时间。—图片归作者所有</figcaption></figure><p id="367b" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">这里也是<strong class="kc hj">不使用 einsum </strong>方法时所用的时间:</p><figure class="lu lv lw lx fd ij er es paragraph-image"><div class="er es me"><img src="../Images/b5793d1f4946d475c689cff962af04e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*PvKkUqmFldrWuq0Z6o9udg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">不使用具有 1000 个时期和批次大小为 80 的 einsum 的批次梯度下降所用的时间。—图片归作者所有</figcaption></figure><blockquote class="kv kw kx"><p id="8c89" class="ka kb ky kc b kd ke kf kg kh ki kj kk kz kl km kn la ko kp kq lb kr ks kt ku hb bi translated">在我的机器上，普通实现比 einsum 实现慢 1，460 倍。慢了 146，022%。唷！</p></blockquote><p id="d551" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">我同意没有 einsum 的批量梯度下降实现可以进一步改进。但它仍然很麻烦，容易出错，并且这种编码在神经网络中使用时无法扩展。</p><p id="726f" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">如果这种时间比较不能促使你开始使用 einsum 方法，那么你应该尝试实现任何简单的神经网络，不管有没有 einsum。然后你会开始欣赏它的简单性、速度、记忆效率和表现力。</p><p id="befd" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">请慷慨鼓掌(这根本不需要花费)，并在下面分享你的评论，让我知道你是如何喜欢这篇文章的。</p><p id="e92b" class="pw-post-body-paragraph ka kb hi kc b kd ke kf kg kh ki kj kk jg kl km kn jk ko kp kq jo kr ks kt ku hb bi translated">我是 TCS 的机器学习工程师，我的(数字软件和解决方案)团队正在开发令人惊叹的产品。点击下面的链接，了解更多关于我们产品的信息:</p><div class="lc ld ez fb le lf"><a href="https://www.tcs.com/dss" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab dw"><div class="lh ab li cl cj lj"><h2 class="bd hj fi z dy lk ea eb ll ed ef hh bi translated">数字软件和解决方案:提供高度个性化的体验</h2><div class="mf l"><h3 class="bd b fi z dy lk ea eb ll ed ef dx translated">Digital Software &amp; Solutions 的互联智能解决方案将帮助您转变产品和服务…</h3></div><div class="lm l"><p class="bd b fp z dy lk ea eb ll ed ef dx translated">www.tcs.com</p></div></div><div class="ln l"><div class="mg l lp lq lr ln ls io lf"/></div></div></a></div></div></div>    
</body>
</html>