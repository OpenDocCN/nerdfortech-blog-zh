<html>
<head>
<title>Scraping Data Tables from Natural Stat Trick Using Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用漂亮的汤从自然统计技巧中抓取数据表</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/scraping-data-tables-from-natural-stat-trick-using-beautiful-soup-3251191bc3e1?source=collection_archive---------5-----------------------#2021-03-06">https://medium.com/nerd-for-tech/scraping-data-tables-from-natural-stat-trick-using-beautiful-soup-3251191bc3e1?source=collection_archive---------5-----------------------#2021-03-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e5bec1231a8bd574f9d75f24d8ae792e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PTXg3InjO1FBUpm2"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">信用:<a class="ae iu" href="https://www.gettyimages.com/search/photographer?family=editorial&amp;photographer=Bruce+Bennett" rel="noopener ugc nofollow" target="_blank">布鲁斯·班尼特</a> /职员</figcaption></figure><p id="3a63" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我将演示如何从<a class="ae iu" href="http://naturalstattrick.com" rel="noopener ugc nofollow" target="_blank"> Natural Stat Trick </a>的表格中抓取数据，这是一个获取标准和高级 NHL 统计数据的网站。Natural Stat Trick 是一个著名的、经常被引用的非霍奇金淋巴瘤分析数据源，被作家和粉丝们广泛使用。</p><p id="031b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，使用这个漂亮的汤库，我将按照步骤抓取 html 并将数据转换成熊猫数据帧。然后，我将展示一个方便的 liner，它适用于 Natural Stat Trick 上的表格，也适用于其他网页上的表格，这取决于它们的复杂程度。最后，关于改变 URL 以改变您可以获得的数据的参数的提示。</p><p id="b7eb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里是一个 jupyter 笔记本的<a class="ae iu" href="https://github.com/gschwaeb/scraping_naturalstattrick" rel="noopener ugc nofollow" target="_blank"> github repo </a>和所有下面的代码。</p><h1 id="ad3c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">一步一步的美汤</h1><p id="6919" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">导入以下库</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="badf" class="lf ju hi lb b fi lg lh l li lj">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><p id="e56f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">requests.get()方法将下载一个网页并返回一个响应对象</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="547d" class="lf ju hi lb b fi lg lh l li lj">url = “<a class="ae iu" href="http://www.naturalstattrick.com/playerteams.php?fromseason=20202021&amp;thruseason=20202021&amp;stype=2&amp;sit=5v5&amp;score=all&amp;stdoi=oi&amp;rate=n&amp;team=ALL&amp;pos=S&amp;loc=B&amp;toi=0&amp;gpfilt=none&amp;fd=&amp;td=&amp;tgp=410&amp;lines=single&amp;draftteam=ALL" rel="noopener ugc nofollow" target="_blank">http://www.naturalstattrick.com/playerteams.php?fromseason=20202021&amp;thruseason=20202021&amp;stype=2&amp;sit=5v5&amp;score=all&amp;stdoi=oi&amp;rate=n&amp;team=ALL&amp;pos=S&amp;loc=B&amp;toi=0&amp;gpfilt=none&amp;fd=&amp;td=&amp;tgp=410&amp;lines=single&amp;draftteam=ALL</a>"</span><span id="7eff" class="lf ju hi lb b fi lk lh l li lj">req = requests.get(url)</span></pre><p id="2532" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了确认它没有错误地工作，我们可以运行。状态代码方法。我们正在寻找这个返回 200，这意味着我们都很好。<a class="ae iu" href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes" rel="noopener ugc nofollow" target="_blank"> HTML 代码</a>。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="3006" class="lf ju hi lb b fi lg lh l li lj">req.status_code</span></pre><p id="9055" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们将请求中的 html 文本传递到一个漂亮的 Soup 对象中，这样我们就可以使用漂亮的 Soup 库来解析它。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="ad17" class="lf ju hi lb b fi lg lh l li lj">soup = BeautifulSoup(req.content)</span></pre><p id="14ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用。方法来遍历 html 中的子节点级别。我们将把它传递给一个列表来访问不同的级别。对于此网页，顶层只有一个孩子</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="e69a" class="lf ju hi lb b fi lg lh l li lj">top = list(soup.children)</span></pre><p id="18d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在第二层，有两个子节点:header 和 body。表的内容将位于索引 1 处的正文中。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="d12d" class="lf ju hi lb b fi lg lh l li lj">body = list(top[0].children)[1]</span></pre><p id="202a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用。find_all 方法过滤所有具有指定 html 标签的数据，并将其放入一个列表中。我们希望所有的“th”标签都获得表格标题。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="fb91" class="lf ju hi lb b fi lg lh l li lj">body.find_all(‘th’)</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/9d27b0ce7bbd066964853c38147a5240.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*ythVuyUdH02LnoQ0ShZ2Iw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">body.find_all('th') return 语句</figcaption></figure><p id="2d57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">的。text 方法将提取标记中的文本。我们将把列文本传递到一个列表中，供以后使用。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="469f" class="lf ju hi lb b fi lg lh l li lj">columns = [item.text for item in body.find_all(‘th’)]<br/>columns</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/42bcc11f24060ec92cbf8c9abe39294b.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*oA2njj_8y4zdHKAcpwcchg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">列返回语句</figcaption></figure><p id="456d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们将找到所有包含数据的“td”标签</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="4d56" class="lf ju hi lb b fi lg lh l li lj">body.find_all(‘td’)</span></pre><p id="0f77" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将把数据的文本传递给一个列表</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="c5aa" class="lf ju hi lb b fi lg lh l li lj">data = [e.text for e in body.find_all(‘td’)]</span></pre><p id="5301" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们将遍历数据列表，为表中的每一行数据创建一个列表列表。稍后我们将使用它来创建一个熊猫数据帧。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="7ab7" class="lf ju hi lb b fi lg lh l li lj">start = 0<br/>table= []<br/>#loop through entire data<br/>while start+len(columns) &lt;= len(data):<br/>    player = []<br/>    #use length of columns as iteration stop point to get list of info for 1 player <br/>    for i in range(start,start+len(columns)):<br/>        player.append(data[i])<br/>    #add player row to list<br/>    table.append(player)<br/>    #start at next player<br/>    start += len(columns)</span></pre><p id="0759" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">将列表的列表读给熊猫数据帧</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="6ee3" class="lf ju hi lb b fi lg lh l li lj">df = pd.DataFrame(table, columns = columns, dtype = ‘float’).set_index(‘’)</span></pre><p id="b625" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">瞧啊。我们已经有了一个熊猫数据框架，可以用来做一些分析。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="17ac" class="lf ju hi lb b fi lg lh l li lj">df.head()</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/a782d18ac2faf245f08331283b16c3db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMwIALw2zfwcPAYfbCbruA.png"/></div></div></figure><h1 id="54ae" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">唯一的班轮</h1><p id="1b56" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">如前所述，我们可以在一行简洁的代码中完成所有的抓取、搜索和转换到数据帧的工作！熊猫。read_html 方法将 html 表格读入 DataFrame 对象列表，它建立在 BeautifulSoup4 和 lxml 之上。它还可以将列转换为适当的数据类型。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="c72e" class="lf ju hi lb b fi lg lh l li lj">df2 = pd.read_html(url, header=0, index_col = 0, na_values=[“-”])[0]<br/>df2.head()</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/0c73bf2c4f8501a742515e3e25c7097c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tj6mcgWski730wLyat7Bmg.png"/></div></div></figure><p id="3b59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">容易多了！</p><h1 id="b073" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">关于 URL 参数的注释</h1><p id="e8ee" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">通过改变代码中传递的 URL 中的元素，可以改变表中返回的数据。这允许动态提取不同类型的数据。例如，你可以切换到不同的赛季，日期，看守门员统计，看率而不是计数，过滤不同的比赛情况等…</p><p id="e1a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我从 URL 中提取了所有潜在的参数选项作为它们自己的变量。有关参数选项的完整指南，请查看 Github 笔记本。使用 python 方法。格式，我可以更改 URL 字符串中的参数。与我之前使用的 URL 字符串相比，我将把 stdoi 参数改为‘g ’,以获得守门员的具体统计数据来进行演示</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="869e" class="lf ju hi lb b fi lg lh l li lj">fromseason = 20202021</span><span id="dd8f" class="lf ju hi lb b fi lk lh l li lj">thruseason = 20202021</span><span id="efb3" class="lf ju hi lb b fi lk lh l li lj">stype = 2 </span><span id="c4b8" class="lf ju hi lb b fi lk lh l li lj">sit = ‘5v5’</span><span id="f35c" class="lf ju hi lb b fi lk lh l li lj">score = ‘all’ </span><span id="8a0d" class="lf ju hi lb b fi lk lh l li lj">stdoi = ‘g’ </span><span id="e358" class="lf ju hi lb b fi lk lh l li lj">rate = ‘n’</span><span id="1882" class="lf ju hi lb b fi lk lh l li lj">team = ‘ALL’ </span><span id="ab05" class="lf ju hi lb b fi lk lh l li lj">pos = ‘S’ </span><span id="3fce" class="lf ju hi lb b fi lk lh l li lj">loc = ‘B’ </span><span id="6e1b" class="lf ju hi lb b fi lk lh l li lj">toi = 0 </span><span id="4b62" class="lf ju hi lb b fi lk lh l li lj">gpfilt = ‘none’ </span><span id="ced1" class="lf ju hi lb b fi lk lh l li lj">fd = ‘’ </span><span id="9789" class="lf ju hi lb b fi lk lh l li lj">td = ‘’ </span><span id="456c" class="lf ju hi lb b fi lk lh l li lj">lines = ‘single’ </span><span id="8c09" class="lf ju hi lb b fi lk lh l li lj">draftteam = ‘ALL’ </span><span id="2999" class="lf ju hi lb b fi lk lh l li lj">url = ‘<a class="ae iu" href="http://www.naturalstattrick.com/playerteams.php?fromseason={}&amp;thruseason={}&amp;stype={}&amp;sit={}&amp;score={}&amp;stdoi={}&amp;rate={}&amp;team={}&amp;pos={}&amp;loc={}&amp;toi={}&amp;gpfilt={}&amp;fd={}&amp;td={}td&amp;tgp={}&amp;lines={}&amp;draftteam={}'.format(" rel="noopener ugc nofollow" target="_blank">http://www.naturalstattrick.com/playerteams.php?fromseason={}&amp;thruseason={}&amp;stype={}&amp;sit={}&amp;score={}&amp;stdoi={}&amp;rate={}&amp;team={}&amp;pos={}&amp;loc={}&amp;toi={}&amp;gpfilt={}&amp;fd={}&amp;td={}td&amp;tgp={}&amp;lines={}&amp;draftteam={}'.format(</a><br/> fromseason,<br/> thruseason,<br/> stype, <br/> sit,<br/> score, <br/> stdoi, <br/> rate, <br/> team, <br/> pos, <br/> loc, <br/> toi, <br/> gpfilt, <br/> fd, <br/> td, <br/> tgp, <br/> lines, <br/> draftteam)</span><span id="8160" class="lf ju hi lb b fi lk lh l li lj">print(url)</span><span id="2d46" class="lf ju hi lb b fi lk lh l li lj">df3 = pd.read_html(url, header=0, index_col = 0, na_values=["-"])[0]<br/>df3.head()</span></pre><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/7a6a6b1f49cef12b0a3662624c3ced83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQQyl_HQehoo-p3KssTFTA.png"/></div></div></figure><h1 id="91ca" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="8df4" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">你现在有了从 Natural Stat Trick 和其他类似网站的表格中获取数据的工具。首先尝试一下 pd.read_html，如果这不起作用，您可以一步一步地使用漂亮的汤库。您还可以动态更新 URL 参数来获取不同类型的数据。</p><p id="1957" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管 Natural Stat Trick 的提供商允许公众免费访问这些数据，但如果你发现自己经常使用这些数据，可以考虑订阅<a class="ae iu" href="https://www.patreon.com/naturalstattrick" rel="noopener ugc nofollow" target="_blank"> Patreon </a>来支持网站的持续运营。</p><h1 id="9fe5" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">来源</h1><p id="b0ca" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">-【http://www.naturalstattrick.com/-<br/>-<a class="ae iu" href="https://requests.readthedocs.io/en/master/user/quickstart/" rel="noopener ugc nofollow" target="_blank">-【https://requests.readthedocs.io/en/master/user/quickstart/</a><br/>-<a class="ae iu" href="https://theathletic.com/415611/2018/07/05/an-advanced-stats-primer-with-naturalstattricks-brad-timmins/" rel="noopener ugc nofollow" target="_blank">https://theathletic . com/415611/2018/07/05/an-advanced-stats-primer-with-natural stattricks-Brad-Tim mins/</a><br/>-<a class="ae iu" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a><br/>-<a class="ae iu" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#reading-html-content" rel="noopener ugc nofollow" target="_blank">https://pandas . pydata . org/pandas-docs/stable/user _ guide/io . html #阅读</a></p></div></div>    
</body>
</html>