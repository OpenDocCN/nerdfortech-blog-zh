<html>
<head>
<title>Face-Mask detection with Nvidia Jetson Nano (Yolov5)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Nvidia Jetson Nano (Yolov5)进行面罩检测</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/face-mask-detection-with-nvidia-jetson-nano-yolov5-b66f286f16d4?source=collection_archive---------0-----------------------#2021-06-11">https://medium.com/nerd-for-tech/face-mask-detection-with-nvidia-jetson-nano-yolov5-b66f286f16d4?source=collection_archive---------0-----------------------#2021-06-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><p id="ec47" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">本教程展示了如何实现一个系统，通过该系统可以区分戴面具的人<strong class="in hj">、<strong class="in hj">没戴面具、</strong>和戴错了<strong class="in hj">面具的人</strong>。</strong></p><p id="7486" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">这是一个经典的分类问题，对此我们不需要重新发明轮子。我们将使用<strong class="in hj"> Yolov5 </strong>一个基于<strong class="in hj"> PyTorch </strong>构建的神经网络分类框架，PyTorch 是一个用C++编写的机器学习框架，可以作为一个库在<strong class="in hj"> Python </strong>中访问。</p><p id="99cd" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">作为硬件，我们将使用Nvidia的<strong class="in hj"> Jetson Nano </strong>，通过其<strong class="in hj">128</strong>T16】CUDA核心加速底层线性代数运算。此外，将使用一个<strong class="in hj"> ESP32摄像头</strong>，通过<strong class="in hj"> WIFI (HTTP) </strong>提供其摄像头流。</p><p id="cf41" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated"><em class="jj">ESP32 CAM没有USB连接器，因此我们还需要一个FTDI编程器，该编程器通过跳线直接连接到ESP32 CAM的GPIO引脚，并可通过迷你USB转USB电缆连接到PC。</em></p><div class="jk jl jm jn fd ab cb"><figure class="jo ii jp jq jr js jt paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><img src="../Images/8179acec91fa0233d502bdf1acfad339.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/0*FH_jLN2m1l9946GE.jpg"/></div></figure><figure class="jo ii ka jq jr js jt paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><img src="../Images/222b8d1630f8bd6c8da284a2aa491f80.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/0*XYKCZQE_eg_yKrsy"/></div></figure><figure class="jo ii jp jq jr js jt paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><img src="../Images/3007c258b4a28f342683bee0de2301a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/0*_jdbdWmcqnS3cfAM.jpg"/></div><figcaption class="kb kc et er es kd ke bd b be z dx kf di kg kh translated">从左至右:Nvidia Jetson NanoESP32凸轮；FTDI程序员</figcaption></figure></div><h1 id="c63d" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">1.初始化杰特森纳米</h1><p id="1547" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">在我们可以使用我们的Jetson Nano之前，我们必须在micro SD卡上刻录官方JetPack SDK。Jetpack的图片可以在Nvidia的官方网站上找到并下载。遵循<a class="ae ll" href="https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write" rel="noopener ugc nofollow" target="_blank">入门</a>教程，该教程描述了如何在SD卡上蚀刻图像以及如何访问您的Jetson Nano。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/b63af2a2713080fbc59a69441a743cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*ZVklKJhcVeDY6Q3erSwNcQ.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">闪烁的Nvidia的JetPack图像</figcaption></figure><p id="3c79" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">完成教程后，我们开始更新Nano上的包。<em class="jj">(整个项目需要互联网连接)</em>:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="76b8" class="ls kj hi lo b fi lt lu l lv lw">sudo apt update &amp;&amp; sudo apt upgrade</span></pre><h1 id="84c3" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">2.在Nvidia Jetson Nano上安装支持GPU (Cuda)的PyTorch</h1><p id="e8a6" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">我们从安装PIP(python包管理器)开始:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="4182" class="ls kj hi lo b fi lt lu l lv lw">sudo apt install curl<br/>curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py<br/>sudo python3 get-pip.py</span></pre><p id="fc24" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">通常会出现一个错误，说明<em class="jj">“pip的依赖解析器当前没有考虑所有已安装的包”。</em>可以忽略。</p><p id="32c3" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">现在我们需要为PyTorch下载轮子。这是Nvidia工程师预先构建的库:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="a1ea" class="ls kj hi lo b fi lt lu l lv lw">sudo apt-<strong class="lo hj">get</strong> install libopenblas-<strong class="lo hj">base</strong> libopenmpi-dev</span><span id="686a" class="ls kj hi lo b fi lx lu l lv lw">curl -LO <a class="ae ll" href="https://nvidia.box.com/shared/static/p57jwntv436lfrd78inwl7iml6p13fzh.whl" rel="noopener ugc nofollow" target="_blank">https://nvidia.box.com/shared/static/p57jwntv436lfrd78inwl7iml6p13fzh.whl</a></span><span id="8708" class="ls kj hi lo b fi lx lu l lv lw">mv <a class="ae ll" href="https://nvidia.box.com/shared/static/p57jwntv436lfrd78inwl7iml6p13fzh.whl" rel="noopener ugc nofollow" target="_blank">p57jwntv436lfrd78inwl7iml6p13fzh.whl</a> torch-1.8.0-cp36-cp36m-linux_aarch64.whl</span><span id="3570" class="ls kj hi lo b fi lx lu l lv lw">sudo pip3 install torch-1.8.0-cp36-cp36m-linux_aarch64.whl</span></pre><p id="9718" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">安装PyTorch之后。可以通过运行以下命令来确认这一点:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="5029" class="ls kj hi lo b fi lt lu l lv lw">sudo python3 -c "import torch; print(torch.cuda.is_available())"</span></pre><p id="a533" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果返回<strong class="in hj"> true </strong> PyTorch已经成功安装，CUDA库已经找到。</p><p id="08b7" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">PyTorch也需要火炬视觉。以下代码用于构建火炬视觉。这可能需要一段时间:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="1884" class="ls kj hi lo b fi lt lu l lv lw">sudo apt install libjpeg-dev zlib1g-dev<br/>git clone --branch v0.9.1 <a class="ae ll" href="https://github.com/pytorch/vision" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/vision</a> torchvision<br/>cd torchvision/<br/>sudo python3 setup.py install<br/>cd ..</span></pre><h1 id="4738" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">3.下载YOLOv5脚本</h1><p id="ccc8" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">我们将继续下载YOLOv5并安装它的需求。</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="d390" class="ls kj hi lo b fi lt lu l lv lw">git clone <a class="ae ll" href="https://github.com/ultralytics/yolov5.git" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5.git</a><br/>cd yolov5<br/>export OPENBLAS_CORETYPE=ARMV8<br/>sudo apt install libfreetype6-dev python3-dev<br/>sudo pip3 install numpy==1.19.4<br/>sudo pip3 install --ignore-installed PyYAML&gt;=5.3.1<br/>sudo pip3 install -r requirements.txt</span></pre><p id="c500" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">现在，我们可以通过在命令提示符下键入以下命令来测试YOLOv5:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="f32e" class="ls kj hi lo b fi lt lu l lv lw">sudo python3 detect.py</span></pre><p id="6534" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果一切正常，输出应该如下所示:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="e679" class="ls kj hi lo b fi lt lu l lv lw">Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device=’’, exist_ok=False, half=False, hide_conf=False, hide_labels=False, imgsz=640, iou_thres=0.45, line_thickness=3, max_det=1000, name=’exp’, nosave=False, project=’runs/detect’, save_conf=False, save_crop=False, save_txt=False, source=’data/images’, update=False, view_img=False, weights=’yolov5s.pt’)<br/>YOLOv5 🚀 v5.0–177-g5c32bd3 torch 1.8.0 CUDA:0 (NVIDIA Tegra X1, 3956.1328125MB)</span><span id="05ff" class="ls kj hi lo b fi lx lu l lv lw">Fusing layers… <br/>Model Summary: 224 layers, 7266973 parameters, 0 gradients<br/>image 1/2 /home/xlagor/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 1 fire hydrant, Done. (0.809s)<br/>image 2/2 /home/xlagor/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, Done. (0.226s)<br/>Results saved to runs/detect/exp2<br/>Done. (3.082s)</span></pre><h1 id="f3b3" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak"> 4。相机软件和IDE配置</strong></h1><p id="5c0b" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">现在我们需要一个摄像机流来输入YOLOv5。从技术上讲，人们可以使用任何<strong class="in hj"> HTTP MJPEG流</strong>，但我们将使用ESP32 CAM模块。它有一个内置的WIFI模块，非常适合许多使用案例，因为它更灵活。</p><p id="863f" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">首先在你的台式电脑上下载并安装<a class="ae ll" href="https://code.visualstudio.com/download" rel="noopener ugc nofollow" target="_blank"> Visual Studio代码</a>。一旦进入VSCode，我们就可以安装名为<strong class="in hj"> PlatformIO IDE </strong>的扩展。这是一个IDE，改进了处理嵌入式设备时的工作流程。</p><p id="746e" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">现在是下载代码的时候了，该代码将被刷新到ESP32 CAM模块上。将其克隆到您选择的目录中:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="6341" class="ls kj hi lo b fi lt lu l lv lw">git clone <a class="ae ll" href="https://github.com/FrederikRogalski/esp32-cam-mjpeg" rel="noopener ugc nofollow" target="_blank">https://github.com/FrederikRogalski/esp32-cam-mjpeg</a></span></pre><p id="42d8" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">在Visual Studio代码中打开目录。PlatformIO识别platformio.ini文件并激活自身。这可以通过观察IDE底部的工具栏来验证。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es ly"><img src="../Images/a0413ba5c83fbddd5333da0793285069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6zEMTh96GZxWwQstUYaQiA.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">平台视频图标</figcaption></figure><p id="9b34" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">该代码还需要wifi凭据。将它们放在目录<em class="jj"> src </em>中名为<em class="jj"> home_wifi_multi.h </em>的文件中。这可以通过下面的命令来实现。确保您位于git存储库的底部:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="aa20" class="ls kj hi lo b fi lt lu l lv lw">echo '#define SSID1 "&lt;Your WIFI Name&gt;"\n#define PWD1 "&lt;Your WIFI Password&gt;"' &gt; ./src/home_wifi_multi.h</span></pre><p id="3e49" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">之后，软件就可以上传了。</p><h1 id="ec9e" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated"><strong class="ak"> 5。闪烁ESP32凸轮模块</strong></h1><p id="6167" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">在刷新之前，模块必须连接到台式PC。这是通过利用FTDI编程器、一些跳线和迷你USB到USB电缆来实现的。</p><div class="jk jl jm jn fd ab cb"><figure class="jo ii lz jq jr js jt paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><img src="../Images/4be7eee380555d0c8c422ec7578b8453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*isJQT0qrPKuLnnHVdBi82g.png"/></div></figure><figure class="jo ii ma jq jr js jt paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><img src="../Images/a11864470508ec1d0844dee1c074c783.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/0*zi_Cdg55DdMPMqZP"/></div><figcaption class="kb kc et er es kd ke bd b be z dx mb di mc kh translated">从<a class="ae ll" href="https://randomnerdtutorials.com/program-upload-code-esp32-cam/" rel="noopener ugc nofollow" target="_blank">如何编程/上传代码到ESP32-CAM AI-Thinker(Arduino IDE)</a>连接ESP32 CAM到FTDI适配器原理图</figcaption></figure></div><p id="e3af" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">按照示意图所示连接跳线。在将台式PC连接到适配器之前，确保编程器的跳线正在连接5V配置引脚。</p><p id="4467" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">将USB电缆连接到台式PC后，可以编译和上传代码。这是通过按IDE中的箭头按钮(➔)来实现的。一旦出现以下内容，点击ESP32 cam模块上的复位按钮(标记为<em class="jj"> rst </em>):</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="80b2" class="ls kj hi lo b fi lt lu l lv lw">Connecting........___</span></pre><p id="ebd3" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果一切正常，终端应该显示如下内容:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="f724" class="ls kj hi lo b fi lt lu l lv lw">Writing at 0x########...</span></pre><p id="bdbf" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果不成功，再试一次。有时需要几次。</p><p id="6e4d" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">上传完成后，点击电气插头图标(🔌)并拆除连接IO0和地线的电线。这将禁止引导，按下复位按钮，程序开始运行。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es md"><img src="../Images/e0ddc71077b2140c47ba080616487572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzxFIDzP72BXfesfBwiy4A.png"/></div></div></figure><p id="21cb" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果成功连接到wifi，该程序将自动输出其IP地址。该链接可以在您选择的浏览器中打开，以访问摄像机流。请注意，一次只能有一个连接，因此在继续之前，请确保通过关闭选项卡来关闭连接。</p><h1 id="38b4" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">6.从YOLOv5访问流</h1><p id="ddd7" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">现在，我们可以通过在Jetson Nano上运行以下代码来连接这两个组件(确保更改IP地址):</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="1e5c" class="ls kj hi lo b fi lt lu l lv lw">sudo python3 detect.py --source <a class="ae ll" href="http://192.168.2.166/mjpeg/1" rel="noopener ugc nofollow" target="_blank">http://&lt;ip-of-esp32-cam&gt;/mjpeg/1</a> --view-img</span></pre><p id="c0a7" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">默认情况下，YOLOv5将运行一个模型，在COCO数据集上进行预训练。但是如果我们想训练自己的模型呢？</p><h1 id="9810" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">7 .<strong class="ak">。获取数据</strong></h1><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es me"><img src="../Images/c1e9400031dbd139d9fb3d6ba8733900.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iKSfYMWk7xCkxQGX-tEu0Q.png"/></div></div></figure><p id="4faf" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">如果我们想要训练我们自己的模型来分类人们戴口罩是正确的，不正确的，或者甚至不戴口罩，我们需要这三类的数据。幸运的是，已经有数据集抑制这些类。一个例子是来自Kaggle的<a class="ae ll" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank">人脸面具检测数据集</a>。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es mf"><img src="../Images/ad40751d81d3b4a920ec3ee69e504367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b_fSq6Ady6Gps7ktS7BzuQ.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated">给图片贴标签</figcaption></figure><p id="6785" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">但是找到数据只是成功的一半。将它转换成正确的格式，并通过组合多个数据集甚至自己标记它们来平衡它，这是另一半。让这一步变得更容易的最简单的方法是使用像<a class="ae ll" href="https://roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>这样的端到端平台。上传所有数据，标记未标记的图像，并扩充数据集。对于导出，选择YOLOv5格式。</p><figure class="jk jl jm jn fd ii er es paragraph-image"><div role="button" tabindex="0" class="ju jv di jw bf jx"><div class="er es mg"><img src="../Images/7358db08934e6fbadd655ad20ea15e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrA4vTnRya3TOdfeqlagZA.png"/></div></div></figure><h1 id="184c" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">8.训练模型</h1><p id="847d" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">训练肯定不会在Jetson Nano上进行，而是在一台更强大的计算机上进行。配置这样的训练机器超出了本教程的范围，但是可以在网上找到很多安装CUDA的教程。</p><p id="79e7" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">在培训计算机上克隆YOLOv5存储库。</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="a60e" class="ls kj hi lo b fi lt lu l lv lw">git clone <a class="ae ll" href="https://github.com/ultralytics/yolov5.git" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5.git</a><br/>cd yolov5</span></pre><p id="7e1d" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">此外，将数据集复制到训练计算机上YOLOv5存储库的根文件夹中。使用Roboflow时，只需在导出选项卡中选择<strong class="in hj"> <em class="jj">终端</em> </strong>并执行训练机上显示的命令。它看起来有点像这样:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="d12e" class="ls kj hi lo b fi lt lu l lv lw">curl -L "https://app.roboflow.com/ds/#######?key=#######" &gt; roboflow.zip; unzip roboflow.zip; rm roboflow.zip</span></pre><p id="755f" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">之后，可以通过调用以下命令开始训练:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="1131" class="ls kj hi lo b fi lt lu l lv lw">python3 train.py --img 640 --batch 16 --epochs 5 --data &lt;your-dataset-definition&gt;.yaml --weights yolov5s.pt</span></pre><p id="ed5a" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">该命令以16个为一批，大小为640x640，训练5个历元。这些参数可以根据您的需要进行配置。我发现训练大多在100个纪元后收敛。</p><h1 id="cab1" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">9.运行自定义模型</h1><p id="1d6f" class="pw-post-body-paragraph il im hi in b io lg iq ir is lh iu iv iw li iy iz ja lj jc jd je lk jg jh ji hb bi translated">训练后可以在<strong class="in hj"><em class="jj">【权重】</em> </strong>文件夹中找到训练好的模型。最后训练的权重将被称为<strong class="in hj"> <em class="jj"> last.pt </em> </strong>，最好的将被称为<strong class="in hj"> <em class="jj"> best.pt </em> </strong>。只需将它复制到您的Jetson Nano上，并使用以下命令指定它:</p><pre class="jk jl jm jn fd ln lo lp lq aw lr bi"><span id="75a4" class="ls kj hi lo b fi lt lu l lv lw">sudo python3 detect.py --source <a class="ae ll" href="http://192.168.2.166/mjpeg/1" rel="noopener ugc nofollow" target="_blank">http://&lt;ip-of-esp32-cam&gt;/mjpeg/1</a> --view-img --weights &lt;path/to/custom/weights.pt&gt;</span></pre></div></div>    
</body>
</html>