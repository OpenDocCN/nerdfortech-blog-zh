<html>
<head>
<title>Basic intuition of LDA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LDA的基本直觉</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/basic-intuition-of-lda-33f34f6ad603?source=collection_archive---------14-----------------------#2021-08-01">https://medium.com/nerd-for-tech/basic-intuition-of-lda-33f34f6ad603?source=collection_archive---------14-----------------------#2021-08-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="2ae7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每当我们遇到涉及图像数据分类的机器学习模型或必须处理复杂维度的向量时，计算就会成为及时获得结果的障碍。因此，使用减少涉及向量的计算复杂性并帮助获得及时和更好的结果的算法是直观的。我们将讨论一种使用降维的分类技术——线性鉴别分析或LDA。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/627d6153a11be7325ca378bda1233cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOoUO-dJ6QJpAcKOuzLHmQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片由Edureka提供</figcaption></figure><h1 id="dd1e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">降维与线性判别分析</h1><p id="fe4b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">假设我们正在处理一个包含图像的数据集。我们的目标是训练一个模型，将图像分为两个或更多类别。那么数据集中的这些图像本质上是什么呢？它们是需要处理的更高维的向量，导致大量的计算工作和延迟。一个很好的例子是研究人类基因的模型，它通常包括大量的多维数据。减少维度不仅可以节省时间和资源，还可以帮助消除不必要的复杂性。<br/>线性判别分析(LDA)是一种在统计学、模式识别和机器学习中使用的方法，用于寻找表征或分离两类或更多类对象或事件的特征的线性组合。所得到的组合可以用作线性分类器，或者更常见的是，在稍后的分类之前用于维度减少。目标是找到一个或多个轴，以便在投影数据时，确保类之间的最大距离，并且每个类中的数据分散或变化最小，这是良好分类模型的直观要求。<br/>LDA的工作与PCA的工作几乎相同，除了一些小的不同-</p><ol class=""><li id="1774" class="kw kx hi ih b ii ij im in iq ky iu kz iy la jc lb lc ld le bi translated">PCA是一种无监督的技术，而LDA是有监督的，即它使用标签进行训练。</li><li id="25dd" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated">PCA找到最大化数据方差的轴，而LDA找到最大化聚类之间的距离同时最小化每个类中的方差的轴。</li></ol><p id="2c15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，我们的目标是找到这样的轴，帮助我们降低复杂数据集的维度，同时帮助我们以有效的方式将给定数据分类到所需的聚类中。值得注意的是，对于k类分类问题，我们只能找到前k-1个这样的轴-对于三类数据集，我们只能找到前两个轴，其细节将在后面讨论。</p><h1 id="b2d8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">理论与方法</h1><p id="427c" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">让我们取一个二元分类数据集，它有一个多达n个点的矩阵X = [x₁ x₂ x₃ x₄ … ]，其中x中的每个点都是一个维数为d的向量，从而使x成为一个d⨉n矩阵。我们还有一个1⨉n矩阵Y= [y₁ y₂ y₃ y₄ … ]，它包含类编码，即y ∈{0，1}，其中0和1表示两个类的编码。我们的目标是将点投影到一个轴上，使得类间距离最大，类内方差最小。让我们假设w₁是一个d⨉1维度的向量，它应该是我们的轴之一。因此，x₁沿w₁的投影值将是w₁ᵀx₁，其中w₁ᵀ是w₁的转置，维度为1⨉d，从而使乘积成为标量。因此，我们试图把x的所有值都投影到w₁.上</p><p id="cee8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据定义，类0的平均值表示为μ₀是⅟ₙ∑xᵢ，因此yᵢ是0。类似地，μ₁ = ⅟ₙ∑xᵢ，这样yᵢ就是1。如果我们将每一项乘以w₁ᵀ，新的平均值也会乘以相同的因子，即w₁ᵀ.<br/>所以，现在我们有了两个集群的方法，我们的目标是最大化它们之间的距离。为了适应负面结果的前景，我们试图最大化(w₁ᵀμ₀-w₁ᵀμ₁)的价值。根据定义，</p><p id="c4cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(w₁ᵀμ₀-w₁ᵀμ₁)=(w₁ᵀμ₀-w₁ᵀμ₁)ᵀ(w₁ᵀμ₀-w₁ᵀμ₁)<br/>=(μ₀-μ₁)ᵀ(w₁)(w₁ᵀ)(μ₀-μ₁)<br/>=w₁ᵀ(μ₀-μ₁)ᵀ(μ₀-μ₁)w₁<br/>=w₁ᵀSₑw₁，其中sₑ是(μ₀-μ₁)ᵀ(μ₀-μ₁)或类间方差</p><p id="884d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong> <em class="lk">上述转换是可能的，因为乘法的结果是scaler，给出了scaler trace，scaler trace暗示矩阵的元素可以旋转。</em></p><p id="e1a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还知道，求矩阵x的协方差的形式是通过求XXᵀ.所以，<br/>variance(w₁ᵀx)=(w₁ᵀx)(w₁ᵀx)ᵀ<br/>u₁ᵀ(wwᵀ)u₁<br/>w₁ᵀ∑w₁，其中∑为x的协方差矩阵，维数为d⨉d <br/>所以，类0和1的类方差分别为w₁ᵀ ∑₀ w₁和w₁ᵀ ∑₁ w₁。为了最小化它们，我们可以认为它们的和是最小的。所以，<br/> w₁ᵀ(∑₀+∑₁)w₁或w₁ᵀ(Sᵢ)w₁被认为是最小的，<br/>这里Sᵢ = ∑₀+∑₁</p><p id="65b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们有类间方差w₁ᵀ Sₑ w₁和类内方差w₁ᵀ Sᵢ w₁，其中类间方差被最大化，类内方差被最小化，因此，总的来说，它们的比率可以最大化。这可以通过固定w₁ᵀ Sᵢ w₁ = 1和最大化w₁ᵀ Sₑ w₁.来实现</p><p id="dc7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将使用拉格朗日形式来求解方程- <br/> L(w₁，λ₁)=(w₁ᵀsₑw₁)-λ₁(w₁ᵀsᵢw₁-1)<br/>以获得最大值/鞍点，我们对这个w.r.t. w₁进行部分微分并使其等于0，并且，撇开复杂的计算，得到下面的方程-<br/>2sₑw₁-2λ₁sᵢw₁= 0<br/>sₑw₁=λ₁sᵢw₁<br/>(sᵢsₑ)w‖=λw‖，其中s是s的逆</p><p id="ca94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它是特征值和特征向量对的表示。这里的问题是，Sₑ是两个一维向量的乘积，因此秩为1，因此乘积的总秩为1。因此，只有一对特征向量和特征值存在。</p><h1 id="7554" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">扩展到k类</h1><p id="7640" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">现在我们将其扩展到k类数据集。我们会用W = [w₁ w₂ w₃ … wₖ-₁]替换w₁，这是意料之中的(对于k个职业，k-1个轴是可用的)。所以，w的维数是d⨉(k-1).</p><p id="c73e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要找出一种方法来使用这个矩阵w来使比率最大化，所以一种方法是可能使用(w₁ᵀ Sₑ w₁)和(w₁ᵀ Sᵢ w₁)的迹，这相当于对个体方差求和。<br/>所以Trace(w₁ᵀ Sₑ w₁)/trace(w₁ᵀ Sᵢ w₁)是要最大化的。<br/>使用类似的拉格朗日概念，我们得到一个方程-<br/>trace(w₁ᵀsₑw₁)-λ₁(trace(w₁ᵀsᵢw₁)-1，这将最终给我们k-1个特征向量，因为(Sᵢ Sₑ)具有k-1个秩。</p><p id="1e6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，很容易计算Sᵢ，因为它只是单个类内方差的总和。但是发现新Sₑ有两个以上的类会带来一个问题，但是我们有一个解决方案！我们知道总方差Sₜ是类内方差和类间方差之和，计算Sₜ.很容易所以通过逆向计算，我们得到Sₑ.</p><p id="c5be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Sₜ = ⅟ₙ∑(xᵢ-μ)(xᵢ-μ)ᵀ，其中μ是整个xᵢ.的平均值</p><p id="4e86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们有了所有需要的值，我们可以很容易地找出前k-1个轴！</p></div></div>    
</body>
</html>