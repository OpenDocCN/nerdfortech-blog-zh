<html>
<head>
<title>Loss functions in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的损失函数</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/what-loss-function-to-use-for-machine-learning-project-b5c5bd4a151e?source=collection_archive---------0-----------------------#2022-02-24">https://medium.com/nerd-for-tech/what-loss-function-to-use-for-machine-learning-project-b5c5bd4a151e?source=collection_archive---------0-----------------------#2022-02-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e7fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我将解释在机器学习中在哪里以及为什么使用特定的损失函数。看完这篇博客，你会知道每个功能的优缺点，以及选择哪一个来解决你的问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/75345660ca1c21266157906ba76d298f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UQ3IpUZ3zl9wn02L"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">艾萨克·史密斯在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="3020" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="3f0e" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在机器学习中，损失函数定义了模型的预测距离目标值有多远。必须正确选择它，因为所有参数都是根据它的值更新的。损失函数的选择由模型的目的决定。</p><p id="5253" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将讨论两类问题，<strong class="ih hj">回归</strong>和<strong class="ih hj">分类</strong>。</p><h1 id="5853" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">回归</h1><p id="b7b1" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我从一个简单的解释和所有这些函数背后的数学开始。最后我会用观想呈现一些例子，应该会让理论更清晰，让你有更深的理解。</p><h2 id="d9b5" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">1.均方误差</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/1b886a46ce1b477b854a71fb4fda5150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2OjfrvPHuOzbJ6LSyJJXoQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，m-示例</figcaption></figure><p id="a724" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="a2e1" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">易导数</li><li id="bc0b" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">存在解析解</li><li id="88dd" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">小错误的小更新</li></ul><p id="e464" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点:</strong></p><ul class=""><li id="fa8a" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">对异常值不稳健</li></ul><p id="9999" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，<strong class="ih hj"> MSE </strong>总体上严重地惩罚了错误，但这是一把双刃剑。想象一下远处的异常值和平方误差。我们有一个巨大的体重更新，可能会使模型失去平衡。</p><p id="f221" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了澄清，当损失的斜率(梯度)等于 0 时，存在<strong class="ih hj">解析解</strong>。在这种情况下，是有可能的。这是一个重要的属性，因为令人惊讶的是，并不是所有的函数都有这个属性。</p><blockquote class="ma mb mc"><p id="fa9c" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">简单的导数使得<strong class="ih hj"> MSE </strong>成为一个非常流行的算法，你可以在一些<strong class="ih hj">分类</strong>问题中找到它。</p></blockquote><h2 id="f60a" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">2.绝对平均误差</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/0c4e8e5c119809e5261b85dfabecbf7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQ5eqMlht56o4SfgYALR4g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，m-示例</figcaption></figure><p id="9274" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="bf5a" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">对异常值稳健</li></ul><p id="676c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点:</strong></p><ul class=""><li id="5141" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">没有解析解</li><li id="c044" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><strong class="ih hj">梯度幅度</strong>对于所有误差都是相同的</li></ul><p id="00a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> MAE </strong>是目标和预测之差的绝对值。这个函数的主要问题是它实际上没有一个<strong class="ih hj">解</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mi"><img src="../Images/81414835ad4a08c6c64d17470cc50979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YQd860cogOGzaSWxTe6AzQ.png"/></div></div></figure><p id="acce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如你所知，<strong class="ih hj">解</strong>应该是导数等于 0 的时候，这种情况下是不可能的。</p><p id="1e22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，您可以看到，对于每个误差，<strong class="ih hj">梯度</strong>要么是 1，要么是-1。这意味着我们通过<strong class="ih hj">相同的值</strong>来更新权重，不管误差有多大。</p><blockquote class="ma mb mc"><p id="a024" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">这个函数的明显用途是回归问题，但它也用于其他领域，例如<strong class="ih hj"> CycleGAN </strong>论文。它充当<strong class="ih hj">一致性损失</strong>，并计算原始图像和重新生成的图像之间的差异。[1]</p></blockquote><h2 id="1402" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">3.伪 Huber 损失</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mj"><img src="../Images/3c899d4fba22ca9221f1b0987a53486b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlZqrPNU6m5yJPbZt59YRA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，m-示例</figcaption></figure><p id="859b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="f8cd" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">对异常值稳健</li><li id="dd0d" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">存在解析解</li></ul><p id="15ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点:</strong></p><ul class=""><li id="a670" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">需要对 delta 参数[2]进行统计微调</li></ul><p id="5647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">伪 Huber </strong>函数结合了<strong class="ih hj"> MAE </strong>函数的健壮性和<strong class="ih hj"> MSE </strong>的实际存在的解决方案。</p><p id="ae63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有一个额外的参数<strong class="ih hj"> delta </strong>，它控制函数从二次到线性的切换。它还剪切梯度，限制了<strong class="ih hj">异常值</strong>的影响。</p><p id="1549" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果数据来自高斯分布，则<strong class="ih hj">增量</strong>的良好起始值为 1.35。[2]</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mk"><img src="../Images/3124e4979cc9d394da47e0c3868cc5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6_RcXxIV0-Q5p258DopyQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">δ= 5 时的 Huber 损失</figcaption></figure><blockquote class="ma mb mc"><p id="226a" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">由于剪切梯度的能力，在快速 R-CNN 模型中使用了<strong class="ih hj">伪胡伯</strong>来防止<strong class="ih hj">爆炸梯度</strong>。</p></blockquote><h2 id="99e1" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">比较</h2><p id="e227" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">经过一点理论，这是一个好主意，看看每个函数的结果。</p><div class="je jf jg jh fd ab cb"><figure class="ml ji mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/98e2f1076caef6a6c30140c4850acd8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*sPSE5oj_MyCEjadArAmxYw.png"/></div></figure><figure class="ml ji mr mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><img src="../Images/379331201feeee25a5535e964ccb0ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*NTeD0d2m9_V6yyCQ3A8LEg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx ms di mt mu translated">红点是预测值。</figcaption></figure></div><p id="a435" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，<strong class="ih hj">伪 Huber </strong>显示了<strong class="ih hj">对来自 MAE 损失的异常值的鲁棒性</strong>以及来自 MSE 的接近预测的较小值<strong class="ih hj">更新</strong>。</p><p id="f740" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果想看图和损失函数的 Python 代码，可以看看我的<a class="ae jt" href="https://github.com/maciejbalawejder/MLalgorithms-collection/blob/main/Loss%20functions/loss_functions.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github </strong> </a>。</p><h1 id="2c66" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">分类</h1><h2 id="b553" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">1.范畴交叉熵</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/4f8dddde743c1e3aa4123d59ff1e08f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dWBN35WKQ-qkO4rtKgfnvw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，c-类</figcaption></figure><p id="75a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="8f20" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">严厉惩罚错误的预测</li><li id="860b" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">为多类问题做最好的工作</li></ul><p id="aa38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">灵感来自于<strong class="ih hj">信息论</strong>，一种给定随机变量的两种概率分布之间的度量。如果想了解更多，可以看看这个<a class="ae jt" href="https://www.youtube.com/watch?v=ErfnhcEV1O8" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">视频</strong> </a>。</p><p id="1214" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在机器学习中，一个分布是模型的<strong class="ih hj">输出</strong>(在 Softmax 函数之后)，第二个是<strong class="ih hj">目标向量</strong>。让我们创建一个简单的<strong class="ih hj">多类</strong>预测模型来对猫、汽车和犀牛进行分类，并看看它在实践中是如何工作的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mv"><img src="../Images/05f47ee3c228c742657bf007f3641cf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9PKzy8DjqjIQWjptImHhw.png"/></div></div></figure><p id="7400" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如你所见，交叉熵关注于<strong class="ih hj">期望的</strong>输出，并严重惩罚错误的预测。看函数图就变得很直观了。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mk"><img src="../Images/184c2cdd5afc2bae85d97d1934f03f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eb6TnEH8JWzKrsHTNDVUpw.png"/></div></div></figure><blockquote class="ma mb mc"><p id="e28f" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">它是大多数<strong class="ih hj">多类</strong>分类问题的 go-to 损失函数。</p></blockquote><h2 id="438f" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">2.二元交叉熵</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/f23061bd63ec19464f34849bb3b6a6b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cqtLZVFe14o5xa4cjvTUvg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，c-类</figcaption></figure><p id="421a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点:</strong></p><ul class=""><li id="8622" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">适用于<strong class="ih hj">多标签</strong>问题和二元分类</li></ul><p id="4a93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二元交叉熵的工作方式类似于分类交叉熵。它以指数方式惩罚错误的预测。</p><p id="74e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主要区别在于应用。BCE 主要用于<strong class="ih hj">多标签分类</strong>，其中输入可以属于多个类。最简单的例子就是像<strong class="ih hj">蜘蛛侠</strong>这样的电影，同时被归为动作、冒险、奇幻、科幻类型。</p><p id="2ff4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，让我们建立一个简单的电影/电视剧类型分类器。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mw"><img src="../Images/b50df93d123c9d6640fb0ed27ebf2e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jT89Dlgws7bDjLOhNBu1YA.png"/></div></div></figure><p id="36bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在分类交叉熵之后，BCE 应该非常直观。它们的工作原理相同，但应用不同。</p><h2 id="8e2a" class="kx jv hi bd jw ky kz la ka lb lc ld ke iq le lf ki iu lg lh km iy li lj kq lk bi translated">3.KL-发散损失</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/72d70bf12789e65cdb45b97b48c248cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xqxd0AI1hen93vue0oPN7w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">y-目标，ŷ-预测，c-类</figcaption></figure><blockquote class="ma mb mc"><p id="133f" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">同样，这个想法来自于<strong class="ih hj">信息论</strong>，所以如果你想知道更多，并且用简单的英语得到<strong class="ih hj"> KL </strong>的解释，我强烈推荐这篇<a class="ae jt" href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" rel="noopener ugc nofollow" target="_blank">文章</a>。</p></blockquote><p id="b682" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点</strong>:</p><ul class=""><li id="1085" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">像图像一样近似复杂的目标分布</li></ul><p id="ccfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，KL-divergence 损失是从我们的网络预测的<strong class="ih hj">交叉熵分布</strong>和 <strong class="ih hj">目标分布</strong>的<strong class="ih hj">熵之间的差异。它告诉我们模型离期望的分布有多远。因此，我们用它作为损失函数。</strong></p><p id="0fc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="md">哪里可以用？</em></p><p id="c377" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设您插入来自我们的<strong class="ih hj"> CCE </strong>分类器的值。在这种情况下，输出将是与<strong class="ih hj">相同的</strong>(但计算速度较慢)，因为目标分配仅集中在<strong class="ih hj">期望的</strong>输出上。</p><p id="ff4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是想象一下，如果你要生成一个图像，那么你的目标分布就要复杂得多<strong class="ih hj"/>。这种情况下，<strong class="ih hj"> KL </strong>效果最好。我们在深度生成模型中遇到过它，比如变分自动编码器(<strong class="ih hj"> VAE </strong>)，但不仅限于此。</p><blockquote class="ma mb mc"><p id="9537" class="if ig md ih b ii ij ik il im in io ip me ir is it mf iv iw ix mg iz ja jb jc hb bi translated">我个人第一次听说是在一篇<strong class="ih hj"> Comma.ai </strong> <a class="ae jt" href="https://blog.comma.ai/end-to-end-lateral-planning/" rel="noopener ugc nofollow" target="_blank">的博文</a>里。他们使用<strong class="ih hj"> KL </strong> (🥬 ) loss 在模拟器中训练他们的自动驾驶软件。</p></blockquote><h1 id="8089" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="e2eb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">损失函数是机器学习问题的核心组成部分。他们评估模型的性能并相应地更新权重。在本教程之后，您了解了特定函数的优缺点以及在哪里使用它们！</p><p id="caf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果想看我的其他项目，可以查看我的<a class="ae jt" href="https://maciejbalawejder.medium.com/" rel="noopener"> <strong class="ih hj">中</strong> </a>和<a class="ae jt" href="https://github.com/maciejbalawejder" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">Github</strong></a><strong class="ih hj"/>简介。</p><h1 id="c1d2" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><p id="50eb" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><a class="ae jt" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a>使用循环一致对抗网络的不成对图像到图像翻译</p><p id="4e62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jt" href="https://stats.stackexchange.com/questions/465937/how-to-choose-delta-parameter-in-huber-loss-function" rel="noopener ugc nofollow" target="_blank">【2】</a>Huber 损失函数中 delta 参数如何选择？</p></div></div>    
</body>
</html>