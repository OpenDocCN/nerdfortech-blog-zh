<html>
<head>
<title>Lane detection with OpenCV — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenCV进行车道检测—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/nerd-for-tech/lane-detection-with-opencv-part-1-ad9ea5758c07?source=collection_archive---------5-----------------------#2021-02-14">https://medium.com/nerd-for-tech/lane-detection-with-opencv-part-1-ad9ea5758c07?source=collection_archive---------5-----------------------#2021-02-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="af60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们承认:有些技术只是比其他技术更有趣、更时尚。一个同时在技术上非常有趣并有可能从根本上改变我们生活的领域是与自动驾驶汽车相关的领域。他们来了。在某种程度上，他们已经在这里了。他们正在吸引大量投资。甚至苹果似乎也在考虑制造iCar。简单地说，他们在我们的未来。</p><p id="4ab1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我第一次看到自动驾驶汽车是在2010年。)，在东京，在丰田展厅。你可以作为一名乘客尝试一下，大约1欧元，所以我就这么做了。这辆车开得非常慢，显然它依赖于嵌入道路中的传感器，这辆车似乎能够检测到我前面的车停下来了。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/08a617da4b501f62c6015d51b1d3587a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HSscDDu6AOfwLArJDwpQCg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">一辆丰田自动驾驶汽车在我的自动驾驶汽车前面，(2010年，东京)</figcaption></figure><p id="4002" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">显然，技术已经进步了很多，我们现在可以更多地依赖计算机视觉和先进的传感器，如激光雷达和雷达。实际上，在我居住的挪威奥斯陆，有一辆无人驾驶巴士在行驶，这是试验的一部分；它带着几个人慢慢前进，为了安全，有一个人一直在上面，他们不得不在路上放一些面板来帮助激光雷达探测道路，但这仍然是一个起点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jt"><img src="../Images/394d3efd4d68b220681c38776005b753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUpe8SjJtyJNUBoyTHOH1A.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">挪威奥斯陆的自动驾驶巴士</figcaption></figure><p id="78d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动驾驶汽车的一个经典任务是车道检测，这是本帖的论点。</p><p id="c761" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下内容主要摘自《自动驾驶汽车的实践愿景和行为》一书，这本书是我在Krishtof Korda的帮助下为Packt出版社写的。</p><h1 id="56cc" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">阈值处理</h1><p id="65be" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated"><em class="ky">代码需要Python 3.7，OpenCV和NumPy。</em></p><p id="155c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于人类来说，沿着一条车道走是很容易的，但是对于计算机来说，这就不那么简单了。一个问题是道路的图像有太多的信息。我们需要简化它，只选择图像中我们感兴趣的部分。我们将只分析图像中带有车道的部分，但是我们还需要将车道从图像的其余部分中分离出来，例如，使用颜色选择。毕竟，道路通常是黑色或深色的，车道通常是白色或黄色的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kz"><img src="../Images/cbff69fbc41065a6c234de8efd1421a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cf1kO5EZWCOufds_7rFvOA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参考图片，来自极速之梦</figcaption></figure><p id="de66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，图像可以分解成三个通道:红色、绿色和蓝色。我们知道，OpenCV将图像存储为BGR(意思是，第一个字节是蓝色通道，而不是红色通道)，但从概念上来说，没有区别。<br/>这是曾经分开的三个频道:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es la"><img src="../Images/bf40bfe037743cd2701b2860302d65b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2P5H9ILx6aswUE5yFJlRxg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">BGR通道:蓝色、绿色和红色通道</figcaption></figure><p id="60b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们看起来都很好。我们可以尝试通过选择白色像素来分离车道。由于白色是(255，255，255)，我们可以留出一些空白，并选择180度以上的颜色。要执行此操作，我们需要创建一个与所选通道大小相同的黑色图像，然后将原始通道中180°以上的所有像素涂成白色:</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="ba0a" class="lg jw hi lc b fi lh li l lj lk">img_threshold = np.zeros_like(channel)<br/>img_threshold [(channel &gt;= 180)] = 255</span></pre><p id="e443" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/b95ad3c75d77e2a2761a9ffaadaa5ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxDhOsTnWKXYE585KepHNw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">BGR通道:蓝色、绿色和红色通道，阈值高于180</figcaption></figure><p id="3b06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有其他颜色空间(在书中解释)你可以尝试，如HLS，HSV，实验室和YCbCr。<br/>经过一些实验，绿色通道似乎可以用于边缘检测，而来自HLS空间的L通道可以用作额外的阈值处理，因此我们将坚持使用这些通道。这些设置对于黄线来说应该也是可以的，而不同的颜色可能需要不同的阈值。</p><h1 id="d902" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">透视校正</h1><p id="2a00" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">让我们退一步，从简单的开始。最简单的例子就是直道。让我们看看它是什么样子的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lm"><img src="../Images/23260d22aa9790e9230efd369dd9dc10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsCwYWDQhflbnwXoJAxIcw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">直道，来自速度之梦</figcaption></figure><p id="b83c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们在公路上空飞行，从鸟瞰的角度来看，车道应该是平行的，但在图片中，由于视角的原因，它们不是平行的。<br/>透视取决于镜头的焦距(焦距越短的镜头显示的透视感越强)和相机的位置。一旦相机安装在汽车上，视角是固定的，因此我们可以考虑并校正图像。<br/> OpenCV有一个计算透视变换的方法:<br/><em class="ky">getperspective transform()</em>。<br/>它需要两个参数，都是四个点的数组，标识透视的梯形。一个数组是源，一个数组是目的。这意味着可以使用相同的方法来计算逆变换，只需交换参数:</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="9119" class="lg jw hi lc b fi lh li l lj lk">perspective_correction = cv2.getPerspectiveTransform(src, dst)<br/>perspective_correction_inv = cv2.getPerspectiveTransform(dst,<br/>src)</span></pre><p id="fd8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要选择车道周围的区域，加上一个小的余量:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/f76cc0cfac6cf169182765ea2d4fb73e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LY1xE5oudVePhlgNJ2d2mg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">车道周围有感兴趣区域的梯形</figcaption></figure><p id="2b6f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，目的地是一个矩形(因为我们想把它弄直)。图3.14显示了带有原始透视图的绿色梯形(前面代码中的src变量)和白色矩形(前面代码中的dst变量)，这是所需的透视图。请注意，为了清楚起见，它们被绘制为重叠的，但是作为参数传递的矩形的坐标被移动，就好像它从X坐标0开始。<br/>我们现在可以应用透视校正，并获得我们的鸟瞰图:</p><pre class="je jf jg jh fd lb lc ld le aw lf bi"><span id="bec0" class="lg jw hi lc b fi lh li l lj lk">cv2.warpPerspective(img, perspective_correction, warp_size,<br/>flags=cv2.INTER_LANCZOS4)</span></pre><p id="5160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ky"> warpPerspective() </em>方法接受四个参数:<br/>源图像。<br/>转换矩阵，从<em class="ky"> getPerspectiveTransform()获得。</em> <br/>输出图像的大小。在我们的例子中，宽度与原始图像相同，但是高度只是梯形/矩形的高度。<br/>一些标志，用于指定插值。<strong class="ih hj"> INTER_LINEAR </strong>是一个常见的选择，但我建议尝试一下，并尝试一下<strong class="ih hj"> INTER_LANCZOS4 </strong>。<br/>这是使用<strong class="ih hj"> INTER_LINEAR </strong>扭曲的结果:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/74048f5e83837318e1513ceb99ba3e5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gBDd6_eTRA-se8TBchQv5w.jpeg"/></div></div></figure><p id="174f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是使用<strong class="ih hj"> INTER_LANCZOS4 </strong>的结果:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/4c72ae20b88dc0a4f5ac421df06708ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rWDrtgGagZEdsS97n53tZA.png"/></div></div></figure><p id="951d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它们非常相似，但仔细观察会发现，使用LANCZOS4重采样执行的插值更清晰。我们将在后面看到，在管道的末端，差异是显著的。<br/>在两幅图像中可以清楚地看到，我们的线条现在是垂直的，这可以直观地帮助我们。</p><p id="8b44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下一部分，我们将看到如何利用这个图像。</p></div></div>    
</body>
</html>